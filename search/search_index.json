{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"BES Playbook These chapters are intended to support development and modernization efforts within the BES AFLCMC/HIA Logistic Division as it transforms its methodologies to procure, develop and implement specialized IT products using current best practices.","title":"Home"},{"location":"#bes-playbook","text":"These chapters are intended to support development and modernization efforts within the BES AFLCMC/HIA Logistic Division as it transforms its methodologies to procure, develop and implement specialized IT products using current best practices.","title":"BES Playbook"},{"location":"search/","text":"BES Playbook Search No content is added from this page. See search.html template in bes-theme.","title":"BES Playbook Search"},{"location":"search/#bes-playbook-search","text":"No content is added from this page. See search.html template in bes-theme.","title":"BES Playbook Search"},{"location":"acquisitions/1-1-acquisitions/","text":"Agile Acquisitions","title":"1. Overview"},{"location":"acquisitions/1-1-acquisitions/#agile-acquisitions","text":"","title":"Agile Acquisitions"},{"location":"agile/1-1-purpose/","text":"1.1 Purpose Agile Playbook Benefits Consistent use of BEST practices and templates Establishes AF Agile Body of Knowledge - continually improved by AF community Provides \"Quick Start\" for new programs adopting agile working within AF Provides non-technical professionals with an understanding of how to use agile Builds confidence and effective communications across Government-Industry team Identifies and reduces or eliminates barriers Transforms culture from one focused on traditional processes to one focused on timely customer capability delivery.","title":"1.1 Purpose"},{"location":"agile/1-1-purpose/#11-purpose","text":"","title":"1.1 Purpose"},{"location":"agile/1-1-purpose/#agile-playbook-benefits","text":"Consistent use of BEST practices and templates Establishes AF Agile Body of Knowledge - continually improved by AF community Provides \"Quick Start\" for new programs adopting agile working within AF Provides non-technical professionals with an understanding of how to use agile Builds confidence and effective communications across Government-Industry team Identifies and reduces or eliminates barriers Transforms culture from one focused on traditional processes to one focused on timely customer capability delivery.","title":"Agile Playbook Benefits"},{"location":"agile/1-2-audience/","text":"1.2 Audience While this Agile Playbook provides value to all personnel involved in a new agile project startup, the primary audience for this document is government project management teams determining how to enable an agile development environment. From that perspective, the Agile Playbook seeks to enable the government team for a startup or in-progress project to gain a better understanding of the steps necessary to proactively establish the regulatory and process guidelines that are conducive to an agile approach. To do this, the agile playbook will focus primarily on providing a better understanding of the following areas and how they enable the success of an agile project: Contracts Resources Communications","title":"1.2 Audience"},{"location":"agile/1-2-audience/#12-audience","text":"While this Agile Playbook provides value to all personnel involved in a new agile project startup, the primary audience for this document is government project management teams determining how to enable an agile development environment. From that perspective, the Agile Playbook seeks to enable the government team for a startup or in-progress project to gain a better understanding of the steps necessary to proactively establish the regulatory and process guidelines that are conducive to an agile approach. To do this, the agile playbook will focus primarily on providing a better understanding of the following areas and how they enable the success of an agile project: Contracts Resources Communications","title":"1.2 Audience"},{"location":"agile/1-3-references/","text":"1.1 References DoDI 5000.75, Business Systems Requirements and Acquisition, Feb 2, 2017 US Air Force Enterprise Logistics Flight Plan v2.0 (ELFP), April 2016 Enterprise Logistics Technology Annex v1.0 (ELFP), June 2016 AFGM2018-63-146-01 Rapid Acquisition Activities 13 June 2018 AFMAN 63-144 Business Capability Requirements, Compliance, and System Acquisition 25 July 2018 AFPAM 63-123 Product Support Business Case Analysis 1 July 2017","title":"1.3 References"},{"location":"agile/1-3-references/#11-references","text":"DoDI 5000.75, Business Systems Requirements and Acquisition, Feb 2, 2017 US Air Force Enterprise Logistics Flight Plan v2.0 (ELFP), April 2016 Enterprise Logistics Technology Annex v1.0 (ELFP), June 2016 AFGM2018-63-146-01 Rapid Acquisition Activities 13 June 2018 AFMAN 63-144 Business Capability Requirements, Compliance, and System Acquisition 25 July 2018 AFPAM 63-123 Product Support Business Case Analysis 1 July 2017","title":"1.1 References"},{"location":"agile/10-1-appendix-e/","text":"10.1 GLOSSARY","title":"10.1 Glossary"},{"location":"agile/10-1-appendix-e/#101-glossary","text":"","title":"10.1 GLOSSARY"},{"location":"agile/11-1-appendix-f/","text":"11.1 CDRLs","title":"11.1 CDRLS"},{"location":"agile/11-1-appendix-f/#111-cdrls","text":"","title":"11.1 CDRLs"},{"location":"agile/2-1-waterfall/","text":"2.1 Waterfall background (where is the reader coming from) It is challenging to use agile methods in the DoD and AF because the workforce has been trained in and has practiced the traditional waterfall methodology for 50+ years. In many ways, the waterfall methodology was implemented as a way to carefully control risk along the development path and accommodate the often stove piped organizations that supported development efforts. This means that the processes, procedures, acquisition rules, contracting approaches, testing requirements, and so on are all based on the traditional waterfall method.","title":"2.1 Waterfall Background"},{"location":"agile/2-1-waterfall/#21-waterfall-background-where-is-the-reader-coming-from","text":"It is challenging to use agile methods in the DoD and AF because the workforce has been trained in and has practiced the traditional waterfall methodology for 50+ years. In many ways, the waterfall methodology was implemented as a way to carefully control risk along the development path and accommodate the often stove piped organizations that supported development efforts. This means that the processes, procedures, acquisition rules, contracting approaches, testing requirements, and so on are all based on the traditional waterfall method.","title":"2.1 Waterfall background (where is the reader coming from)"},{"location":"agile/2-2-introduction/","text":"2.2 Agile Introduction 2.2.1 4 Agile Values The Agile Manifesto describes the overarching beliefs of Agile software development as follows (http://agilemanifesto.org): We are uncovering better ways of developing software by doing it and helping others do it. Through this work we have come to value: That is, while there is value in the items on the right, we value the items on the left more. 2.2.2 Benefits of Agile over Traditional Methods Higher quality product (incremental development, continuous integration and automated testing tools allow developers to fix issues quicker when they are fresh in their mind and have fewer secondary effects on code built on top of a bug). Ability to change dynamically to customer/user wants, needs, and/or requirements (value adaptation based on increased transparency, formal feedback events, and high degree of customer collaboration). Ability to balance workloads based on cross-functional teams (while team members often have areas of expertise, agile emphasizes cross-functionality which allows flexibility to surge resources as necessary). Decreases and eventually eliminates the \"throw over the wall\" approach, thereby allowing development, operations, and security to work together iteratively to swarm on a particular issue or bug, should one come up, during releases to lower environments (this decreases the risk of failures in production if all environments are aligned and mirrored-appropriately). Shorter implementation time to usable product (provides quicker return on investment, decreased risk of project failure, faster end-user feedback into the development cycle and increased customer satisfaction). Ability to balance technical debt and new functionality, thereby decreasing technical debt over time. 2.2.3 High-Level Differences 2.2.4 Friction Points with Waterfall Lack of Ownership - The traditional regulatory environment is based on establishment of fixed requirements, letting the external development team develop the product and then inspecting and validating the product to see if it meets the requirements (tennis match of throwing things back and forth between customers and developers with the assumption that both parties understand the requirements in the same way). -- Recommended Mitigation : The key to any agile methodology is collaboration. A dedicated PO (PO) (can be a government employee or contractor on the business level or on the technical team) with decision making authority or immediate reach-back for those decisions is necessary to support the velocity of agile methodologies in being able to provide value in an ever-changing environment. Lack of Collaboration - Traditional design reviews (Preliminary Design Review / Critical Design Review) currently focus on developers presenting their design results at a fixed point of time after exhaustive analysis. -- Recommended Mitigation : What is needed is mini-collaborative design reviews that are done in such a way that integration elements are identified early enough while allowing additional design elements to be refined as close to the work being done as necessary (based on changes happening constantly - re-work will be generated on designs which are done too early and no longer apply to the current situation). Traditional CDRL formats - The traditional government waterfall process intentionally incurs oversight costs as a risk mitigation strategy to ensure that progress was made by contracted agents. In terms of documentations, the government includes in their Contract Deliverable Requirements List (CDRL) a list of documents which are formatted and generated based on a waterfall development framework. The reviewers of these documents are familiar with what the old contents were, and when reviewing delivered documents expect the same waterfall content which are focused on large immovable designs versus less-detailed more agile enabling designs. -- Recommended Mitigation : Contracts need to be modified up front so that only the necessary CDRLs that provide actual value are included and document deliveries are based on an agile timeline (smaller iterative updates versus large updates for significant milestones). (NOTE: While adequate documentation is necessary - the definition of \"adequate\" needs to be modified to provide timely value as determined by the document owners). See recommended CDRL considerations attachment in Section 3.5. Team and team member performance - Agile is based on team dynamics which take time to coalesce (normally that means there is a start-up period where less physical value is produced in the short-term while establishing the foundation to more rapidly produce value in the long-term). This means that by the straight-line value metrics of traditional project management, the project will appear behind at first. The normal strategy here is to provide more \"waterfall\" elements into the equation to try and \"catch-up\" the project which actually impedes / restricts the capabilities of the team to add value. Then in the end if the blame is placed on the agile system versus on the waterfall regulatory restrictions that were placed on it in order to \"catch it up\". -- Recommended Mitigation : Establish trust and transparency (see Communication Management section) as the team learns together how to implement an agile-based process which is understood and accepted by the government and development team. Include more formalized process to \"ramp up\" new government and contractor team members and their understanding of the system and environments. Uncontrolled change/scope creep versus managed change to provide increased value. Waterfall methodologies focus on a formal change management process in order to manage scope creep. Agile is inherently flexible in nature - it welcomes change based on the need to provide value to an ever-changing reality versus provide the value determined during a snapshot in time planning event which could have taken place months or years previously. However, the issue with agile is this inherent flexibility leads to general requirements which allow for the customer to revise in an ad hoc manner which facilitates uncontrolled scope creep (which is okay unless there is a hard deadline in providing the product based on the initial general requirements). -- Recommended Mitigation : Establish a flexible change management system (this will be based on the amount of trust established by the team). It should be flexible enough to rapidly adapt to the changing reality of what the definition of value is within existing requirements while implementing formal steps to manage scope creep (an example is adding a new requirement / feature versus revising an existing one). Earned value reporting - EV is an attempt to monitor the progress of a project by linking contract to cost to contents - these fixed linkages established at the beginning of the contract are normally difficult to change as the work adapts to reality (I.e. we already reported these features and their value to our superiors and it is too hard to revise - so we would rather use the logic we reported instead of revising that logic to fit reality). This often causes a disconnect between the development team and the contracting team as the metrics based on past logic which EV is measuring does not reflect the evolved reality existing in the agile development environment. -- Recommended Mitigation : Link earned value costs to features (can be based on high-level estimates done during feature driven planning. Conduct final feature refinement (work / story breakdown) as close to the actual development effort as possible (as an example for Scrum - conduct feature refinement 2 sprints out to better reflect reality. Base the EV metrics on the percentage of the features decomposed work items / user stories completed. External testing requirements - external test organizations (including those involved with Development Testing and Evaluation (DT&E), Quality Testing and Evaluation (QT&E), etc) often require advanced information for their test events (examples include the release contents, developers test plan, test cases, conditions, etc. Sometimes up to 270 days prior to a test event). Also, these test events are scheduled at fixed milestones versus being iterative in nature. These two items constrain the flexibility of agile to both react to evolving requirements as well as receive timely feedback from testers to incorporate in current development efforts (waiting until the contents of 6 sprints are released before receiving any feedback on their results - see Extreme Programming (XP) Test Driven Development section for possible practices). -- Recommended Mitigation : External testers need to be integrated into the government / development team to derive the evolution of the requirements in preparation for their external testing. An additional step is to establish an iterative external testing cycle which coincides with the agile framework battle rhythm (rather than conduct annual large testing events). Pure agile theorists - unable to allow for regulatory requirements because they are \"not agile\". One of the final and most difficult problems is not the transition from waterfall to agile of the government, but the inability of agile implementers to allow for the regulatory requirements mandated by the government. Just as a waterfall purist will blame agile for all difficulties encountered, the agile purist will blame all issues on the waterfall regulations imposed. -- Recommended Mitigation : What is necessary is to find the correct hybrid framework between the two extremes that allow the process to work in the most efficient manner possible and also allows buy-in from all team members (the transition from a strictly waterfall to an appropriate hybrid framework may also be iterative in nature).","title":"2.2 Introduction"},{"location":"agile/2-2-introduction/#22-agile-introduction","text":"","title":"2.2 Agile Introduction"},{"location":"agile/2-2-introduction/#221-4-agile-values","text":"The Agile Manifesto describes the overarching beliefs of Agile software development as follows (http://agilemanifesto.org): We are uncovering better ways of developing software by doing it and helping others do it. Through this work we have come to value: That is, while there is value in the items on the right, we value the items on the left more.","title":"2.2.1 4 Agile Values"},{"location":"agile/2-2-introduction/#222-benefits-of-agile-over-traditional-methods","text":"Higher quality product (incremental development, continuous integration and automated testing tools allow developers to fix issues quicker when they are fresh in their mind and have fewer secondary effects on code built on top of a bug). Ability to change dynamically to customer/user wants, needs, and/or requirements (value adaptation based on increased transparency, formal feedback events, and high degree of customer collaboration). Ability to balance workloads based on cross-functional teams (while team members often have areas of expertise, agile emphasizes cross-functionality which allows flexibility to surge resources as necessary). Decreases and eventually eliminates the \"throw over the wall\" approach, thereby allowing development, operations, and security to work together iteratively to swarm on a particular issue or bug, should one come up, during releases to lower environments (this decreases the risk of failures in production if all environments are aligned and mirrored-appropriately). Shorter implementation time to usable product (provides quicker return on investment, decreased risk of project failure, faster end-user feedback into the development cycle and increased customer satisfaction). Ability to balance technical debt and new functionality, thereby decreasing technical debt over time.","title":"2.2.2 Benefits of Agile over Traditional Methods"},{"location":"agile/2-2-introduction/#223-high-level-differences","text":"","title":"2.2.3 High-Level Differences"},{"location":"agile/2-2-introduction/#224-friction-points-with-waterfall","text":"Lack of Ownership - The traditional regulatory environment is based on establishment of fixed requirements, letting the external development team develop the product and then inspecting and validating the product to see if it meets the requirements (tennis match of throwing things back and forth between customers and developers with the assumption that both parties understand the requirements in the same way). -- Recommended Mitigation : The key to any agile methodology is collaboration. A dedicated PO (PO) (can be a government employee or contractor on the business level or on the technical team) with decision making authority or immediate reach-back for those decisions is necessary to support the velocity of agile methodologies in being able to provide value in an ever-changing environment. Lack of Collaboration - Traditional design reviews (Preliminary Design Review / Critical Design Review) currently focus on developers presenting their design results at a fixed point of time after exhaustive analysis. -- Recommended Mitigation : What is needed is mini-collaborative design reviews that are done in such a way that integration elements are identified early enough while allowing additional design elements to be refined as close to the work being done as necessary (based on changes happening constantly - re-work will be generated on designs which are done too early and no longer apply to the current situation). Traditional CDRL formats - The traditional government waterfall process intentionally incurs oversight costs as a risk mitigation strategy to ensure that progress was made by contracted agents. In terms of documentations, the government includes in their Contract Deliverable Requirements List (CDRL) a list of documents which are formatted and generated based on a waterfall development framework. The reviewers of these documents are familiar with what the old contents were, and when reviewing delivered documents expect the same waterfall content which are focused on large immovable designs versus less-detailed more agile enabling designs. -- Recommended Mitigation : Contracts need to be modified up front so that only the necessary CDRLs that provide actual value are included and document deliveries are based on an agile timeline (smaller iterative updates versus large updates for significant milestones). (NOTE: While adequate documentation is necessary - the definition of \"adequate\" needs to be modified to provide timely value as determined by the document owners). See recommended CDRL considerations attachment in Section 3.5. Team and team member performance - Agile is based on team dynamics which take time to coalesce (normally that means there is a start-up period where less physical value is produced in the short-term while establishing the foundation to more rapidly produce value in the long-term). This means that by the straight-line value metrics of traditional project management, the project will appear behind at first. The normal strategy here is to provide more \"waterfall\" elements into the equation to try and \"catch-up\" the project which actually impedes / restricts the capabilities of the team to add value. Then in the end if the blame is placed on the agile system versus on the waterfall regulatory restrictions that were placed on it in order to \"catch it up\". -- Recommended Mitigation : Establish trust and transparency (see Communication Management section) as the team learns together how to implement an agile-based process which is understood and accepted by the government and development team. Include more formalized process to \"ramp up\" new government and contractor team members and their understanding of the system and environments. Uncontrolled change/scope creep versus managed change to provide increased value. Waterfall methodologies focus on a formal change management process in order to manage scope creep. Agile is inherently flexible in nature - it welcomes change based on the need to provide value to an ever-changing reality versus provide the value determined during a snapshot in time planning event which could have taken place months or years previously. However, the issue with agile is this inherent flexibility leads to general requirements which allow for the customer to revise in an ad hoc manner which facilitates uncontrolled scope creep (which is okay unless there is a hard deadline in providing the product based on the initial general requirements). -- Recommended Mitigation : Establish a flexible change management system (this will be based on the amount of trust established by the team). It should be flexible enough to rapidly adapt to the changing reality of what the definition of value is within existing requirements while implementing formal steps to manage scope creep (an example is adding a new requirement / feature versus revising an existing one). Earned value reporting - EV is an attempt to monitor the progress of a project by linking contract to cost to contents - these fixed linkages established at the beginning of the contract are normally difficult to change as the work adapts to reality (I.e. we already reported these features and their value to our superiors and it is too hard to revise - so we would rather use the logic we reported instead of revising that logic to fit reality). This often causes a disconnect between the development team and the contracting team as the metrics based on past logic which EV is measuring does not reflect the evolved reality existing in the agile development environment. -- Recommended Mitigation : Link earned value costs to features (can be based on high-level estimates done during feature driven planning. Conduct final feature refinement (work / story breakdown) as close to the actual development effort as possible (as an example for Scrum - conduct feature refinement 2 sprints out to better reflect reality. Base the EV metrics on the percentage of the features decomposed work items / user stories completed. External testing requirements - external test organizations (including those involved with Development Testing and Evaluation (DT&E), Quality Testing and Evaluation (QT&E), etc) often require advanced information for their test events (examples include the release contents, developers test plan, test cases, conditions, etc. Sometimes up to 270 days prior to a test event). Also, these test events are scheduled at fixed milestones versus being iterative in nature. These two items constrain the flexibility of agile to both react to evolving requirements as well as receive timely feedback from testers to incorporate in current development efforts (waiting until the contents of 6 sprints are released before receiving any feedback on their results - see Extreme Programming (XP) Test Driven Development section for possible practices). -- Recommended Mitigation : External testers need to be integrated into the government / development team to derive the evolution of the requirements in preparation for their external testing. An additional step is to establish an iterative external testing cycle which coincides with the agile framework battle rhythm (rather than conduct annual large testing events). Pure agile theorists - unable to allow for regulatory requirements because they are \"not agile\". One of the final and most difficult problems is not the transition from waterfall to agile of the government, but the inability of agile implementers to allow for the regulatory requirements mandated by the government. Just as a waterfall purist will blame agile for all difficulties encountered, the agile purist will blame all issues on the waterfall regulations imposed. -- Recommended Mitigation : What is necessary is to find the correct hybrid framework between the two extremes that allow the process to work in the most efficient manner possible and also allows buy-in from all team members (the transition from a strictly waterfall to an appropriate hybrid framework may also be iterative in nature).","title":"2.2.4 Friction Points with Waterfall"},{"location":"agile/2-transformation/","text":"2 Agile Transformation 2.1 Waterfall background (where is the reader coming from) It is challenging to use agile methods in the DoD and AF because the workforce has been trained in and has practiced the traditional waterfall methodology for 50+ years. In many ways, the waterfall methodology was implemented as a way to carefully control risk along the development path and accommodate the often stove piped organizations that supported development efforts. This means that the processes, procedures, acquisition rules, contracting approaches, testing requirements, and so on are all based on the traditional waterfall method.","title":"2 transformation"},{"location":"agile/2-transformation/#2-agile-transformation","text":"","title":"2 Agile Transformation"},{"location":"agile/2-transformation/#21-waterfall-background-where-is-the-reader-coming-from","text":"It is challenging to use agile methods in the DoD and AF because the workforce has been trained in and has practiced the traditional waterfall methodology for 50+ years. In many ways, the waterfall methodology was implemented as a way to carefully control risk along the development path and accommodate the often stove piped organizations that supported development efforts. This means that the processes, procedures, acquisition rules, contracting approaches, testing requirements, and so on are all based on the traditional waterfall method.","title":"2.1 Waterfall background (where is the reader coming from)"},{"location":"agile/3-0-overview/","text":"3 Applying Agile Methods and Mindset Within The Air Force At the inception of a software-based project, the detailed software requirements may be unknown or unknowable, and even if the requirements are known, they usually experience significant changes as the development progresses. To address these evolving requirements issues, agile or iterative development promotes enhanced collaboration between program managers, requirements analysts, testers, the end-user community, and, of course, the software developers. This approach develops software iteratively in short cycles (called \"sprints,\" \"spirals,\" or \"spins\"), and involves frequent testing, user feedback, rapid deliveries, and adaptation to changing requirements. While traditional Waterfall software development was approached via rigorous preplanning to fully specify requirements before building an entire computer program application, Agile software development breaks the project down to provide iterative improvements which also adapt to the evolving environment. This allows government Program Managers to incorporate changed or new requirements in accordance with user needs, thus promoting modular IT contracting. This section focuses on how to incorporate Agile practices into the Air Force acquisition organizations, contracting and the PMO organizations to pro-actively enable an Agile development framework rather than have the framework adapt to a pre-defined waterfall based contracting approach. As this section is predominantly focused on the mindset shift, it will focus on presenting considerations versus prescribing a specific methodology.","title":"3.0 Overview"},{"location":"agile/3-0-overview/#3-applying-agile-methods-and-mindset-within-the-air-force","text":"At the inception of a software-based project, the detailed software requirements may be unknown or unknowable, and even if the requirements are known, they usually experience significant changes as the development progresses. To address these evolving requirements issues, agile or iterative development promotes enhanced collaboration between program managers, requirements analysts, testers, the end-user community, and, of course, the software developers. This approach develops software iteratively in short cycles (called \"sprints,\" \"spirals,\" or \"spins\"), and involves frequent testing, user feedback, rapid deliveries, and adaptation to changing requirements. While traditional Waterfall software development was approached via rigorous preplanning to fully specify requirements before building an entire computer program application, Agile software development breaks the project down to provide iterative improvements which also adapt to the evolving environment. This allows government Program Managers to incorporate changed or new requirements in accordance with user needs, thus promoting modular IT contracting. This section focuses on how to incorporate Agile practices into the Air Force acquisition organizations, contracting and the PMO organizations to pro-actively enable an Agile development framework rather than have the framework adapt to a pre-defined waterfall based contracting approach. As this section is predominantly focused on the mindset shift, it will focus on presenting considerations versus prescribing a specific methodology.","title":"3 Applying Agile Methods and Mindset Within The Air Force"},{"location":"agile/3-1-contracting/","text":"3.1 Agile Contracting Before jumping into the Agile development, PMOs should take time to consider how Agile can benefit their program, what the issues will be, and if perhaps a hybrid approach (combination of Waterfall and Agile) is the best approach. Some of the concepts that need to be considered when embarking on the use of Agile are discussed below. The discussion assumes the government will be contracting with a firm to actually do the development. Since the contractor will be creating the Agile organization structure, it is important the government understands the contractors' Agile organization and how the government interacts within that structure. The better the understanding, the less likely there will be inadvertent roadblocks or obstacles created to impede the progress of the Agile team(s). If the government is doing the development internally, some of the actions may differ and would be accomplished by the government. The following establish some of the key variables which must be considered in the context of enabling an Agile development framework. Acquisition life cycle Team environment End-user access Training and coaching Oversight including milestone reviews, documentation, evaluation (metrics) Rewards and incentives Culture These concepts were actual issues that programs deal with during their use of Agile methods. The concepts discussed here overlap and are intertwined. In many cases, the concepts are mutually reinforcing. 3.1.1 Acquisition Life Cycle The acquisition life cycle consists of multiple phases: Materiel Solution Analysis, Technology Development, Engineering and Manufacturing Development, Production & Deployment and Operations & Support. Each of these phases presents unique challenges and opportunities. Some phases lend themselves to the use of Agile better than others. The PMO should determine how to best employ Agile in their program depending on their specific situation. The following paragraphs propose questions to ask and identify issues to consider in building an Agile program. If the PMO is doing a Request for Proposal (RFP), no matter which phase, ensure that the RFP contains language that allows the use of Agile. In many instances, the traditional RFP language makes it difficult, if not impossible, to propose an Agile-based solution. One consideration is the types of reviews and documents required. If the PMO wants to employ Agile, be prepared to allow for Agile style document development, i.e., incremental development of documents and data for reviews that result from the individual iterations and/or releases. This might not seem much different from what the traditional waterfall methods provide but consider the level of detail may be sparser using Agile in the earlier versions of the documents. Even final documents might not contain the amount of detail provided in traditional documents. The key here is not the volume, but the content. A necessary and sufficient criterion is that all important information required for operation and maintenance of the system are supplied. 3.1.2 Team Environment Due to the size and complexity of most Air force programs, multiple agile iteration teams will be needed. The number is dependent upon the program and in some instances the locations of the contractor team. The larger the number of teams, the more complicated the communications and the greater the need for more users to be involved. In an ideal situation, each agile iteration team would have access to their own dedicated Product Owner. However, that is not practical in the DoD environment so alternatives need to be employed. PMO can consider the use of Product Owner proxies, rotating personnel every x weeks (x usually is two-four weeks), or perhaps a separate - team of subject matter experts (SMEs) accessible by the agile iteration teams as needed. The structure of the overall program team-especially the contractor team-is dependent upon which Agile method is chosen. Agile Scrum, Kanban and XP are just three examples of management practices within Agile methods. Typically, the contractor determines the flavor of Agile. However, the government PMO team needs to be responsive and supportive of that method. Otherwise, using Agile will have less than optimal results. The Agile team also must exhibit behavior reflecting the approach. Seven Extreme Programming (XP) engineering practices have been observed to scale up to enterprise-level Agile development projects and will serve as a foundation for the discussion of Agile contractin The Define/Build/Test Component. Three basic workflows are combined in the component team: define, build, and test, operating cooperatively within a pre-defined period, known as a time box. The juxtaposition of these skill sets into one team tends to run counter to some conventional methods employed in DoD programs, where these players are often separated by intent. Two-Level Planning. Two-level planning is portrayed as providing both guidance of how software is to be inserted into the operational environment as well as allowing some flexibility to accommodate what is learned during development: The top level of the planning cycle is termed release level planning. This cycle of planning defines series of releases that broadly define capability to be contained in each release. This could be done at the feature set level. The second level of the planning cycle is termed iteration or flow level planning, where work is made ready for development within either a time-boxed iteration or rhythmic workflow approach. Mastering the flow / Iteration. The ability of a team to reliably execute a process flow (Kanban) or sequence of iterations (Scrum / XP) may well be the key behavior that distinguishes a team capable of exploiting Agile techniques in a large organization. If this capability is not present, the likelihood of success is minimal at best. The development iteration or workflow consists of the following key activities: creation of complete, tested, working code implementing a set of features and integration of the developed code into the working baseline. The result is potentially releasable to the user. Producing Smaller and More Frequent Releases. One goal of an agile development framework is the desire for more frequent feedback from the customer and/or stakeholders to avoid large-scale course corrections. The shorter duration of iterations or workflow lead time will help to maintain more or less continuous feedback from the customer. Concurrent Testing. Concurrent testing practices are based upon thorough testing of code both during development and during integration. The goal is that all code is tested. One primary methodology for this is the application of a Test-Driven-Development Approach where the unit tests for software are created prior to the actual code development. DevOps Continuous Integration (CI)/Continuous Delivery (CD) Pipelines. DevOps CI/CD pipelines may well be the most useful and controversial practice advocated in the Agile community. The DevOps CI/CD model diverges from the usual V-shaped model advocated by traditional systems engineering practice employed in DoD programs. In the V-shaped model, requirements synthesis, allocation, and development are carried out in a top-down fashion. This is followed by a bottom-up sequence of integration and verification activities, leading to a product ready for production. DevOps CI/CD pipeline processes are contingent upon the ability to concurrently execute two crucial activities: (1) collect incremental changes from multiple developers on a regular basis, ideally on a daily basis on code check-in, and (2) perform the nightly build discipline, where all changes are brought together in an incremental software baseline, which is in turn compiled and tested with the available automated unit, security, functional and regression test tools. Regular Reflection and Adaptation. Reflection and adaptation (called the Retrospective in Scrum) is the Agile version of continuous process improvement that is highlighted in other quality practices such as CMMI-DEV processes. In keeping with the bottom-up discipline of Agile approaches, this introspection is driven down to the individual team level. 3.1.3 Contracting Consideration Checklist Procure the repeatable process for the delivery of functional products Contractual Requirements should be the scope, period of performance, and price. The technical execution of the project should be at the discretion of the Product Owner Enhancement and fixes should be owned by the same team Contract Types: Fixed Price per iteration is good for the procurement of the process for an entire team but the current DoD acquisition process does not support short-term contract changes Time and Materials is ideal for the procurement of time of required skill sets but the risk is entirely on the government A preferred type which enables agile development is a \"Rent the Factory\" type contract: Establish contract to resource (\"rent\") a team for a specified time period from a contractor Control change through PMO management of the Product Backlog Implement within contract incremental options for extension to decrease government risk (off-ramp for lack of performance) Provide reward incentives for excellence in performance","title":"3.1 Agile Contracting"},{"location":"agile/3-1-contracting/#31-agile-contracting","text":"Before jumping into the Agile development, PMOs should take time to consider how Agile can benefit their program, what the issues will be, and if perhaps a hybrid approach (combination of Waterfall and Agile) is the best approach. Some of the concepts that need to be considered when embarking on the use of Agile are discussed below. The discussion assumes the government will be contracting with a firm to actually do the development. Since the contractor will be creating the Agile organization structure, it is important the government understands the contractors' Agile organization and how the government interacts within that structure. The better the understanding, the less likely there will be inadvertent roadblocks or obstacles created to impede the progress of the Agile team(s). If the government is doing the development internally, some of the actions may differ and would be accomplished by the government. The following establish some of the key variables which must be considered in the context of enabling an Agile development framework. Acquisition life cycle Team environment End-user access Training and coaching Oversight including milestone reviews, documentation, evaluation (metrics) Rewards and incentives Culture These concepts were actual issues that programs deal with during their use of Agile methods. The concepts discussed here overlap and are intertwined. In many cases, the concepts are mutually reinforcing.","title":"3.1 Agile Contracting"},{"location":"agile/3-1-contracting/#311-acquisition-life-cycle","text":"The acquisition life cycle consists of multiple phases: Materiel Solution Analysis, Technology Development, Engineering and Manufacturing Development, Production & Deployment and Operations & Support. Each of these phases presents unique challenges and opportunities. Some phases lend themselves to the use of Agile better than others. The PMO should determine how to best employ Agile in their program depending on their specific situation. The following paragraphs propose questions to ask and identify issues to consider in building an Agile program. If the PMO is doing a Request for Proposal (RFP), no matter which phase, ensure that the RFP contains language that allows the use of Agile. In many instances, the traditional RFP language makes it difficult, if not impossible, to propose an Agile-based solution. One consideration is the types of reviews and documents required. If the PMO wants to employ Agile, be prepared to allow for Agile style document development, i.e., incremental development of documents and data for reviews that result from the individual iterations and/or releases. This might not seem much different from what the traditional waterfall methods provide but consider the level of detail may be sparser using Agile in the earlier versions of the documents. Even final documents might not contain the amount of detail provided in traditional documents. The key here is not the volume, but the content. A necessary and sufficient criterion is that all important information required for operation and maintenance of the system are supplied.","title":"3.1.1 Acquisition Life Cycle"},{"location":"agile/3-1-contracting/#312-team-environment","text":"Due to the size and complexity of most Air force programs, multiple agile iteration teams will be needed. The number is dependent upon the program and in some instances the locations of the contractor team. The larger the number of teams, the more complicated the communications and the greater the need for more users to be involved. In an ideal situation, each agile iteration team would have access to their own dedicated Product Owner. However, that is not practical in the DoD environment so alternatives need to be employed. PMO can consider the use of Product Owner proxies, rotating personnel every x weeks (x usually is two-four weeks), or perhaps a separate - team of subject matter experts (SMEs) accessible by the agile iteration teams as needed. The structure of the overall program team-especially the contractor team-is dependent upon which Agile method is chosen. Agile Scrum, Kanban and XP are just three examples of management practices within Agile methods. Typically, the contractor determines the flavor of Agile. However, the government PMO team needs to be responsive and supportive of that method. Otherwise, using Agile will have less than optimal results. The Agile team also must exhibit behavior reflecting the approach. Seven Extreme Programming (XP) engineering practices have been observed to scale up to enterprise-level Agile development projects and will serve as a foundation for the discussion of Agile contractin The Define/Build/Test Component. Three basic workflows are combined in the component team: define, build, and test, operating cooperatively within a pre-defined period, known as a time box. The juxtaposition of these skill sets into one team tends to run counter to some conventional methods employed in DoD programs, where these players are often separated by intent. Two-Level Planning. Two-level planning is portrayed as providing both guidance of how software is to be inserted into the operational environment as well as allowing some flexibility to accommodate what is learned during development: The top level of the planning cycle is termed release level planning. This cycle of planning defines series of releases that broadly define capability to be contained in each release. This could be done at the feature set level. The second level of the planning cycle is termed iteration or flow level planning, where work is made ready for development within either a time-boxed iteration or rhythmic workflow approach. Mastering the flow / Iteration. The ability of a team to reliably execute a process flow (Kanban) or sequence of iterations (Scrum / XP) may well be the key behavior that distinguishes a team capable of exploiting Agile techniques in a large organization. If this capability is not present, the likelihood of success is minimal at best. The development iteration or workflow consists of the following key activities: creation of complete, tested, working code implementing a set of features and integration of the developed code into the working baseline. The result is potentially releasable to the user. Producing Smaller and More Frequent Releases. One goal of an agile development framework is the desire for more frequent feedback from the customer and/or stakeholders to avoid large-scale course corrections. The shorter duration of iterations or workflow lead time will help to maintain more or less continuous feedback from the customer. Concurrent Testing. Concurrent testing practices are based upon thorough testing of code both during development and during integration. The goal is that all code is tested. One primary methodology for this is the application of a Test-Driven-Development Approach where the unit tests for software are created prior to the actual code development. DevOps Continuous Integration (CI)/Continuous Delivery (CD) Pipelines. DevOps CI/CD pipelines may well be the most useful and controversial practice advocated in the Agile community. The DevOps CI/CD model diverges from the usual V-shaped model advocated by traditional systems engineering practice employed in DoD programs. In the V-shaped model, requirements synthesis, allocation, and development are carried out in a top-down fashion. This is followed by a bottom-up sequence of integration and verification activities, leading to a product ready for production. DevOps CI/CD pipeline processes are contingent upon the ability to concurrently execute two crucial activities: (1) collect incremental changes from multiple developers on a regular basis, ideally on a daily basis on code check-in, and (2) perform the nightly build discipline, where all changes are brought together in an incremental software baseline, which is in turn compiled and tested with the available automated unit, security, functional and regression test tools. Regular Reflection and Adaptation. Reflection and adaptation (called the Retrospective in Scrum) is the Agile version of continuous process improvement that is highlighted in other quality practices such as CMMI-DEV processes. In keeping with the bottom-up discipline of Agile approaches, this introspection is driven down to the individual team level.","title":"3.1.2 Team Environment"},{"location":"agile/3-1-contracting/#313-contracting-consideration-checklist","text":"Procure the repeatable process for the delivery of functional products Contractual Requirements should be the scope, period of performance, and price. The technical execution of the project should be at the discretion of the Product Owner Enhancement and fixes should be owned by the same team Contract Types: Fixed Price per iteration is good for the procurement of the process for an entire team but the current DoD acquisition process does not support short-term contract changes Time and Materials is ideal for the procurement of time of required skill sets but the risk is entirely on the government A preferred type which enables agile development is a \"Rent the Factory\" type contract: Establish contract to resource (\"rent\") a team for a specified time period from a contractor Control change through PMO management of the Product Backlog Implement within contract incremental options for extension to decrease government risk (off-ramp for lack of performance) Provide reward incentives for excellence in performance","title":"3.1.3 Contracting Consideration Checklist"},{"location":"agile/3-2-stakeholder/","text":"3.2 Agile Organization, Roles, and Responsibilities - Stakeholder Level One addition to the typical traditional Air Force PMO organization is an Agile Coach. As described in the previous training and coaching section, the Agile Coach is someone who can provide real-time answers for the immediate Agile issue. Another addition to the typical PMO staff is an end-user representative, the PO, who is empowered to work with the contractors' agile development team and make decisions that are binding for the development. Given the nature of government contracting, care must be taken to ensure that the PO user representative has the legal authority to direct the contractor. We can envision a situation where constructive change could become an issue. Another addition to the PMO is a DevSecOps Lead who works with the with contractor engineering support teams that may be divided into two segments: Continuous Integration Team and Continuous Delivery/Deployment Team to implement configuration management, version control, automated build, automated security testing, automated functional testing and regression testing. The government needs skilled Agile personnel to review the documentation and understand how the Agile software development approach works. Many traditional PMO teams do not have software representatives experienced with modern software development approaches. That could be more problematic in an Agile environment, where any shortfalls quickly become more visible. Another challenge is keeping high-performing Agile teams together long enough for them to achieve peak performance. This is a challenge because developers can change at the end of a contractual period of performance. The continuity of an Agile team enhances the tacit knowledge of the program and this improves overall performance. One recommendation might be to look at is putting key Agile technical leads into the PMO under a separate contract vehicle or hire them to work for the government PMO organization itself. 3.2.1 Stakeholder Consideration Checklist: Empower the Product Owner to make technical decisions Provide regular feedback to stakeholders demonstrating progress Maintain a short feedback loop with users Align with external organizations Testing Configuration","title":"3.2 Agile Stakeholder"},{"location":"agile/3-2-stakeholder/#32-agile-organization-roles-and-responsibilities-stakeholder-level","text":"One addition to the typical traditional Air Force PMO organization is an Agile Coach. As described in the previous training and coaching section, the Agile Coach is someone who can provide real-time answers for the immediate Agile issue. Another addition to the typical PMO staff is an end-user representative, the PO, who is empowered to work with the contractors' agile development team and make decisions that are binding for the development. Given the nature of government contracting, care must be taken to ensure that the PO user representative has the legal authority to direct the contractor. We can envision a situation where constructive change could become an issue. Another addition to the PMO is a DevSecOps Lead who works with the with contractor engineering support teams that may be divided into two segments: Continuous Integration Team and Continuous Delivery/Deployment Team to implement configuration management, version control, automated build, automated security testing, automated functional testing and regression testing. The government needs skilled Agile personnel to review the documentation and understand how the Agile software development approach works. Many traditional PMO teams do not have software representatives experienced with modern software development approaches. That could be more problematic in an Agile environment, where any shortfalls quickly become more visible. Another challenge is keeping high-performing Agile teams together long enough for them to achieve peak performance. This is a challenge because developers can change at the end of a contractual period of performance. The continuity of an Agile team enhances the tacit knowledge of the program and this improves overall performance. One recommendation might be to look at is putting key Agile technical leads into the PMO under a separate contract vehicle or hire them to work for the government PMO organization itself.","title":"3.2 Agile Organization, Roles, and Responsibilities - Stakeholder Level"},{"location":"agile/3-2-stakeholder/#321-stakeholder-consideration-checklist","text":"Empower the Product Owner to make technical decisions Provide regular feedback to stakeholders demonstrating progress Maintain a short feedback loop with users Align with external organizations Testing Configuration","title":"3.2.1 Stakeholder Consideration Checklist:"},{"location":"agile/3-3-projectmanagement/","text":"3.3 Project Management This section describes how project management practices need to be adjusted in support of Agile projects by first identifying common Agile practices and then describing how these management practices work in terms of scope, schedule and cost baselines for the project work. 3.3.1 Planning An integrated project management plan (PMP) is developed for the Agile project to define the basis of all project work and how the work will be performed. It describes how the project will be executed, monitored, control and closed. From the Agile perspective, the performance measurement baseline is an integrated scope, schedule, and cost baseline for the software release project work maintained in the Product Backlog against which project execution metrics are used to measure and manage performance. The PMP describes the series of phases (themes, initiatives, and epics) the project passes through from initiation to closure. The PMP also describes the Agile development management approach; i.e. Agile iteration-based (Scrum/XP), flow-based (Kanban) or a hybrid model. Figure 1 describes the hierarchal structure of the Agile project work effort. Notice that this view of the project work hierarchy is similar to the WBS in predictive (Waterfall) projects. One additional consideration is that the above hierarchy promotes a multi-team or \"scaled\" agile approach. While methodologies exist to support the scaling of agile (i.e. Scaled Agile Framework (SAFe), Scrum of Scrums, Disciplined Agile Delivery (DAD), etc), these will not be presented in this playbook but are a topic for further elaboration as an organization's agile process matures. 3.3.2 Scope In Agile projects the requirements are defined by the organization's stakeholders and Product Owner with support from the Agile Team in the form of Epics, Features, user stories or PBIs that are maintained in the Product Backlog. Therefore, the project scope for an Agile project begins with the organization's governance process which commonly consists of a Configuration Control Board (CCB) that produces a high-level product backlog for a release consisting of a list of approved requirements defined in the form of epics, features and sometimes high-level PBIs. The product owner then works with the Agile Inception Team to prioritize these items (epics, features, PBIs if applicable). The PMO can initially use the MoSCoW (Must Have, Should Have, Could Have, Won't Have this time) method to prioritize requirements. 3.3.3 Forecasting Schedule and Cost Once the user stories and PBIs in the product backlog are defined, prioritized and the MVP determined, Agile estimating techniques can be applied to estimate the effort for each feature, sum up the effort for all the features in a project as well as determine which features would be part of which release. The PMO and development team are then able to forecast a schedule and cost for the release project. There are several gross-level estimation techniques used by teams using agile approaches such as Scrum, Kanban, and eXtreme Programming which include T-shirt Sizes (for Features), and Affinity Mapping. T-Shirt Sizes . This estimation technique can be applied when providing a quick and rough estimation to a project feature. Here, the features are estimated in T-shirt sizes, ranging from XS to XL, which would be later converted to numbers, as per requirements. In this type of estimation, the estimators assign a size to each of the features. Points are assigned to the each of the T-Shirt Sizes using the Fibonacci-like format: 0, 1, 2, 3, 5, 8, 13, 20, 40, 100. These points are summed up and based on a rough estimate of how many feature points can get done within a time period by a normal agile team (note, the more detailed the refinement, the better the estimates). 3.3.4 Cost The cost for the release is estimated by using the team's iteration average cost and multiplying it by the number of iterations estimated to complete the backlog. For example, the following formula to determine budgeted cost can demonstrate this estimation for the above example: (Team monthly cost (example: $15,000.00 per month) multiplied by the number of months/iterations (example: 5 months) = $75,000.00 + other expenses = forecast budgeted cost. The above example is utterly simplistic and does not take into account the following factors: The Inception phase at the beginning that is required to develop the product backlog, estimate the size in story points and develop an architecture vision; Changes in scope during the Construction iterations caused by adding new features driven by urgent business needs or Cybersecurity issues; A Transition phase at the end of development for Government Acceptance Tests and Security Tests required to achieve customer acceptance and Authority to Operate (AtO) for deployment; Many other variables such as Cloud Migration and implementation of a DevSecOps reference model. 3.3.5 Project Management Consideration Checklist The project manager removes ensures funding, organizes stakeholder interactions and keeps the team from being distracted Work in increments. Buy, build, and fail small. Make proceed and pivot decisions regularly. Learn from mistakes but don't punish the people Leverage the efficiency of commercial contracting methods. If and when possible, use services and tools sold by private sector vendors. Use living roadmaps not fixed Integrated master schedules","title":"3.3 Project Management"},{"location":"agile/3-3-projectmanagement/#33-project-management","text":"This section describes how project management practices need to be adjusted in support of Agile projects by first identifying common Agile practices and then describing how these management practices work in terms of scope, schedule and cost baselines for the project work.","title":"3.3 Project Management"},{"location":"agile/3-3-projectmanagement/#331-planning","text":"An integrated project management plan (PMP) is developed for the Agile project to define the basis of all project work and how the work will be performed. It describes how the project will be executed, monitored, control and closed. From the Agile perspective, the performance measurement baseline is an integrated scope, schedule, and cost baseline for the software release project work maintained in the Product Backlog against which project execution metrics are used to measure and manage performance. The PMP describes the series of phases (themes, initiatives, and epics) the project passes through from initiation to closure. The PMP also describes the Agile development management approach; i.e. Agile iteration-based (Scrum/XP), flow-based (Kanban) or a hybrid model. Figure 1 describes the hierarchal structure of the Agile project work effort. Notice that this view of the project work hierarchy is similar to the WBS in predictive (Waterfall) projects. One additional consideration is that the above hierarchy promotes a multi-team or \"scaled\" agile approach. While methodologies exist to support the scaling of agile (i.e. Scaled Agile Framework (SAFe), Scrum of Scrums, Disciplined Agile Delivery (DAD), etc), these will not be presented in this playbook but are a topic for further elaboration as an organization's agile process matures.","title":"3.3.1 Planning"},{"location":"agile/3-3-projectmanagement/#332-scope","text":"In Agile projects the requirements are defined by the organization's stakeholders and Product Owner with support from the Agile Team in the form of Epics, Features, user stories or PBIs that are maintained in the Product Backlog. Therefore, the project scope for an Agile project begins with the organization's governance process which commonly consists of a Configuration Control Board (CCB) that produces a high-level product backlog for a release consisting of a list of approved requirements defined in the form of epics, features and sometimes high-level PBIs. The product owner then works with the Agile Inception Team to prioritize these items (epics, features, PBIs if applicable). The PMO can initially use the MoSCoW (Must Have, Should Have, Could Have, Won't Have this time) method to prioritize requirements.","title":"3.3.2 Scope"},{"location":"agile/3-3-projectmanagement/#333-forecasting-schedule-and-cost","text":"Once the user stories and PBIs in the product backlog are defined, prioritized and the MVP determined, Agile estimating techniques can be applied to estimate the effort for each feature, sum up the effort for all the features in a project as well as determine which features would be part of which release. The PMO and development team are then able to forecast a schedule and cost for the release project. There are several gross-level estimation techniques used by teams using agile approaches such as Scrum, Kanban, and eXtreme Programming which include T-shirt Sizes (for Features), and Affinity Mapping. T-Shirt Sizes . This estimation technique can be applied when providing a quick and rough estimation to a project feature. Here, the features are estimated in T-shirt sizes, ranging from XS to XL, which would be later converted to numbers, as per requirements. In this type of estimation, the estimators assign a size to each of the features. Points are assigned to the each of the T-Shirt Sizes using the Fibonacci-like format: 0, 1, 2, 3, 5, 8, 13, 20, 40, 100. These points are summed up and based on a rough estimate of how many feature points can get done within a time period by a normal agile team (note, the more detailed the refinement, the better the estimates).","title":"3.3.3 Forecasting Schedule and Cost"},{"location":"agile/3-3-projectmanagement/#334-cost","text":"The cost for the release is estimated by using the team's iteration average cost and multiplying it by the number of iterations estimated to complete the backlog. For example, the following formula to determine budgeted cost can demonstrate this estimation for the above example: (Team monthly cost (example: $15,000.00 per month) multiplied by the number of months/iterations (example: 5 months) = $75,000.00 + other expenses = forecast budgeted cost. The above example is utterly simplistic and does not take into account the following factors: The Inception phase at the beginning that is required to develop the product backlog, estimate the size in story points and develop an architecture vision; Changes in scope during the Construction iterations caused by adding new features driven by urgent business needs or Cybersecurity issues; A Transition phase at the end of development for Government Acceptance Tests and Security Tests required to achieve customer acceptance and Authority to Operate (AtO) for deployment; Many other variables such as Cloud Migration and implementation of a DevSecOps reference model.","title":"3.3.4 Cost"},{"location":"agile/3-3-projectmanagement/#335-project-management-consideration-checklist","text":"The project manager removes ensures funding, organizes stakeholder interactions and keeps the team from being distracted Work in increments. Buy, build, and fail small. Make proceed and pivot decisions regularly. Learn from mistakes but don't punish the people Leverage the efficiency of commercial contracting methods. If and when possible, use services and tools sold by private sector vendors. Use living roadmaps not fixed Integrated master schedules","title":"3.3.5 Project Management Consideration Checklist"},{"location":"agile/3-4-delivery/","text":"3.4 Agile CDRLs and Delivery 3.4.1 Overview One of the four agile manifesto values is that \"working products are valued over comprehensive documentation\". Many times this is viewed by the agile purist as a justification for not doing documentation. However, even in agile, there is a value for doing documentation. Documentation exists to support the development teams work in creating the product and supporting the product after release. Prior to looking deeper at agile content and delivery recommendations for CDRLs, here are some general considerations to keep in mind when determining the format, content, and delivery schedule for CDRLs within an agile framework - \"Just in time\" a. Document late (based on design completion) - Consolidate deliverable design documentation as late as possible (though can be iteratively updated) - better to have the stable concepts versus speculative ideas which are constantly changing as part of the agile framework and would require constant document revisions and submissions. b. Document continuously (based on iteration) - iteratively update development related documentation (i.e. user guides) in parallel with development efforts to not lose critical ideas. A key concept here is the idea of a living document, which is discussed below. \"Just sufficient\" - Sufficiency is defined by the document owner (provide the necessary useful documentation elements). Additional thoughts: a. Provide the fewest CDRLs possible with the least amount of overlap (I.e. considering combining the Interface Requirements Specification (IRS) with the Interface Design Description IDD). b. Better communication means less documentation (collaboration is key to agile - often a conversation between engineers can eliminate the need for a staffing document). c. Working software does not eliminate the need for documentation - the software delivered still needs to be improved, operated and maintained in the future - documentation's value is transferring product knowledge gained in development to users, operators and maintainers or to new development personnel when contracts change. \"NOT Just Because\" - Treat documentation as any other requirement that needs to be justified by the government document owner (since resources will need to be allocated to produce it). Documentation work efforts can then be prioritized within the product backlog based on the value it provides. 3.4.2 Agile CDRL Content Considerations Agile is built to be fast and flexible, and the contents of the CDRLs must be able to keep up with this development framework. CDRLs should not be an after-thought - they must be incorporated into the process. In other words, we don't want big CDRLs that are out of date by the time they are published. We need documents which can be frequently updated based on the ongoing iterative development efforts. Updates for CDRLs should be provided incrementally by the team when it is fresh in their mind, versus producing documentation at the end of the release when much of the valuable information has already been forgotten. In the military, this is a mindset switch. 3.4.3 Agile CDRL Delivery Consideration In order to maintain the current value of CDRLs, these documents should be flexible enough to keep up with an iterative update approach (versus long periods of time between updates). In that case, the best methodology is to establish a system to enable CDRLs as \"living documents\". This can best be enabled by re-thinking the methodology of delivery for CDRLs. By considering alternate digital delivery methodologies, CDRLs can be more quickly updated and maintain their relevance throughout the agile development process. One final note to this section is while Sharepoint or a shared drive may fulfill the CDRL requirements above, a further shift from the traditional mindset is to provide appropriate dashboards or reports within an existing system to provide the CDRL information requirements. An example of this is the Test Descriptions / Scripts. Executable test cases are normally already stored in a digital format within the test management software. 3.4.4 CDRL Recommended Modifications Attachment The following link is to an attachment which provides a more detailed list of CDRLs normally associated with a software development project. The list contains the associated DID, waterfall description, agile recommended modifications, and normal delivery timelines (i.e. are the documents delivered one time for the project, at specified design reviews, with a delivery, or on an as needed basis. CDRL List","title":"3.4 Agile CDRLs and Delivery"},{"location":"agile/3-4-delivery/#34-agile-cdrls-and-delivery","text":"","title":"3.4 Agile CDRLs and Delivery"},{"location":"agile/3-4-delivery/#341-overview","text":"One of the four agile manifesto values is that \"working products are valued over comprehensive documentation\". Many times this is viewed by the agile purist as a justification for not doing documentation. However, even in agile, there is a value for doing documentation. Documentation exists to support the development teams work in creating the product and supporting the product after release. Prior to looking deeper at agile content and delivery recommendations for CDRLs, here are some general considerations to keep in mind when determining the format, content, and delivery schedule for CDRLs within an agile framework - \"Just in time\" a. Document late (based on design completion) - Consolidate deliverable design documentation as late as possible (though can be iteratively updated) - better to have the stable concepts versus speculative ideas which are constantly changing as part of the agile framework and would require constant document revisions and submissions. b. Document continuously (based on iteration) - iteratively update development related documentation (i.e. user guides) in parallel with development efforts to not lose critical ideas. A key concept here is the idea of a living document, which is discussed below. \"Just sufficient\" - Sufficiency is defined by the document owner (provide the necessary useful documentation elements). Additional thoughts: a. Provide the fewest CDRLs possible with the least amount of overlap (I.e. considering combining the Interface Requirements Specification (IRS) with the Interface Design Description IDD). b. Better communication means less documentation (collaboration is key to agile - often a conversation between engineers can eliminate the need for a staffing document). c. Working software does not eliminate the need for documentation - the software delivered still needs to be improved, operated and maintained in the future - documentation's value is transferring product knowledge gained in development to users, operators and maintainers or to new development personnel when contracts change. \"NOT Just Because\" - Treat documentation as any other requirement that needs to be justified by the government document owner (since resources will need to be allocated to produce it). Documentation work efforts can then be prioritized within the product backlog based on the value it provides.","title":"3.4.1 Overview"},{"location":"agile/3-4-delivery/#342-agile-cdrl-content-considerations","text":"Agile is built to be fast and flexible, and the contents of the CDRLs must be able to keep up with this development framework. CDRLs should not be an after-thought - they must be incorporated into the process. In other words, we don't want big CDRLs that are out of date by the time they are published. We need documents which can be frequently updated based on the ongoing iterative development efforts. Updates for CDRLs should be provided incrementally by the team when it is fresh in their mind, versus producing documentation at the end of the release when much of the valuable information has already been forgotten. In the military, this is a mindset switch.","title":"3.4.2 Agile CDRL Content Considerations"},{"location":"agile/3-4-delivery/#343-agile-cdrl-delivery-consideration","text":"In order to maintain the current value of CDRLs, these documents should be flexible enough to keep up with an iterative update approach (versus long periods of time between updates). In that case, the best methodology is to establish a system to enable CDRLs as \"living documents\". This can best be enabled by re-thinking the methodology of delivery for CDRLs. By considering alternate digital delivery methodologies, CDRLs can be more quickly updated and maintain their relevance throughout the agile development process. One final note to this section is while Sharepoint or a shared drive may fulfill the CDRL requirements above, a further shift from the traditional mindset is to provide appropriate dashboards or reports within an existing system to provide the CDRL information requirements. An example of this is the Test Descriptions / Scripts. Executable test cases are normally already stored in a digital format within the test management software.","title":"3.4.3 Agile CDRL Delivery Consideration"},{"location":"agile/3-4-delivery/#344-cdrl-recommended-modifications-attachment","text":"The following link is to an attachment which provides a more detailed list of CDRLs normally associated with a software development project. The list contains the associated DID, waterfall description, agile recommended modifications, and normal delivery timelines (i.e. are the documents delivered one time for the project, at specified design reviews, with a delivery, or on an as needed basis. CDRL List","title":"3.4.4 CDRL Recommended Modifications Attachment"},{"location":"agile/3-5-metrics/","text":"3.5 Measuring Agile Delivery, KPIs, and Metrics - Status Reporting In Agile, the system always runs, thus Agile metrics are empirical and business value-based measurements instead of predictive measurements such as the performance measurement baseline and earned value that are used in traditional Waterfall. Agile metrics measure what the Agile Team delivers, not what the team predicts it will deliver. Project teams use this data for improved schedule and cost forecasts as well as for surfacing problems and issues that the Agile Team can diagnose and address. The metrics described below address Team Metrics, Program Metrics and Portfolio Metrics. These metrics were derived from the Project Management Institute, Inc. Agile Practice Guide, SAFe Metrics, DAD, and Atlassian web sites. 3.5.1 Team Iteration Metrics The Agile team metrics discussed below focus on the delivery of software. Whether the project team is a Scrum or Kanban team, each of these agile metrics will help the team better understand their development process, making releasing software easier. Scrum Metrics Sprint burndown. Scrum teams organize development into time-boxed sprint iterations. At the outset of the sprint, the team forecasts how many story points they can finish during a sprint. A sprint burndown report (Figure 2) then tracks the completion of work during the sprint. The x-axis represents time, and the y-axis refers to the amount of story points left to complete. The goal is to have all the forecasted work completed by the end of the sprint. A team that consistently meets its forecast is a compelling advertisement for Agile in their organization, however, it may be too good to be true if the team is inflating the numbers by declaring an item complete before it really is. In the long run cheating hampers learning and improvement. There are several anti-patterns to watch for in team performance: The team finishes early sprint after sprint because they aren't committing to enough work in the sprint backlog. The team misses their forecast sprint after sprint because they're committing to too much work. The burndown line makes steep drops rather than a more gradual burndown because the work hasn't been broken down into granular user stories or PBIs. The product owner adds PBIs or changes the scope mid-sprint. Velocity Velocity is the average amount of work a Scrum team completes during a sprint, measured in story points and we used it in the example from the prior section to forecast a release schedule. The product owner can use velocity to predict how quickly a team can work through the product backlog, since the velocity chart report tracks the forecasted and completed work over several iteration-the more iterations, the more accurate the forecast. Each team's velocity is unique. If team A has a velocity of 25 story points and team B has a velocity of 50 story points, it doesn't mean that team B has higher throughput. Because each team's story point estimation technique is unique, their sprint velocity will be as well. Organizations should resist the temptation to compare velocity across teams. Instead, Program Management should measure the level of effort and output of work based on each team's unique interpretation of story points. Kanban Metrics Team Kanban Board Flow-based Agile Teams using Kanban methods and Kanban Boards need to use different measurements like work in progress, lead time for delivery of a feature to customer, cycle time for completion of a task on the Kanban Board, and response time - the amount of time the item waits until work begins. Figure 4 shows an example of an Agile team's initial Kanban board, which captures their current workflow states: analyze, review, build, and integrate and test. After defining the initial process and Work in Process (WIP) limits and executing for a while, the Kanban team's bottlenecks should surface. If this is the case, the Kanban Team refines the workflow process step where the bottleneck occurred or reduces some WIP limits until it becomes evident that a workflow state is 'starving' or is too full. In this manner the Kanban Team continually adjusts the process workflows to optimize their flow. For example, changing WIP limits and merging, splitting, or redefining workflow states. Cumulative Flow Diagram The cumulative flow diagram is a key resource for Kanban teams, helping them ensure the flow of work across the team is consistent. With number of issues on the Y axis, time on the X axis, and colors to indicate the various workflow states, it visually points out shortages and bottlenecks and works in conjunction with Work in Process (WIP) limits. The cumulative flow diagram should look smooth(ish) from left to right. Bubbles or gaps in any one color indicate shortages and bottlenecks, so when the Agile Team sees one, they should look for ways to smooth out color bands across the chart. Anti-patterns to look for are: Blocking issues create large backups in some parts of the process and starvation in others. Unchecked backlog growth over time. This results from product owners not closing issues that are obsolete or simply too low in priority to ever be pulled in.","title":"3.5 Status Reporting"},{"location":"agile/3-5-metrics/#35-measuring-agile-delivery-kpis-and-metrics-status-reporting","text":"In Agile, the system always runs, thus Agile metrics are empirical and business value-based measurements instead of predictive measurements such as the performance measurement baseline and earned value that are used in traditional Waterfall. Agile metrics measure what the Agile Team delivers, not what the team predicts it will deliver. Project teams use this data for improved schedule and cost forecasts as well as for surfacing problems and issues that the Agile Team can diagnose and address. The metrics described below address Team Metrics, Program Metrics and Portfolio Metrics. These metrics were derived from the Project Management Institute, Inc. Agile Practice Guide, SAFe Metrics, DAD, and Atlassian web sites.","title":"3.5 Measuring Agile Delivery, KPIs, and Metrics - Status Reporting"},{"location":"agile/3-5-metrics/#351-team-iteration-metrics","text":"The Agile team metrics discussed below focus on the delivery of software. Whether the project team is a Scrum or Kanban team, each of these agile metrics will help the team better understand their development process, making releasing software easier.","title":"3.5.1 Team Iteration Metrics"},{"location":"agile/3-5-metrics/#scrum-metrics","text":"Sprint burndown. Scrum teams organize development into time-boxed sprint iterations. At the outset of the sprint, the team forecasts how many story points they can finish during a sprint. A sprint burndown report (Figure 2) then tracks the completion of work during the sprint. The x-axis represents time, and the y-axis refers to the amount of story points left to complete. The goal is to have all the forecasted work completed by the end of the sprint. A team that consistently meets its forecast is a compelling advertisement for Agile in their organization, however, it may be too good to be true if the team is inflating the numbers by declaring an item complete before it really is. In the long run cheating hampers learning and improvement. There are several anti-patterns to watch for in team performance: The team finishes early sprint after sprint because they aren't committing to enough work in the sprint backlog. The team misses their forecast sprint after sprint because they're committing to too much work. The burndown line makes steep drops rather than a more gradual burndown because the work hasn't been broken down into granular user stories or PBIs. The product owner adds PBIs or changes the scope mid-sprint. Velocity Velocity is the average amount of work a Scrum team completes during a sprint, measured in story points and we used it in the example from the prior section to forecast a release schedule. The product owner can use velocity to predict how quickly a team can work through the product backlog, since the velocity chart report tracks the forecasted and completed work over several iteration-the more iterations, the more accurate the forecast. Each team's velocity is unique. If team A has a velocity of 25 story points and team B has a velocity of 50 story points, it doesn't mean that team B has higher throughput. Because each team's story point estimation technique is unique, their sprint velocity will be as well. Organizations should resist the temptation to compare velocity across teams. Instead, Program Management should measure the level of effort and output of work based on each team's unique interpretation of story points.","title":"Scrum Metrics"},{"location":"agile/3-5-metrics/#kanban-metrics","text":"Team Kanban Board Flow-based Agile Teams using Kanban methods and Kanban Boards need to use different measurements like work in progress, lead time for delivery of a feature to customer, cycle time for completion of a task on the Kanban Board, and response time - the amount of time the item waits until work begins. Figure 4 shows an example of an Agile team's initial Kanban board, which captures their current workflow states: analyze, review, build, and integrate and test. After defining the initial process and Work in Process (WIP) limits and executing for a while, the Kanban team's bottlenecks should surface. If this is the case, the Kanban Team refines the workflow process step where the bottleneck occurred or reduces some WIP limits until it becomes evident that a workflow state is 'starving' or is too full. In this manner the Kanban Team continually adjusts the process workflows to optimize their flow. For example, changing WIP limits and merging, splitting, or redefining workflow states. Cumulative Flow Diagram The cumulative flow diagram is a key resource for Kanban teams, helping them ensure the flow of work across the team is consistent. With number of issues on the Y axis, time on the X axis, and colors to indicate the various workflow states, it visually points out shortages and bottlenecks and works in conjunction with Work in Process (WIP) limits. The cumulative flow diagram should look smooth(ish) from left to right. Bubbles or gaps in any one color indicate shortages and bottlenecks, so when the Agile Team sees one, they should look for ways to smooth out color bands across the chart. Anti-patterns to look for are: Blocking issues create large backups in some parts of the process and starvation in others. Unchecked backlog growth over time. This results from product owners not closing issues that are obsolete or simply too low in priority to ever be pulled in.","title":"Kanban Metrics"},{"location":"agile/3-mindset/","text":"","title":"3 mindset"},{"location":"agile/4-1-architecture/","text":"4.1 Agile Management Tools (AMT) 4.1.1 Purpose: While the environment is established by stakeholder management and contractual obligations, it is also necessary to establish the physical infrastructure (toolset) necessary to enable agile. With that in mind, this section will focus on the provisioning of an infrastructure that supplies 4 general functions: Backlog Management - the tools necessary to capture and refine requirements as well as allows the PO to prioritize the different work efforts to provide the most value. This is the tool that maintains a prioritized and organized listing of the work items which need to be done for the project. Work management - the tools necessary to execute the specific methodology which will be employed by the development team (Scrum, Kanban, XP, hybrid). This is the tool which provides the team the ability to collaborate on the development of their work items (Scrum Board, Kanban Board, etc). Communications Management - the tools necessary to communicate the status of the development effort to internal and external stakeholders. It includes the ability to create reports, provide metrics (does not define the metrics themselves), and implement collaborative dashboards with information which is relevant (i.e. work items complete, work items remaining, identified risks, identified issues, test status, etc). The actual capabilities of the tool which will be used will be based on the communications needs of the stakeholders involved (the evolution of a dashboard or report is often iterative in nature as communication needs are better refined). Continuous Integration - While not a necessity, a continuous integration tool makes agile run much more efficiently. The concept of iterative deliveries to the customer requires a mechanism which allows for continuous inputs by the developers to the code to provide smaller increments versus the big bang development approach of waiting till everything is done. With continuous integration, you get an iterative product of better quality based on the integrated automated testing functionality built into the tool (will cover automated testing methodologies and benefits in a companion playbook). Each section below will include the recommended capabilities required of the enabling tools (general in nature - not tied to specific methodology) One note - the infrastructure tools used by the HIA community are on the Atlassian set of agile products as well as Team Foundation Server (TFS) / Visual Studios Team Server (VSTS). The table below shows a quick overview of the differences and similarities between the two in reference to enabling an agile framework. Links describing how to enable the management systems below within the VSTS/TFS and the Atlassian Products are found in Appendix C - Key Links. 4.1.2 Backlog Management When considering which tool to use, the following functionalities should be provided: Capture and refine requirements into nested Product Backlog Items (PBIs) - Epics, Features, User Stories Organize and prioritize those requirements Provide a reporting capability to show necessary details to understand the status of those Product Backlog Items 4.1.3 Work Management (i.e. Release Roadmap/Scrum Boards/Kanban Boards) The following functionalities should be provided: Capability to establish an agile execution board: Scrum - Sprint Board Kanban - Kanban Board XP / Hybrid - Agile Board Ability to refine the work in progress (add and update the status details of the different work items - including tasks, user stories, etc.) Ability to assign responsible parties to the different work items (while agile emphasizes the establishment of responsibility when capacity is available, there needs to be a method to monitor which work items have a responsible resource and which ones are still available to be worked on) Capability to report necessary details to understand the status of work in progress (metrics analysis will be provided later in the discussion of communication tools - here we are looking at status of individual versus aggregate work items). 4.1.4 Communication Management Recommend functions include the ability to produce the following: Dashboards Metric Analysis Reports: Release Roadmaps - These will be discussed later in the methodology, but the release roadmap provides an overview of when features are expected to be complete. In terms of project management, the release roadmap can be used to establish the schedule for the project. 4.1.5 Continuous Integration Architecture and Management Recommended functionality for enabling continuous integration in any toolset: Version control tool (code repository management) Instrumented or scripted build process Trigger capability for implementing a build and test cycle based on code check-in Automated testing implementation capability Automated alerts, in case of a failed test, back to the developers so that they can resolve issue immediately (provide feedback on issues)","title":"4.1 Agile Management Tools"},{"location":"agile/4-1-architecture/#41-agile-management-tools-amt","text":"","title":"4.1 Agile Management Tools (AMT)"},{"location":"agile/4-1-architecture/#411-purpose","text":"While the environment is established by stakeholder management and contractual obligations, it is also necessary to establish the physical infrastructure (toolset) necessary to enable agile. With that in mind, this section will focus on the provisioning of an infrastructure that supplies 4 general functions: Backlog Management - the tools necessary to capture and refine requirements as well as allows the PO to prioritize the different work efforts to provide the most value. This is the tool that maintains a prioritized and organized listing of the work items which need to be done for the project. Work management - the tools necessary to execute the specific methodology which will be employed by the development team (Scrum, Kanban, XP, hybrid). This is the tool which provides the team the ability to collaborate on the development of their work items (Scrum Board, Kanban Board, etc). Communications Management - the tools necessary to communicate the status of the development effort to internal and external stakeholders. It includes the ability to create reports, provide metrics (does not define the metrics themselves), and implement collaborative dashboards with information which is relevant (i.e. work items complete, work items remaining, identified risks, identified issues, test status, etc). The actual capabilities of the tool which will be used will be based on the communications needs of the stakeholders involved (the evolution of a dashboard or report is often iterative in nature as communication needs are better refined). Continuous Integration - While not a necessity, a continuous integration tool makes agile run much more efficiently. The concept of iterative deliveries to the customer requires a mechanism which allows for continuous inputs by the developers to the code to provide smaller increments versus the big bang development approach of waiting till everything is done. With continuous integration, you get an iterative product of better quality based on the integrated automated testing functionality built into the tool (will cover automated testing methodologies and benefits in a companion playbook). Each section below will include the recommended capabilities required of the enabling tools (general in nature - not tied to specific methodology) One note - the infrastructure tools used by the HIA community are on the Atlassian set of agile products as well as Team Foundation Server (TFS) / Visual Studios Team Server (VSTS). The table below shows a quick overview of the differences and similarities between the two in reference to enabling an agile framework. Links describing how to enable the management systems below within the VSTS/TFS and the Atlassian Products are found in Appendix C - Key Links.","title":"4.1.1 Purpose:"},{"location":"agile/4-1-architecture/#412-backlog-management","text":"When considering which tool to use, the following functionalities should be provided: Capture and refine requirements into nested Product Backlog Items (PBIs) - Epics, Features, User Stories Organize and prioritize those requirements Provide a reporting capability to show necessary details to understand the status of those Product Backlog Items","title":"4.1.2 Backlog Management"},{"location":"agile/4-1-architecture/#413-work-management-ie-release-roadmapscrum-boardskanban-boards","text":"The following functionalities should be provided: Capability to establish an agile execution board: Scrum - Sprint Board Kanban - Kanban Board XP / Hybrid - Agile Board Ability to refine the work in progress (add and update the status details of the different work items - including tasks, user stories, etc.) Ability to assign responsible parties to the different work items (while agile emphasizes the establishment of responsibility when capacity is available, there needs to be a method to monitor which work items have a responsible resource and which ones are still available to be worked on) Capability to report necessary details to understand the status of work in progress (metrics analysis will be provided later in the discussion of communication tools - here we are looking at status of individual versus aggregate work items).","title":"4.1.3 Work Management (i.e. Release Roadmap/Scrum Boards/Kanban Boards)"},{"location":"agile/4-1-architecture/#414-communication-management","text":"Recommend functions include the ability to produce the following: Dashboards Metric Analysis Reports: Release Roadmaps - These will be discussed later in the methodology, but the release roadmap provides an overview of when features are expected to be complete. In terms of project management, the release roadmap can be used to establish the schedule for the project.","title":"4.1.4 Communication Management"},{"location":"agile/4-1-architecture/#415-continuous-integration-architecture-and-management","text":"Recommended functionality for enabling continuous integration in any toolset: Version control tool (code repository management) Instrumented or scripted build process Trigger capability for implementing a build and test cycle based on code check-in Automated testing implementation capability Automated alerts, in case of a failed test, back to the developers so that they can resolve issue immediately (provide feedback on issues)","title":"4.1.5 Continuous Integration Architecture and Management"},{"location":"agile/5-1-backlog/","text":"5.1 Part I - Establish the Product Backlog (PB) and Constraints: 5.1.1 Establish the Product Backlog For a government project the initial list of requirements is established within the contract and will be used as the foundation for the initial PB development (and captured within the appropriate Backlog Management tool). The establishment of the PB is comparable to the establishment of a language - in this case it is the language of \"value\" that provides for understanding between the government and the development team. For this \"value\" language - the individual PB components provide the words and grammar (think of Epics as Paragraphs, Features as sentences and User Stories/Cards as words), while the order of the backlog based on prioritization of \"value\" provides the context of the product story. This initial section focuses on the creation of the Product Backlog. Later sections will discuss how the PB is prioritized to provide the most value up front as well as how it evolves based on a changing environment to continue to remain value relevant. As the PB will generally follow a rolling-wave planning process with more detail provided as it becomes available or necessary, it can initially be setup with larger organizational elements (epics and features) which will be iteratively refined later. A recommended nested organization for these components include: Epics - These include functionality which can take one or more releases to complete. For government contracts, these can be linked to a Contract Line Item Number for easier reference to cost tracking and earned value metrics. Features - These include functionality components that will generally take more than one iteration to complete and provide the functionality to the users through releases. Product Backlog Items (PBI) - These include the product increments which consolidate to provide the functionality of the feature and generally can be accomplished within a single iteration. PBIs can be decomposed into specific tasks with hours estimated for completion. The main component of the PB is the PBI that may be named something different depending on the framework (for Scrum and XP can be a user story, for Kanban can be a simple work item or card). In translating a requirement to a PBI, it is necessary to understand that the PBI can contain 1 or more requirements as it is based on the customer functional need (can be captured in government use case documents). However, while functional requirements will most likely include BES Process Directory requirements terms including \"shall\" which dictates the provision of a functional capability, they may also include conditional requirements indicated by the \"must\", \"must not\" and \"required\" requirements descriptions indicating additional performance requirements or constraints). Additional non-functional requirements to be considered include: Preparation and conduct of design reviews Hardware setup (Different environments) Tool setup (Software tools) Network Setup (establishing connectivity - access requirements, ports and protocols) UAT, Pre-Prod, Prod transitions (can be facilitated by continuous integration and Devops) Documentation (User Guides / CDRL's / Training Materials Regression testing (can be facilitated by automated testing) Cybersecurity testing The typical PBI contains a minimum of 3 elements - Title: Ensure this ties to the logic of the work (many times the titles of a PBI can cause confusion between the PO and development team if improperly stated). Description: Explains the customers need and the functionality required. Acceptance Criteria: Explains the conditions under which the PO will accept the work item as complete (note that there are additional criteria which will be discussed in presenting a \"Definition of Done\"). These criteria should be testable (I.e. should be specific enough to be able to qualify as complete or not complete). A typical PBI descriptions contains the following elements: \"As a...\" - Defines the perspective of the user who needs the functionality. \"I need...\" - Defines the functionality needed. \"So that...\" - Defines the why of the functionality (enables the developers' ingenuity as they may have a better solution which still meets the \"why\" of the user's request though the how may be something different). Example: As a maintenance scheduler I need to be able to review the Daily Schedule So that I can review the events scheduled for the day and the status of their completion Additional information can be included within the description. One recommendation is to include the requirement number(s) from the original contract in this section to facilitate the creation of the Requirement's Traceability Matrix necessary for design reviews and deliveries. While the PO is the primary owner of the backlog, the initial creation of the backlog is most effective when completed in a collaborative manner. While the term Sprint 0 is not an official Scrum term, it does provide a context for doing the preparation work necessary to initiate an agile methodology (without the PBI's it is not possible to do the work). Whatever it is called, there is a preparation session which is necessary to prime the pump of the agile framework by building the initial PB. Here is a recommended approach to doing this which ends with the government System Functional Review (SFR) which established the PB as the Functional Baseline: Preparation Phases (Phases are provided here as timeline will have to adjust based on size and complexity of requirements as well as whether preliminary planning has been done...i.e. feature driven planning): Phase 1: (Government and Development Team collaboration preparation) Government provides initial Requirements Traceability Matrix (RTM). Government provides initial feature backlog linked to RTM to development team (with minimum of description filled out and rough draft of acceptance criteria). Development team reviews feature descriptions and provides feature backlog feedback to government at end of the phase with recommended revised acceptance criteria and questions of clarification for review prior to physical collaboration. Phase 2 (Physical Collaboration - government and development team) Collaboratively refine features with end-state of initial Title, Description, and Acceptance Criteria agreed on by government and development team Conduct breakout sessions as necessary to provide additional details to development team necessary to make initial estimates of feature sizes Development team makes initial estimates of feature sizes (T-Shirt sizing). Development team prepares for SFR. 5.1.2 System Functional Review (SFR) The SFR is a multi-disciplined system-level technical review ensures that the functional baseline is established and has a reasonable expectation of satisfying the requirements of draft capability development document (CDD) within the current budget and schedule. It completes the process of defining the system-level technical requirements that are documented in the system performance specification. According to the BPD, a successful completion of SFR provides a sound technical basis for proceeding into preliminary design. If the above collaboration is done correctly, this review becomes a \"value language\" confirmation brief ensuring that the PB correctly reflects the requirements of the contract and are consistent with cost (program budget), risk and other system constraints. Audience : Functional Review Board (FRB) members Objectives : Reconfirm that Capability Package Requirements are linked to PB Features derived during the preparation event above (Sprint 0) Initial identification of system-level document changes which will need to be addressed during design reviews (see CDRL section (link within main document)) Establish Functional Baseline. Add Feature list to the Program Product Backlog to be considered in Release Planning for development based on PMO priorities and value determination. Determine based on Release Planning when each Feature should be considered within either the Preliminary Design Review or the Critical Design Review. Outputs : Required inputs for a Configuration Control Board (CCB). Approved PB and Functional Baseline based on Configuration Control Directive (CCD) from CCB. Updated system release roadmap with new features. Updated Requirement Traceability Matrix with links from requirements to PB. Identified system-level CDRLs to update for design reviews based on PB contents. Identified features for design reviews (Preliminary Design Review [PDR] and Critical Design Review [CDR]) 5.1.3 Release Management Release management is about determining what is expected to be in each release and what comes next for the development team as well as identifying PBI dependencies early enough so that they can be rectified prior to becoming impediments during development. The PB includes those features approved in the functional baseline by the PMO during the System Functional Release (SFR) conducted at the end of Sprint 0. The features are prioritized within the PB by the PMO and considered by a Release Planning committee for inclusion in upcoming releases. Those features which are selected for inclusion in upcoming releases are updated on the Release Roadmap based on their tentative estimate of completion. The Release Roadmap is a high-level view of the PB features, with a loose time frame for when the team will refine and develop those features. Proposed agenda for Release Planning meeting: Objective Overview Review Current Release Roadmap (Starting point) Review Current Status of Development Streams (Establish current status which may have changed since last release planning session) Determine dates for: Next Release (Feature focus for the CDR) Next Release (+1) (Feature focus for the PDR) Review Product Backlog Feature Priority Lists (Confirm priorities) Confirm Features for Next Release Identify Features for Next Release (+1) Update Release Roadmap (Use information from session to update the release roadmap) Discuss any release process improvement steps (Continuous Improvement) 5.1.4 System Engineering Design Reviews Link to DAU System Engineering Overview (Add to links appendix - will not be contained in base document): https://www.dau.mil/guidebooks/Shared%20Documents%20HTML/Chapter%203%20Systems%20Engineering.aspx#toc83 A secondary advantage of implementing a pro-active release management system is the ability to establish what features will be reviewed at what level for Agile-based design review gates (here we are talking about Preliminary and Critical Design Reviews but not in the level of detail that was expected within traditional development engineering management plans as Agile is about doing architectural design \"just in time\" and iteratively \"just enough\"). The Design Reviews can be synchronized with the above release management process to fulfill their primary objectives based on two different perspectives: Preliminary Design Review (PDR): Focus : The features included in the release after the upcoming release (long-term perspective). Objectives : Provide sufficient confidence in the preliminary design's integration with necessary system components to serve as the starting point for Agile incremental design during development. Provide technical confidence that the capability need can be satisfied within cost goals based on the schedule included in the release roadmap. Confirms that high-level design decisions are consistent with the user's performance, schedule needs, and the validated Capability Development Document (CDD). Establishes the allocated baseline (based on features), which is placed under formal configuration control. Agile Revisions : Identify dependencies on external requirements or other features to ensure proper sequencing and identify issues for resolution prior to them becoming impediments (identifies feature risks early). Determine required infrastructure requirements so they can be acquired prior to development. Agenda Template : Review Release Roadmap Review Features for the release after the immediate upcoming release. Review Feature description Review Feature acceptance criteria Review Features system-level design integration (focused on necessary design integration of feature capability) Review Feature dependencies (I.e. external interface requirements, additional software requirements) - these will become an initial set of assumptions for risk management (the goal is to mitigate the risks so that the assumption will not impede our development efforts later) Review Feature CDRL requirements (what CDRLs will need to be updated based on the completion of the feature development) Review Feature size estimates (establishes metric for estimating duration) Revise Release Roadmap as necessary based on updated information Critical Design Review (CDR): Focus : The features included in the next (upcoming) release (short-term perspective). Objectives : Establishes the initial product baseline (based on features), which is placed under formal configuration control. Confirms the high-level system design is expected to meet system performance requirements Confirms the system is on track to achieve affordability and should-cost goals as evidenced by the design documentation Establishes requirements and system interfaces for enabling system elements such as support equipment, training system, maintenance and data systems. Agile Revisions : Confirms that dependencies identified in the PDR have a resolution strategy that will be completed in time to enable development of the dependent features (will not become impediments during development). Confirms that features are ready for further refinement into work items for the development team. Agenda Template : Review Release Roadmap Review Features for the upcoming release. Review Feature description Review Feature acceptance criteria Review Features system-level design integration and system requirements: UI change requirements (mock-ups if available) Middle tier requirements (services) Data structure requirements Review Feature dependencies to ensure they have been resolved or a feasible resolution strategy is in place prior to beginning work on the feature (these address the initial assumptions determined during the PDR) Review Feature CDRL requirements - update as required Review Feature size estimates (establishes metric for estimating duration) - update based on additional information Revise Release Roadmap as necessary based on updated information 5.1.5 Refine the Product Backlog (Features -> Initial PBIs) In general, the refinement process establishes the \"development language\" between the Development Team and the Government through their designated PO. Feature refinement should be conducted about 2 months prior to working on the first PBI of the feature. The objectives of feature refinement are to: Break down feature to individual PBIs (user stories, cards, work items, etc) with, at a minimum, a description and acceptance criteria; Provide an initial estimate of the complexity of the work item (sizing estimates can be associated with established costs and used for EV metrics); Gain the formal approval of the PO to include the refined work items into the Product Backlog. Feature refinement in preparation for development work conducted between the government PO and Development Team: Normally takes 1-2 hours per feature if done correctly (the more discussion, the better clarity of understanding between the government and the development team increasing the likelihood that the development product will meet government expectations). Refine initial title, description, acceptance criteria at the feature - level based on knowledge acquired since design review - this is the focus of the PMO input - provides the WHAT of the feature. Identify the logic of the work. Identify the initial user stories. Ensure that the stories have a description and acceptance criteria which provide a common reference for the team to produce an initial sizing estimate (provides metric for EV - can be updated later). Identify infrastructure requirements (i.e. suites) necessary for development. Three questions to guide Feature Refinement Discussion and what they are attempting to elicit: What do you want to see at the end? (Acceptance Criteria) What are the high-level steps to get there? (Logic) What are the sub-steps for each of the high-level steps? (PBIs) 5.1.6 Prioritize the Product Backlog Agile is about providing value to the government customer as quickly as possible. Less valuable work is ranked lower in the priority scale. Thus, after refinement of the features into PBIs within the PB, it is necessary to rank them based on the value they provide. There are multiple considerations in evaluating the value of each individual PBI including: What provides most value functionally to the government user? What impact does the PBI have on other items within the backlog (i.e. are their dependencies between work items)? Cost / impact assessment of each PBI. Learning - Are their efficiencies to be gained for the remaining work items by completing a specific story earlier (i.e. taking a smaller item which is easier to do to establish the templates and processes for doing more complex work items of a similar nature later but at a more rapid pace)? Are their negative impacts to other PBIs by not completing one earlier? Regulatory deadlines (not considered agile, but is a consideration for prioritization) It is the responsibility of the PO, as the representative of the government to continuously reprioritize the PB to provide the most value to the government based on the current environment (especially as new PBIs are added or removed from the PB). Prioritization considerations to avoid (as they are normally short-term perspectives which may reduce long-term value): Highest Ranking Person in the Room Flavor of the Day 5.1.7 Constraints Analysis The above sections focus on refining requirements into work items, but there are several; other areas of regulatory constraints within the governmental regulatory environment that should be addressed prior to determining as well as implementing an Agile development methodology. The following is a non-exhaustive list of items that may impact the execution of development based on scope (these provide a basis for discussion between the Government and Development Team to determine which will be enforced and to what level): External testing requirements such as DT&E and QT&E (capacity may be required to prepare and support testing - need to delineate what falls to the development team and what will be done by the government) Additional BPD Design, Test, Functional Readiness Reviews (all come with a preparation and documentation overhead - will need to discuss expectations and agile modifications based on iterative versus up front design) Development environment limitations (discussion around whether the contractor will control the environment or whether it is an externally administered environment - I.e. the Capabilities Integration Environment (CIE)) Access requirements (security requirements may dictate which personnel resources can be allocated to a team) Re-usability and compatibility requirements (establishes the boundaries of initiative for the developers - \"can be innovative within these limits\") Cybersecurity requirements (the pre-requisite cybersecurity requirements may limit development options) 5.1.8 Change Management While there is an inherent flexibility within Agile methodologies to accept change specifically through backlog grooming and PBI refinement, there is still the challenge of differentiating between contractual scope additions versus simple requirement refinement. The differentiation of what will be left within the authority of the PO to approve through backlog refinement and what requirement changes need formal approval in the form of a Configuration Change Directive (CCD) should be established prior to the beginning of development to ensure proper steps are taken within the established constraints to adapt to change. When a formal configuration change is necessary, the government Configuration Control Board (CCB) with input from the Functional Review Board (FRB) should: Review the list of any new user requests, deficiency reports and change requests received in the project space; Assess the impact of a change; Assign a priority to the change; Assign a business value to the change; and Implement a CCD to insert an approved work item for the change into the Product Backlog (upon completion of any contractual modification requirements to accept in the new work)","title":"5.1 Part I - Establish the Product Backlog (PB) and Constraints"},{"location":"agile/5-1-backlog/#51-part-i-establish-the-product-backlog-pb-and-constraints","text":"","title":"5.1 Part I - Establish the Product Backlog (PB) and Constraints:"},{"location":"agile/5-1-backlog/#511-establish-the-product-backlog","text":"For a government project the initial list of requirements is established within the contract and will be used as the foundation for the initial PB development (and captured within the appropriate Backlog Management tool). The establishment of the PB is comparable to the establishment of a language - in this case it is the language of \"value\" that provides for understanding between the government and the development team. For this \"value\" language - the individual PB components provide the words and grammar (think of Epics as Paragraphs, Features as sentences and User Stories/Cards as words), while the order of the backlog based on prioritization of \"value\" provides the context of the product story. This initial section focuses on the creation of the Product Backlog. Later sections will discuss how the PB is prioritized to provide the most value up front as well as how it evolves based on a changing environment to continue to remain value relevant. As the PB will generally follow a rolling-wave planning process with more detail provided as it becomes available or necessary, it can initially be setup with larger organizational elements (epics and features) which will be iteratively refined later. A recommended nested organization for these components include: Epics - These include functionality which can take one or more releases to complete. For government contracts, these can be linked to a Contract Line Item Number for easier reference to cost tracking and earned value metrics. Features - These include functionality components that will generally take more than one iteration to complete and provide the functionality to the users through releases. Product Backlog Items (PBI) - These include the product increments which consolidate to provide the functionality of the feature and generally can be accomplished within a single iteration. PBIs can be decomposed into specific tasks with hours estimated for completion. The main component of the PB is the PBI that may be named something different depending on the framework (for Scrum and XP can be a user story, for Kanban can be a simple work item or card). In translating a requirement to a PBI, it is necessary to understand that the PBI can contain 1 or more requirements as it is based on the customer functional need (can be captured in government use case documents). However, while functional requirements will most likely include BES Process Directory requirements terms including \"shall\" which dictates the provision of a functional capability, they may also include conditional requirements indicated by the \"must\", \"must not\" and \"required\" requirements descriptions indicating additional performance requirements or constraints). Additional non-functional requirements to be considered include: Preparation and conduct of design reviews Hardware setup (Different environments) Tool setup (Software tools) Network Setup (establishing connectivity - access requirements, ports and protocols) UAT, Pre-Prod, Prod transitions (can be facilitated by continuous integration and Devops) Documentation (User Guides / CDRL's / Training Materials Regression testing (can be facilitated by automated testing) Cybersecurity testing The typical PBI contains a minimum of 3 elements - Title: Ensure this ties to the logic of the work (many times the titles of a PBI can cause confusion between the PO and development team if improperly stated). Description: Explains the customers need and the functionality required. Acceptance Criteria: Explains the conditions under which the PO will accept the work item as complete (note that there are additional criteria which will be discussed in presenting a \"Definition of Done\"). These criteria should be testable (I.e. should be specific enough to be able to qualify as complete or not complete). A typical PBI descriptions contains the following elements: \"As a...\" - Defines the perspective of the user who needs the functionality. \"I need...\" - Defines the functionality needed. \"So that...\" - Defines the why of the functionality (enables the developers' ingenuity as they may have a better solution which still meets the \"why\" of the user's request though the how may be something different). Example: As a maintenance scheduler I need to be able to review the Daily Schedule So that I can review the events scheduled for the day and the status of their completion Additional information can be included within the description. One recommendation is to include the requirement number(s) from the original contract in this section to facilitate the creation of the Requirement's Traceability Matrix necessary for design reviews and deliveries. While the PO is the primary owner of the backlog, the initial creation of the backlog is most effective when completed in a collaborative manner. While the term Sprint 0 is not an official Scrum term, it does provide a context for doing the preparation work necessary to initiate an agile methodology (without the PBI's it is not possible to do the work). Whatever it is called, there is a preparation session which is necessary to prime the pump of the agile framework by building the initial PB. Here is a recommended approach to doing this which ends with the government System Functional Review (SFR) which established the PB as the Functional Baseline:","title":"5.1.1 Establish the Product Backlog"},{"location":"agile/5-1-backlog/#preparation-phases","text":"(Phases are provided here as timeline will have to adjust based on size and complexity of requirements as well as whether preliminary planning has been done...i.e. feature driven planning): Phase 1: (Government and Development Team collaboration preparation) Government provides initial Requirements Traceability Matrix (RTM). Government provides initial feature backlog linked to RTM to development team (with minimum of description filled out and rough draft of acceptance criteria). Development team reviews feature descriptions and provides feature backlog feedback to government at end of the phase with recommended revised acceptance criteria and questions of clarification for review prior to physical collaboration. Phase 2 (Physical Collaboration - government and development team) Collaboratively refine features with end-state of initial Title, Description, and Acceptance Criteria agreed on by government and development team Conduct breakout sessions as necessary to provide additional details to development team necessary to make initial estimates of feature sizes Development team makes initial estimates of feature sizes (T-Shirt sizing). Development team prepares for SFR.","title":"Preparation Phases"},{"location":"agile/5-1-backlog/#512-system-functional-review-sfr","text":"The SFR is a multi-disciplined system-level technical review ensures that the functional baseline is established and has a reasonable expectation of satisfying the requirements of draft capability development document (CDD) within the current budget and schedule. It completes the process of defining the system-level technical requirements that are documented in the system performance specification. According to the BPD, a successful completion of SFR provides a sound technical basis for proceeding into preliminary design. If the above collaboration is done correctly, this review becomes a \"value language\" confirmation brief ensuring that the PB correctly reflects the requirements of the contract and are consistent with cost (program budget), risk and other system constraints. Audience : Functional Review Board (FRB) members Objectives : Reconfirm that Capability Package Requirements are linked to PB Features derived during the preparation event above (Sprint 0) Initial identification of system-level document changes which will need to be addressed during design reviews (see CDRL section (link within main document)) Establish Functional Baseline. Add Feature list to the Program Product Backlog to be considered in Release Planning for development based on PMO priorities and value determination. Determine based on Release Planning when each Feature should be considered within either the Preliminary Design Review or the Critical Design Review. Outputs : Required inputs for a Configuration Control Board (CCB). Approved PB and Functional Baseline based on Configuration Control Directive (CCD) from CCB. Updated system release roadmap with new features. Updated Requirement Traceability Matrix with links from requirements to PB. Identified system-level CDRLs to update for design reviews based on PB contents. Identified features for design reviews (Preliminary Design Review [PDR] and Critical Design Review [CDR])","title":"5.1.2 System Functional Review (SFR)"},{"location":"agile/5-1-backlog/#513-release-management","text":"Release management is about determining what is expected to be in each release and what comes next for the development team as well as identifying PBI dependencies early enough so that they can be rectified prior to becoming impediments during development. The PB includes those features approved in the functional baseline by the PMO during the System Functional Release (SFR) conducted at the end of Sprint 0. The features are prioritized within the PB by the PMO and considered by a Release Planning committee for inclusion in upcoming releases. Those features which are selected for inclusion in upcoming releases are updated on the Release Roadmap based on their tentative estimate of completion. The Release Roadmap is a high-level view of the PB features, with a loose time frame for when the team will refine and develop those features. Proposed agenda for Release Planning meeting: Objective Overview Review Current Release Roadmap (Starting point) Review Current Status of Development Streams (Establish current status which may have changed since last release planning session) Determine dates for: Next Release (Feature focus for the CDR) Next Release (+1) (Feature focus for the PDR) Review Product Backlog Feature Priority Lists (Confirm priorities) Confirm Features for Next Release Identify Features for Next Release (+1) Update Release Roadmap (Use information from session to update the release roadmap) Discuss any release process improvement steps (Continuous Improvement)","title":"5.1.3 Release Management"},{"location":"agile/5-1-backlog/#514-system-engineering-design-reviews","text":"Link to DAU System Engineering Overview (Add to links appendix - will not be contained in base document): https://www.dau.mil/guidebooks/Shared%20Documents%20HTML/Chapter%203%20Systems%20Engineering.aspx#toc83 A secondary advantage of implementing a pro-active release management system is the ability to establish what features will be reviewed at what level for Agile-based design review gates (here we are talking about Preliminary and Critical Design Reviews but not in the level of detail that was expected within traditional development engineering management plans as Agile is about doing architectural design \"just in time\" and iteratively \"just enough\"). The Design Reviews can be synchronized with the above release management process to fulfill their primary objectives based on two different perspectives: Preliminary Design Review (PDR): Focus : The features included in the release after the upcoming release (long-term perspective). Objectives : Provide sufficient confidence in the preliminary design's integration with necessary system components to serve as the starting point for Agile incremental design during development. Provide technical confidence that the capability need can be satisfied within cost goals based on the schedule included in the release roadmap. Confirms that high-level design decisions are consistent with the user's performance, schedule needs, and the validated Capability Development Document (CDD). Establishes the allocated baseline (based on features), which is placed under formal configuration control. Agile Revisions : Identify dependencies on external requirements or other features to ensure proper sequencing and identify issues for resolution prior to them becoming impediments (identifies feature risks early). Determine required infrastructure requirements so they can be acquired prior to development. Agenda Template : Review Release Roadmap Review Features for the release after the immediate upcoming release. Review Feature description Review Feature acceptance criteria Review Features system-level design integration (focused on necessary design integration of feature capability) Review Feature dependencies (I.e. external interface requirements, additional software requirements) - these will become an initial set of assumptions for risk management (the goal is to mitigate the risks so that the assumption will not impede our development efforts later) Review Feature CDRL requirements (what CDRLs will need to be updated based on the completion of the feature development) Review Feature size estimates (establishes metric for estimating duration) Revise Release Roadmap as necessary based on updated information Critical Design Review (CDR): Focus : The features included in the next (upcoming) release (short-term perspective). Objectives : Establishes the initial product baseline (based on features), which is placed under formal configuration control. Confirms the high-level system design is expected to meet system performance requirements Confirms the system is on track to achieve affordability and should-cost goals as evidenced by the design documentation Establishes requirements and system interfaces for enabling system elements such as support equipment, training system, maintenance and data systems. Agile Revisions : Confirms that dependencies identified in the PDR have a resolution strategy that will be completed in time to enable development of the dependent features (will not become impediments during development). Confirms that features are ready for further refinement into work items for the development team. Agenda Template : Review Release Roadmap Review Features for the upcoming release. Review Feature description Review Feature acceptance criteria Review Features system-level design integration and system requirements: UI change requirements (mock-ups if available) Middle tier requirements (services) Data structure requirements Review Feature dependencies to ensure they have been resolved or a feasible resolution strategy is in place prior to beginning work on the feature (these address the initial assumptions determined during the PDR) Review Feature CDRL requirements - update as required Review Feature size estimates (establishes metric for estimating duration) - update based on additional information Revise Release Roadmap as necessary based on updated information","title":"5.1.4 System Engineering Design Reviews"},{"location":"agile/5-1-backlog/#515-refine-the-product-backlog-features-initial-pbis","text":"In general, the refinement process establishes the \"development language\" between the Development Team and the Government through their designated PO. Feature refinement should be conducted about 2 months prior to working on the first PBI of the feature. The objectives of feature refinement are to: Break down feature to individual PBIs (user stories, cards, work items, etc) with, at a minimum, a description and acceptance criteria; Provide an initial estimate of the complexity of the work item (sizing estimates can be associated with established costs and used for EV metrics); Gain the formal approval of the PO to include the refined work items into the Product Backlog. Feature refinement in preparation for development work conducted between the government PO and Development Team: Normally takes 1-2 hours per feature if done correctly (the more discussion, the better clarity of understanding between the government and the development team increasing the likelihood that the development product will meet government expectations). Refine initial title, description, acceptance criteria at the feature - level based on knowledge acquired since design review - this is the focus of the PMO input - provides the WHAT of the feature. Identify the logic of the work. Identify the initial user stories. Ensure that the stories have a description and acceptance criteria which provide a common reference for the team to produce an initial sizing estimate (provides metric for EV - can be updated later). Identify infrastructure requirements (i.e. suites) necessary for development. Three questions to guide Feature Refinement Discussion and what they are attempting to elicit: What do you want to see at the end? (Acceptance Criteria) What are the high-level steps to get there? (Logic) What are the sub-steps for each of the high-level steps? (PBIs)","title":"5.1.5 Refine the Product Backlog (Features -&gt; Initial PBIs)"},{"location":"agile/5-1-backlog/#516-prioritize-the-product-backlog","text":"Agile is about providing value to the government customer as quickly as possible. Less valuable work is ranked lower in the priority scale. Thus, after refinement of the features into PBIs within the PB, it is necessary to rank them based on the value they provide. There are multiple considerations in evaluating the value of each individual PBI including: What provides most value functionally to the government user? What impact does the PBI have on other items within the backlog (i.e. are their dependencies between work items)? Cost / impact assessment of each PBI. Learning - Are their efficiencies to be gained for the remaining work items by completing a specific story earlier (i.e. taking a smaller item which is easier to do to establish the templates and processes for doing more complex work items of a similar nature later but at a more rapid pace)? Are their negative impacts to other PBIs by not completing one earlier? Regulatory deadlines (not considered agile, but is a consideration for prioritization) It is the responsibility of the PO, as the representative of the government to continuously reprioritize the PB to provide the most value to the government based on the current environment (especially as new PBIs are added or removed from the PB). Prioritization considerations to avoid (as they are normally short-term perspectives which may reduce long-term value): Highest Ranking Person in the Room Flavor of the Day","title":"5.1.6 Prioritize the Product Backlog"},{"location":"agile/5-1-backlog/#517-constraints-analysis","text":"The above sections focus on refining requirements into work items, but there are several; other areas of regulatory constraints within the governmental regulatory environment that should be addressed prior to determining as well as implementing an Agile development methodology. The following is a non-exhaustive list of items that may impact the execution of development based on scope (these provide a basis for discussion between the Government and Development Team to determine which will be enforced and to what level): External testing requirements such as DT&E and QT&E (capacity may be required to prepare and support testing - need to delineate what falls to the development team and what will be done by the government) Additional BPD Design, Test, Functional Readiness Reviews (all come with a preparation and documentation overhead - will need to discuss expectations and agile modifications based on iterative versus up front design) Development environment limitations (discussion around whether the contractor will control the environment or whether it is an externally administered environment - I.e. the Capabilities Integration Environment (CIE)) Access requirements (security requirements may dictate which personnel resources can be allocated to a team) Re-usability and compatibility requirements (establishes the boundaries of initiative for the developers - \"can be innovative within these limits\") Cybersecurity requirements (the pre-requisite cybersecurity requirements may limit development options)","title":"5.1.7 Constraints Analysis"},{"location":"agile/5-1-backlog/#518-change-management","text":"While there is an inherent flexibility within Agile methodologies to accept change specifically through backlog grooming and PBI refinement, there is still the challenge of differentiating between contractual scope additions versus simple requirement refinement. The differentiation of what will be left within the authority of the PO to approve through backlog refinement and what requirement changes need formal approval in the form of a Configuration Change Directive (CCD) should be established prior to the beginning of development to ensure proper steps are taken within the established constraints to adapt to change. When a formal configuration change is necessary, the government Configuration Control Board (CCB) with input from the Functional Review Board (FRB) should: Review the list of any new user requests, deficiency reports and change requests received in the project space; Assess the impact of a change; Assign a priority to the change; Assign a business value to the change; and Implement a CCD to insert an approved work item for the change into the Product Backlog (upon completion of any contractual modification requirements to accept in the new work)","title":"5.1.8 Change Management"},{"location":"agile/5-2-methodology/","text":"5.2 Part II - Establish the Methodology: 5.2.1 Definition of \"Ready\" and \"done\" Prior to implementing a specific development methodology, the definitions for the development entry and exit criteria need to be defined. Thus, prior to beginning development through any of the methodologies, two definitions should be agreed upon between the PO and development team in reference to individual PBIs: Deifinition of Ready Purpose Describes materials and topics that must be included and addressed in well written backlog items (I.e. Scrum / XP User Stories, Kanban cards) Used to evaluate whether or not a PBI has been appropriately elaborated and is ready for development Helps ensure that backlog items are complete and understandable before being scheduled for an iteration. EXAMPLE DEFINITION OF READY CHECKLIST Description clearly states the who (\"As a\"), what (\"I want to\"), and why (\"so that\") are for the backlog item PO has approved the backlog item Acceptance criteria is clearly defined Scenarios and expected outcomes are clearly defined Artifacts defining user interface requirements are included (if applicable) Business rules are referenced or included (if applicable) Dependencies are identified Development Team has reviewed and confirmed they understand the backlog item Backlog item is appropriately estimated (I.e. sized for scrum) \"Definition of Done\" for the PBI is understood Definition of Done Purpose The \"Definition of Done\" describes criterion that must be met by each committed User Story or Defect to development before the PO can validate that the PBI is accepted. Definition is used to help ensure that the developed product is consistent with the associated backlog item, is high quality, and is ready for production testing. \"Done\" establishes quality norms and assures the PO that major defects are not likely to be identified during production testing EXAMPLE DEFINITION OF DONE CHECKLIST Unit testing and module testing are complete All acceptance criteria defined within the PBI are met Test results have been reviewed with the PO The PO concurs with the adequacy of the testing The backlog item has passed acceptance testing by the PO The development product has been demonstrated and accepted by the PO 5.2.2 Scrum This section provides a template for the scrum process. As it is a template, government and development teams are encouraged to adapt the process based on team structure, culture and regulatory constraints to make it more efficient. To that effect, this section is prescriptive versus directive in nature. Also note that we have transitioned from the general agile term of PBI to user stories as they relate to Scrum. Scrum Methodology: Scrum Events The five key Scrum events are: Product Backlog Refinement - Based on the project release roadmap and PO priorities, there are two components to refinement: Feature Refinement - Breaking down features and setting priorities (this process was explained in Section 5.1.5 above under feature refinement) User Story Refinement - Grooming user stories so that they are ready to be accepted into a sprint Sprint Planning: Determining the goals and related stories for a sprint Sprint Execution - Developing and testing stories so they are done Sprint Review - Providing feedback to improve the product Sprint Retrospective - Determining how to improve the process Product Backlog Refinement Feature Refinement Session (2 Sprints early) : Coordinated by the Scrum Master with the Solution Architect and Customer System Engineer (and POs if available) to: Ensure that the feature acceptance criteria are still correct for upcoming features originally determined during Sprint 0 activities. Ensure that all dependencies (possible future impediments) have a resolution strategy prior to development. Ensure that design tenets are understood within the context of the feature work. User Story Refinement Collaboration (Between Feature and User Story Refinement Sessions) : Team designated Business Analyst works collaboratively with the PO to refine story priority and the acceptance criteria necessary to accomplish the associated feature functionality. Team testers can also add necessary positive test cases based on draft acceptance criteria to the story (facilitates test driven development). Refinement Session - User Stories (1 Sprint early) : Business Analyst discusses each story with the development team to ensure understanding of delivery requirements. The PO is included in this refinement session, but it is the development team that is being introduced to the stories. The PO is there to confirm through listening to the team's conversations with the Business Analyst that his/her intent is understood within the context of the story. This refinement session is done to ensure that each story meets the established Definition of Ready prior to being accepted into the sprint for development. Meeting the Definition of Ready : The acronym INVEST provides a high-level cross-check of whether a story is Ready for development. It is normally part of the last check done on a story during either Refinement Day activities or as part of Sprint Planning for priority stories that have been updated since Refinement Day. While it is presented here under the Scrum section, it can be used with modification (I.e. Kanban work flow estimates versus sprint estimates) within the other agile frameworks as a final check for each PBI). The acronym represents the following criteria: (I) Independent - Story contains no dependencies on unavailable external resources or preparatory user story completion (N) Negotiable - Three perspectives must be represented in refinement of the user story to meet the PO's intent - Business Analyst, Developer, Tester - if they have not been involved in refinement, a key perspective on the complexity of the story is missing from the preparatory analysis. (V) Valuable - Established by the prioritization given by the POs. (E) Estimable - Estimates provide a gage for the acceptance of future work levels into a sprint as well as for forecasting future work timelines - they gain value over time as the team evolves. (S) Small - User stories should be small enough to complete within a sprint while large enough to provide observable value to the PO. (T) Testable - Positive manual test cases will be added to appropriate user stories prior to being taken into the sprint to account for successful achievement of acceptance criteria. As necessary, these tests will be augmented during the sprint with additional negative manual and automated tests. Based on the high-level of interaction between the team and the PO in this option, each story should have as a minimum 3 touch points with the PO to confirm that PO's intent is maintained throughout refinement. At a minimum, these touch points are the verification of the acceptance criteria in the documentation, the answering of team questions during team refinement of stories, and the final acceptance of the story as ready for development At this point the story is considered \"ready\" for acceptance into a sprint during sprint planning. Sprint Planning Sprint Planning (Appendix A) Planning centers around the presence of the PO within the Planning meeting. During this meeting, the PO will review the current list of Ready user stories to ensure that they are still valuable (relevant), as well as reprioritize the Backlog based on existing value as necessary (this facilitates the team's acceptance of work into the sprint as they simply take user stories from the top of the list within their established sprint capacity. Sprint Execution Sprint Execution (Appendix A) While developers and testers work to complete and validate the work required for each user story, Business Analysts and, if necessary, POs are available for clarification of requirements to ensure that the work produced meets the intent of the customer. If refinement has been done correctly, sprint execution consists of developers completing their work, testers executing the tests developed prior to the sprint (with the addition of any necessary negative test cases), and BAs and testers reviewing the completed work with the PO in order to receive early feedback or formal closure of the story as meeting the teams \"Definition of Done\". The user story acceptance criteria is the foundation for this definition. The story points assigned to sprint user stories not designated as \"Done\" are not counted when measuring sprint completion velocity. Sprint Review Sprint Review (Appendix A) Story acceptance as Done is completed by the PO only (the same person who approves the acceptance criteria must be the person who approves work against the approved acceptance criteria). If the PO believes that the work does not satisfy the customer requirements, they have to make a decision: if the work does not meet the acceptance criteria, they can reject the work as not done and provide additional clarification; if the work meets the acceptance criteria, but the PO wants additional revisions, additional user stories are created and prioritized within the existing backlog. The key to the review is that it is interactive between the PO and Development Team - the focus being to improve the product. Sprint Retrospective Sprint Retrospective (Appendix A) This is where the POs and the Development Team focus on improving the Agile process. Critical to understanding the concept of the retrospective is that learning always occurs during these events (Successful sprints can indicate items to sustain; failed sprints provide opportunities to learn where the team can improve). One note to remember in the retrospective is that the process should facilitate the development efforts - not impede them (hence why this document is presented as a template - it needs to be adjusted to fit the needs of the agile environment in which it exists which is a combination of the people, processes, tools, relationships and levels of trust involved in the project).","title":"5.2 Part II - Establish the Methodology"},{"location":"agile/5-2-methodology/#52-part-ii-establish-the-methodology","text":"","title":"5.2 Part II - Establish the Methodology:"},{"location":"agile/5-2-methodology/#521-definition-of-ready-and-done","text":"Prior to implementing a specific development methodology, the definitions for the development entry and exit criteria need to be defined. Thus, prior to beginning development through any of the methodologies, two definitions should be agreed upon between the PO and development team in reference to individual PBIs: Deifinition of Ready Purpose Describes materials and topics that must be included and addressed in well written backlog items (I.e. Scrum / XP User Stories, Kanban cards) Used to evaluate whether or not a PBI has been appropriately elaborated and is ready for development Helps ensure that backlog items are complete and understandable before being scheduled for an iteration. EXAMPLE DEFINITION OF READY CHECKLIST Description clearly states the who (\"As a\"), what (\"I want to\"), and why (\"so that\") are for the backlog item PO has approved the backlog item Acceptance criteria is clearly defined Scenarios and expected outcomes are clearly defined Artifacts defining user interface requirements are included (if applicable) Business rules are referenced or included (if applicable) Dependencies are identified Development Team has reviewed and confirmed they understand the backlog item Backlog item is appropriately estimated (I.e. sized for scrum) \"Definition of Done\" for the PBI is understood Definition of Done Purpose The \"Definition of Done\" describes criterion that must be met by each committed User Story or Defect to development before the PO can validate that the PBI is accepted. Definition is used to help ensure that the developed product is consistent with the associated backlog item, is high quality, and is ready for production testing. \"Done\" establishes quality norms and assures the PO that major defects are not likely to be identified during production testing EXAMPLE DEFINITION OF DONE CHECKLIST Unit testing and module testing are complete All acceptance criteria defined within the PBI are met Test results have been reviewed with the PO The PO concurs with the adequacy of the testing The backlog item has passed acceptance testing by the PO The development product has been demonstrated and accepted by the PO","title":"5.2.1 Definition of \"Ready\" and \"done\""},{"location":"agile/5-2-methodology/#522-scrum","text":"This section provides a template for the scrum process. As it is a template, government and development teams are encouraged to adapt the process based on team structure, culture and regulatory constraints to make it more efficient. To that effect, this section is prescriptive versus directive in nature. Also note that we have transitioned from the general agile term of PBI to user stories as they relate to Scrum. Scrum Methodology: Scrum Events The five key Scrum events are: Product Backlog Refinement - Based on the project release roadmap and PO priorities, there are two components to refinement: Feature Refinement - Breaking down features and setting priorities (this process was explained in Section 5.1.5 above under feature refinement) User Story Refinement - Grooming user stories so that they are ready to be accepted into a sprint Sprint Planning: Determining the goals and related stories for a sprint Sprint Execution - Developing and testing stories so they are done Sprint Review - Providing feedback to improve the product Sprint Retrospective - Determining how to improve the process Product Backlog Refinement Feature Refinement Session (2 Sprints early) : Coordinated by the Scrum Master with the Solution Architect and Customer System Engineer (and POs if available) to: Ensure that the feature acceptance criteria are still correct for upcoming features originally determined during Sprint 0 activities. Ensure that all dependencies (possible future impediments) have a resolution strategy prior to development. Ensure that design tenets are understood within the context of the feature work. User Story Refinement Collaboration (Between Feature and User Story Refinement Sessions) : Team designated Business Analyst works collaboratively with the PO to refine story priority and the acceptance criteria necessary to accomplish the associated feature functionality. Team testers can also add necessary positive test cases based on draft acceptance criteria to the story (facilitates test driven development). Refinement Session - User Stories (1 Sprint early) : Business Analyst discusses each story with the development team to ensure understanding of delivery requirements. The PO is included in this refinement session, but it is the development team that is being introduced to the stories. The PO is there to confirm through listening to the team's conversations with the Business Analyst that his/her intent is understood within the context of the story. This refinement session is done to ensure that each story meets the established Definition of Ready prior to being accepted into the sprint for development. Meeting the Definition of Ready : The acronym INVEST provides a high-level cross-check of whether a story is Ready for development. It is normally part of the last check done on a story during either Refinement Day activities or as part of Sprint Planning for priority stories that have been updated since Refinement Day. While it is presented here under the Scrum section, it can be used with modification (I.e. Kanban work flow estimates versus sprint estimates) within the other agile frameworks as a final check for each PBI). The acronym represents the following criteria: (I) Independent - Story contains no dependencies on unavailable external resources or preparatory user story completion (N) Negotiable - Three perspectives must be represented in refinement of the user story to meet the PO's intent - Business Analyst, Developer, Tester - if they have not been involved in refinement, a key perspective on the complexity of the story is missing from the preparatory analysis. (V) Valuable - Established by the prioritization given by the POs. (E) Estimable - Estimates provide a gage for the acceptance of future work levels into a sprint as well as for forecasting future work timelines - they gain value over time as the team evolves. (S) Small - User stories should be small enough to complete within a sprint while large enough to provide observable value to the PO. (T) Testable - Positive manual test cases will be added to appropriate user stories prior to being taken into the sprint to account for successful achievement of acceptance criteria. As necessary, these tests will be augmented during the sprint with additional negative manual and automated tests. Based on the high-level of interaction between the team and the PO in this option, each story should have as a minimum 3 touch points with the PO to confirm that PO's intent is maintained throughout refinement. At a minimum, these touch points are the verification of the acceptance criteria in the documentation, the answering of team questions during team refinement of stories, and the final acceptance of the story as ready for development At this point the story is considered \"ready\" for acceptance into a sprint during sprint planning. Sprint Planning Sprint Planning (Appendix A) Planning centers around the presence of the PO within the Planning meeting. During this meeting, the PO will review the current list of Ready user stories to ensure that they are still valuable (relevant), as well as reprioritize the Backlog based on existing value as necessary (this facilitates the team's acceptance of work into the sprint as they simply take user stories from the top of the list within their established sprint capacity. Sprint Execution Sprint Execution (Appendix A) While developers and testers work to complete and validate the work required for each user story, Business Analysts and, if necessary, POs are available for clarification of requirements to ensure that the work produced meets the intent of the customer. If refinement has been done correctly, sprint execution consists of developers completing their work, testers executing the tests developed prior to the sprint (with the addition of any necessary negative test cases), and BAs and testers reviewing the completed work with the PO in order to receive early feedback or formal closure of the story as meeting the teams \"Definition of Done\". The user story acceptance criteria is the foundation for this definition. The story points assigned to sprint user stories not designated as \"Done\" are not counted when measuring sprint completion velocity. Sprint Review Sprint Review (Appendix A) Story acceptance as Done is completed by the PO only (the same person who approves the acceptance criteria must be the person who approves work against the approved acceptance criteria). If the PO believes that the work does not satisfy the customer requirements, they have to make a decision: if the work does not meet the acceptance criteria, they can reject the work as not done and provide additional clarification; if the work meets the acceptance criteria, but the PO wants additional revisions, additional user stories are created and prioritized within the existing backlog. The key to the review is that it is interactive between the PO and Development Team - the focus being to improve the product. Sprint Retrospective Sprint Retrospective (Appendix A) This is where the POs and the Development Team focus on improving the Agile process. Critical to understanding the concept of the retrospective is that learning always occurs during these events (Successful sprints can indicate items to sustain; failed sprints provide opportunities to learn where the team can improve). One note to remember in the retrospective is that the process should facilitate the development efforts - not impede them (hence why this document is presented as a template - it needs to be adjusted to fit the needs of the agile environment in which it exists which is a combination of the people, processes, tools, relationships and levels of trust involved in the project).","title":"5.2.2 Scrum"},{"location":"agile/5-3-kanban/","text":"5.3 Kanban Considerations for establishing a Kanban process: Establish the Kanban Board - Visualize the workflow to organize, optimize, and track the work item development progress (allows for transparency of status) Limit Work in Progress (WIP) - Kanban is about flow. The more items in progress, the more risk of nothing getting done. It is better to have a limited WIP that emphasizes the Lean pull system. That is, when a resource has completed work on a work item and moved it to the next column, s/he pulls the next work item from the column before it. A starting rule for each policy column is limit WIP to amount of column resources + 1 (i.e. for a development column - the WIP would be the number of developers on the team plus one - that allows for a developer who hits an impediment to stop work on that work item and pull another one from those completed in the previous column while the Agile Lead works to remove the impediment. This allows for the flow to continue). Key points in Kanban: Minimize Lead Time (the time a work item is in any specific stage / column) Minimize Cycle Time (the time for the entire work flow cycle to complete for a single work item) - since establishing a cycle time allows for estimation of work items, but not all work items are the same complexity - one methodology for differentiating the work item complexity is to provide multiple swim lanes for tracking work progress - One for work items which have an expected cycle time of 1 week One for 2-week items One for 1-month items Optional - an expedited swim lane (similar to the express lane at a supermarket) for high-priority work items that should take precedence over all others (this will be mentioned again as a strategy for using Kanban to manage Operations and Maintenance work items) Manage flow - The Agile Lead works with the development team to ensure that workflow issues are identified and resolved (i.e. if there is a backup in the workflow, an additional resource may be needed to relieve pressure on the bottleneck column) Make process policies explicit - Each column on the Kanban Board should have an explicit policy which indicates when the work in that column is complete (policy = that column's \"Definition of Done\") Improve the process - In collaboration between the development team and PMO - there should be a focus on continuous improvement of the process (re-define the policies, determine whether columns should be added, determine whether columns should be deleted) While Scrum focuses on a cross-functional team, Kanban focuses more on aligning the resources with the policies. A simple representation of a Kanban Board (this also provides a quick start-up template for HIA products) is: Templated steps / policies for an initial Development Team Kanban board: Backlog : PMO PO prioritizes the Work Items in the Backlog Identify : Development Team Business Analyst in coordination with the PMO PO will identify / refine the description and acceptance criteria for the work item PO Approved : PMO PO will approve the description and acceptance criteria (Confirms that the work meets functional requirements - think mini-PDR) Design : Development Team's Senior Developer will complete draft solution design Cyber Assessment : Developer's cybersecurity representative (ICW PMO Cybersecurity) will complete security assessment of solution PMO Engineer Approved : PMO Engineer will approve design of solution (Confirm that solution meets technical requirements - think mini-CDR) - work item now \"ready\" for development. Develop / Implement : Developers implement the solution Test : Development team testers and cybersecurity will conduct testing and update documentation as needed Pending Acceptance : Development team will demonstrate completed work item functionality to PMO Done : PMO will accept work item as complete (meets the Definition of Done) An Operations and Maintenance team provides an example of a project built for Kanban. The backlog would contain the ticket items requiring resolution with the priority of work established by a government Product Owner. This approach allows refinement of last minute prioritized work items identified by system users through the workflow's column policies identified above (the process of making the work item \"ready\" is captured within the workflow). Also, if the Kanban board swim lanes are setup as described above, the board will contain an expedite lane for flowing through critical fixes requiring short duration resolution. (Note: Another example would be the cybersecurity team handling the implementation of required TCNO/IAVAs.) 5.3.1 Kanban Cadences While Scrum Events focus on execution of the time-boxed process, the key Kanban events (cadences - named for their formal rhythm) focus on organizing, optimizing, and tracking the development process. The cadences indicated below are interdependent as represented in the figure above - some meetings inform others, while feedback from other meetings drive changes to the process. Strategy Review (Release Management) - Are the Backlog priorities still correct? Is the Release Roadmap up to date? Play: Link to Play below in the Appendix Overview: A Strategy Review session is held to periodically review the current status of the development effort as well as revise the Release Roadmap to ensure that it correctly reflects current value and priorities. The question answered during this meeting is: Are we doing the right thing? The Release Management process described before represents an example of the events and timelines reflected within this cadence. Example cadence : Quarterly or based on release period - should look at current and next release and how the PB reflects that plan / strategy. Stand-ups - Focused on the Kanban board and managing workflow Play: Link to Play below in the Appendix Overview: While the focus of the Scrum stand-up meeting is on the individual work and how it relates to the team's ability to meet sprint (time-boxed) goals (What did I do yesterday? What will I do today? What is impeding my work?), the focus of the stand-up for Kanban is managing the flow of work items among the Development Team resources to make it as efficient as possible (managing workflow to minimize the time any piece of work is in any stage of development). While the stand-up can be done daily, it is not a requirement of Kanban as the trigger for work to be pulled into the next column is automatic (completion of the column policy for that work item and next column resource availability). The cadence recommendation of a week is a goal - the team will most likely start out in a daily cadence until the workflow is better understood. Example cadence : Initially daily. Can evolve to once a week to coordinate the efforts of the team and resolve work-in-progress bottlenecks. Replenishment Meeting - Similar to the Sprint planning sessions - these meetings ensure that the work items which will be brought into the development stream are prioritized and \"ready\" to be worked on. Play: Link to Play below in the Appendix Overview: The replenishment meeting ensures that there is \"ready\" work prioritized in the backlog to be brought into the workflow. The battle rhythm for when these meetings are necessary are dependent on the workflow (the recommendation is to start by having this monthly and then determine whether it should happen more or less often). It should take the work that the government has identified (refined down to the work item level) and ensure that the work is \"ready\" to enter into the workflow. It is the last step in determining which prioritized work is up next and ensuring that the work still adds value to the government. Example cadence : Once every month (or as necessary to ensure that there is a \"ready\" backlog of work to feed the development stream). Delivery Planning Meeting - This meeting coordinates product hand-off based on current work delivered between multiple entities: Developers, Product Owners, Testers, Trainers, Users (can be facilitated with establishment of Continuous Delivery process and structure). Play: Link to Play below in the Appendix Overview: The Delivery Planning meeting is a discussion between multiple entities of the results of the actual workflow (while the Strategy Meeting establishes a plan, the Delivery Planning Meeting looks at the reality). An assessment is made of the Kanban board to determine what work in progress will be completed by a specific time to pass it on to the next entity in the chain. It is about establishing expectation management so that external agencies can plan for events which are dependent on the contents of the delivery. These include: - PMO ensuring that reviewers are ready to conduct the Physical Configuration Audits and appropriate document reviews, - The LDTO agency coordinating testing events based on specific RALOT. - Users providing timely feedback; - Functionals coordinating training events so that released functionality into production can be used. Example cadence : Once every month to update downfield receivers of the product (highly dependent on the release timeline - i.e. a release once a quarter might only require this meeting once a quarter). Operations Review - How do we improve the process from the organization's point of view Play: Link to Play below in the Appendix Overview: This review is similar to a Scrum retrospective (how to improve the process) but looks at the release management system from an organizational point of view. It looks at improving the entire system as it relates to incorporating the Kanban team workflow methodology into the government review and release system. While the Delivery Planning Meeting focuses on coordinating the efficient release of the product, this meeting is about improving the release process based on lessons learned. It looks back on each release from the perspective of all stakeholders to continuously improve the system for the next release. Example cadence : Once every 3 months (or by exception) following the Release Delivery Service Delivery Review - Review of the release product from the user's point of view. Play: Link to Play below in the Appendix Overview: This review is conducted to determine if the items being produced are actually meeting the user's needs. The Service Delivery Review focuses on what was produced from the end-user's point of view and whether it fulfills their functional needs as well as quality standards. It provides a direct feedback chain from the end user to allow the PMO PO insight into requirement and prioritization changes, as well as the development team to understand better how their product is being viewed by the users of the system (including their satisfaction and concerns). Example cadence: Once every 3 months (or by exception) following the Release Delivery. Frequency will vary based on user first look events or actual releases to the field - need to provide end-user enough time to review delivered product. Risk Review - Done as necessary to review all identified risks to determine the status of risk mitigation measures and issue / impediment resolution. Play: Link to Play below in the Appendix Overview: The Risk Review discusses the probability and impact of planning assumptions being wrong and what steps the PMO and development team are taking to minimize those risks. It focuses on what steps are being taken to minimize the probability of false assumptions impacting delivery cost or schedule. This review focuses on reduces uncertainties in the system in order to establish predictability and reliability in the system which enables trust to form within the different organizational entities including the PMO, development team, external testers, users, etc. Example cadence : Once every 2 weeks (or combined with PMO Risk Management Meeting)","title":"5.3 Kanban"},{"location":"agile/5-3-kanban/#53-kanban","text":"Considerations for establishing a Kanban process: Establish the Kanban Board - Visualize the workflow to organize, optimize, and track the work item development progress (allows for transparency of status) Limit Work in Progress (WIP) - Kanban is about flow. The more items in progress, the more risk of nothing getting done. It is better to have a limited WIP that emphasizes the Lean pull system. That is, when a resource has completed work on a work item and moved it to the next column, s/he pulls the next work item from the column before it. A starting rule for each policy column is limit WIP to amount of column resources + 1 (i.e. for a development column - the WIP would be the number of developers on the team plus one - that allows for a developer who hits an impediment to stop work on that work item and pull another one from those completed in the previous column while the Agile Lead works to remove the impediment. This allows for the flow to continue). Key points in Kanban: Minimize Lead Time (the time a work item is in any specific stage / column) Minimize Cycle Time (the time for the entire work flow cycle to complete for a single work item) - since establishing a cycle time allows for estimation of work items, but not all work items are the same complexity - one methodology for differentiating the work item complexity is to provide multiple swim lanes for tracking work progress - One for work items which have an expected cycle time of 1 week One for 2-week items One for 1-month items Optional - an expedited swim lane (similar to the express lane at a supermarket) for high-priority work items that should take precedence over all others (this will be mentioned again as a strategy for using Kanban to manage Operations and Maintenance work items) Manage flow - The Agile Lead works with the development team to ensure that workflow issues are identified and resolved (i.e. if there is a backup in the workflow, an additional resource may be needed to relieve pressure on the bottleneck column) Make process policies explicit - Each column on the Kanban Board should have an explicit policy which indicates when the work in that column is complete (policy = that column's \"Definition of Done\") Improve the process - In collaboration between the development team and PMO - there should be a focus on continuous improvement of the process (re-define the policies, determine whether columns should be added, determine whether columns should be deleted) While Scrum focuses on a cross-functional team, Kanban focuses more on aligning the resources with the policies. A simple representation of a Kanban Board (this also provides a quick start-up template for HIA products) is: Templated steps / policies for an initial Development Team Kanban board: Backlog : PMO PO prioritizes the Work Items in the Backlog Identify : Development Team Business Analyst in coordination with the PMO PO will identify / refine the description and acceptance criteria for the work item PO Approved : PMO PO will approve the description and acceptance criteria (Confirms that the work meets functional requirements - think mini-PDR) Design : Development Team's Senior Developer will complete draft solution design Cyber Assessment : Developer's cybersecurity representative (ICW PMO Cybersecurity) will complete security assessment of solution PMO Engineer Approved : PMO Engineer will approve design of solution (Confirm that solution meets technical requirements - think mini-CDR) - work item now \"ready\" for development. Develop / Implement : Developers implement the solution Test : Development team testers and cybersecurity will conduct testing and update documentation as needed Pending Acceptance : Development team will demonstrate completed work item functionality to PMO Done : PMO will accept work item as complete (meets the Definition of Done) An Operations and Maintenance team provides an example of a project built for Kanban. The backlog would contain the ticket items requiring resolution with the priority of work established by a government Product Owner. This approach allows refinement of last minute prioritized work items identified by system users through the workflow's column policies identified above (the process of making the work item \"ready\" is captured within the workflow). Also, if the Kanban board swim lanes are setup as described above, the board will contain an expedite lane for flowing through critical fixes requiring short duration resolution. (Note: Another example would be the cybersecurity team handling the implementation of required TCNO/IAVAs.)","title":"5.3 Kanban"},{"location":"agile/5-3-kanban/#531-kanban-cadences","text":"While Scrum Events focus on execution of the time-boxed process, the key Kanban events (cadences - named for their formal rhythm) focus on organizing, optimizing, and tracking the development process. The cadences indicated below are interdependent as represented in the figure above - some meetings inform others, while feedback from other meetings drive changes to the process. Strategy Review (Release Management) - Are the Backlog priorities still correct? Is the Release Roadmap up to date? Play: Link to Play below in the Appendix Overview: A Strategy Review session is held to periodically review the current status of the development effort as well as revise the Release Roadmap to ensure that it correctly reflects current value and priorities. The question answered during this meeting is: Are we doing the right thing? The Release Management process described before represents an example of the events and timelines reflected within this cadence. Example cadence : Quarterly or based on release period - should look at current and next release and how the PB reflects that plan / strategy. Stand-ups - Focused on the Kanban board and managing workflow Play: Link to Play below in the Appendix Overview: While the focus of the Scrum stand-up meeting is on the individual work and how it relates to the team's ability to meet sprint (time-boxed) goals (What did I do yesterday? What will I do today? What is impeding my work?), the focus of the stand-up for Kanban is managing the flow of work items among the Development Team resources to make it as efficient as possible (managing workflow to minimize the time any piece of work is in any stage of development). While the stand-up can be done daily, it is not a requirement of Kanban as the trigger for work to be pulled into the next column is automatic (completion of the column policy for that work item and next column resource availability). The cadence recommendation of a week is a goal - the team will most likely start out in a daily cadence until the workflow is better understood. Example cadence : Initially daily. Can evolve to once a week to coordinate the efforts of the team and resolve work-in-progress bottlenecks. Replenishment Meeting - Similar to the Sprint planning sessions - these meetings ensure that the work items which will be brought into the development stream are prioritized and \"ready\" to be worked on. Play: Link to Play below in the Appendix Overview: The replenishment meeting ensures that there is \"ready\" work prioritized in the backlog to be brought into the workflow. The battle rhythm for when these meetings are necessary are dependent on the workflow (the recommendation is to start by having this monthly and then determine whether it should happen more or less often). It should take the work that the government has identified (refined down to the work item level) and ensure that the work is \"ready\" to enter into the workflow. It is the last step in determining which prioritized work is up next and ensuring that the work still adds value to the government. Example cadence : Once every month (or as necessary to ensure that there is a \"ready\" backlog of work to feed the development stream). Delivery Planning Meeting - This meeting coordinates product hand-off based on current work delivered between multiple entities: Developers, Product Owners, Testers, Trainers, Users (can be facilitated with establishment of Continuous Delivery process and structure). Play: Link to Play below in the Appendix Overview: The Delivery Planning meeting is a discussion between multiple entities of the results of the actual workflow (while the Strategy Meeting establishes a plan, the Delivery Planning Meeting looks at the reality). An assessment is made of the Kanban board to determine what work in progress will be completed by a specific time to pass it on to the next entity in the chain. It is about establishing expectation management so that external agencies can plan for events which are dependent on the contents of the delivery. These include: - PMO ensuring that reviewers are ready to conduct the Physical Configuration Audits and appropriate document reviews, - The LDTO agency coordinating testing events based on specific RALOT. - Users providing timely feedback; - Functionals coordinating training events so that released functionality into production can be used. Example cadence : Once every month to update downfield receivers of the product (highly dependent on the release timeline - i.e. a release once a quarter might only require this meeting once a quarter). Operations Review - How do we improve the process from the organization's point of view Play: Link to Play below in the Appendix Overview: This review is similar to a Scrum retrospective (how to improve the process) but looks at the release management system from an organizational point of view. It looks at improving the entire system as it relates to incorporating the Kanban team workflow methodology into the government review and release system. While the Delivery Planning Meeting focuses on coordinating the efficient release of the product, this meeting is about improving the release process based on lessons learned. It looks back on each release from the perspective of all stakeholders to continuously improve the system for the next release. Example cadence : Once every 3 months (or by exception) following the Release Delivery Service Delivery Review - Review of the release product from the user's point of view. Play: Link to Play below in the Appendix Overview: This review is conducted to determine if the items being produced are actually meeting the user's needs. The Service Delivery Review focuses on what was produced from the end-user's point of view and whether it fulfills their functional needs as well as quality standards. It provides a direct feedback chain from the end user to allow the PMO PO insight into requirement and prioritization changes, as well as the development team to understand better how their product is being viewed by the users of the system (including their satisfaction and concerns). Example cadence: Once every 3 months (or by exception) following the Release Delivery. Frequency will vary based on user first look events or actual releases to the field - need to provide end-user enough time to review delivered product. Risk Review - Done as necessary to review all identified risks to determine the status of risk mitigation measures and issue / impediment resolution. Play: Link to Play below in the Appendix Overview: The Risk Review discusses the probability and impact of planning assumptions being wrong and what steps the PMO and development team are taking to minimize those risks. It focuses on what steps are being taken to minimize the probability of false assumptions impacting delivery cost or schedule. This review focuses on reduces uncertainties in the system in order to establish predictability and reliability in the system which enables trust to form within the different organizational entities including the PMO, development team, external testers, users, etc. Example cadence : Once every 2 weeks (or combined with PMO Risk Management Meeting)","title":"5.3.1 Kanban Cadences"},{"location":"agile/5-4-xp/","text":"5.4 Extreme Programming (XP) XP's primary contribution to the software development world is an interdependent collection of engineering practices that teams can use to be more effective and produce higher quality code. Many teams adopting agile start by using a different framework and when they identify the need for more?disciplined engineering practices they adopt several if not all of the engineering practices espoused by XP. The recommended methodology here is to begin with the Scrum Framework Events listed before and then adopt as necessary the XP engineering practices which enhance the process. General differences between Scrum and XP: Scrum uses sprints which are normally 2-4 weeks long. XP uses iterations which are normally 1-2 weeks long. Sprint backlogs are normally sacred while XP embraces more flexibility if a higher priority work item comes in (understanding that it will replace an equivalent work item already accepted into the iteration). If the team identifies some stories that they are unable to estimate because they don't understand all of the technical considerations involved, they can introduce a spike to do some focused research on that particular story or a common aspect of multiple stories. Spikes are short, time-boxed time frames set aside for the purposes of doing research on a particular aspect of the project. Spikes can occur before regular iterations start or alongside ongoing iterations. XP focuses on practice excellence. The method prescribes a small number of absolutely essential practices and encourages teams to perform those practices as good as they possibly can, almost to the extreme. This is where the name comes from. Not because the practices themselves are necessarily radical rather that teams continuously focus so intently on continuously improving their ability to perform those few practices. With that in mind, the initial recommended XP methodology will focus on the following initial events with selected engineering practices being employed during execution of these events: Product Backlog Refinement Iteration Planning Iteration Iteration Review Iteration Retrospective The core of XP is the interconnected set of software development practices listed below. While it is possible to do these practices in isolation, many teams have found some practices reinforce the others and should be done in conjunction to fully eliminate the risks you often face in software development. The XP Practices have changed a bit since they were initially introduced. The original twelve practices are listed below. If you would like more information about how these practices were originally described, you can visit? http://ronjeffries.com/xprog/what-is-extreme-programming/. Planning Games Small Releases Metaphor Simple Design Testing Refactoring Pair Programming Collective Ownership Continuous Integration 40-hour week On-site Customer Coding Standard Below are the descriptions of the practices as described in the second edition of Extreme Programming Explained - Embrace?Change.?These descriptions include refinements based on experiences of many who practice extreme programming and reflect a more practical set of practices. Sit Together . Since communication is one of the five values of XP, and most people agree that face to face conversation is the best form of communication, have the team sit together in the same space without barriers to communication, such as cubicle walls (note that there are always exception to this rule for remote workers - but these exceptions should be minimized). Whole Team . A cross functional group of people with the necessary roles for a product form a single team. This means people with a need as well as all the people who play some part in satisfying that need all work together on a daily basis to accomplish a specific outcome. Informative Workspace . Set up the team space to facilitate face to face communication. Allow people to have some privacy when they need it, and make the work of the team transparent to each other and to interested parties outside the team. Utilize Information Radiators to actively communicate up-to-date information. Energized Work . Teams are most effective at software development when they are focused and free from distractions.?Energized work means taking steps to make sure the team is able physically and mentally to get into a focused state. This means do not overwork the team (surges should be minimized). Pair Programming . Pair Programming means all production software is developed by two people sitting at the same machine. The idea behind this practice is that two brains and four eyes are better than one brain and two eyes. This practice effectively provides a continuous code review and quicker response to nagging problems that may impede one person doing it on their own.?Teams that have used pair programming have found that it improves quality and does not actually take twice as long because they are able to work through problems quicker, and they stay more focused on the task at hand, thereby creating less code to accomplish the same thing. Stories . Describe what the product should do in terms meaningful to customers and users. These?stories?are intended to be short descriptions of things users want to be able to do with the product that can be used for planning and serve as reminders for more detailed conversations when the team gets around to realizing that particular story. Weekly Cycle . The Weekly Cycle is synonymous to?an?iteration. In the case of XP, the team meets on the first day of the week to reflect on progress to date, the customer picks the stories they would like delivered in that week, and the team determines how they will approach those stories. The goal by the end of the week is to have running tested features that realize the selected stories. The intent behind the time boxed delivery period is to produce something to show to the PMO for feedback. Quarterly Cycle . The Quarterly Cycle is synonymous to a release. The purpose is to keep the detailed work of each weekly cycle in context of the overall project. The Customer lays out the overall plan for the team in terms of features desired within a particular quarter, which provides the team with a view of the forest while they are in the trees, and it also helps the customer to work with other stakeholders who may need some idea of when features will be available. Remember when planning a quarterly cycle the information about any particular story is at a relatively high level, the order of story delivery within a quarterly cycle can change and the stories included in the quarterly cycle may change. Revisiting the plan following each iteration provides an opportunity to keep everyone informed as soon as those changes become apparent to keep surprises to a minimum. Slack . The idea behind slack in XP terms is to add some low priority tasks or stories in your weekly and quarterly cycles that can be dropped if the team gets behind on more important tasks or stories. Put another way, account for the inherent variability in estimates to make sure you leave yourself a good chance of meeting your forecasts. Ten-Minute Build . The goal with the Ten-Minute Build is to automatically build the whole system and run all of the tests in ten minutes. The founders of XP suggested a 10 minute time frame because if a team has a build that takes longer than that, it is less likely to be run on a frequent basis, thus introducing longer time between errors. This practice encourages the team to automate the build and test process to run on a regular basis. This practice supports the practice of Continuous Integration and is supported by the practice of Test First Development. Continuous Integration . Continuous Integration?is a practice where code changes are immediately tested when they are added to a larger code base. The benefit of this practice is the development team can catch and fix integration issues sooner. Most teams dread the code integration step because of the inherent discovery of conflicts and issues that result. Most teams take the approach \"If it hurts, avoid it as long as possible\". Practitioners of XP suggest \"if it hurts, do it more often\". The reasoning behind that approach is that if the development team experiences problems every time they integrate code, the more frequently they integrate, the smaller the changes and the easier to determine the source of the problem. This practice requires is highly dependent on Ten Minute Build and Test First Development. Test-First Programming . Instead of following the normal path of: Develop code -> write tests -> run tests The practice of Test-First Programming follows the path of Test Driven Development (TDD): Write failing automated test -> run failing test -> develop code to make test pass -> run test -> repeat As with Continuous Integration, Test-First Programming reduces the feedback cycle for developers to identify and resolve issues, thereby decreasing the number of bugs that get introduced into production. Incremental Design . The practice of?Incremental Design?suggests that the team does a little bit of work up front to understand the proper breadth-wise perspective of the system design, and then dives into the details of a particular aspect of that design when it delivers specific features. This approach reduces the cost of changes and allows the team to make design decisions when necessary based on the most current information available. The practice of Refactoring was originally listed among the 12 core, but was incorporated into the practice of Incremental Design. Refactoring is an excellent practice to use to keep the design simple, and one of the most recommended uses of refactoring is to remove duplication of processes. The biggest impact on instituting this practice is determining the scope of the governments formal design reviews (PDR/CDR) as this practice provides the inputs to these activities during the actual development iteration. 5.4.1 XP Process Cycle 5.4.2 XP Events (Similar to Scrum - minor revisions, associated engineering practices) Using the Scrum framework for the baseline of events to start the XP process, the following events are summarized here to avoid redundancy with the Scrum section above. Only key differences will be presented here along with a recommendation of which engineering processes could be incorporated into these events (note that many of the engineering practices can be employed in multiple events - below is only one recommendation): a. Product Backlog Refinement - Are the Backlog priorities still correct? Is the Release Roadmap up to date? Play: Link to Play below in the Appendix Overview : Backlog refinement focuses on providing a prioritized set of \"ready\" (see Definition of Ready above) user stories for the development team to accept into the next iteration as well as a \"ready\" reserve set of user stories which are available to the team during the iteration in case additional capacity becomes available. XP differences : Introduction of Spike to do focused research on stories which require more clarity. Applicable Engineering Practices : Quarterly Cycle, Stories, Incremental Design b. Iteration Planning - Are the Backlog priorities still correct? Is the Release Roadmap up to date? Play: Link to Play below in the Appendix Overview : During this meeting, the Product Owner will review the current list of Ready user stories to ensure that they are still valuable (relevant), as well as reprioritize the Backlog based on existing value as necessary (this facilitates the team's acceptance of work into the iteration as they simply take user stories from the top of the list within their established iteration capacity. XP differences : XP uses iterations which are normally 1-2 weeks long. Applicable Engineering Practices : Weekly Cycle, Slack c. Iteration - Are the Backlog priorities still correct? Is the Release Roadmap up to date? Play: Link to Play below in the Appendix Overview : Iteration execution consists of developers completing their work, testers executing the tests developed prior to the iteration (with the addition of any necessary negative test cases), and BAs and testers reviewing the completed work with the Product Owner in order to receive early feedback or formal closure of the story as meeting the teams \"Definition of Done\". XP differences : Focus of XP is on Test-First Programming and Pair Programming in the execution stage (tests fail at the beginning because the code is notdeveloped - working in pairs, the developers develop the code to pass the tests, when development testing is done - the team testers do a final verification of the initial tests along with any additional negative tests they have written. This process can also be facilitated by implementing a Continuous Integration system to maximize the use of automated testing. Applicable Engineering Practices : Sit Together, Informative Workspace, Energized Work, Pair Programming, Test-First Programming, Continuous Integration, Ten-Minute Build d. Iteration Review - Are the Backlog priorities still correct? Is the Release Roadmap up to date? Play: Link to Play below in the Appendix Overview : The iteration review is a presentation to Stakeholders of the completed increment based on acceptance by the Product Owner. The key to the review is that it is interactive between the Stakeholders and Development Team - the focus being to provide a feedback mechanism to improve the product. XP differences : None. Applicable Engineering Practices : None e. Iteration Retrospective - Are the Backlog priorities still correct? Is the Release Roadmap up to date? Play: Link to Play below in the Appendix Overview : This is where the Product Owners and the Development Team focus on improving the Agile process. Critical to understanding the concept of the retrospective is that learning always occurs during these events whether the iteration was successful or not. XP differences : Focus will not only be on events - it will include the team's selected engineering practices. Applicable Engineering Practices : Whole Team","title":"5.4 Extreme Programming"},{"location":"agile/5-4-xp/#54-extreme-programming-xp","text":"XP's primary contribution to the software development world is an interdependent collection of engineering practices that teams can use to be more effective and produce higher quality code. Many teams adopting agile start by using a different framework and when they identify the need for more?disciplined engineering practices they adopt several if not all of the engineering practices espoused by XP. The recommended methodology here is to begin with the Scrum Framework Events listed before and then adopt as necessary the XP engineering practices which enhance the process. General differences between Scrum and XP: Scrum uses sprints which are normally 2-4 weeks long. XP uses iterations which are normally 1-2 weeks long. Sprint backlogs are normally sacred while XP embraces more flexibility if a higher priority work item comes in (understanding that it will replace an equivalent work item already accepted into the iteration). If the team identifies some stories that they are unable to estimate because they don't understand all of the technical considerations involved, they can introduce a spike to do some focused research on that particular story or a common aspect of multiple stories. Spikes are short, time-boxed time frames set aside for the purposes of doing research on a particular aspect of the project. Spikes can occur before regular iterations start or alongside ongoing iterations. XP focuses on practice excellence. The method prescribes a small number of absolutely essential practices and encourages teams to perform those practices as good as they possibly can, almost to the extreme. This is where the name comes from. Not because the practices themselves are necessarily radical rather that teams continuously focus so intently on continuously improving their ability to perform those few practices. With that in mind, the initial recommended XP methodology will focus on the following initial events with selected engineering practices being employed during execution of these events: Product Backlog Refinement Iteration Planning Iteration Iteration Review Iteration Retrospective The core of XP is the interconnected set of software development practices listed below. While it is possible to do these practices in isolation, many teams have found some practices reinforce the others and should be done in conjunction to fully eliminate the risks you often face in software development. The XP Practices have changed a bit since they were initially introduced. The original twelve practices are listed below. If you would like more information about how these practices were originally described, you can visit? http://ronjeffries.com/xprog/what-is-extreme-programming/. Planning Games Small Releases Metaphor Simple Design Testing Refactoring Pair Programming Collective Ownership Continuous Integration 40-hour week On-site Customer Coding Standard Below are the descriptions of the practices as described in the second edition of Extreme Programming Explained - Embrace?Change.?These descriptions include refinements based on experiences of many who practice extreme programming and reflect a more practical set of practices. Sit Together . Since communication is one of the five values of XP, and most people agree that face to face conversation is the best form of communication, have the team sit together in the same space without barriers to communication, such as cubicle walls (note that there are always exception to this rule for remote workers - but these exceptions should be minimized). Whole Team . A cross functional group of people with the necessary roles for a product form a single team. This means people with a need as well as all the people who play some part in satisfying that need all work together on a daily basis to accomplish a specific outcome. Informative Workspace . Set up the team space to facilitate face to face communication. Allow people to have some privacy when they need it, and make the work of the team transparent to each other and to interested parties outside the team. Utilize Information Radiators to actively communicate up-to-date information. Energized Work . Teams are most effective at software development when they are focused and free from distractions.?Energized work means taking steps to make sure the team is able physically and mentally to get into a focused state. This means do not overwork the team (surges should be minimized). Pair Programming . Pair Programming means all production software is developed by two people sitting at the same machine. The idea behind this practice is that two brains and four eyes are better than one brain and two eyes. This practice effectively provides a continuous code review and quicker response to nagging problems that may impede one person doing it on their own.?Teams that have used pair programming have found that it improves quality and does not actually take twice as long because they are able to work through problems quicker, and they stay more focused on the task at hand, thereby creating less code to accomplish the same thing. Stories . Describe what the product should do in terms meaningful to customers and users. These?stories?are intended to be short descriptions of things users want to be able to do with the product that can be used for planning and serve as reminders for more detailed conversations when the team gets around to realizing that particular story. Weekly Cycle . The Weekly Cycle is synonymous to?an?iteration. In the case of XP, the team meets on the first day of the week to reflect on progress to date, the customer picks the stories they would like delivered in that week, and the team determines how they will approach those stories. The goal by the end of the week is to have running tested features that realize the selected stories. The intent behind the time boxed delivery period is to produce something to show to the PMO for feedback. Quarterly Cycle . The Quarterly Cycle is synonymous to a release. The purpose is to keep the detailed work of each weekly cycle in context of the overall project. The Customer lays out the overall plan for the team in terms of features desired within a particular quarter, which provides the team with a view of the forest while they are in the trees, and it also helps the customer to work with other stakeholders who may need some idea of when features will be available. Remember when planning a quarterly cycle the information about any particular story is at a relatively high level, the order of story delivery within a quarterly cycle can change and the stories included in the quarterly cycle may change. Revisiting the plan following each iteration provides an opportunity to keep everyone informed as soon as those changes become apparent to keep surprises to a minimum. Slack . The idea behind slack in XP terms is to add some low priority tasks or stories in your weekly and quarterly cycles that can be dropped if the team gets behind on more important tasks or stories. Put another way, account for the inherent variability in estimates to make sure you leave yourself a good chance of meeting your forecasts. Ten-Minute Build . The goal with the Ten-Minute Build is to automatically build the whole system and run all of the tests in ten minutes. The founders of XP suggested a 10 minute time frame because if a team has a build that takes longer than that, it is less likely to be run on a frequent basis, thus introducing longer time between errors. This practice encourages the team to automate the build and test process to run on a regular basis. This practice supports the practice of Continuous Integration and is supported by the practice of Test First Development. Continuous Integration . Continuous Integration?is a practice where code changes are immediately tested when they are added to a larger code base. The benefit of this practice is the development team can catch and fix integration issues sooner. Most teams dread the code integration step because of the inherent discovery of conflicts and issues that result. Most teams take the approach \"If it hurts, avoid it as long as possible\". Practitioners of XP suggest \"if it hurts, do it more often\". The reasoning behind that approach is that if the development team experiences problems every time they integrate code, the more frequently they integrate, the smaller the changes and the easier to determine the source of the problem. This practice requires is highly dependent on Ten Minute Build and Test First Development. Test-First Programming . Instead of following the normal path of: Develop code -> write tests -> run tests The practice of Test-First Programming follows the path of Test Driven Development (TDD): Write failing automated test -> run failing test -> develop code to make test pass -> run test -> repeat As with Continuous Integration, Test-First Programming reduces the feedback cycle for developers to identify and resolve issues, thereby decreasing the number of bugs that get introduced into production. Incremental Design . The practice of?Incremental Design?suggests that the team does a little bit of work up front to understand the proper breadth-wise perspective of the system design, and then dives into the details of a particular aspect of that design when it delivers specific features. This approach reduces the cost of changes and allows the team to make design decisions when necessary based on the most current information available. The practice of Refactoring was originally listed among the 12 core, but was incorporated into the practice of Incremental Design. Refactoring is an excellent practice to use to keep the design simple, and one of the most recommended uses of refactoring is to remove duplication of processes. The biggest impact on instituting this practice is determining the scope of the governments formal design reviews (PDR/CDR) as this practice provides the inputs to these activities during the actual development iteration.","title":"5.4 Extreme Programming (XP)"},{"location":"agile/5-4-xp/#541-xp-process-cycle","text":"","title":"5.4.1 XP Process Cycle"},{"location":"agile/5-4-xp/#542-xp-events-similar-to-scrum-minor-revisions-associated-engineering-practices","text":"Using the Scrum framework for the baseline of events to start the XP process, the following events are summarized here to avoid redundancy with the Scrum section above. Only key differences will be presented here along with a recommendation of which engineering processes could be incorporated into these events (note that many of the engineering practices can be employed in multiple events - below is only one recommendation): a. Product Backlog Refinement - Are the Backlog priorities still correct? Is the Release Roadmap up to date? Play: Link to Play below in the Appendix Overview : Backlog refinement focuses on providing a prioritized set of \"ready\" (see Definition of Ready above) user stories for the development team to accept into the next iteration as well as a \"ready\" reserve set of user stories which are available to the team during the iteration in case additional capacity becomes available. XP differences : Introduction of Spike to do focused research on stories which require more clarity. Applicable Engineering Practices : Quarterly Cycle, Stories, Incremental Design b. Iteration Planning - Are the Backlog priorities still correct? Is the Release Roadmap up to date? Play: Link to Play below in the Appendix Overview : During this meeting, the Product Owner will review the current list of Ready user stories to ensure that they are still valuable (relevant), as well as reprioritize the Backlog based on existing value as necessary (this facilitates the team's acceptance of work into the iteration as they simply take user stories from the top of the list within their established iteration capacity. XP differences : XP uses iterations which are normally 1-2 weeks long. Applicable Engineering Practices : Weekly Cycle, Slack c. Iteration - Are the Backlog priorities still correct? Is the Release Roadmap up to date? Play: Link to Play below in the Appendix Overview : Iteration execution consists of developers completing their work, testers executing the tests developed prior to the iteration (with the addition of any necessary negative test cases), and BAs and testers reviewing the completed work with the Product Owner in order to receive early feedback or formal closure of the story as meeting the teams \"Definition of Done\". XP differences : Focus of XP is on Test-First Programming and Pair Programming in the execution stage (tests fail at the beginning because the code is notdeveloped - working in pairs, the developers develop the code to pass the tests, when development testing is done - the team testers do a final verification of the initial tests along with any additional negative tests they have written. This process can also be facilitated by implementing a Continuous Integration system to maximize the use of automated testing. Applicable Engineering Practices : Sit Together, Informative Workspace, Energized Work, Pair Programming, Test-First Programming, Continuous Integration, Ten-Minute Build d. Iteration Review - Are the Backlog priorities still correct? Is the Release Roadmap up to date? Play: Link to Play below in the Appendix Overview : The iteration review is a presentation to Stakeholders of the completed increment based on acceptance by the Product Owner. The key to the review is that it is interactive between the Stakeholders and Development Team - the focus being to provide a feedback mechanism to improve the product. XP differences : None. Applicable Engineering Practices : None e. Iteration Retrospective - Are the Backlog priorities still correct? Is the Release Roadmap up to date? Play: Link to Play below in the Appendix Overview : This is where the Product Owners and the Development Team focus on improving the Agile process. Critical to understanding the concept of the retrospective is that learning always occurs during these events whether the iteration was successful or not. XP differences : Focus will not only be on events - it will include the team's selected engineering practices. Applicable Engineering Practices : Whole Team","title":"5.4.2 XP Events (Similar to Scrum - minor revisions, associated engineering practices)"},{"location":"agile/5-5-team/","text":"5.5 Part III - Establish the Team The following section provides a general overview of the roles required for effective execution of the different agile methodologies presented in this playbook. Note that these are \"roles\", and, based on the team size, can be implemented by one or more people. Also, the same person can have multiple roles (i.e. a BA and a Scrum Master) though this might not lend to optimal effectiveness. 5.5.1 Scrum Roles and Responsibilities The relationship between development team members and the PMO is critical as understanding between the two will breed the trust necessary for successful execution of an agile process. Product Owners : These are representatives of the PMO with the necessary functional knowledge of the system to be able to collaborate effectively with the development team. One of the key aspects within the government environment is that often, the Product Owner is a collection of individuals representing different perspective (Program Management, Functionality, Engineering, and Cybersecurity are examples of these perspectives). Whether there are 1 or more people representing this position, individual or group must have the ability to make decisions on the requirements to effectively collaborate with the business analyst and the development team. Note that a government Project Manager may fulfill the role of the Product Owner, but they must have the functional knowledge to allow for effective clarification of requirements to the development team. POs are responsible for establishing: a. Requirements / Acceptance Criteria b. Priorities c. Clarification on Requirements for the Development Team d. Approval of \"Done\" for stories. Development Teams : Formed around the specific projects, their purpose is to create quality code that produces value for the government. They have the following components (the size and composition of each team will vary based on the development requirements within a release): a. Scrum Master - They are the Process Advisor to the PO. b. Business Analyst(s) - Responsible for gathering the requirements and translating them into documentation which not only reflects the intent of the PObut are also understandable and executable by the developers within the team. c. Developers (General) - Responsible for - focus is functionality to the users. e. Tester / Quality Assurance (QA) - Responsible for implementation of quality within the team. 5.5.2 Kanban Roles and Responsibilities For Scrum, the Product Owner, Scrum Master and Development team roles must be assigned. In Kanban, the workflow dictates the role requirements. The refinement work can be done prior to entering the workflow (thus requiring a government Product Owner and a team Business Analyst) or the work can be part of the workflow (i.e. a column for refinement). Depending on the policies of the Kanban board workflow, resources will be allocated which can work on the work items within the column. Optimally, there would be specialists as necessary for the different workflow aspects and a couple of generalists could work to ease bottlenecks within the workflow. Additionally, while an Agile Lead familiar with Kanban would maintain the discipline within the system and would also enable faster optimization of the system, a Project Manager could also serve as the team lead for managing the workflow. However, to provide a checklist to begin with in implementing a Kanban team (and to provide flexibility to adapt to or adopt other methodologies), the recommended roles for a Kanban Team startup would be: Agile Lead / Coach - Similar to Scrum Master above but experienced in the execution of Kanban. Product Owner - Same as Product Owner in Scrum. Development Team Members - Determined as necessary to enable the workflow (i.e. business analyst, developers, testers, cybersecurity personnel as necessary based on the different policies of the Kanban Board). Key here is the team is not required to be cross-functional so can be formed around specialists and generalists as necessary. 5.5.3 XP Roles and Responsibilities Although Extreme Programming specifies engineering practices for the development team to follow, it does not really establish specific roles for the people on the team.?Depending on the reference material on roles in XP, there is either no guidance, or there is a description of how roles typically found in more traditional projects behave on Extreme Programming projects. Here are four most common roles associated with Extreme Programming:? ? The Customer - The Customer role in XP is almost exactly the same as the Product Owner Role in Scrum (same responsibilities stated above). ? ? The Developer - Because XP does not have much need for role definition, everyone on the team (with the exception of the customer and a couple of secondary roles listed below) is labeled a developer. ? The Coach - This role is similar to the Scrum Master role for Scrum. The fundamental difference is that this Agile lead should have experience with XP Practices.? The main value of the coach is that they have gone through it before and can help the team maintain practice discipline and avoid process mistakes.? 5.5.4 Roles and Responsibilities Plays Since the core roles are essentially the same between the different agile frameworks, there will only be one play for each of the roles common to all frameworks. We will not be discussing developers and testers / quality assurance here as these are roles common to IT development environment. However, when drafting job requirements, the following should be added in the preferred qualifications: Experience in agile development methodologies (Scrum, Kanban, and/or XP) The following agile related roles have plays associated with them: Agile Lead (includes Coach and Scrum Master) Product Owner Business Analyst The contents of each role play is the following: Recommended skill sets Recommended qualifications Recommended certifications General Responsibility Overview Link: Appendix B: Key Personnel Plays","title":"5.5 Part III - Establish the Team"},{"location":"agile/5-5-team/#55-part-iii-establish-the-team","text":"The following section provides a general overview of the roles required for effective execution of the different agile methodologies presented in this playbook. Note that these are \"roles\", and, based on the team size, can be implemented by one or more people. Also, the same person can have multiple roles (i.e. a BA and a Scrum Master) though this might not lend to optimal effectiveness.","title":"5.5 Part III - Establish the Team"},{"location":"agile/5-5-team/#551-scrum-roles-and-responsibilities","text":"The relationship between development team members and the PMO is critical as understanding between the two will breed the trust necessary for successful execution of an agile process. Product Owners : These are representatives of the PMO with the necessary functional knowledge of the system to be able to collaborate effectively with the development team. One of the key aspects within the government environment is that often, the Product Owner is a collection of individuals representing different perspective (Program Management, Functionality, Engineering, and Cybersecurity are examples of these perspectives). Whether there are 1 or more people representing this position, individual or group must have the ability to make decisions on the requirements to effectively collaborate with the business analyst and the development team. Note that a government Project Manager may fulfill the role of the Product Owner, but they must have the functional knowledge to allow for effective clarification of requirements to the development team. POs are responsible for establishing: a. Requirements / Acceptance Criteria b. Priorities c. Clarification on Requirements for the Development Team d. Approval of \"Done\" for stories. Development Teams : Formed around the specific projects, their purpose is to create quality code that produces value for the government. They have the following components (the size and composition of each team will vary based on the development requirements within a release): a. Scrum Master - They are the Process Advisor to the PO. b. Business Analyst(s) - Responsible for gathering the requirements and translating them into documentation which not only reflects the intent of the PObut are also understandable and executable by the developers within the team. c. Developers (General) - Responsible for - focus is functionality to the users. e. Tester / Quality Assurance (QA) - Responsible for implementation of quality within the team.","title":"5.5.1 Scrum Roles and Responsibilities"},{"location":"agile/5-5-team/#552-kanban-roles-and-responsibilities","text":"For Scrum, the Product Owner, Scrum Master and Development team roles must be assigned. In Kanban, the workflow dictates the role requirements. The refinement work can be done prior to entering the workflow (thus requiring a government Product Owner and a team Business Analyst) or the work can be part of the workflow (i.e. a column for refinement). Depending on the policies of the Kanban board workflow, resources will be allocated which can work on the work items within the column. Optimally, there would be specialists as necessary for the different workflow aspects and a couple of generalists could work to ease bottlenecks within the workflow. Additionally, while an Agile Lead familiar with Kanban would maintain the discipline within the system and would also enable faster optimization of the system, a Project Manager could also serve as the team lead for managing the workflow. However, to provide a checklist to begin with in implementing a Kanban team (and to provide flexibility to adapt to or adopt other methodologies), the recommended roles for a Kanban Team startup would be: Agile Lead / Coach - Similar to Scrum Master above but experienced in the execution of Kanban. Product Owner - Same as Product Owner in Scrum. Development Team Members - Determined as necessary to enable the workflow (i.e. business analyst, developers, testers, cybersecurity personnel as necessary based on the different policies of the Kanban Board). Key here is the team is not required to be cross-functional so can be formed around specialists and generalists as necessary.","title":"5.5.2 Kanban Roles and Responsibilities"},{"location":"agile/5-5-team/#553-xp-roles-and-responsibilities","text":"Although Extreme Programming specifies engineering practices for the development team to follow, it does not really establish specific roles for the people on the team.?Depending on the reference material on roles in XP, there is either no guidance, or there is a description of how roles typically found in more traditional projects behave on Extreme Programming projects. Here are four most common roles associated with Extreme Programming:? ? The Customer - The Customer role in XP is almost exactly the same as the Product Owner Role in Scrum (same responsibilities stated above). ? ? The Developer - Because XP does not have much need for role definition, everyone on the team (with the exception of the customer and a couple of secondary roles listed below) is labeled a developer. ? The Coach - This role is similar to the Scrum Master role for Scrum. The fundamental difference is that this Agile lead should have experience with XP Practices.? The main value of the coach is that they have gone through it before and can help the team maintain practice discipline and avoid process mistakes.?","title":"5.5.3 XP Roles and Responsibilities"},{"location":"agile/5-5-team/#554-roles-and-responsibilities-plays","text":"Since the core roles are essentially the same between the different agile frameworks, there will only be one play for each of the roles common to all frameworks. We will not be discussing developers and testers / quality assurance here as these are roles common to IT development environment. However, when drafting job requirements, the following should be added in the preferred qualifications: Experience in agile development methodologies (Scrum, Kanban, and/or XP) The following agile related roles have plays associated with them: Agile Lead (includes Coach and Scrum Master) Product Owner Business Analyst The contents of each role play is the following: Recommended skill sets Recommended qualifications Recommended certifications General Responsibility Overview Link: Appendix B: Key Personnel Plays","title":"5.5.4 Roles and Responsibilities Plays"},{"location":"agile/6-1-scrum/","text":"6.1 Scrum 6.1.1 Backlog Refinement Formal Collaboration Session 6.1.2 Sprint Planning 6.1.3 Sprint Execution 6.1.4 Sprint Review 6.1.5 Sprint Retrospective","title":"6.1 Scrum"},{"location":"agile/6-1-scrum/#61-scrum","text":"","title":"6.1 Scrum"},{"location":"agile/6-1-scrum/#611-backlog-refinement-formal-collaboration-session","text":"","title":"6.1.1 Backlog Refinement Formal Collaboration Session"},{"location":"agile/6-1-scrum/#612-sprint-planning","text":"","title":"6.1.2 Sprint Planning"},{"location":"agile/6-1-scrum/#613-sprint-execution","text":"","title":"6.1.3 Sprint Execution"},{"location":"agile/6-1-scrum/#614-sprint-review","text":"","title":"6.1.4 Sprint Review"},{"location":"agile/6-1-scrum/#615-sprint-retrospective","text":"","title":"6.1.5 Sprint Retrospective"},{"location":"agile/6-2-kanban/","text":"6.2 Kanban 6.2.1 Strategy Review/Release Management 6.2.2 Stand-up 6.2.3 Replenishment Meeting 6.2.4 Delivery Planning Meeting 6.2.5 Operations Review 6.2.6 Service Delivery Review 6.2.7 Risk Review","title":"6.2 Kanban"},{"location":"agile/6-2-kanban/#62-kanban","text":"","title":"6.2 Kanban"},{"location":"agile/6-2-kanban/#621-strategy-reviewrelease-management","text":"","title":"6.2.1 Strategy Review/Release Management"},{"location":"agile/6-2-kanban/#622-stand-up","text":"","title":"6.2.2 Stand-up"},{"location":"agile/6-2-kanban/#623-replenishment-meeting","text":"","title":"6.2.3 Replenishment Meeting"},{"location":"agile/6-2-kanban/#624-delivery-planning-meeting","text":"","title":"6.2.4 Delivery Planning Meeting"},{"location":"agile/6-2-kanban/#625-operations-review","text":"","title":"6.2.5 Operations Review"},{"location":"agile/6-2-kanban/#626-service-delivery-review","text":"","title":"6.2.6 Service Delivery Review"},{"location":"agile/6-2-kanban/#627-risk-review","text":"","title":"6.2.7 Risk Review"},{"location":"agile/6-3-xp/","text":"6.3 Extreme Programming 6.3.1 Backlog Refinement Formal Collaboration Session 6.3.2 Iteration Planning 6.3.3 Iteration 6.3.4 Iteration Review 6.3.5 Iteration Retrospective","title":"6.3 Extreme Programming"},{"location":"agile/6-3-xp/#63-extreme-programming","text":"","title":"6.3 Extreme Programming"},{"location":"agile/6-3-xp/#631-backlog-refinement-formal-collaboration-session","text":"","title":"6.3.1 Backlog Refinement Formal Collaboration Session"},{"location":"agile/6-3-xp/#632-iteration-planning","text":"","title":"6.3.2 Iteration Planning"},{"location":"agile/6-3-xp/#633-iteration","text":"","title":"6.3.3 Iteration"},{"location":"agile/6-3-xp/#634-iteration-review","text":"","title":"6.3.4 Iteration Review"},{"location":"agile/6-3-xp/#635-iteration-retrospective","text":"","title":"6.3.5 Iteration Retrospective"},{"location":"agile/7-1-lead/","text":"7.1 Agile Lead","title":"7.1 Agile Lead"},{"location":"agile/7-1-lead/#71-agile-lead","text":"","title":"7.1 Agile Lead"},{"location":"agile/7-2-owner/","text":"7.2 Product Owner","title":"7.2 Product Owner"},{"location":"agile/7-2-owner/#72-product-owner","text":"","title":"7.2 Product Owner"},{"location":"agile/7-3-analyst/","text":"7.3 Business Analyst","title":"7.3 Business Analyst"},{"location":"agile/7-3-analyst/#73-business-analyst","text":"","title":"7.3 Business Analyst"},{"location":"agile/8-1-general/","text":"8.1 Agile in General","title":"8.1 Agile in General"},{"location":"agile/8-1-general/#81-agile-in-general","text":"","title":"8.1 Agile in General"},{"location":"agile/8-2-tools/","text":"8.2 Agile Tools 8.2.1 VSTS / TFS Overview: https://msdn.microsoft.com/en-us/library/ms364062(v=vs.80).aspx Backlog Management: Work Mangement: Communication Management: Continuous Integration: 8.2.2 Atlassian (JIRA) Overview: https://confluence.atlassian.com/jirasoftwarecloud/jira-software-overview-779293724.html Backlog Management: Work Management: Communication Management: Continuous Integration:","title":"8.2 Agile Tools"},{"location":"agile/8-2-tools/#82-agile-tools","text":"","title":"8.2 Agile Tools"},{"location":"agile/8-2-tools/#821-vsts-tfs","text":"Overview: https://msdn.microsoft.com/en-us/library/ms364062(v=vs.80).aspx Backlog Management: Work Mangement: Communication Management: Continuous Integration:","title":"8.2.1 VSTS / TFS"},{"location":"agile/8-2-tools/#822-atlassian-jira","text":"Overview: https://confluence.atlassian.com/jirasoftwarecloud/jira-software-overview-779293724.html Backlog Management: Work Management: Communication Management: Continuous Integration:","title":"8.2.2 Atlassian (JIRA)"},{"location":"agile/9-1-appendix-d/","text":"9.1 AGILE TERMINOLOGY Source: https://www.agilealliance.org/agile101/agile-glossary/ A Acceptance Test Driven Development (ATDD) Acceptance Test Driven Development (ATDD) involves team members with different perspectives (customer, development, testing) collaborating to write acceptance tests in advance of implementing the corresponding functionality. Acceptance Testing An acceptance test is a formal description of the behavior of a software product, generally expressed as an example or a usage scenario. A number of different notations and approaches have been proposed for such examples or scenarios. In many cases the aim is that it should be possible to automate the execution of such tests by a software tool, either ad-hoc to the development team or off the shelf. Antipattern Antipatterns are common solutions to common problems where the solution is ineffective and may result in undesired consequences. Automated Build In the context of software development, build refers to the process that converts files and other assets under the developers' responsibility into a software product in its final or consumable form. The build is automated when these steps are repeatable, require no direct human intervention, and can be performed at any time with no information other than what is stored in the source code control repository. B Backlog A backlog is an ordered list of items representing everything that may be needed to deliver a specific outcome. There are different types of backlogs depending on the type of item they contain and the approach being used. Backlog Grooming Backlog grooming is when the PO and some, or all, of the rest of the team refine the backlog on a regular basis to ensure the backlog contains the appropriate items, that they are prioritized, and that the items at the top of the backlog are ready for delivery. Behavior Driven Development (BDD) BDD is a practice where members of the team discuss the expected behavior of a system in order to build a shared understanding of expected functionality. Burndown Chart Burndown charts and burnup charts track the amount of output (in terms of hours, story points, or backlog items) a team has completed across an iteration or a project. Business Agility Business agility is the ability of an organization to sense changes internally or externally and respond accordingly in order to deliver value to its customers. C Collective Ownership Collective code ownership is the explicit convention that every team member can make changes to any code file as necessary: either to complete a development task, to repair a defect, or to improve the code's overall structure. Continuous Deployment Continuous deployment aims to reduce the time elapsed between writing a line of code and making that code available to users in production. To achieve continuous deployment, the team relies on infrastructure that automates and instruments the various steps leading up to deployment, so that after each integration successfully meeting these release criteria, the live application is updated with new code. Continuous Integration Continuous Integration is the practice of merging code changes into a shared repository several times a day in order to release a product version at any moment. This requires an integration procedure which is reproducible and automated. CRC Cards Class Responsibility Collaborator (CRC) Cards are an object oriented design technique teams can use to discuss what a class should know and do and what other classes it interacts with. Customer Development Customer development is a four-step framework that provides a way to use a scientific approach to validate assumptions about your product and business. D Daily Meeting The daily meeting is one of the most commonly practiced Agile techniques and presents opportunity for a team to get together on a regular basis to coordinate their activities. Definition of Done The definition of done is an agreed upon list of the activities deemed necessary to get a product increment, usually represented by a user story, to a done state by the end of a sprint. Definition of Ready Definition of Ready involves creating clear criteria that a user story must meet before being accepted into an upcoming iteration. This is typically based on the INVEST matrix. E Epic An epic is a large user story. Estimation In software development, an \"estimate\" is the evaluation of the effort necessary to carry out a given development task; this is most often expressed in terms of duration. Exploratory Testing Exploratory testing is, more than strictly speaking a \"practice,\" a style or approach to testing software which is often contrasted to \"scripted testing.\" Extreme Programming Extreme Programming (XP) is an agile software development framework that aims to produce higher quality software, and higher quality of life for the development team. XP is the most specific of the agile frameworks regarding appropriate engineering practices for software development. F Facilitation A facilitator is a person who chooses or is given the explicit role of conducting a meeting. Frequent Releases An Agile team frequently releases its product into the hands of end users, listening to feedback, whether critical or appreciative. G Given When Then The Given-When-Then formula is a template intended to guide the writing of acceptance tests for a User Story: (Given) some context, (When) some action is carried out, (Then) a particular set of observable consequences should obtain. H Heartbeat Retrospective The team meets regularly to reflect on the most significant events that occurred since the previous such meeting, and identify opportunities for improvement. I Incremental Development In an Agile context, Incremental Development is when each successive version of a product is usable, and each builds upon the previous version by adding user-visible functionality. Information Radiators \"Information radiator\" is the term for any of a number of visual displays which a team places in a highly visible location, so that all team members can see the latest information at a glance. Integration \"Integration\" (or \"integrating\") refers to any efforts still required for a project team to deliver a product suitable for release as a functional whole. INVEST The acronym INVEST stands for a set of criteria used to assess the quality of a user story. If the story fails to meet one of these criteria, the team may want to reword it. Iteration An iteration is a timebox during which development takes place. The duration may vary from project to project and is usually fixed. Iterative Development Agile projects are iterative insofar as they intentionally allow for \"repeating\" software development activities, and for potentially \"revisiting\" the same work products (the phrase \"planned rework\" is sometimes used; refactoring is a good example). K Kanban The Kanban Method is a means to design, manage and improve flow for knowledge work and allows teams to start where they are to drive evolutionary change. Kanban Board A Kanban Board is a visual workflow tool consisting of multiple columns. Each column represents a different stage in the workflow process. L Lead Time Lead Time is the time between a customer order and delivery. In software development, it can also be the time between a requirement made and its fulfillment. M Milestone Retrospective A Milestone Retrospective is a team's detailed analysis of the project's significant events after a set period of time or at the project's end. Minimum Marketable Feature (MMF) A Minimum Marketable Feature is a small, self-contained feature that can be developed quickly and that delivers significant value to the user. Minimum Viable Product (MVP) A Minimum Viable Product is, as Eric Ries said, the \"version of a new product which allows a team to collect the maximum amount of validated learning about customers with the least effort.\" Mob Programming Mob Programming is a software development approach where the whole team works on the same thing, at the same time, in the same space, and at the same computer. Mock Objects Mock Objects (commonly used in the context of crafting automated unit tests) consist of instantiating a test-specific version of a software component. N Niko-niko Calendar A Niko-niko Calendar is updated daily with each team member's mood for that day. Over time the calendar reveals patterns of change in the moods of the team, or of individual members. P Pair Programming Pair programming consists of two programmers sharing a single workstation (one screen, keyboard and mouse among the pair). Personas Personas are synthetic biographies of fictitious users of the future product. Planning Poker An approach to estimation used by Agile teams. Each team member \"plays\" a card bearing a numerical value corresponding to a point estimation for a user story. Points (estimates in) Agile teams generally prefer to express estimates in units other than the time-honored \"man-hours.\" Possibly the most widespread unit is \"story points.\" Product Owner (PO) The PO is a role created by the Scrum Framework responsible for making sure the team delivers the desired outcome. Project Chartering A high-level summary of the project's key success factors displayed on one wall of the team room as a flipchart-sized sheet of paper. Q Quick Design Session When \"simple design\" choices have far-reaching consequences, two or more developers meet for a quick design session at a whiteboard. R Refactoring Refactoring consists of improving the internal structure of an existing program's source code, while preserving its external behavior. Relative Estimation Relative estimation consists of estimating tasks or user stories by comparison or by grouping of items of equivalent difficulty. Role-feature-reason The \"role-feature-reason\" template is one of the most commonly recommended aids to write user stories: As a ... I want ... So that ... Rule of Simplicity Rules of Simplicity is a set of criteria, in priority order, proposed by Kent Beck to judge whether some source code is \"simple enough.\" S Scrum Scrum is a process framework used to manage product development and other knowledge work. Scrum Master The scrum master is responsible for ensuring the team lives agile values and principles and follows the practices that the team agreed they would use. Scrum of Scrums A technique to scale Scrum up to large groups (over a dozen people), consisting of dividing the groups into Agile teams of 5-10. Sign Up for Tasks Members of an Agile development team normally choose which tasks to work on, rather than being assigned work by a manager. Simple Design A team adopting the \"simple design\" practice bases its software design strategy on a set of \"simple design\" principles. Sprint Planning Sprint planning is an event that occurs at the beginning of a sprint where the team determines the product backlog items they will work on during that sprint. Story Mapping Story mapping consists of ordering user stories along two independent dimensions. Story Splitting Splitting consists of breaking up one user story into smaller ones, while preserving the property that each user story separately has measurable business value. Sustainable Pace The team aims for a work pace that they would be able to sustain indefinitely. T Task Board The most basic form of a task board is divided into three columns labeled \"To Do,\" \"In Progress,\" and \"Done.\" Cards are placed in the columns to reflect the current status of that task. Test Driven Development (TDD) \"Test-driven development\" is a style of programming in which three activities are tightly interwoven: coding, testing (in the form of writing unit tests) and design (in the form of refactoring). Team A \"team\" in the Agile sense is a small group of people, assigned to the same project or effort, nearly all of them on a full-time basis. Team Room The team (ideally the whole team, including the PO or domain expert) has the use of a dedicated space for the duration of the project, set apart from other groups' activities. Three C's \"Card, Conversation, Confirmation\" is a formula that captures the components of a User Story. Three Amigos Three amigos refers to the primary perspectives to examine an increment of work before, during, and after development. Those perspectives are Business, Development, and Testing. Three Questions The daily meeting is structured around some variant of the following three questions: What have you completed? What will you do next? What is getting in your way? Timebox A timebox is a previously agreed period of time during which a person or a team works steadily towards completion of some goal. U Ubiquitous Language Striving to use the vocabulary of a given business domain, not only in discussions about the requirements for a software product, but in discussions of design as well and all the way into \"the product's source code itself.\" Unit Testing A unit test is a short program fragment written and maintained by the developers on the product team, which exercises some narrow part of the product's source code and checks the results. Usability Testing Usability testing is an empirical, exploratory technique to answer questions such as \"how would an end user respond to our software under realistic conditions?\" User Stories In consultation with the customer or PO, the team divides up the work to be done into functional increments called \"user stories.\" V Velocity At the end of each iteration, the team adds up effort estimates associated with user stories that were completed during that iteration. This total is called velocity. Version Control Version control is not strictly an Agile \"practice\" insofar as it is now widespread in the industry as a whole. But it is mentioned here for several reasons.","title":"9.1 Agile Terminology"},{"location":"agile/9-1-appendix-d/#91-agile-terminology","text":"Source: https://www.agilealliance.org/agile101/agile-glossary/ A Acceptance Test Driven Development (ATDD) Acceptance Test Driven Development (ATDD) involves team members with different perspectives (customer, development, testing) collaborating to write acceptance tests in advance of implementing the corresponding functionality. Acceptance Testing An acceptance test is a formal description of the behavior of a software product, generally expressed as an example or a usage scenario. A number of different notations and approaches have been proposed for such examples or scenarios. In many cases the aim is that it should be possible to automate the execution of such tests by a software tool, either ad-hoc to the development team or off the shelf. Antipattern Antipatterns are common solutions to common problems where the solution is ineffective and may result in undesired consequences. Automated Build In the context of software development, build refers to the process that converts files and other assets under the developers' responsibility into a software product in its final or consumable form. The build is automated when these steps are repeatable, require no direct human intervention, and can be performed at any time with no information other than what is stored in the source code control repository. B Backlog A backlog is an ordered list of items representing everything that may be needed to deliver a specific outcome. There are different types of backlogs depending on the type of item they contain and the approach being used. Backlog Grooming Backlog grooming is when the PO and some, or all, of the rest of the team refine the backlog on a regular basis to ensure the backlog contains the appropriate items, that they are prioritized, and that the items at the top of the backlog are ready for delivery. Behavior Driven Development (BDD) BDD is a practice where members of the team discuss the expected behavior of a system in order to build a shared understanding of expected functionality. Burndown Chart Burndown charts and burnup charts track the amount of output (in terms of hours, story points, or backlog items) a team has completed across an iteration or a project. Business Agility Business agility is the ability of an organization to sense changes internally or externally and respond accordingly in order to deliver value to its customers. C Collective Ownership Collective code ownership is the explicit convention that every team member can make changes to any code file as necessary: either to complete a development task, to repair a defect, or to improve the code's overall structure. Continuous Deployment Continuous deployment aims to reduce the time elapsed between writing a line of code and making that code available to users in production. To achieve continuous deployment, the team relies on infrastructure that automates and instruments the various steps leading up to deployment, so that after each integration successfully meeting these release criteria, the live application is updated with new code. Continuous Integration Continuous Integration is the practice of merging code changes into a shared repository several times a day in order to release a product version at any moment. This requires an integration procedure which is reproducible and automated. CRC Cards Class Responsibility Collaborator (CRC) Cards are an object oriented design technique teams can use to discuss what a class should know and do and what other classes it interacts with. Customer Development Customer development is a four-step framework that provides a way to use a scientific approach to validate assumptions about your product and business. D Daily Meeting The daily meeting is one of the most commonly practiced Agile techniques and presents opportunity for a team to get together on a regular basis to coordinate their activities. Definition of Done The definition of done is an agreed upon list of the activities deemed necessary to get a product increment, usually represented by a user story, to a done state by the end of a sprint. Definition of Ready Definition of Ready involves creating clear criteria that a user story must meet before being accepted into an upcoming iteration. This is typically based on the INVEST matrix. E Epic An epic is a large user story. Estimation In software development, an \"estimate\" is the evaluation of the effort necessary to carry out a given development task; this is most often expressed in terms of duration. Exploratory Testing Exploratory testing is, more than strictly speaking a \"practice,\" a style or approach to testing software which is often contrasted to \"scripted testing.\" Extreme Programming Extreme Programming (XP) is an agile software development framework that aims to produce higher quality software, and higher quality of life for the development team. XP is the most specific of the agile frameworks regarding appropriate engineering practices for software development. F Facilitation A facilitator is a person who chooses or is given the explicit role of conducting a meeting. Frequent Releases An Agile team frequently releases its product into the hands of end users, listening to feedback, whether critical or appreciative. G Given When Then The Given-When-Then formula is a template intended to guide the writing of acceptance tests for a User Story: (Given) some context, (When) some action is carried out, (Then) a particular set of observable consequences should obtain. H Heartbeat Retrospective The team meets regularly to reflect on the most significant events that occurred since the previous such meeting, and identify opportunities for improvement. I Incremental Development In an Agile context, Incremental Development is when each successive version of a product is usable, and each builds upon the previous version by adding user-visible functionality. Information Radiators \"Information radiator\" is the term for any of a number of visual displays which a team places in a highly visible location, so that all team members can see the latest information at a glance. Integration \"Integration\" (or \"integrating\") refers to any efforts still required for a project team to deliver a product suitable for release as a functional whole. INVEST The acronym INVEST stands for a set of criteria used to assess the quality of a user story. If the story fails to meet one of these criteria, the team may want to reword it. Iteration An iteration is a timebox during which development takes place. The duration may vary from project to project and is usually fixed. Iterative Development Agile projects are iterative insofar as they intentionally allow for \"repeating\" software development activities, and for potentially \"revisiting\" the same work products (the phrase \"planned rework\" is sometimes used; refactoring is a good example). K Kanban The Kanban Method is a means to design, manage and improve flow for knowledge work and allows teams to start where they are to drive evolutionary change. Kanban Board A Kanban Board is a visual workflow tool consisting of multiple columns. Each column represents a different stage in the workflow process. L Lead Time Lead Time is the time between a customer order and delivery. In software development, it can also be the time between a requirement made and its fulfillment. M Milestone Retrospective A Milestone Retrospective is a team's detailed analysis of the project's significant events after a set period of time or at the project's end. Minimum Marketable Feature (MMF) A Minimum Marketable Feature is a small, self-contained feature that can be developed quickly and that delivers significant value to the user. Minimum Viable Product (MVP) A Minimum Viable Product is, as Eric Ries said, the \"version of a new product which allows a team to collect the maximum amount of validated learning about customers with the least effort.\" Mob Programming Mob Programming is a software development approach where the whole team works on the same thing, at the same time, in the same space, and at the same computer. Mock Objects Mock Objects (commonly used in the context of crafting automated unit tests) consist of instantiating a test-specific version of a software component. N Niko-niko Calendar A Niko-niko Calendar is updated daily with each team member's mood for that day. Over time the calendar reveals patterns of change in the moods of the team, or of individual members. P Pair Programming Pair programming consists of two programmers sharing a single workstation (one screen, keyboard and mouse among the pair). Personas Personas are synthetic biographies of fictitious users of the future product. Planning Poker An approach to estimation used by Agile teams. Each team member \"plays\" a card bearing a numerical value corresponding to a point estimation for a user story. Points (estimates in) Agile teams generally prefer to express estimates in units other than the time-honored \"man-hours.\" Possibly the most widespread unit is \"story points.\" Product Owner (PO) The PO is a role created by the Scrum Framework responsible for making sure the team delivers the desired outcome. Project Chartering A high-level summary of the project's key success factors displayed on one wall of the team room as a flipchart-sized sheet of paper. Q Quick Design Session When \"simple design\" choices have far-reaching consequences, two or more developers meet for a quick design session at a whiteboard. R Refactoring Refactoring consists of improving the internal structure of an existing program's source code, while preserving its external behavior. Relative Estimation Relative estimation consists of estimating tasks or user stories by comparison or by grouping of items of equivalent difficulty. Role-feature-reason The \"role-feature-reason\" template is one of the most commonly recommended aids to write user stories: As a ... I want ... So that ... Rule of Simplicity Rules of Simplicity is a set of criteria, in priority order, proposed by Kent Beck to judge whether some source code is \"simple enough.\" S Scrum Scrum is a process framework used to manage product development and other knowledge work. Scrum Master The scrum master is responsible for ensuring the team lives agile values and principles and follows the practices that the team agreed they would use. Scrum of Scrums A technique to scale Scrum up to large groups (over a dozen people), consisting of dividing the groups into Agile teams of 5-10. Sign Up for Tasks Members of an Agile development team normally choose which tasks to work on, rather than being assigned work by a manager. Simple Design A team adopting the \"simple design\" practice bases its software design strategy on a set of \"simple design\" principles. Sprint Planning Sprint planning is an event that occurs at the beginning of a sprint where the team determines the product backlog items they will work on during that sprint. Story Mapping Story mapping consists of ordering user stories along two independent dimensions. Story Splitting Splitting consists of breaking up one user story into smaller ones, while preserving the property that each user story separately has measurable business value. Sustainable Pace The team aims for a work pace that they would be able to sustain indefinitely. T Task Board The most basic form of a task board is divided into three columns labeled \"To Do,\" \"In Progress,\" and \"Done.\" Cards are placed in the columns to reflect the current status of that task. Test Driven Development (TDD) \"Test-driven development\" is a style of programming in which three activities are tightly interwoven: coding, testing (in the form of writing unit tests) and design (in the form of refactoring). Team A \"team\" in the Agile sense is a small group of people, assigned to the same project or effort, nearly all of them on a full-time basis. Team Room The team (ideally the whole team, including the PO or domain expert) has the use of a dedicated space for the duration of the project, set apart from other groups' activities. Three C's \"Card, Conversation, Confirmation\" is a formula that captures the components of a User Story. Three Amigos Three amigos refers to the primary perspectives to examine an increment of work before, during, and after development. Those perspectives are Business, Development, and Testing. Three Questions The daily meeting is structured around some variant of the following three questions: What have you completed? What will you do next? What is getting in your way? Timebox A timebox is a previously agreed period of time during which a person or a team works steadily towards completion of some goal. U Ubiquitous Language Striving to use the vocabulary of a given business domain, not only in discussions about the requirements for a software product, but in discussions of design as well and all the way into \"the product's source code itself.\" Unit Testing A unit test is a short program fragment written and maintained by the developers on the product team, which exercises some narrow part of the product's source code and checks the results. Usability Testing Usability testing is an empirical, exploratory technique to answer questions such as \"how would an end user respond to our software under realistic conditions?\" User Stories In consultation with the customer or PO, the team divides up the work to be done into functional increments called \"user stories.\" V Velocity At the end of each iteration, the team adds up effort estimates associated with user stories that were completed during that iteration. This total is called velocity. Version Control Version control is not strictly an Agile \"practice\" insofar as it is now widespread in the industry as a whole. But it is mentioned here for several reasons.","title":"9.1 AGILE TERMINOLOGY"},{"location":"cloud/1-1-cloud/","text":"App Technology Refresh for Cloud","title":"1. Overview"},{"location":"cloud/1-1-cloud/#app-technology-refresh-for-cloud","text":"","title":"App Technology Refresh for Cloud"},{"location":"cyber/1-1-cyber/","text":"Cyber Security","title":"1. Overview"},{"location":"cyber/1-1-cyber/#cyber-security","text":"","title":"Cyber Security"},{"location":"devops/1-1-devops/","text":"","title":"1. Overview"},{"location":"low-code/1-1-plays/","text":"Low-Code Framework Plays What the heck is Low-Code Delight the User, They are the real customer Agile is the only way Empower the User Too many cooks spoil the pot, Select One Leader and hold them accountable Use Experienced Teams Select a product and build, Migration is not an option Automate Everything Look to the Clouds for hosting Don\u2019t forget the Interfaces Fast track ATO Use Data to Drive Decisions","title":"1.1 Overview"},{"location":"low-code/1-1-plays/#low-code-framework-plays","text":"What the heck is Low-Code Delight the User, They are the real customer Agile is the only way Empower the User Too many cooks spoil the pot, Select One Leader and hold them accountable Use Experienced Teams Select a product and build, Migration is not an option Automate Everything Look to the Clouds for hosting Don\u2019t forget the Interfaces Fast track ATO Use Data to Drive Decisions","title":"Low-Code Framework Plays"},{"location":"low-code/10-1-references/","text":"","title":"10.1 References"},{"location":"low-code/11-1-contributors/","text":"","title":"11.1 Chapter 5 Low-Code Playbook Contributors"},{"location":"low-code/2-1-intro/","text":"2.1 Introduction In April 2016, Air Force (AF) Logistics (A4) published the \"US Air Force Enterprise Logistics Flight Plan v2.0\" (ELFP) and a subordinate document titled the \"Enterprise Logistics Technology Annex\" (ELTA) was published in June 2016. This plan and annex describe the 2035 future state of AF Enterprise Logistics \"synthesized logistics information\". To achieve the longer-term ELFP and ELTA goals, a series of enabling initiatives was defined to achieve necessary foundational near-term milestones. The \"Enterprise Logistics IT (ELIT) Agile Model-Driven Functionality Improvement Playbook Chapter\" is one of these initiatives. Agile Model-Driven Functionality Improvement provides the Air Force (AF) with methods for improving functionality within applications using business process modeling graphical tools that subject matter experts (SMEs) can understand and use. These models can be used to improve and rapidly extend application functionality using agile process modeling tools. This is accomplished by creating functional models of the components from existing application code and by creating models for new application components. Low-Code Development Platforms (LCDP) is the term industry uses to describe these tools & methodologies. To align with common industry terminology this Playbook Chapter will use the term \"Low-Code\" to describe Agile Model-Driven Functionality Improvement development frameworks.","title":"2.1 Introduction"},{"location":"low-code/2-1-intro/#21-introduction","text":"In April 2016, Air Force (AF) Logistics (A4) published the \"US Air Force Enterprise Logistics Flight Plan v2.0\" (ELFP) and a subordinate document titled the \"Enterprise Logistics Technology Annex\" (ELTA) was published in June 2016. This plan and annex describe the 2035 future state of AF Enterprise Logistics \"synthesized logistics information\". To achieve the longer-term ELFP and ELTA goals, a series of enabling initiatives was defined to achieve necessary foundational near-term milestones. The \"Enterprise Logistics IT (ELIT) Agile Model-Driven Functionality Improvement Playbook Chapter\" is one of these initiatives. Agile Model-Driven Functionality Improvement provides the Air Force (AF) with methods for improving functionality within applications using business process modeling graphical tools that subject matter experts (SMEs) can understand and use. These models can be used to improve and rapidly extend application functionality using agile process modeling tools. This is accomplished by creating functional models of the components from existing application code and by creating models for new application components. Low-Code Development Platforms (LCDP) is the term industry uses to describe these tools & methodologies. To align with common industry terminology this Playbook Chapter will use the term \"Low-Code\" to describe Agile Model-Driven Functionality Improvement development frameworks.","title":"2.1 Introduction"},{"location":"low-code/2-2-problem/","text":"2.2 Problem Statement The AF Logistics portfolio is comprised of many applications that are in a variety of lifecycle stages. These applications contain critical business rules and process flows used to support AF missions. They were generally developed using traditional Software Development Life Cycle (SDLC) processes based on the sequential Waterfall Software Development methodology. Applications were created using the functional and technical best practices and paradigms available at the time to support requirements but may now be outdated. This has resulted in a portfolio of applications where maintaining, improving and extending functionality is extremely difficult, costly, resource intensive and requires long schedules. Additionally, the AF has a shortage of logistics Subject Matter Experts (SMEs) capable of reinventing AF Logistics processes. Using traditional AF functional improvement methods, these valuable SMEs spend a lot of time on mundane activities that are not focused on transforming the business in order to improve and rapidly deploy business systems capabilities.","title":"2.2 Problem Statement"},{"location":"low-code/2-2-problem/#22-problem-statement","text":"The AF Logistics portfolio is comprised of many applications that are in a variety of lifecycle stages. These applications contain critical business rules and process flows used to support AF missions. They were generally developed using traditional Software Development Life Cycle (SDLC) processes based on the sequential Waterfall Software Development methodology. Applications were created using the functional and technical best practices and paradigms available at the time to support requirements but may now be outdated. This has resulted in a portfolio of applications where maintaining, improving and extending functionality is extremely difficult, costly, resource intensive and requires long schedules. Additionally, the AF has a shortage of logistics Subject Matter Experts (SMEs) capable of reinventing AF Logistics processes. Using traditional AF functional improvement methods, these valuable SMEs spend a lot of time on mundane activities that are not focused on transforming the business in order to improve and rapidly deploy business systems capabilities.","title":"2.2 Problem Statement"},{"location":"low-code/2-3-purpose/","text":"2.3 Purpose This Low-Code Playbook Chapter is a continuation of effort by the BES PEO to establish modern practices and methods to accelerate software development and deployment of value for Logistics Information Systems, Business Systems and its end users. Preceded by playbooks for Agile, Automated Testing, User Experience, and Automated Application Modernization (AAM) this playbook aims to provide approaches, methods, and tools to apply Low-Code development frameworks to digitally transform AF Logistics systems. The intent of the Low-Code Playbook is to provide a high-level descriptive set of instructions for BES AFLCMC/HIA programs identifying how and what proven agile processes and tools should be used to automate and standardize improvements in logistics systems. This Playbook will provide HIA with methods for improving functionality within applications using business process modeling management tools that subject matter experts (SMEs) can understand and utilize. This Playbook Chapter serves as a \u201cliving document,\u201d delivering value in the present while providing a foundation for future updates and enhancements as the state of technology and the needs of stakeholders and end-users served by Logistics Information Systems continually evolve. This playbook chapter is not intended to replace the standard processes described in the current version of the BES Process Directory (BPD) ( https://www.dau.mil/cop/bes/Pages/Documents.aspx ) but rather provide additional software development concepts & methodologies that may not be covered in depth within the current version of the BES BPD. The Low-Code Playbook Chapter, in its current version, serves as a set of best practices that may be used in conjunction with updated BPD content.","title":"2.3 Purpose"},{"location":"low-code/2-3-purpose/#23-purpose","text":"This Low-Code Playbook Chapter is a continuation of effort by the BES PEO to establish modern practices and methods to accelerate software development and deployment of value for Logistics Information Systems, Business Systems and its end users. Preceded by playbooks for Agile, Automated Testing, User Experience, and Automated Application Modernization (AAM) this playbook aims to provide approaches, methods, and tools to apply Low-Code development frameworks to digitally transform AF Logistics systems. The intent of the Low-Code Playbook is to provide a high-level descriptive set of instructions for BES AFLCMC/HIA programs identifying how and what proven agile processes and tools should be used to automate and standardize improvements in logistics systems. This Playbook will provide HIA with methods for improving functionality within applications using business process modeling management tools that subject matter experts (SMEs) can understand and utilize. This Playbook Chapter serves as a \u201cliving document,\u201d delivering value in the present while providing a foundation for future updates and enhancements as the state of technology and the needs of stakeholders and end-users served by Logistics Information Systems continually evolve. This playbook chapter is not intended to replace the standard processes described in the current version of the BES Process Directory (BPD) ( https://www.dau.mil/cop/bes/Pages/Documents.aspx ) but rather provide additional software development concepts & methodologies that may not be covered in depth within the current version of the BES BPD. The Low-Code Playbook Chapter, in its current version, serves as a set of best practices that may be used in conjunction with updated BPD content.","title":"2.3 Purpose"},{"location":"low-code/2-4-scope/","text":"2.4 Scope The Low-Code Playbook Chapter describes approaches and methods to apply visual model-driven software development constructs to modernize legacy applications or develop new systems to enable digital transformation strategies using agile processes. This playbook chapter includes: Description of Low-Code application development core concepts Benefits of Low-Code framework implementation Limitations of Low-Code frameworks Low-Code project guidance using Agile processes Low-Code systems architecture considerations Low-Code tools overview and evaluation criteria guidance Air Force Low-Code pathfinder application analysis Conclusions and Recommendations","title":"2.4 Scope"},{"location":"low-code/2-4-scope/#24-scope","text":"The Low-Code Playbook Chapter describes approaches and methods to apply visual model-driven software development constructs to modernize legacy applications or develop new systems to enable digital transformation strategies using agile processes. This playbook chapter includes: Description of Low-Code application development core concepts Benefits of Low-Code framework implementation Limitations of Low-Code frameworks Low-Code project guidance using Agile processes Low-Code systems architecture considerations Low-Code tools overview and evaluation criteria guidance Air Force Low-Code pathfinder application analysis Conclusions and Recommendations","title":"2.4 Scope"},{"location":"low-code/2-5-audience/","text":"2.5 Intended Audience While this playbook can provide value to all personnel involved in a software development project, the primary audience for this playbook are those individuals who are responsible for the planning, development, and management of strategic digital transformation projects that employ or might benefit from an Agile Low-Code approach to systems modernization and development projects. For Program Managers and those in similar roles, this playbook will provide a foundation of knowledge to enable more effective planning and support for programs where Business Process Automation (BPA), Robotic Processes Automation (RPA), or Web Enablement & Mobile Application Development concepts might be required. For software engineers and those in similar roles, this playbook will provide a valuable resource for design patterns and guidelines from which applications can be efficiently developed, enabling faster design decisions and more rapid deployment while ensuring consistency and quality across all digital experiences delivered by Logistics Information Systems.","title":"2.5 Audience"},{"location":"low-code/2-5-audience/#25-intended-audience","text":"While this playbook can provide value to all personnel involved in a software development project, the primary audience for this playbook are those individuals who are responsible for the planning, development, and management of strategic digital transformation projects that employ or might benefit from an Agile Low-Code approach to systems modernization and development projects. For Program Managers and those in similar roles, this playbook will provide a foundation of knowledge to enable more effective planning and support for programs where Business Process Automation (BPA), Robotic Processes Automation (RPA), or Web Enablement & Mobile Application Development concepts might be required. For software engineers and those in similar roles, this playbook will provide a valuable resource for design patterns and guidelines from which applications can be efficiently developed, enabling faster design decisions and more rapid deployment while ensuring consistency and quality across all digital experiences delivered by Logistics Information Systems.","title":"2.5 Intended Audience"},{"location":"low-code/2-6-benefits/","text":"2.6 Benefits Create Playbook and methods once, used by everyone Consistent use of BEST practices and templates Individual AF Logistics applications can be functionally improved using model-driven business process graphical tools, Enables faster application functional upgrades These methods can be applied across the AF Logistics Enterprise and provide a way to manage the functional business rules across the portfolio allowing for portfolio-level remodeling and rationalization Business Process Modeling is designed to model, implement, maintain and improve work-flow style code, data structures and interfaces Once the groundwork has been laid and the models have been properly created, changes to the models can be made very quickly (compared to traditional methods)","title":"2.6 Benefits"},{"location":"low-code/2-6-benefits/#26-benefits","text":"Create Playbook and methods once, used by everyone Consistent use of BEST practices and templates Individual AF Logistics applications can be functionally improved using model-driven business process graphical tools, Enables faster application functional upgrades These methods can be applied across the AF Logistics Enterprise and provide a way to manage the functional business rules across the portfolio allowing for portfolio-level remodeling and rationalization Business Process Modeling is designed to model, implement, maintain and improve work-flow style code, data structures and interfaces Once the groundwork has been laid and the models have been properly created, changes to the models can be made very quickly (compared to traditional methods)","title":"2.6 Benefits"},{"location":"low-code/3-1-what-is/","text":"3.1 What is Low-Code? PEO BES PMOs building custom-coded applications from scratch are faced with many challenges where developers are unable to keep pace with user demand for new capability which leads to increasing technical debt and poor application usability. Adding traditional \u201chand-coding\u201d developers to overcome this technical debt dilemma creates competition for scarce and expensive developer talent which makes it difficult for BES PMO application development teams to surge staff to address capability backlogs. Thus, BES PMOs are caught in a vicious cycle: Development bottlenecks mean BES PMOs App portfolios are unable to meet the user and stakeholder business needs for new applications and features. This leads to gaps in the digital portfolio and to rushed applications that deliver a poor user experience. These underperforming apps add to the technical debt, and the need to fix their shortfalls creates more development bottlenecks. The sheer demand for digital business services from industry and government organizations has outgrown the capability of conventional hand-coding platforms to meet the industries competitive environment and defense organizations business and mission needs. Low-code platform vendor offerings, which initially came about due to the explosion of mobile device Apps and the resulting change in consumer and (even) employee expectations, is the answer to the need to accelerate application development. BES PMOs care deeply about solving their digital business challenges with technology and fielding the right solutions to the warfighters. Increasing demand for more software Applications (Apps) ever more quickly is the big driver of low-code acceptance by organizations. Gartner and Forrester Research assessments of leading low-code platforms reveals vendors overcoming previous limitations on organizations acceptance of low-code platform solutions by supporting hand-coding to meet customer Integration, Reporting and Business Intelligence (BI) analytical needs. Several low-code vendors have incorporated no-code functionality and tools designed for business SMEs which allow them to contribute to development projects. Their contributions range from screen and workflow prototypes to complete portions of projects. Low-code development is defined as the ability to build apps quickly by reducing the need to hand-code. This is made possible by low-code application development platforms which a Forrester Research assessment states: \u201c...enable rapid application delivery with minimal hand-coding; minimum upfront investment in setup, configuration, and training; and faster App deployment.\u201d With a low-code development platform, developers don\u2019t hand-code an application line-by-line, they draw it visually \u2014 like a flowchart. Developers draw the business app logic, interfaces, rules, integrations, data import and all the other components that comprise running an application. This makes developing of new applications quick and intuitive. With low-code, BES PMO IT and business app users, stakeholders and app development contractors can work together - collaboratively. BES PMO Business Functional SMEs specify their idea (or need) for a new application by working with low-code developers to draw the flow chart, clicking, configuring, dragging and dropping. The low-code platform then takes that idea \u2014 the intention behind the new business app \u2014 and translates it instantly into working software. As a low-code platform translates from intention to application, the translation process becomes an opportunity for developers to layer on extra features, automatically. For example, the application could be translated to run natively on every Apple iOS and Android mobile device. It could offer easy portability across different clouds. It could automatically incorporate best-of-breed security control features, to enable compliance with the latest and most stringent security standards. It could be engineered to run with bulletproof availability or translated with features that enable it to upgrade itself automatically and always integrate easily to other enterprise systems\u2014making it immune to technical debt. A strong low-code translation layer delivers all these extra features\u2014free\u2014for every application. With traditional development, building in these features comes with extra cost\u2014more developers spending more time on a project. In many cases, BES PMO organizations forego the added features because the development cost is too high. In hand-coded apps, the quality of the application is a function of developer skills and time spent. With low-code, software quality is a function of the sophistication of the low-code platform selected by the BES PMO. Low-code app development and deployment is not only faster, but it results in an application that\u2019s demonstrably more feature rich with a better user experience than one simply built with lines of code. Delivering Apps with low-code is different from traditional hand-coding, therefore, a different process is needed to help the project team focused on doing the right things at the right time. In Section 4 - Low-Code Project Guidance, we describe how a low-code project\u2019s process flow is optimized for delivering operational apps. Tasks and activities are described with who is responsible for: (1) product owner and stakeholder collaboration on tasks, (2) who is responsible for the work effort to complete the task, and (3) who has the final accountability for the task completion.","title":"3.1 What is Low-Code?"},{"location":"low-code/3-1-what-is/#31-what-is-low-code","text":"PEO BES PMOs building custom-coded applications from scratch are faced with many challenges where developers are unable to keep pace with user demand for new capability which leads to increasing technical debt and poor application usability. Adding traditional \u201chand-coding\u201d developers to overcome this technical debt dilemma creates competition for scarce and expensive developer talent which makes it difficult for BES PMO application development teams to surge staff to address capability backlogs. Thus, BES PMOs are caught in a vicious cycle: Development bottlenecks mean BES PMOs App portfolios are unable to meet the user and stakeholder business needs for new applications and features. This leads to gaps in the digital portfolio and to rushed applications that deliver a poor user experience. These underperforming apps add to the technical debt, and the need to fix their shortfalls creates more development bottlenecks. The sheer demand for digital business services from industry and government organizations has outgrown the capability of conventional hand-coding platforms to meet the industries competitive environment and defense organizations business and mission needs. Low-code platform vendor offerings, which initially came about due to the explosion of mobile device Apps and the resulting change in consumer and (even) employee expectations, is the answer to the need to accelerate application development. BES PMOs care deeply about solving their digital business challenges with technology and fielding the right solutions to the warfighters. Increasing demand for more software Applications (Apps) ever more quickly is the big driver of low-code acceptance by organizations. Gartner and Forrester Research assessments of leading low-code platforms reveals vendors overcoming previous limitations on organizations acceptance of low-code platform solutions by supporting hand-coding to meet customer Integration, Reporting and Business Intelligence (BI) analytical needs. Several low-code vendors have incorporated no-code functionality and tools designed for business SMEs which allow them to contribute to development projects. Their contributions range from screen and workflow prototypes to complete portions of projects. Low-code development is defined as the ability to build apps quickly by reducing the need to hand-code. This is made possible by low-code application development platforms which a Forrester Research assessment states: \u201c...enable rapid application delivery with minimal hand-coding; minimum upfront investment in setup, configuration, and training; and faster App deployment.\u201d With a low-code development platform, developers don\u2019t hand-code an application line-by-line, they draw it visually \u2014 like a flowchart. Developers draw the business app logic, interfaces, rules, integrations, data import and all the other components that comprise running an application. This makes developing of new applications quick and intuitive. With low-code, BES PMO IT and business app users, stakeholders and app development contractors can work together - collaboratively. BES PMO Business Functional SMEs specify their idea (or need) for a new application by working with low-code developers to draw the flow chart, clicking, configuring, dragging and dropping. The low-code platform then takes that idea \u2014 the intention behind the new business app \u2014 and translates it instantly into working software. As a low-code platform translates from intention to application, the translation process becomes an opportunity for developers to layer on extra features, automatically. For example, the application could be translated to run natively on every Apple iOS and Android mobile device. It could offer easy portability across different clouds. It could automatically incorporate best-of-breed security control features, to enable compliance with the latest and most stringent security standards. It could be engineered to run with bulletproof availability or translated with features that enable it to upgrade itself automatically and always integrate easily to other enterprise systems\u2014making it immune to technical debt. A strong low-code translation layer delivers all these extra features\u2014free\u2014for every application. With traditional development, building in these features comes with extra cost\u2014more developers spending more time on a project. In many cases, BES PMO organizations forego the added features because the development cost is too high. In hand-coded apps, the quality of the application is a function of developer skills and time spent. With low-code, software quality is a function of the sophistication of the low-code platform selected by the BES PMO. Low-code app development and deployment is not only faster, but it results in an application that\u2019s demonstrably more feature rich with a better user experience than one simply built with lines of code. Delivering Apps with low-code is different from traditional hand-coding, therefore, a different process is needed to help the project team focused on doing the right things at the right time. In Section 4 - Low-Code Project Guidance, we describe how a low-code project\u2019s process flow is optimized for delivering operational apps. Tasks and activities are described with who is responsible for: (1) product owner and stakeholder collaboration on tasks, (2) who is responsible for the work effort to complete the task, and (3) who has the final accountability for the task completion.","title":"3.1 What is Low-Code?"},{"location":"low-code/3-2-vs-no-code/","text":"3.2 Low-Code vs. No-Code Frameworks Low-Code Platforms Vendor Low-Code Platform offerings provide App developer professionals a common set of automation tools and features to perform visual modeling App development, platform and App admin, and App deployment using automated DevOps and SysOps tools and features. This enables creation of smarter applications that provide users with intelligent decision support, automate tasks, and improve operating performance. These features are powered by core engines or services within the low-code platform \u2013 capability that low-code developers can draw on to enrich the functionality of their application. In the absence of these low-code engines, developers would be forced to code them from scratch (a complex development challenge), or, more likely, they would choose to hand-code logic like process flows or business rules into their apps. The result? Those hand-coded applications would be far less flexible and much more expensive to maintain. As a result, low-code development offers a significant advantage whenever there\u2019s a need to build automation into an application. Automation features of low-code platforms can include: A process engine that coordinates and manages end-to-end business processes. The process engine coordinates activities and data movement between people and other systems. It assigns tasks and routes work to both people and software robots. It also provides operational analytics that enable business leadership to monitor and improve performance. Robotic process automation (RPA) capability to fully automate low-value, repetitive tasks \u2013 freeing up users for more productive work. Business rules capability to define, manage and execute rules within the application. These rules can be used (and reused) for everything from defining organizational business policies and security policies to dynamically governing how interfaces are rendered. A wide array of AI services to improve application usability, guide users to informed decisions, and much more. One of the most difficult and time-consuming aspects of enterprise application development is integrating new applications with existing legacy \u201cbrown-field\u201d or new \u201cgreen-field\u201d business system Apps. To reduce the cost of these integrations and enable low-code applications to fit seamlessly into an enterprise architecture, low-code platform vendors are investing in: Drag-and-drop interfaces for declarative integration development. A robust set of integration connectors to common enterprise systems and support for the latest integration standards such as OpenAPI, which enable no-code integration to a wide variety of external systems. Capabilities that enable low-code developers to effortlessly build APIs into their applications, so those applications can be called by other enterprise systems. Specialized capabilities for designing and building applications that are a composite of data from enterprise systems, coupled with newly developed application logic and interface design. This enables application modernization without the extract and port data from existing systems \u2014 a difficult and often risky process. No-Code Platforms Vendor No-Code platform functionality means just that...zero coding is required. Business SMEs quickly transform ideas (or needs) into business apps...with no-code app-building functionality. Most vendor low-code platforms have no-code functionality and tools whereby business SMEs use model-driven-development visual, drag-and-drop development tools and point-and-click interface creation to import data, create and review App functionality, give feedback, validate assumptions, and identify improvements to evolve the applications. However, in most cases only departmental web applications with simple functionality features can be completed using a no-code graphically driven, model-based-development environment.","title":"3.2 Low-Code vs. No-Code Frameworks"},{"location":"low-code/3-2-vs-no-code/#32-low-code-vs-no-code-frameworks","text":"","title":"3.2 Low-Code vs. No-Code Frameworks"},{"location":"low-code/3-2-vs-no-code/#low-code-platforms","text":"Vendor Low-Code Platform offerings provide App developer professionals a common set of automation tools and features to perform visual modeling App development, platform and App admin, and App deployment using automated DevOps and SysOps tools and features. This enables creation of smarter applications that provide users with intelligent decision support, automate tasks, and improve operating performance. These features are powered by core engines or services within the low-code platform \u2013 capability that low-code developers can draw on to enrich the functionality of their application. In the absence of these low-code engines, developers would be forced to code them from scratch (a complex development challenge), or, more likely, they would choose to hand-code logic like process flows or business rules into their apps. The result? Those hand-coded applications would be far less flexible and much more expensive to maintain. As a result, low-code development offers a significant advantage whenever there\u2019s a need to build automation into an application. Automation features of low-code platforms can include: A process engine that coordinates and manages end-to-end business processes. The process engine coordinates activities and data movement between people and other systems. It assigns tasks and routes work to both people and software robots. It also provides operational analytics that enable business leadership to monitor and improve performance. Robotic process automation (RPA) capability to fully automate low-value, repetitive tasks \u2013 freeing up users for more productive work. Business rules capability to define, manage and execute rules within the application. These rules can be used (and reused) for everything from defining organizational business policies and security policies to dynamically governing how interfaces are rendered. A wide array of AI services to improve application usability, guide users to informed decisions, and much more. One of the most difficult and time-consuming aspects of enterprise application development is integrating new applications with existing legacy \u201cbrown-field\u201d or new \u201cgreen-field\u201d business system Apps. To reduce the cost of these integrations and enable low-code applications to fit seamlessly into an enterprise architecture, low-code platform vendors are investing in: Drag-and-drop interfaces for declarative integration development. A robust set of integration connectors to common enterprise systems and support for the latest integration standards such as OpenAPI, which enable no-code integration to a wide variety of external systems. Capabilities that enable low-code developers to effortlessly build APIs into their applications, so those applications can be called by other enterprise systems. Specialized capabilities for designing and building applications that are a composite of data from enterprise systems, coupled with newly developed application logic and interface design. This enables application modernization without the extract and port data from existing systems \u2014 a difficult and often risky process.","title":"Low-Code Platforms"},{"location":"low-code/3-2-vs-no-code/#no-code-platforms","text":"Vendor No-Code platform functionality means just that...zero coding is required. Business SMEs quickly transform ideas (or needs) into business apps...with no-code app-building functionality. Most vendor low-code platforms have no-code functionality and tools whereby business SMEs use model-driven-development visual, drag-and-drop development tools and point-and-click interface creation to import data, create and review App functionality, give feedback, validate assumptions, and identify improvements to evolve the applications. However, in most cases only departmental web applications with simple functionality features can be completed using a no-code graphically driven, model-based-development environment.","title":"No-Code Platforms"},{"location":"low-code/3-3-use-cases/","text":"3.3 Low-Code Use Cases There is a wide range of low-code platforms available for facilitating digital transformation for BES PMOs application portfolios. In Section 5 - Low-Code Platform Tool Selection Guidance we survey the industry leaders in low-code development platforms and provide selection guidance based on Gartner and Forrester Research criteria and PCMag testing. In fact, there are three distinct use cases for digital transformation within BES - digital operations, digital experiences, and digital core \u2013 which are all enabled by low-code development platforms. Digital Business Operations Digital transformation starts from within the organization. These are the apps that support BES PMOs internal logistics, business, finance, accounting and human resources operations. The goal is to replace what has been cobbled together and what relies on manual effort, email, spreadsheets, and small departmental apps. The typical low-code solutions are dashboards, workflows, web portals, mobile applications, and small-to-medium-sized database apps. The needs of digital business operations include the rapid development of mobile and web responsive apps; simple development of forms, reports and workflows; fast integration with systems of record; rapid change and deployment; built-in analytics for productivity insights; dashboards for managers; and machine learning and AI integration for sophisticated decision makers. Digital Experiences Another low-code use case is tackling what customers experience digitally. The typical solutions are customer mobile apps, customer portals, and business portals and can include field operations apps and even apps for warfighter mission support. Building digital experiences requires human centered design principles, rapid prototyping and development, pixel-perfect design, massive scalability, and security, including for offline data. In addition, these user experiences are instrumented to generate metrics that provide insights for BES PMO app portfolio continuous improvement efforts. Digital Core The final use case for low-code digital transformation addresses the combination of aging systems and highly customized COTS packages. These core systems are not always able to keep up with the demands of the Air Force logistics, business and finance users. Replacing them could take several years. In these situations, hardly anything is typical, but a few examples of what the Air Force has built are found in Logistics Apps; ERP systems in the financial products sector; human resources management Apps, and Civil Engineering support Apps. Every successful organization has to make the transition from a world defined primarily by repetition to one primarily defined by change. Digital transformation is leading the biggest business transformation in the structure of how humans work together since the Agricultural Revolution. Leading low-code vendors support these common digital business use cases with tools and features to deliver web and mobile user experiences, including sophisticated forms, page navigation, and single-page apps. Other functionality includes basic data management and reporting, workflow automation, and collaboration tools and features. Differentiated products include tools for pixel-perfect native mobile apps, natural language processing, event-management applications, and apps incorporating machine learning. The leading vendors have also moved into business process automation, real-time applications, Analytics and Artificial Intelligence (AI) services, as well as large, mission-critical apps such as case management and content management.","title":"3.3 Low-Code Use Cases"},{"location":"low-code/3-3-use-cases/#33-low-code-use-cases","text":"There is a wide range of low-code platforms available for facilitating digital transformation for BES PMOs application portfolios. In Section 5 - Low-Code Platform Tool Selection Guidance we survey the industry leaders in low-code development platforms and provide selection guidance based on Gartner and Forrester Research criteria and PCMag testing. In fact, there are three distinct use cases for digital transformation within BES - digital operations, digital experiences, and digital core \u2013 which are all enabled by low-code development platforms.","title":"3.3 Low-Code Use Cases"},{"location":"low-code/3-3-use-cases/#digital-business-operations","text":"Digital transformation starts from within the organization. These are the apps that support BES PMOs internal logistics, business, finance, accounting and human resources operations. The goal is to replace what has been cobbled together and what relies on manual effort, email, spreadsheets, and small departmental apps. The typical low-code solutions are dashboards, workflows, web portals, mobile applications, and small-to-medium-sized database apps. The needs of digital business operations include the rapid development of mobile and web responsive apps; simple development of forms, reports and workflows; fast integration with systems of record; rapid change and deployment; built-in analytics for productivity insights; dashboards for managers; and machine learning and AI integration for sophisticated decision makers.","title":"Digital Business Operations"},{"location":"low-code/3-3-use-cases/#digital-experiences","text":"Another low-code use case is tackling what customers experience digitally. The typical solutions are customer mobile apps, customer portals, and business portals and can include field operations apps and even apps for warfighter mission support. Building digital experiences requires human centered design principles, rapid prototyping and development, pixel-perfect design, massive scalability, and security, including for offline data. In addition, these user experiences are instrumented to generate metrics that provide insights for BES PMO app portfolio continuous improvement efforts.","title":"Digital Experiences"},{"location":"low-code/3-3-use-cases/#digital-core","text":"The final use case for low-code digital transformation addresses the combination of aging systems and highly customized COTS packages. These core systems are not always able to keep up with the demands of the Air Force logistics, business and finance users. Replacing them could take several years. In these situations, hardly anything is typical, but a few examples of what the Air Force has built are found in Logistics Apps; ERP systems in the financial products sector; human resources management Apps, and Civil Engineering support Apps. Every successful organization has to make the transition from a world defined primarily by repetition to one primarily defined by change. Digital transformation is leading the biggest business transformation in the structure of how humans work together since the Agricultural Revolution. Leading low-code vendors support these common digital business use cases with tools and features to deliver web and mobile user experiences, including sophisticated forms, page navigation, and single-page apps. Other functionality includes basic data management and reporting, workflow automation, and collaboration tools and features. Differentiated products include tools for pixel-perfect native mobile apps, natural language processing, event-management applications, and apps incorporating machine learning. The leading vendors have also moved into business process automation, real-time applications, Analytics and Artificial Intelligence (AI) services, as well as large, mission-critical apps such as case management and content management.","title":"Digital Core"},{"location":"low-code/3-4-benefits/","text":"3.4 Low-Code Benefits The benefits of modern low-code development platforms are: Minimal coding, as in user-friendly, visual, drag-and-drop functionality: Removal of barriers between Business and IT to support Agile continual collaboration and improvements. Minimal necessary upfront investment in setup, configuration, training, and deployment. Reduced IT SysOps support, with tools so easy to use that even citizen developers can create apps that integrate into the IT environment. Instant, native mobility with no extra time, effort, or resources required. Minimal hand-coding required. Visual, drag-and-drop development tools and point-and-click interface creation to make creating and changing enterprise apps easy and fast. Seamless integration unifying all data, processes, apps, and existing systems. Apps are simple and intuitive to use, providing a streamlined user experience and working as expected on any device. Hyper-responsiveness, the ability to go from idea to App immediately: Ability to rapidly deliver applications in collaboration with product owners and business user stakeholders increases the PMO\u2019s agility and responsiveness to business and mission needs. Speed is at the core of vendor no-code framework functionality: business SMEs ideas can become fully functional and PMOs can launch apps in minutes, not months. Adapt quickly to evolving business conditions, user expectations, and new technologies. Stay ahead of the evolving expectations of stakeholders, users and Senior IT leadership. Deployed in the cloud as PaaS or SaaS services, low-code helps reduce the on-premises IT maintenance burden. Enterprise-grade, secure, scalable functionality - the opposite of what most people think when they hear low-code: Ability to build and launch unique apps that meet enterprise-level mission needs, not just departmental ones. Ability to expand departmental apps to address enterprise-wide challenges, no matter how large. Ability to roll out enterprise-apps across the organization, no matter how many people or how geographically diverse. Security certifications, like PCI, HIPAA, SOC 2 and 3, and many more. Evolve ideas and apps into sophisticated, powerful solutions tailored to business users, stakeholders and the warfighter. Transform the PMO\u2019s IT organization, achieve business agility, and become a digital business leader. Scale instantly for any project, program, or line-of-business, no matter how large.","title":"3.4 Low-Code Benefits"},{"location":"low-code/3-4-benefits/#34-low-code-benefits","text":"The benefits of modern low-code development platforms are:","title":"3.4 Low-Code Benefits"},{"location":"low-code/3-4-benefits/#minimal-coding-as-in-user-friendly-visual-drag-and-drop-functionality","text":"Removal of barriers between Business and IT to support Agile continual collaboration and improvements. Minimal necessary upfront investment in setup, configuration, training, and deployment. Reduced IT SysOps support, with tools so easy to use that even citizen developers can create apps that integrate into the IT environment. Instant, native mobility with no extra time, effort, or resources required. Minimal hand-coding required. Visual, drag-and-drop development tools and point-and-click interface creation to make creating and changing enterprise apps easy and fast. Seamless integration unifying all data, processes, apps, and existing systems. Apps are simple and intuitive to use, providing a streamlined user experience and working as expected on any device.","title":"Minimal coding, as in user-friendly, visual, drag-and-drop functionality:"},{"location":"low-code/3-4-benefits/#hyper-responsiveness-the-ability-to-go-from-idea-to-app-immediately","text":"Ability to rapidly deliver applications in collaboration with product owners and business user stakeholders increases the PMO\u2019s agility and responsiveness to business and mission needs. Speed is at the core of vendor no-code framework functionality: business SMEs ideas can become fully functional and PMOs can launch apps in minutes, not months. Adapt quickly to evolving business conditions, user expectations, and new technologies. Stay ahead of the evolving expectations of stakeholders, users and Senior IT leadership. Deployed in the cloud as PaaS or SaaS services, low-code helps reduce the on-premises IT maintenance burden.","title":"Hyper-responsiveness, the ability to go from idea to App immediately:"},{"location":"low-code/3-4-benefits/#enterprise-grade-secure-scalable-functionality-the-opposite-of-what-most-people-think-when-they-hear-low-code","text":"Ability to build and launch unique apps that meet enterprise-level mission needs, not just departmental ones. Ability to expand departmental apps to address enterprise-wide challenges, no matter how large. Ability to roll out enterprise-apps across the organization, no matter how many people or how geographically diverse. Security certifications, like PCI, HIPAA, SOC 2 and 3, and many more. Evolve ideas and apps into sophisticated, powerful solutions tailored to business users, stakeholders and the warfighter. Transform the PMO\u2019s IT organization, achieve business agility, and become a digital business leader. Scale instantly for any project, program, or line-of-business, no matter how large.","title":"Enterprise-grade, secure, scalable functionality - the opposite of what most people think when they hear low-code:"},{"location":"low-code/3-5-limitations/","text":"3.5 Low-Code Limitations Low-code development frameworks have limits to the complexity of the functionality that can be built using visual drag and drop modeling and point and click. When these limitations are reached, low-code developers may need to drop out of the low-code visual development environment and build the complex functionality using a hand-coding Integrated Development Environment (IDE) and APIs accessible from within the low-code app development framework. Modern low-code development frameworks have now evolved to allow low-code developers to choose to work in either hand-coding or declarative scripting tools. Embedded IDEs, code editors and APIs free developers to build features outside of the low-code platform\u2019s framework but manage that code within the low-code framework project tools. \u201cCode behind\u201d approaches allow low-code developers to swap back and forth between graphical and hand-coding views of their apps and take advantage of visual design tools\u2014like visual drag-and-drop modelers and point-and-click interface creation\u2014to enable the rapid creation, launch, operations and change control of a business app portfolio.","title":"3.5 Low-Code Limitations"},{"location":"low-code/3-5-limitations/#35-low-code-limitations","text":"Low-code development frameworks have limits to the complexity of the functionality that can be built using visual drag and drop modeling and point and click. When these limitations are reached, low-code developers may need to drop out of the low-code visual development environment and build the complex functionality using a hand-coding Integrated Development Environment (IDE) and APIs accessible from within the low-code app development framework. Modern low-code development frameworks have now evolved to allow low-code developers to choose to work in either hand-coding or declarative scripting tools. Embedded IDEs, code editors and APIs free developers to build features outside of the low-code platform\u2019s framework but manage that code within the low-code framework project tools. \u201cCode behind\u201d approaches allow low-code developers to swap back and forth between graphical and hand-coding views of their apps and take advantage of visual design tools\u2014like visual drag-and-drop modelers and point-and-click interface creation\u2014to enable the rapid creation, launch, operations and change control of a business app portfolio.","title":"3.5 Low-Code Limitations"},{"location":"low-code/4-1-strategy/","text":"","title":"4.1 BES Digital Strategy"},{"location":"low-code/4-2-dev-lifecycle/","text":"","title":"4.2 Low-Code Software Development Lifecycle"},{"location":"low-code/4-3-team/","text":"","title":"4.3 Team Structure"},{"location":"low-code/4-4-management-process/","text":"","title":"4.4 Project Management Processes"},{"location":"low-code/4-5-kpi/","text":"","title":"4.5 Key Project Metrics \u2013 KPI\u2019s"},{"location":"low-code/5-1-analysis/","text":"","title":"5.1 How to conduct Low-Code Platform Tool Analysis"},{"location":"low-code/5-2-market-leaders/","text":"","title":"5.2 Current Market Leaders (Forrester, Gartner)"},{"location":"low-code/6-1-con-it/","text":"6.1 Air Force Contracting Information Technology (CON-IT) Contracting Information Technology System (CON-IT) provides a single contract writing system for the Air Force (AF) contracting community to support all contracting needs including base operations, logistics, contingency, and weapons system contracting world-wide. CON-IT will enable strategic sourcing and other acquisition efficiencies by standardizing data, business rules, and milestone tracking. Furthermore, CON-IT will allow for a standardized and integrated method of anticipating, reacting, and responding to the current pace and changes in process, regulation, and technology across the contract domain. When fully implemented, CON-IT will enable process changes necessary to converge on a common contract writing/management capability within the AF. CON-IT will address the current inefficiencies in the contracting domain, given there are multiple contract writing systems that continue to challenge the ability to operate responsively, consistently, and cost-effectively to award, administer, and close out mission critical contracts in a timely fashion. CON-IT will allow the contracting community to fully support compliance with financial auditability and Financial Improvement Audit Readiness (FIAR) goals that depend on the integrity of the data flow through the Procure to Pay (P2P) process. 6.1.1 Program Overview The CON-IT program provides the Air Force with a procurement capability for processing all contract requirements from inception to closeout, supported by a modern, secure technical architecture enabling end-to-end alignment of business processes and data, compliant with regulation, supporting FIAR audit readiness, and providing business information for decision makers. CON-IT will share data using the DLA Transaction Services (DLATS) Global Exchange (GEX) with several AF, DOD, and Federal procurement, contracting and financial information systems. CON-IT complies with the Procurement Data Standard (PDS) and/or Purchase Request Data Standard (PRDS) which enforces FAR- and DFARS-based business rules that have been documented as constraints and data values in the PDS and PRDS eXtensible Markup Language (XML) schemas. Contracting professionals provide contracting support capabilities to a wide spectrum of missions, including (but not limited to) weapons systems, research & development, logistics and sustainment, installation and mission support, and contingency operations which includes supporting other federal agencies during natural disasters. The Air Force Contracting Strategic Plan 2009-2013 outline these capabilities. Specifically, Goal 3 states \u201cWe will posture the Air Force as a demanding customer to our suppliers and ensure our Air Force Contracting processes and systems are able to meet the challenges of today and tomorrow.\u201d Objective 3.2 further states that \u201ctechnology offers significant possibilities for improvement\u201d through \u201ctwo technical upgrades: (1) implementing a single contract writing system and (2) developing a web-based capability for decentralized ordering.\u201d The goal of CON-IT is to become the Air Force\u2019s single contract writing system. CON-IT will provide contracting professionals with a seamless workspace that supports all requirements defined in the CON-IT Bounded User Requirements. The CON-IT program will deploy system capabilities as a series of development / test / delivery capability increments and releases following an agile approach to both acquisition and development. CON-IT will provide the key tool towards meeting the Air Force\u2019s requirement for improved contracting effectiveness and efficiencies, as directed by SAF/AQC. 6.1.2 Program POC\u2019s AF CON-IT Program Management Office (PMO) POC Role Major General Holt AF Functional (Customer) System Owner Mr. Michael Allen Program Manager Mr. Ted Blonk Deputy Program Manager Mr. Bob Harts Chief Engineer (Owner of DevSecOps & entire Architecture) Mr. Nathan Hay Lead Engineer (deputy owner of all DevSecOps, Networking, Infrastructure, architecture) Mr. Jake Haney ISSM (ATO package and Security compliance management) Mr. Dave Mitchell Data Interface Product Owner (all Data Interfaces for Ingress and Egress for CON-IT) Mr. Patrick Knepper Function Owner/Requirements AQCI \u2013 Program Manager Mrs. Lara Emmons Deputy Function/Requirements Owner AQCI \u2013 Program Manager Mr. Bill Woods Function customer interface and Functional requirements representative. (Bill is the hands-on functional liaison to AF PMO and AQCI customers) 6.1.3 Platform Selection Process Unlike many programs, CON-IT existed in various forms since initiation in 2001 as the Defense Acquisition Domain Sourcing (DADS) program and shortly thereafter as the Defense Business Sourcing Environment (DBSE) program. After ASD/NII MS A approval, the executive agent at the Department\u2019s Business Transformation Agency (BTA) put the program in abeyance as it did not have the funding required to initiate post-milestone A tasks. DBSE would have replaced all Department of Defense (DOD) contract writing and contract management programs and/or applications with a standard DOD-wide system. Shortly after putting DBSE in abeyance, MG Pair (USA) identified a follow-on Standard Procurement System (SPS) increment, version 4.2.3, as a partial, low-cost solution to meet many DBSE requirements. However, on 3 Jan 2007 after several version 4.2.3 test failures, MG Pair cancelled SPS version 4.2.3, re-baselined the program to the final 4.2.2 version and restructured the program office to provide minimal support in the form of service releases to keep the product current until the Department could find a replacement. CON-IT\u2019s Appian development platform provides the Air Force a solution to satisfy DBSE functional requirements using low-code development. CON-IT was assessed against an existing DISA contracting system that is based on the Appian Low-Code platform. CON-IT was able to work with DISA team members and adapt the Appian code base and existing functionality for contracting. CON-IT made system updates to the Appian code base to enhance the existing code to meet AF contracting requirements. CON-IT is hosted in United States Department of Agriculture (USDA) data centers with Disaster Recover/Failover Site. The system is categorized as Impact level 4. CON-IT has an ATO managed through AF program management office located at Wright Patterson AFB. 6.1.4 High Level Design CON-IT is based on the Appian N-tier architecture engineered to have the processing, data management, and presentation tiers physically and logically separated. The processing, data management and presentation components are hosted on compute clusters configured in a high availability configuration, ensuring the services provides limiting physical resources sharing. Each service is built to deliver maximum capacity and scalability with only planned outages. High Level Architecture \u2013 Shows Appian N-Tier CON-IT application This view is a detailed architectural view of Appian Low-Code Engine Layer 6.1.5 Key Benefits of Implementing Low-Code for CON-IT The key benefits CON-IT realized from the Appian Low-Code Development Platform are: Ability to rapidly deliver applications in collaboration with Air Force product owners and contracting user stakeholders increases the PMO\u2019s agility and responsiveness to business and mission needs. Speed is at the core of Appian low-code framework functionality: business SMEs ideas can become fully functional and the PMOs can launch apps in minutes, not months. Minimal hand-coding required. Minimal necessary upfront investment in setup, configuration, training, and deployment. Visual, drag-and-drop development tools and point-and-click interface creation to make creating and changing enterprise apps easy and fast. Seamless integration with 3 GL external Apps to unify all data, processes, apps, and existing systems. Apps are simple and intuitive to use, providing a streamlined user experience and work as expected on any device. Ability to roll out enterprise-apps across the Air Force, no matter how many people or how geographically diverse. Scale to meet the CON-IT line-of-business requirements and large number of concurrent users.","title":"6.1 Air Force Contracting Information Technology (CON-IT)"},{"location":"low-code/6-1-con-it/#61-air-force-contracting-information-technology-con-it","text":"Contracting Information Technology System (CON-IT) provides a single contract writing system for the Air Force (AF) contracting community to support all contracting needs including base operations, logistics, contingency, and weapons system contracting world-wide. CON-IT will enable strategic sourcing and other acquisition efficiencies by standardizing data, business rules, and milestone tracking. Furthermore, CON-IT will allow for a standardized and integrated method of anticipating, reacting, and responding to the current pace and changes in process, regulation, and technology across the contract domain. When fully implemented, CON-IT will enable process changes necessary to converge on a common contract writing/management capability within the AF. CON-IT will address the current inefficiencies in the contracting domain, given there are multiple contract writing systems that continue to challenge the ability to operate responsively, consistently, and cost-effectively to award, administer, and close out mission critical contracts in a timely fashion. CON-IT will allow the contracting community to fully support compliance with financial auditability and Financial Improvement Audit Readiness (FIAR) goals that depend on the integrity of the data flow through the Procure to Pay (P2P) process.","title":"6.1 Air Force Contracting Information Technology (CON-IT)"},{"location":"low-code/6-1-con-it/#611-program-overview","text":"The CON-IT program provides the Air Force with a procurement capability for processing all contract requirements from inception to closeout, supported by a modern, secure technical architecture enabling end-to-end alignment of business processes and data, compliant with regulation, supporting FIAR audit readiness, and providing business information for decision makers. CON-IT will share data using the DLA Transaction Services (DLATS) Global Exchange (GEX) with several AF, DOD, and Federal procurement, contracting and financial information systems. CON-IT complies with the Procurement Data Standard (PDS) and/or Purchase Request Data Standard (PRDS) which enforces FAR- and DFARS-based business rules that have been documented as constraints and data values in the PDS and PRDS eXtensible Markup Language (XML) schemas. Contracting professionals provide contracting support capabilities to a wide spectrum of missions, including (but not limited to) weapons systems, research & development, logistics and sustainment, installation and mission support, and contingency operations which includes supporting other federal agencies during natural disasters. The Air Force Contracting Strategic Plan 2009-2013 outline these capabilities. Specifically, Goal 3 states \u201cWe will posture the Air Force as a demanding customer to our suppliers and ensure our Air Force Contracting processes and systems are able to meet the challenges of today and tomorrow.\u201d Objective 3.2 further states that \u201ctechnology offers significant possibilities for improvement\u201d through \u201ctwo technical upgrades: (1) implementing a single contract writing system and (2) developing a web-based capability for decentralized ordering.\u201d The goal of CON-IT is to become the Air Force\u2019s single contract writing system. CON-IT will provide contracting professionals with a seamless workspace that supports all requirements defined in the CON-IT Bounded User Requirements. The CON-IT program will deploy system capabilities as a series of development / test / delivery capability increments and releases following an agile approach to both acquisition and development. CON-IT will provide the key tool towards meeting the Air Force\u2019s requirement for improved contracting effectiveness and efficiencies, as directed by SAF/AQC.","title":"6.1.1 Program Overview"},{"location":"low-code/6-1-con-it/#612-program-pocs","text":"AF CON-IT Program Management Office (PMO) POC Role Major General Holt AF Functional (Customer) System Owner Mr. Michael Allen Program Manager Mr. Ted Blonk Deputy Program Manager Mr. Bob Harts Chief Engineer (Owner of DevSecOps & entire Architecture) Mr. Nathan Hay Lead Engineer (deputy owner of all DevSecOps, Networking, Infrastructure, architecture) Mr. Jake Haney ISSM (ATO package and Security compliance management) Mr. Dave Mitchell Data Interface Product Owner (all Data Interfaces for Ingress and Egress for CON-IT) Mr. Patrick Knepper Function Owner/Requirements AQCI \u2013 Program Manager Mrs. Lara Emmons Deputy Function/Requirements Owner AQCI \u2013 Program Manager Mr. Bill Woods Function customer interface and Functional requirements representative. (Bill is the hands-on functional liaison to AF PMO and AQCI customers)","title":"6.1.2 Program POC\u2019s"},{"location":"low-code/6-1-con-it/#613-platform-selection-process","text":"Unlike many programs, CON-IT existed in various forms since initiation in 2001 as the Defense Acquisition Domain Sourcing (DADS) program and shortly thereafter as the Defense Business Sourcing Environment (DBSE) program. After ASD/NII MS A approval, the executive agent at the Department\u2019s Business Transformation Agency (BTA) put the program in abeyance as it did not have the funding required to initiate post-milestone A tasks. DBSE would have replaced all Department of Defense (DOD) contract writing and contract management programs and/or applications with a standard DOD-wide system. Shortly after putting DBSE in abeyance, MG Pair (USA) identified a follow-on Standard Procurement System (SPS) increment, version 4.2.3, as a partial, low-cost solution to meet many DBSE requirements. However, on 3 Jan 2007 after several version 4.2.3 test failures, MG Pair cancelled SPS version 4.2.3, re-baselined the program to the final 4.2.2 version and restructured the program office to provide minimal support in the form of service releases to keep the product current until the Department could find a replacement. CON-IT\u2019s Appian development platform provides the Air Force a solution to satisfy DBSE functional requirements using low-code development. CON-IT was assessed against an existing DISA contracting system that is based on the Appian Low-Code platform. CON-IT was able to work with DISA team members and adapt the Appian code base and existing functionality for contracting. CON-IT made system updates to the Appian code base to enhance the existing code to meet AF contracting requirements. CON-IT is hosted in United States Department of Agriculture (USDA) data centers with Disaster Recover/Failover Site. The system is categorized as Impact level 4. CON-IT has an ATO managed through AF program management office located at Wright Patterson AFB.","title":"6.1.3 Platform Selection Process"},{"location":"low-code/6-1-con-it/#614-high-level-design","text":"CON-IT is based on the Appian N-tier architecture engineered to have the processing, data management, and presentation tiers physically and logically separated. The processing, data management and presentation components are hosted on compute clusters configured in a high availability configuration, ensuring the services provides limiting physical resources sharing. Each service is built to deliver maximum capacity and scalability with only planned outages. High Level Architecture \u2013 Shows Appian N-Tier CON-IT application This view is a detailed architectural view of Appian Low-Code Engine Layer","title":"6.1.4 High Level Design"},{"location":"low-code/6-1-con-it/#615-key-benefits-of-implementing-low-code-for-con-it","text":"The key benefits CON-IT realized from the Appian Low-Code Development Platform are: Ability to rapidly deliver applications in collaboration with Air Force product owners and contracting user stakeholders increases the PMO\u2019s agility and responsiveness to business and mission needs. Speed is at the core of Appian low-code framework functionality: business SMEs ideas can become fully functional and the PMOs can launch apps in minutes, not months. Minimal hand-coding required. Minimal necessary upfront investment in setup, configuration, training, and deployment. Visual, drag-and-drop development tools and point-and-click interface creation to make creating and changing enterprise apps easy and fast. Seamless integration with 3 GL external Apps to unify all data, processes, apps, and existing systems. Apps are simple and intuitive to use, providing a streamlined user experience and work as expected on any device. Ability to roll out enterprise-apps across the Air Force, no matter how many people or how geographically diverse. Scale to meet the CON-IT line-of-business requirements and large number of concurrent users.","title":"6.1.5 Key Benefits of Implementing Low-Code for CON-IT"},{"location":"low-code/7-1-evaluation/","text":"","title":"7.1 Evaluation Template"},{"location":"low-code/8-1-terminology/","text":"","title":"8.1 Low-Code Terminology"},{"location":"low-code/9-1-glossary/","text":"","title":"9.1 Glossary"},{"location":"modern/1-1-play-1/","text":"1.1 Play 1: Determine the application\u2019s future lifespan Before modernizing any legacy application, it is crucial to understand how long the application will remain in service and under what conditions, to ensure modifications produce a prudent mission value and return on investment (ROI) balance. It is essential for the application or product owner to provide requirements and constraints that direct the effort. Currently, DoD services are rationalizing their application portfolios for mission effectiveness and cost efficiency. This is leading to applications being subsumed by other applications, applications being retired, applications being refactored and deployed to cloud environments, and other portfolio consolidation approaches. Checklist Identify the application modernization project\u2019s champion, the application owner that believes in the value of the endeavor. Obtain and document the application\u2019s future lifespan from the application owner. Gather application modernization requirements and constraints from the application or product owner. If not documented, document these requirements in a formal manner, have it reviewed by the application or product owner, and place under configuration management. This application modernization requirements document should contain: application portfolio information, application rationalization information, application lifespan forecast including dates, requirements list, requirements analysis, other pertinent information that will help when determining the best modernization course of action (COA). Develop a (lean) communication plan to keep application owner, product owner, and stakeholders apprised of important project and related information. Key Questions How long will the modernized application be in service? Are there unique application mission or technical constraints that must be addressed? Will the application be subsumed by another application in the future? If so, when, and what is the technical plan for subsuming? What limitations does this place on the modernization solution?","title":"1.1 Application's Future Lifespan"},{"location":"modern/1-1-play-1/#11-play-1-determine-the-applications-future-lifespan","text":"Before modernizing any legacy application, it is crucial to understand how long the application will remain in service and under what conditions, to ensure modifications produce a prudent mission value and return on investment (ROI) balance. It is essential for the application or product owner to provide requirements and constraints that direct the effort. Currently, DoD services are rationalizing their application portfolios for mission effectiveness and cost efficiency. This is leading to applications being subsumed by other applications, applications being retired, applications being refactored and deployed to cloud environments, and other portfolio consolidation approaches.","title":"1.1  Play 1: Determine the application\u2019s future lifespan"},{"location":"modern/1-1-play-1/#checklist","text":"Identify the application modernization project\u2019s champion, the application owner that believes in the value of the endeavor. Obtain and document the application\u2019s future lifespan from the application owner. Gather application modernization requirements and constraints from the application or product owner. If not documented, document these requirements in a formal manner, have it reviewed by the application or product owner, and place under configuration management. This application modernization requirements document should contain: application portfolio information, application rationalization information, application lifespan forecast including dates, requirements list, requirements analysis, other pertinent information that will help when determining the best modernization course of action (COA). Develop a (lean) communication plan to keep application owner, product owner, and stakeholders apprised of important project and related information.","title":"Checklist"},{"location":"modern/1-1-play-1/#key-questions","text":"How long will the modernized application be in service? Are there unique application mission or technical constraints that must be addressed? Will the application be subsumed by another application in the future? If so, when, and what is the technical plan for subsuming? What limitations does this place on the modernization solution?","title":"Key Questions"},{"location":"modern/1-2-play-2/","text":"1.2 Play 2: Collect, analyze, and assess the existing (legacy) application\u2019s technical baseline Once Play 1 is complete, the existing (legacy) application technical baseline must be collected, reviewed, analyzed, and understood. Many applications will not be documented completely or accurately enough to allow for the necessary analysis and assessment required for developing a modernization solution and plan. In this case, technical baseline documentation gaps must be closed, or an automated discovery tool must be used to extract the technical baseline from the production application. The best approach is to collect the existing documentation and artifacts, as well as use an automated discovery tool, and then correlate the technical information. Checklist Gather technical baseline documentation and engineering artifacts (including models) from the application owner and team. Use an automated discovery tool to obtain the technical baseline from the actual production application. For example, the Micro Focus Enterprise Analyzer tool can discover, evaluate, and document applications, their business value, and their interdependencies across the entire organization. Create a new technical library of technical baseline information to be used during the modernization project. Review all information and develop updated architectural framework views of the application to ensure all stakeholders understand the application\u2019s current technical baseline. Run automated tools against the code baseline to understand the quality of the existing baseline. These tools also provide insight on the steps that may correct quality issues. More information on these tools is provided in the complete playbook. Key Questions Is the technical baseline complete? Are there important gaps? How can the gaps be closed? How can the right automated discovery tool be used to improve the quality of the current (legacy) technical baseline? How much technical debt exists with the current legacy application? How should this technical debt be accounted for?","title":"1.2 Technical Baseline"},{"location":"modern/1-2-play-2/#12-play-2-collect-analyze-and-assess-the-existing-legacy-applications-technical-baseline","text":"Once Play 1 is complete, the existing (legacy) application technical baseline must be collected, reviewed, analyzed, and understood. Many applications will not be documented completely or accurately enough to allow for the necessary analysis and assessment required for developing a modernization solution and plan. In this case, technical baseline documentation gaps must be closed, or an automated discovery tool must be used to extract the technical baseline from the production application. The best approach is to collect the existing documentation and artifacts, as well as use an automated discovery tool, and then correlate the technical information.","title":"1.2 Play 2: Collect, analyze, and assess the existing (legacy) application\u2019s technical baseline"},{"location":"modern/1-2-play-2/#checklist","text":"Gather technical baseline documentation and engineering artifacts (including models) from the application owner and team. Use an automated discovery tool to obtain the technical baseline from the actual production application. For example, the Micro Focus Enterprise Analyzer tool can discover, evaluate, and document applications, their business value, and their interdependencies across the entire organization. Create a new technical library of technical baseline information to be used during the modernization project. Review all information and develop updated architectural framework views of the application to ensure all stakeholders understand the application\u2019s current technical baseline. Run automated tools against the code baseline to understand the quality of the existing baseline. These tools also provide insight on the steps that may correct quality issues. More information on these tools is provided in the complete playbook.","title":"Checklist"},{"location":"modern/1-2-play-2/#key-questions","text":"Is the technical baseline complete? Are there important gaps? How can the gaps be closed? How can the right automated discovery tool be used to improve the quality of the current (legacy) technical baseline? How much technical debt exists with the current legacy application? How should this technical debt be accounted for?","title":"Key Questions"},{"location":"modern/1-3-play-3/","text":"1.3 Play 3: Determine viable application modernization solution options Building on the knowledge gained in the previous plays, this play begins the solution design process by considering the requirements and outcomes the application owner and the enterprise desire for this application\u2019s future state and identifying viable solution options (alternative solutions) that need to be analyzed, compared, evaluated, and communicated. Checklist Perform Solution Discovery and Design and identify viable solution options. Solution Options should align with BES BPD best practices, Air Force preferred technology roadmap, standard hosting (such as CIE and CCE models) and take into account enterprise license agreements and terms. If Mainframe Legacy System, identify UNISYS (or IBM) Mainframe Modernization Solutions Options; i.e. code transformation and refactoring, open architecture mainframe transaction processing emulators, Mainframe Cloud Frameworks, replacement with Low Code COTS package, and database migration connectors If Oracle Solaris or HP-UX legacy Systems identify open architecture Cloud Architecture Reference Models, automated code refactoring and database migration connectors. Perform an analysis of alternatives (AoA) for viable solution options to determine the best option. Begin by creating a scoring matrix and evaluation method that measures the key solution parameters as objectively as possible. Ensure the matrix and method appropriately focuses on the value of applying automated tools over manual labor tasks. Analyze and score each of the viable solution options using the matrix and method. Report findings and recommendations to the appropriate stakeholders. Perform Proof of Concept (POC) projects to validate options and assumptions especially with respect to the use of automated software modernization and engineering tools for the solution options that scored the highest. Identify automated tools (see Section 4) and methods to modernize the application. Work with vendors and see demonstrations of the most encouraging tools. Key Questions What are the BES preferred enterprise IT technologies that should be considered for the modernized application? What IT licenses does the enterprise invest in? What will future licensing agreements be? Does the enterprise desire to move to open source products? Under what conditions? What environments must the modernized application operate in? Consider: development, test, pre-production, production and other environments.","title":"1.3 Modernization Options"},{"location":"modern/1-3-play-3/#13-play-3-determine-viable-application-modernization-solution-options","text":"Building on the knowledge gained in the previous plays, this play begins the solution design process by considering the requirements and outcomes the application owner and the enterprise desire for this application\u2019s future state and identifying viable solution options (alternative solutions) that need to be analyzed, compared, evaluated, and communicated.","title":"1.3 Play 3: Determine viable application modernization solution options"},{"location":"modern/1-3-play-3/#checklist","text":"Perform Solution Discovery and Design and identify viable solution options. Solution Options should align with BES BPD best practices, Air Force preferred technology roadmap, standard hosting (such as CIE and CCE models) and take into account enterprise license agreements and terms. If Mainframe Legacy System, identify UNISYS (or IBM) Mainframe Modernization Solutions Options; i.e. code transformation and refactoring, open architecture mainframe transaction processing emulators, Mainframe Cloud Frameworks, replacement with Low Code COTS package, and database migration connectors If Oracle Solaris or HP-UX legacy Systems identify open architecture Cloud Architecture Reference Models, automated code refactoring and database migration connectors. Perform an analysis of alternatives (AoA) for viable solution options to determine the best option. Begin by creating a scoring matrix and evaluation method that measures the key solution parameters as objectively as possible. Ensure the matrix and method appropriately focuses on the value of applying automated tools over manual labor tasks. Analyze and score each of the viable solution options using the matrix and method. Report findings and recommendations to the appropriate stakeholders. Perform Proof of Concept (POC) projects to validate options and assumptions especially with respect to the use of automated software modernization and engineering tools for the solution options that scored the highest. Identify automated tools (see Section 4) and methods to modernize the application. Work with vendors and see demonstrations of the most encouraging tools.","title":"Checklist"},{"location":"modern/1-3-play-3/#key-questions","text":"What are the BES preferred enterprise IT technologies that should be considered for the modernized application? What IT licenses does the enterprise invest in? What will future licensing agreements be? Does the enterprise desire to move to open source products? Under what conditions? What environments must the modernized application operate in? Consider: development, test, pre-production, production and other environments.","title":"Key Questions"},{"location":"modern/1-4-play-4/","text":"1.4 Play 4: Determine the target (\u201cTo-Be\u201d) modernized application solution Building on Play 3, this play determines the complete target (or \u201cTo-Be\u201d) solution architecture for the modernized application. Checklist Determine the application architecture including: overall architecture, operating system, coding paradigm, code language, frameworks, database type, etc. Determine the development methodologies to be used: agile, DevOps, hybrid. Determine DevOps automation solution (or use one provided by the enterprise). Integrate Cyber Security, accreditation, and compliance requirements as this target solution is defined. Determine the hosting solutions. Will the application be hosted in the cloud (government cloud, shared cloud, private cloud, on-premise hosting, hybrid)? Consider each environment the application needs: development, testing, pre-production, production, and others. Determine where each of these environments be hosted. Determine how the application baseline upgrades will flow between environments (ie: promoted from one environment to the next)? Determine the enterprise computing services (ie: platform as a service, PaaS) required to host the application. Determine solutions for identity and access management (IDAM), data interfacing such as enterprise service bus (ESB) solutions, web services, and microservices. Determine how this application will be operated in the new environment, including backups, monitoring, and disaster recovery. Determine the Help Desk or Service Desk model. BES uses the AF Help Desk. PMs need to address this relatively early in the process and ensure proper agreements and funding are secured. Key Questions Does the target (or \u201cTo-Be\u201d) solution align or comply with enterprise requirements? Are the products used aligned with the enterprise license agreements and forecast?","title":"1.4 Target Application Solution"},{"location":"modern/1-4-play-4/#14-play-4-determine-the-target-to-be-modernized-application-solution","text":"Building on Play 3, this play determines the complete target (or \u201cTo-Be\u201d) solution architecture for the modernized application.","title":"1.4 Play 4: Determine the target (\u201cTo-Be\u201d) modernized application solution"},{"location":"modern/1-4-play-4/#checklist","text":"Determine the application architecture including: overall architecture, operating system, coding paradigm, code language, frameworks, database type, etc. Determine the development methodologies to be used: agile, DevOps, hybrid. Determine DevOps automation solution (or use one provided by the enterprise). Integrate Cyber Security, accreditation, and compliance requirements as this target solution is defined. Determine the hosting solutions. Will the application be hosted in the cloud (government cloud, shared cloud, private cloud, on-premise hosting, hybrid)? Consider each environment the application needs: development, testing, pre-production, production, and others. Determine where each of these environments be hosted. Determine how the application baseline upgrades will flow between environments (ie: promoted from one environment to the next)? Determine the enterprise computing services (ie: platform as a service, PaaS) required to host the application. Determine solutions for identity and access management (IDAM), data interfacing such as enterprise service bus (ESB) solutions, web services, and microservices. Determine how this application will be operated in the new environment, including backups, monitoring, and disaster recovery. Determine the Help Desk or Service Desk model. BES uses the AF Help Desk. PMs need to address this relatively early in the process and ensure proper agreements and funding are secured.","title":"Checklist"},{"location":"modern/1-4-play-4/#key-questions","text":"Does the target (or \u201cTo-Be\u201d) solution align or comply with enterprise requirements? Are the products used aligned with the enterprise license agreements and forecast?","title":"Key Questions"},{"location":"modern/1-5-play-5/","text":"1.5 Play 5: Formulate the application modernization and migration plan (how to move from \u201cAs-Is\u201d to \u201cTo-Be\u201d state) This play develops the plan for migrating the application from the legacy (determined in Play 2) to modernized (determined in Play 3, 4) state using automation. Checklist Create the development environment. Create proper networking solution (consistent with production solution). Allow network access to the enterprise computing services (PaaS) needed (ie: IDAM, ESB, others). Install COTS products to be used. Map business logic components from the legacy to modernized application. Use automated software conversion tools to do the bulk of the work. Note: these tools are specialized, and the right tool(s) must be used for the task at hand. More about these tools are included in the complete playbook. Choose a data store (database) that best meets the applications needs. Map data structures from the legacy to modernized application. Migrate the data from the legacy to modernized data store (database). Transform interfaces if necessary. Ensure interfaces can be tested from development and test environments. Create plan for lean documentation using automated and digital means (to maximum extent possible) for: system design, application design, database design, interface design, test cases, operator\u2019s manual, help/service desk guides Key Questions Are all lifecycle processes defined and documented? What activities are not using automation? Why?","title":"1.5 Modernization and Migration Plan"},{"location":"modern/1-5-play-5/#15-play-5-formulate-the-application-modernization-and-migration-plan-how-to-move-from-as-is-to-to-be-state","text":"This play develops the plan for migrating the application from the legacy (determined in Play 2) to modernized (determined in Play 3, 4) state using automation.","title":"1.5 Play 5: Formulate the application modernization and migration plan (how to move from \u201cAs-Is\u201d to \u201cTo-Be\u201d state)"},{"location":"modern/1-5-play-5/#checklist","text":"Create the development environment. Create proper networking solution (consistent with production solution). Allow network access to the enterprise computing services (PaaS) needed (ie: IDAM, ESB, others). Install COTS products to be used. Map business logic components from the legacy to modernized application. Use automated software conversion tools to do the bulk of the work. Note: these tools are specialized, and the right tool(s) must be used for the task at hand. More about these tools are included in the complete playbook. Choose a data store (database) that best meets the applications needs. Map data structures from the legacy to modernized application. Migrate the data from the legacy to modernized data store (database). Transform interfaces if necessary. Ensure interfaces can be tested from development and test environments. Create plan for lean documentation using automated and digital means (to maximum extent possible) for: system design, application design, database design, interface design, test cases, operator\u2019s manual, help/service desk guides","title":"Checklist"},{"location":"modern/1-5-play-5/#key-questions","text":"Are all lifecycle processes defined and documented? What activities are not using automation? Why?","title":"Key Questions"},{"location":"modern/1-6-play-6/","text":"1.6 Play 6: Execute the application modernization plan This play executes the plan developed in Play 5. Checklist Perform the technical modernization tasks discussed in Play 5. Ensure the Help Desk or Service Desk is ready to provide service during and after production cutover. Cutover Stakeholder coordination. Cutover test. Achieve cyber security authorization to operate. Cutover and Go-Live. Leave legacy system in production, but not serving users, until the new modernized system is deemed ready for initial operating capability (IOC) and can reliably serve users. Key Questions What are the key service levels that must be met by the application? How are these measured and reported to key stakeholders? How will the application be sustained once modernized? How will the application evolve?","title":"1.6 Executing the Plan"},{"location":"modern/1-6-play-6/#16-play-6-execute-the-application-modernization-plan","text":"This play executes the plan developed in Play 5.","title":"1.6 Play 6: Execute the application modernization plan"},{"location":"modern/1-6-play-6/#checklist","text":"Perform the technical modernization tasks discussed in Play 5. Ensure the Help Desk or Service Desk is ready to provide service during and after production cutover. Cutover Stakeholder coordination. Cutover test. Achieve cyber security authorization to operate. Cutover and Go-Live. Leave legacy system in production, but not serving users, until the new modernized system is deemed ready for initial operating capability (IOC) and can reliably serve users.","title":"Checklist"},{"location":"modern/1-6-play-6/#key-questions","text":"What are the key service levels that must be met by the application? How are these measured and reported to key stakeholders? How will the application be sustained once modernized? How will the application evolve?","title":"Key Questions"},{"location":"modern/10-1-checklist/","text":"10.1 Checklist for successful application modernization Our checklist of 7 things to consider for a successful AAM project is as follows: 1. Assess the current state of legacy systems. Legacy software does not always fall under \u201cold\u201d or \u201coutdated\u201d definitions. There are more aspects to assess when identifying the legacy. That is why you need to assess all systems in place to uncover the current and potential issues it can bring up soon. The assessment should be systematic and detailed: Study all aspects of your technology, from code and architecture to visual look and feel, considering your future business plans for product growth. 2. Select the modernization approach that would be the fastest to deliver value. Based on the assessment conducted at the first phase, choose the modernization approach that best fits your needs and will help you deliver results fast. Aside from the modernization approaches, consider existing products you can use instead. There is no need to reinvent the wheel if there is a SaaS solution available at a fraction of cost. Yet, if your system solves rather specific tasks or you want to be able to build more features on top of it, custom product development services might be right for you. In this case, adopting agile software development practices can help you speed up the process and deliver value fast. 3. Rethink the architecture and prioritize for simplicity. Legacy systems often fail to perform as needed due to their overly complex structure. When modernizing your system, less is more in terms of both architecture and functionality. Start by implementing only the most important features. Consider a microservices architecture approach to make your product scalable. Additionally, make sure the newly released application will work well with the rest of the tools used in your business by default. If you plan to change any of the tools soon, consider several possible options and keep their requirements in mind when building your application. 4. Choose the technology stack to deliver optimal performance and user experience. When reengineering your system, make sure you use a solid and future-ready technology stack. The choice of technologies should completely depend on the product specifics. Consult with your internal IT staff or address a professional tech consultancy. The right tech stack contributes to building a performant, reliable and efficient product. Adopt a solid quality assurance and testing process to deliver the best results. 5. Document for future system growth. To avoid the same mistakes that made you reengineer your current solution, introduce (or adopt best practices used by other companies) a set of coding standards and internal processes. Orderly documented and clean code make your software easy to understand, extend and maintain in the future. 6. Create a separate support and retirement schedule for your legacy system. Even if you have a brand-new system running like a clockwork, you will still need your legacy software, just in case. So, don\u2019t kill it all at once. Document and archive your solutions so you can easily access and refer to them when needed. Therefore, you need to support your legacy system for some time and plan for retiring your legacy system only when your new product is up and running. 7. Plan for training and system updates. Working with the old systems for years, your employees might need some time and guidance to master the new software. So be ready to invest in knowledge transfer and staff training for better performance and efficiency. Additionally, plan for regular system updates. If you fail to keep your product up to date, you will soon face another modernization challenge.","title":"10 1 checklist"},{"location":"modern/10-1-checklist/#101-checklist-for-successful-application-modernization","text":"Our checklist of 7 things to consider for a successful AAM project is as follows:","title":"10.1 Checklist for successful application modernization"},{"location":"modern/10-1-checklist/#1-assess-the-current-state-of-legacy-systems","text":"Legacy software does not always fall under \u201cold\u201d or \u201coutdated\u201d definitions. There are more aspects to assess when identifying the legacy. That is why you need to assess all systems in place to uncover the current and potential issues it can bring up soon. The assessment should be systematic and detailed: Study all aspects of your technology, from code and architecture to visual look and feel, considering your future business plans for product growth.","title":"1.  Assess the current state of legacy systems."},{"location":"modern/10-1-checklist/#2-select-the-modernization-approach-that-would-be-the-fastest-to-deliver-value","text":"Based on the assessment conducted at the first phase, choose the modernization approach that best fits your needs and will help you deliver results fast. Aside from the modernization approaches, consider existing products you can use instead. There is no need to reinvent the wheel if there is a SaaS solution available at a fraction of cost. Yet, if your system solves rather specific tasks or you want to be able to build more features on top of it, custom product development services might be right for you. In this case, adopting agile software development practices can help you speed up the process and deliver value fast.","title":"2. Select the modernization approach that would be the fastest to deliver value."},{"location":"modern/10-1-checklist/#3-rethink-the-architecture-and-prioritize-for-simplicity","text":"Legacy systems often fail to perform as needed due to their overly complex structure. When modernizing your system, less is more in terms of both architecture and functionality. Start by implementing only the most important features. Consider a microservices architecture approach to make your product scalable. Additionally, make sure the newly released application will work well with the rest of the tools used in your business by default. If you plan to change any of the tools soon, consider several possible options and keep their requirements in mind when building your application.","title":"3. Rethink the architecture and prioritize for simplicity."},{"location":"modern/10-1-checklist/#4-choose-the-technology-stack-to-deliver-optimal-performance-and-user-experience","text":"When reengineering your system, make sure you use a solid and future-ready technology stack. The choice of technologies should completely depend on the product specifics. Consult with your internal IT staff or address a professional tech consultancy. The right tech stack contributes to building a performant, reliable and efficient product. Adopt a solid quality assurance and testing process to deliver the best results.","title":"4. Choose the technology stack to deliver optimal performance and user experience."},{"location":"modern/10-1-checklist/#5-document-for-future-system-growth","text":"To avoid the same mistakes that made you reengineer your current solution, introduce (or adopt best practices used by other companies) a set of coding standards and internal processes. Orderly documented and clean code make your software easy to understand, extend and maintain in the future.","title":"5. Document for future system growth."},{"location":"modern/10-1-checklist/#6-create-a-separate-support-and-retirement-schedule-for-your-legacy-system","text":"Even if you have a brand-new system running like a clockwork, you will still need your legacy software, just in case. So, don\u2019t kill it all at once. Document and archive your solutions so you can easily access and refer to them when needed. Therefore, you need to support your legacy system for some time and plan for retiring your legacy system only when your new product is up and running.","title":"6. Create a separate support and retirement schedule for your legacy system."},{"location":"modern/10-1-checklist/#7-plan-for-training-and-system-updates","text":"Working with the old systems for years, your employees might need some time and guidance to master the new software. So be ready to invest in knowledge transfer and staff training for better performance and efficiency. Additionally, plan for regular system updates. If you fail to keep your product up to date, you will soon face another modernization challenge.","title":"7. Plan for training and system updates."},{"location":"modern/10-appendix-a/","text":"10.1 Appendix A: Sample Design Integrated Maintenance Data Systems (IMDS) Central Database (CDB) Cloud Migration to Microsoft Azure Note: This is a simplified description of a complicated set of projects. Please contact the proper PMO to get further details. The BES IMDS PMO is leading a project to move the IMDS Central Database (CDB) mainframe application from the DISA DECC legacy UNISYS ClearPath Dorado OS2200 Mainframe on-premise hosting environment to the AF CCE 2.0 Microsoft Azure Government hosting environment on MicroFocus COBOL. The goals were to introduce Agile and DevSecOps practices, reduce costs, modernize the technical stack, and enhance security by leveraging Azure Government IaaS and PaaS web services. ARRAY worked with the Cloud Migrator Astadia in the Discovery and Design phases to adapt Astadia\u2019s Transformation Engine to implement automated code transformation from UNISYS COBOL to Micro Focus COBOL while maintaining all functionality, screens, and reports. The IMDS CDB data, which was hosted on the UNISYS Mainframe Data Management System (DMS) Database and RDBMS, was migrated using Astadia\u2019s database conversion tools to Microsoft Azure SQL. The modernization target was Azure Government Cloud infrastructure in order to address the DoD\u2019s stringent security and compliance requirements and enable implementation of the CloudOne security add-ons to Azure Government. These add-ons consist of VDSS which provides traditional DMZ security for web applications and a next generation firewall for VPN access for SysAdmins and DBAs to protect cloud hosted workloads. Also implemented in the cloud were DISA\u2019s VDMS to provide cloud connected management and security tools and privileged user access and management for DoD networks and users. Telos Xacta 360 is used for continuous security compliance monitoring. Objectives IMDS CDB is the AF base-level automated maintenance management information system. It provides wartime readiness and operational support of aircraft, trainers, simulators, communications-electronics, MRAPS and support equipment maintenance activities to world-wide operating bases, ANG and AFRC sites. The Air Force sought to modify IMDS CDB Software to comply with statutory/regulatory technical improvements and enable an infrastructure platform migration to reduce DISA annual operating costs of a critical maintenance documentation system. The objective was to Rehost (Lift and Shift) IMDS CDB to the Azure Government Cloud. Key characteristics The IMDS CDB application included: Runs on UNISYS Dorado 2200 mainframe at DISA DECCs Users: 237,178 82 Air Force Specialty Codes (AFSCs) Help Desk Calls: ~15,000 / year 2.8M online transactions per day 13 Interfaces 17 Subsystems System Uptime: 99.996% 3.11M Lines of Code, 4 Languages, Two Databases (DMS and RDBMS), 45K Function Points Options Considered USAF had previously researched Refactor and COTS solutions. Selected Solution Rehost - a rehosting strategy (Lift and Shift) was chosen in order to maintain the COBOL code base, but in a modern .NET framework running in the Azure Government Cloud. The Air Force chose this migration path and solution because it was lower cost and less schedule (time) than other approaches and the Air Force did not have a longer-term strategy for IMDS CDB in terms of lifespan or technology conversion. In addition, the Air Force decided this solution greatly reduced most significant technical debt items (i.e. DISA UNISYS Mainframe hosting cost and expected key staff / skills retirements). Modernization Solution The Air Force PMO used the Cloud One program\u2019s engineering resources to perform analysis of the migration strategy and approach for IMDS CDB Cloud migration. Astadia was selected as the Cloud Migrator and ARRAY as the System Integrator. ARRAY is the contractor currently responsible for IMDS CDB application sustainment. Astadia and ARRAY coordinated with the AF Cloud One PMO\u2019s Cloud Service Provider (Microsoft Azure) to develop the \u201cTo-Be\u201d IMDS CDB cloud architecture based Azure IaaS and PaaS services and Astiadia\u2019s OpenMCS emulation of the UNISYS OS2200 transaction processing, batch processing and terminal services. The IMDS CDB\u2019s UNISYS Dorado 2200 DMS and RDBMS Databases was migrated to Azure SQL. The move from UNISYS Mainframes and the DMS and RDBMS database to open-systems platforms requires careful planning. While the potential exists to reduce costs and build compatibility, its realization depends on a thorough discovery and analysis of the UNISYS IMDS CDB application \u201cas-is\u201d architecture and design of a new \u201cto-be\u201d architecture in Azure Government cloud to enable the Air Force to quickly realize the value of the application modernization. Application Modernization Phases Once the Rehost (Lift and Shift) cloud migration strategy was decided upon, Astadia approached the project using their systematic cloud migration roadmap that consists of four phases: Discovery, Design, Transformation, and Deployment (Figure A-1). Each phase consists of several related activities and tasks that build on previous knowledge, prepare for subsequent phases and provide a valuable benchmarks and metrics for the progress of the project. ARRAY worked side by side with Astadia throughout the IMDS CDB phased cloud migration to make it a success. Discovery In the Discovery phase all IMDS CDB applications, languages, databases, networks, platforms, and processes in the UNISYS environment were cataloged and analyzed using Micros Focus Enterprise Analyzer. The interrelationships between applications and all external integration points were documented. In addition to Micro Focus Enterprise Analyzer, Astadia used their own specially-developed parsers, to analyze legacy code quickly and efficiently. This analysis output was used to establish the transformation blueprint of migration rules that are loaded into Astadia Code Transformation Engine during tool setup. These rules get updated and refined throughout the project. [image here] Figure A-1. Astadia\u2019s Cloud Migration Roadmap. Excerpted from Astadia\u2019s Mainframe Modernization: The balanced Path to Success dated 2016. Design After analyzing all the \u201cas-is\u201d source code, data structures, user interfaces, external interfaces, and end-state requirements, the \u201cto-be\u201d cloud migration design and architect is developed. The design includes the following details: Integration with User Interfaces - Users access the mainframe application through green screen terminal emulators that provide character mode terminal interface (T27, UTS). A web-based terminal emulator or mobile application is built on top of the character mode interface which serves as a front end to the modernized application. Batch Processing - UNISYS batch environments handle bulk data processing workloads. Jobs are submitted to the system (WFL, EFL) and processed with minimal operator interaction. Output from the batch jobs is spooled, printed and distributed to users. These batch processing services are replaced with Azure native cloud Windows PowerShell batch processing services. Transaction Processing \u2013 UNISYS transaction processing is at the core of most mission-critical applications like the IMDS CDB with millions of transactions being processed daily. The UNISYS online processing environment (COMS, TIP) provides transaction processing security, integrity, and predictable response times for terminal workloads. Non-functional requirements in transactions per second, or terminal response times are often critical for UNISYS workload execution. This requires careful design and sizing of the underlying Azure network, computing, storage and monitoring for emulation of the transaction processing services in the cloud. Programming Languages \u2013 UNISYS COBOL was used for developing IMDS CDB Applications. Code transformation to Micro focus COBOL is required to enable running the COBOL code on an open system x86 platform. Data Files - Data files are sequential, direct access, fixed and variable lengths, blocked or unblocked, etc. Data in these files are stored in EBCDIC (Extended Binary Coded Decimal Interchange Code), an eight-bit character encoding system used primarily on UNISYS mainframes. These data files need to be converted to ASC and migrated to Azure Storage and Azure SQL. Databases \u2013 IMDS CDB uses the DMS and RDBMS databases which must be converted to Azure SQL relational database services. Environmental software \u2013 UNISYS Mainframes run software to support the management, operation, application development, and security of the system. These services need to be converted to Azure cloud native equivalents. Scheduling software - is used to manage the execution of work flow streams. Output management systems handle the collection, storage and distribution of reports to the users that require them. Scheduling services need to be rearchitected to use cloud native scheduling services. Mainframe source code version control systems - are used to maintain application source code by tracking version as well as release lifecycles. These services need to be converted to the Cloud One Azure DevSecOps Tooltrain. Security - is tightly controlled at all levels of the UNISYS mainframe software. Azure cyber security software and the DISA SCCA add-on modules VDSS, VDMS and Xacta 360 will minimize the risk of data exposure and provide Cybersecurity regulatory compliance. Integration with external systems \u2013 IMDS CDB partner systems integration must be preserved after migration. This includes protocols, interfaces, latency, bandwidth, and more. In the following diagrams we describe the IMDS CDB cloud migration use case implemented in Astadia\u2019s Azure reference architecture. Each implementation is sure to have its own customizations and variations, which is why Astadia and ARRAY conducted a thorough application portfolio inventory, assessment and rationalization. The design, excerpted from Astadia\u2019s Unisys to Azure Reference Architecture white paper, includes details such as Azure components, batch requirements, programming language conversions and replacements, integration with external systems, 3rd-party software requirements, and planning for future needs. The core component of the architecture in Figure A-2 is Astadia\u2019s Mainframe Cloud Framework, which uses a suite of emulators and utilities to execute the transformed legacy COBOL code. OpenMCS is Astadia\u2019s Message Control System (MCS) that provides the necessary transaction processing features of COMS to support migrated COBOL code. This Mainframe Cloud Framework runs on Azure VM compute resources. UNISYS Mainframe hierarchical and flat file data structures will be migrated to Azure SQL RDBMS solution. Elasticity of the solution is facilitated by Azure Load Balancer (ALB) along with Auto Scaling Groups. The UNISYS COBOL is transformed to Micro Focus Visual COBOL for development in Microsoft Visual studio and Astadia\u2019s OpenMCS is used for emulating the UNISYS transaction monitor. This combination allows migrating COBOL applications to Azure Windows with minimum change to the original source. Some program functions may be replaced by the target Windows operating system or other target-platform components, so a gap analysis is performed to find the gaps in services. For example, legacy sort functions may be replaced by RDBMS SQL clauses. A data migration strategy is formulated. Flat files may be kept in their same legacy flat form, but Astadia converted them to relational in order to facilitate integration with modern Azure SQL-based tools, and to facilitate scalability and data integrity. UNISYS DMS and RDBMS data is converted to relational data using Astadia conversions tools and extract-transform-load (ETL) programs. [image here] Figure A-2. Migrating Unisys Dorado (Sperry) mainframe applications to Azure. Excerpted from Astadia\u2019s Unisys to AWS Reference Architecture, dtd 2017. Transformation UNISYS COBOL code transformation to Micro Focus COBOL is performed in Development sprints utilizing Astadia\u2019s Code Transformation Engine automated process to make mass changes to COBOL source code. This tool preserves the business logic and rules of legacy applications while removing proprietary code that can only execute in the source environment and not in Azure. The Transformation Engine\u2019s code migration filters ensure the preservation of mission-critical applications and back-end components such as transcodes, security policies, interfaces and message routing. If the modified code compiles, it\u2019s ready for unit testing. If it doesn\u2019t, developers review the errors, find a fix, update the migration rules, and run the program module(s) through the engine again. Many times, error fixes in one program may be applied to fix the same errors in other programs, to enable leveraging economies of scale. As source COBOL modules go through the transformation process during Development Sprints, the Code Transformation Engine, with improved migration rules, gets faster and more accurate for migrating follow-on COBOL source code modules. This is because source code files tend to repeat the same coding patterns requiring the same transformation rules. Though the Rules-Based Transformation Engine is a proven technology, Astadia worked in collaboration with ARRAY to combine automated transformation and hand-code refactoring to replace those legacy components that would not migrate to Azure without sacrificing their original functionality. In parallel with code transformation, database specialists performed a thorough analysis of the legacy databases and files and developed a detailed data migration strategy. An iterative extract, transform and load process was used to identify potential data-typing issues, develop fixes, and collaborate with ARRAY\u2019s developers and DBAs to validate their accuracy. This iterative process continued until every issue was eliminated. In most cases, the IMDS CDB UNISYS OS2200 flat file data structures, DMS and RDBMS Databases will be replaced with an Azure SQL RDBMS. Astadia has developed conversion tools that analyzes legacy data file layouts and database schemas, and then generates flat file and relational schemas for the target databases, as well as ETL programs, to migrate the data. Astadia\u2019s DBCHECK validates the syntax of the Data and Structure Definition Language (DASDL) from DMS or RDBMS and saves it as an object file with a .DB extension. Astadia\u2019s Database Convert (DBCVT) program then converts the validated DASDL to an SQL Data Definition Language (DDL) schema. This DDL required further analysis and modification by ARRAY\u2019s DBA\u2019s before it could be used to generate the final schema. After the target database and file structures have been created and validated, static data can be migrated to the Azure SQL instance production environment. For dynamic or other data that is created and/or modified frequently during production operations, a data migration strategy was implemented as part of production cutover process. During testing, focus was on the code that has been changed. Testing included: Integration Data accesses Sorting routines that may be affected by using ASCII vs. EBCDIC Code modifications to accommodate data type changes Newly developed code The Continuous Integration/Continuous Delivery (CI/CD) pipeline test processes executed from a non-mainframe web-based platform (emulating a T27 terminal) and followed the Air Force CloudOne DevSecOps best practices and Toolchain. It was recognized at the outset that the IMDS CDB had few, if any, automated test scripts and test documentation, thus much of the project team\u2019s time and resources was spent to develop automated test scripts using the Eggplant Functional Test Automation tool (leader in Gartner Magic Quadrant and The Forrester Wave \u2013 2018). Automated static code quality test tools were run in the CI/CD pipeline to validate coding standards and automated Static Application Security Test (SAST) and Dynamic Application Security Test (DAST) tools were run to validate security controls. Load and stress testing were performed to ensure the migrated IMDS CDB COBOL applications are prepared to handle high transaction volumes. Azure Government Virtual Network (VNet) enables provisioning a logically isolated section of Azure where customers launch and manage interconnected resources in a virtual network that is define and secured with the DISA SCCA suite consisting of VDSS and VDMS. Azure Virtual Machines (VMs) are provisioned to provide on-demand, scalable computing resources. Typically, a VM is chosen to give more control over the computing environment than other pre-configured choices offered. An Azure VM is dedicated to the web server, a VM is dedicated to Batch COBOL applications and another VM is dedicated to online transactions processing OpenMCS COBOL applications. Azure Storage uses an auto-partitioning system that automatically load-balances IMDS CDB data based on traffic. This means that as the demands on the application grow, Azure Storage automatically allocates the appropriate resources to meet them. IMDS CDB Legacy data is best managed on dedicated VMs running Azure SQL. Azure Load Balancer (ALB) automatically distributes incoming web traffic across multiple VM web server and OpenMCS instances to achieve scalability, high-performance, and fault tolerance in the migrated IMCS CDB COBOL.NET applications. It provides the load balancing capability needed to route traffic evenly among the COBOL applications and keep them performing efficiently. Azure Operations Management Suite (OMS) collection of cloud-based services allows IMDS CDB System Administrators and DBAs to monitor and manage the resources now running the legacy applications deployed to Azure. OMS collects and tracks metrics, monitors log files, set alarms, backup and restore critical data, and automatically reacts to changes in Azure resources. OMS is used to resolve problems quickly and keep IMDS CDB migrated COBOL applications running smoothly. ARRAY SMEs identified potential application interface issues within the Azure cloud environment. For example, in the original design the IMDS CDB application would interface with the IMDS Web Services Microsoft Active Directory service which did not turn out to be possible. ARRAY SMEs also identified system monitoring enhancements to allow server error logs to be created and viewed as normal windows logs in the cloud hosting environment allowing for easier access by Systems Administrators. ARRAY also provided IMDS CDB application security enhancements by removing the duplicate CAC restriction functionality. This allowed users requiring multiple accounts associated with the same CAC ID to be able to select a particular user ID during sign-on. Deployment When migrated applications completed testing, verification and optimization, the process of deploying those applications began. In reality, many deployment activities are initiated in parallel with earlier phases\u2014creating and configuring Azure instances, installing and configuring Mainframe emulation software (e.g. Astadia OpenMCS), migrating static data, and other infrastructure security monitoring or framework activities. Development, Test, Staging and Production environments were replicated using the CloudOne Azure DevSecOps Toolchain. After User Acceptance Tests and Cybersecurity Testing is successfully completed and ATO achieved, then dynamic data will be migrated and validated so that cutover to production operations can be completed. Customer Benefits Expected Outcomes: 100% Native Cloud Maintainable, quality code Productive development paradigm where C#.NET coexists with COBOL.NET Mainframe DMS and RDBMS converted to Azure SQL Lessons Learned This project demonstrated to the Air Force that Rehost (Lift and Shift) with automated transformation projects are a viable approach to modernize major legacy UNISYS ClearPath Dorado OS2200 Mainframe COBOL applications to preserve the existing business rules within a cost-effective, open system architecture capable of migration to the cloud. We can highlight specific lessons learned during this project: AF identified key project risks: Risk 1: Testing (test and fix accounts for 50%+ of entire effort; used Eggplant automated functional test tool for automated functional testing and regression testing) Risk 2: CyberSecurity Risk 3: Refactoring and connecting external interfaces Micro Focus toolset is robust and impressive for interim system modernizations COBOL is developed in Eclipse or Visual Studio (both are modern and easy to use) Java or C# developers should be able to code COBOL in these familiar and full featured integrated development environments. Micro Focus COBOL gets compiled to native COBOL.NET so it can use all of the .NET framework and Azure capabilities. IMDS CDB in Azure Government Cloud runs primarily in one region and has a warm standby in a second region for geographic dispersion and disaster recovery. The warm standby can be switched to immediately for disaster recovery after any queued records process (usually less than 15 minutes) Air Force believes operating in Azure Government Cloud with Micro Focus Development tools is more specialized and will require 100% contractor staff.","title":"10.1 Appendix A: Sample Design 1"},{"location":"modern/10-appendix-a/#101-appendix-a-sample-design","text":"","title":"10.1 Appendix A: Sample Design"},{"location":"modern/10-appendix-a/#integrated-maintenance-data-systems-imds-central-database-cdb-cloud-migration-to-microsoft-azure","text":"Note: This is a simplified description of a complicated set of projects. Please contact the proper PMO to get further details. The BES IMDS PMO is leading a project to move the IMDS Central Database (CDB) mainframe application from the DISA DECC legacy UNISYS ClearPath Dorado OS2200 Mainframe on-premise hosting environment to the AF CCE 2.0 Microsoft Azure Government hosting environment on MicroFocus COBOL. The goals were to introduce Agile and DevSecOps practices, reduce costs, modernize the technical stack, and enhance security by leveraging Azure Government IaaS and PaaS web services. ARRAY worked with the Cloud Migrator Astadia in the Discovery and Design phases to adapt Astadia\u2019s Transformation Engine to implement automated code transformation from UNISYS COBOL to Micro Focus COBOL while maintaining all functionality, screens, and reports. The IMDS CDB data, which was hosted on the UNISYS Mainframe Data Management System (DMS) Database and RDBMS, was migrated using Astadia\u2019s database conversion tools to Microsoft Azure SQL. The modernization target was Azure Government Cloud infrastructure in order to address the DoD\u2019s stringent security and compliance requirements and enable implementation of the CloudOne security add-ons to Azure Government. These add-ons consist of VDSS which provides traditional DMZ security for web applications and a next generation firewall for VPN access for SysAdmins and DBAs to protect cloud hosted workloads. Also implemented in the cloud were DISA\u2019s VDMS to provide cloud connected management and security tools and privileged user access and management for DoD networks and users. Telos Xacta 360 is used for continuous security compliance monitoring.","title":"Integrated Maintenance Data Systems (IMDS) Central Database (CDB) Cloud Migration to Microsoft Azure"},{"location":"modern/10-appendix-a/#objectives","text":"IMDS CDB is the AF base-level automated maintenance management information system. It provides wartime readiness and operational support of aircraft, trainers, simulators, communications-electronics, MRAPS and support equipment maintenance activities to world-wide operating bases, ANG and AFRC sites. The Air Force sought to modify IMDS CDB Software to comply with statutory/regulatory technical improvements and enable an infrastructure platform migration to reduce DISA annual operating costs of a critical maintenance documentation system. The objective was to Rehost (Lift and Shift) IMDS CDB to the Azure Government Cloud.","title":"Objectives"},{"location":"modern/10-appendix-a/#key-characteristics","text":"The IMDS CDB application included: Runs on UNISYS Dorado 2200 mainframe at DISA DECCs Users: 237,178 82 Air Force Specialty Codes (AFSCs) Help Desk Calls: ~15,000 / year 2.8M online transactions per day 13 Interfaces 17 Subsystems System Uptime: 99.996% 3.11M Lines of Code, 4 Languages, Two Databases (DMS and RDBMS), 45K Function Points","title":"Key characteristics"},{"location":"modern/10-appendix-a/#options-considered","text":"USAF had previously researched Refactor and COTS solutions.","title":"Options Considered"},{"location":"modern/10-appendix-a/#selected-solution","text":"Rehost - a rehosting strategy (Lift and Shift) was chosen in order to maintain the COBOL code base, but in a modern .NET framework running in the Azure Government Cloud. The Air Force chose this migration path and solution because it was lower cost and less schedule (time) than other approaches and the Air Force did not have a longer-term strategy for IMDS CDB in terms of lifespan or technology conversion. In addition, the Air Force decided this solution greatly reduced most significant technical debt items (i.e. DISA UNISYS Mainframe hosting cost and expected key staff / skills retirements).","title":"Selected Solution"},{"location":"modern/10-appendix-a/#modernization-solution","text":"The Air Force PMO used the Cloud One program\u2019s engineering resources to perform analysis of the migration strategy and approach for IMDS CDB Cloud migration. Astadia was selected as the Cloud Migrator and ARRAY as the System Integrator. ARRAY is the contractor currently responsible for IMDS CDB application sustainment. Astadia and ARRAY coordinated with the AF Cloud One PMO\u2019s Cloud Service Provider (Microsoft Azure) to develop the \u201cTo-Be\u201d IMDS CDB cloud architecture based Azure IaaS and PaaS services and Astiadia\u2019s OpenMCS emulation of the UNISYS OS2200 transaction processing, batch processing and terminal services. The IMDS CDB\u2019s UNISYS Dorado 2200 DMS and RDBMS Databases was migrated to Azure SQL. The move from UNISYS Mainframes and the DMS and RDBMS database to open-systems platforms requires careful planning. While the potential exists to reduce costs and build compatibility, its realization depends on a thorough discovery and analysis of the UNISYS IMDS CDB application \u201cas-is\u201d architecture and design of a new \u201cto-be\u201d architecture in Azure Government cloud to enable the Air Force to quickly realize the value of the application modernization.","title":"Modernization Solution"},{"location":"modern/10-appendix-a/#application-modernization-phases","text":"Once the Rehost (Lift and Shift) cloud migration strategy was decided upon, Astadia approached the project using their systematic cloud migration roadmap that consists of four phases: Discovery, Design, Transformation, and Deployment (Figure A-1). Each phase consists of several related activities and tasks that build on previous knowledge, prepare for subsequent phases and provide a valuable benchmarks and metrics for the progress of the project. ARRAY worked side by side with Astadia throughout the IMDS CDB phased cloud migration to make it a success.","title":"Application Modernization Phases"},{"location":"modern/10-appendix-a/#discovery","text":"In the Discovery phase all IMDS CDB applications, languages, databases, networks, platforms, and processes in the UNISYS environment were cataloged and analyzed using Micros Focus Enterprise Analyzer. The interrelationships between applications and all external integration points were documented. In addition to Micro Focus Enterprise Analyzer, Astadia used their own specially-developed parsers, to analyze legacy code quickly and efficiently. This analysis output was used to establish the transformation blueprint of migration rules that are loaded into Astadia Code Transformation Engine during tool setup. These rules get updated and refined throughout the project. [image here] Figure A-1. Astadia\u2019s Cloud Migration Roadmap. Excerpted from Astadia\u2019s Mainframe Modernization: The balanced Path to Success dated 2016.","title":"Discovery"},{"location":"modern/10-appendix-a/#design","text":"After analyzing all the \u201cas-is\u201d source code, data structures, user interfaces, external interfaces, and end-state requirements, the \u201cto-be\u201d cloud migration design and architect is developed. The design includes the following details: Integration with User Interfaces - Users access the mainframe application through green screen terminal emulators that provide character mode terminal interface (T27, UTS). A web-based terminal emulator or mobile application is built on top of the character mode interface which serves as a front end to the modernized application. Batch Processing - UNISYS batch environments handle bulk data processing workloads. Jobs are submitted to the system (WFL, EFL) and processed with minimal operator interaction. Output from the batch jobs is spooled, printed and distributed to users. These batch processing services are replaced with Azure native cloud Windows PowerShell batch processing services. Transaction Processing \u2013 UNISYS transaction processing is at the core of most mission-critical applications like the IMDS CDB with millions of transactions being processed daily. The UNISYS online processing environment (COMS, TIP) provides transaction processing security, integrity, and predictable response times for terminal workloads. Non-functional requirements in transactions per second, or terminal response times are often critical for UNISYS workload execution. This requires careful design and sizing of the underlying Azure network, computing, storage and monitoring for emulation of the transaction processing services in the cloud. Programming Languages \u2013 UNISYS COBOL was used for developing IMDS CDB Applications. Code transformation to Micro focus COBOL is required to enable running the COBOL code on an open system x86 platform. Data Files - Data files are sequential, direct access, fixed and variable lengths, blocked or unblocked, etc. Data in these files are stored in EBCDIC (Extended Binary Coded Decimal Interchange Code), an eight-bit character encoding system used primarily on UNISYS mainframes. These data files need to be converted to ASC and migrated to Azure Storage and Azure SQL. Databases \u2013 IMDS CDB uses the DMS and RDBMS databases which must be converted to Azure SQL relational database services. Environmental software \u2013 UNISYS Mainframes run software to support the management, operation, application development, and security of the system. These services need to be converted to Azure cloud native equivalents. Scheduling software - is used to manage the execution of work flow streams. Output management systems handle the collection, storage and distribution of reports to the users that require them. Scheduling services need to be rearchitected to use cloud native scheduling services. Mainframe source code version control systems - are used to maintain application source code by tracking version as well as release lifecycles. These services need to be converted to the Cloud One Azure DevSecOps Tooltrain. Security - is tightly controlled at all levels of the UNISYS mainframe software. Azure cyber security software and the DISA SCCA add-on modules VDSS, VDMS and Xacta 360 will minimize the risk of data exposure and provide Cybersecurity regulatory compliance. Integration with external systems \u2013 IMDS CDB partner systems integration must be preserved after migration. This includes protocols, interfaces, latency, bandwidth, and more. In the following diagrams we describe the IMDS CDB cloud migration use case implemented in Astadia\u2019s Azure reference architecture. Each implementation is sure to have its own customizations and variations, which is why Astadia and ARRAY conducted a thorough application portfolio inventory, assessment and rationalization. The design, excerpted from Astadia\u2019s Unisys to Azure Reference Architecture white paper, includes details such as Azure components, batch requirements, programming language conversions and replacements, integration with external systems, 3rd-party software requirements, and planning for future needs. The core component of the architecture in Figure A-2 is Astadia\u2019s Mainframe Cloud Framework, which uses a suite of emulators and utilities to execute the transformed legacy COBOL code. OpenMCS is Astadia\u2019s Message Control System (MCS) that provides the necessary transaction processing features of COMS to support migrated COBOL code. This Mainframe Cloud Framework runs on Azure VM compute resources. UNISYS Mainframe hierarchical and flat file data structures will be migrated to Azure SQL RDBMS solution. Elasticity of the solution is facilitated by Azure Load Balancer (ALB) along with Auto Scaling Groups. The UNISYS COBOL is transformed to Micro Focus Visual COBOL for development in Microsoft Visual studio and Astadia\u2019s OpenMCS is used for emulating the UNISYS transaction monitor. This combination allows migrating COBOL applications to Azure Windows with minimum change to the original source. Some program functions may be replaced by the target Windows operating system or other target-platform components, so a gap analysis is performed to find the gaps in services. For example, legacy sort functions may be replaced by RDBMS SQL clauses. A data migration strategy is formulated. Flat files may be kept in their same legacy flat form, but Astadia converted them to relational in order to facilitate integration with modern Azure SQL-based tools, and to facilitate scalability and data integrity. UNISYS DMS and RDBMS data is converted to relational data using Astadia conversions tools and extract-transform-load (ETL) programs. [image here] Figure A-2. Migrating Unisys Dorado (Sperry) mainframe applications to Azure. Excerpted from Astadia\u2019s Unisys to AWS Reference Architecture, dtd 2017.","title":"Design"},{"location":"modern/10-appendix-a/#transformation","text":"UNISYS COBOL code transformation to Micro Focus COBOL is performed in Development sprints utilizing Astadia\u2019s Code Transformation Engine automated process to make mass changes to COBOL source code. This tool preserves the business logic and rules of legacy applications while removing proprietary code that can only execute in the source environment and not in Azure. The Transformation Engine\u2019s code migration filters ensure the preservation of mission-critical applications and back-end components such as transcodes, security policies, interfaces and message routing. If the modified code compiles, it\u2019s ready for unit testing. If it doesn\u2019t, developers review the errors, find a fix, update the migration rules, and run the program module(s) through the engine again. Many times, error fixes in one program may be applied to fix the same errors in other programs, to enable leveraging economies of scale. As source COBOL modules go through the transformation process during Development Sprints, the Code Transformation Engine, with improved migration rules, gets faster and more accurate for migrating follow-on COBOL source code modules. This is because source code files tend to repeat the same coding patterns requiring the same transformation rules. Though the Rules-Based Transformation Engine is a proven technology, Astadia worked in collaboration with ARRAY to combine automated transformation and hand-code refactoring to replace those legacy components that would not migrate to Azure without sacrificing their original functionality. In parallel with code transformation, database specialists performed a thorough analysis of the legacy databases and files and developed a detailed data migration strategy. An iterative extract, transform and load process was used to identify potential data-typing issues, develop fixes, and collaborate with ARRAY\u2019s developers and DBAs to validate their accuracy. This iterative process continued until every issue was eliminated. In most cases, the IMDS CDB UNISYS OS2200 flat file data structures, DMS and RDBMS Databases will be replaced with an Azure SQL RDBMS. Astadia has developed conversion tools that analyzes legacy data file layouts and database schemas, and then generates flat file and relational schemas for the target databases, as well as ETL programs, to migrate the data. Astadia\u2019s DBCHECK validates the syntax of the Data and Structure Definition Language (DASDL) from DMS or RDBMS and saves it as an object file with a .DB extension. Astadia\u2019s Database Convert (DBCVT) program then converts the validated DASDL to an SQL Data Definition Language (DDL) schema. This DDL required further analysis and modification by ARRAY\u2019s DBA\u2019s before it could be used to generate the final schema. After the target database and file structures have been created and validated, static data can be migrated to the Azure SQL instance production environment. For dynamic or other data that is created and/or modified frequently during production operations, a data migration strategy was implemented as part of production cutover process. During testing, focus was on the code that has been changed. Testing included: Integration Data accesses Sorting routines that may be affected by using ASCII vs. EBCDIC Code modifications to accommodate data type changes Newly developed code The Continuous Integration/Continuous Delivery (CI/CD) pipeline test processes executed from a non-mainframe web-based platform (emulating a T27 terminal) and followed the Air Force CloudOne DevSecOps best practices and Toolchain. It was recognized at the outset that the IMDS CDB had few, if any, automated test scripts and test documentation, thus much of the project team\u2019s time and resources was spent to develop automated test scripts using the Eggplant Functional Test Automation tool (leader in Gartner Magic Quadrant and The Forrester Wave \u2013 2018). Automated static code quality test tools were run in the CI/CD pipeline to validate coding standards and automated Static Application Security Test (SAST) and Dynamic Application Security Test (DAST) tools were run to validate security controls. Load and stress testing were performed to ensure the migrated IMDS CDB COBOL applications are prepared to handle high transaction volumes. Azure Government Virtual Network (VNet) enables provisioning a logically isolated section of Azure where customers launch and manage interconnected resources in a virtual network that is define and secured with the DISA SCCA suite consisting of VDSS and VDMS. Azure Virtual Machines (VMs) are provisioned to provide on-demand, scalable computing resources. Typically, a VM is chosen to give more control over the computing environment than other pre-configured choices offered. An Azure VM is dedicated to the web server, a VM is dedicated to Batch COBOL applications and another VM is dedicated to online transactions processing OpenMCS COBOL applications. Azure Storage uses an auto-partitioning system that automatically load-balances IMDS CDB data based on traffic. This means that as the demands on the application grow, Azure Storage automatically allocates the appropriate resources to meet them. IMDS CDB Legacy data is best managed on dedicated VMs running Azure SQL. Azure Load Balancer (ALB) automatically distributes incoming web traffic across multiple VM web server and OpenMCS instances to achieve scalability, high-performance, and fault tolerance in the migrated IMCS CDB COBOL.NET applications. It provides the load balancing capability needed to route traffic evenly among the COBOL applications and keep them performing efficiently. Azure Operations Management Suite (OMS) collection of cloud-based services allows IMDS CDB System Administrators and DBAs to monitor and manage the resources now running the legacy applications deployed to Azure. OMS collects and tracks metrics, monitors log files, set alarms, backup and restore critical data, and automatically reacts to changes in Azure resources. OMS is used to resolve problems quickly and keep IMDS CDB migrated COBOL applications running smoothly. ARRAY SMEs identified potential application interface issues within the Azure cloud environment. For example, in the original design the IMDS CDB application would interface with the IMDS Web Services Microsoft Active Directory service which did not turn out to be possible. ARRAY SMEs also identified system monitoring enhancements to allow server error logs to be created and viewed as normal windows logs in the cloud hosting environment allowing for easier access by Systems Administrators. ARRAY also provided IMDS CDB application security enhancements by removing the duplicate CAC restriction functionality. This allowed users requiring multiple accounts associated with the same CAC ID to be able to select a particular user ID during sign-on.","title":"Transformation"},{"location":"modern/10-appendix-a/#deployment","text":"When migrated applications completed testing, verification and optimization, the process of deploying those applications began. In reality, many deployment activities are initiated in parallel with earlier phases\u2014creating and configuring Azure instances, installing and configuring Mainframe emulation software (e.g. Astadia OpenMCS), migrating static data, and other infrastructure security monitoring or framework activities. Development, Test, Staging and Production environments were replicated using the CloudOne Azure DevSecOps Toolchain. After User Acceptance Tests and Cybersecurity Testing is successfully completed and ATO achieved, then dynamic data will be migrated and validated so that cutover to production operations can be completed.","title":"Deployment"},{"location":"modern/10-appendix-a/#customer-benefits","text":"Expected Outcomes: 100% Native Cloud Maintainable, quality code Productive development paradigm where C#.NET coexists with COBOL.NET Mainframe DMS and RDBMS converted to Azure SQL","title":"Customer Benefits"},{"location":"modern/10-appendix-a/#lessons-learned","text":"This project demonstrated to the Air Force that Rehost (Lift and Shift) with automated transformation projects are a viable approach to modernize major legacy UNISYS ClearPath Dorado OS2200 Mainframe COBOL applications to preserve the existing business rules within a cost-effective, open system architecture capable of migration to the cloud. We can highlight specific lessons learned during this project: AF identified key project risks: Risk 1: Testing (test and fix accounts for 50%+ of entire effort; used Eggplant automated functional test tool for automated functional testing and regression testing) Risk 2: CyberSecurity Risk 3: Refactoring and connecting external interfaces Micro Focus toolset is robust and impressive for interim system modernizations COBOL is developed in Eclipse or Visual Studio (both are modern and easy to use) Java or C# developers should be able to code COBOL in these familiar and full featured integrated development environments. Micro Focus COBOL gets compiled to native COBOL.NET so it can use all of the .NET framework and Azure capabilities. IMDS CDB in Azure Government Cloud runs primarily in one region and has a warm standby in a second region for geographic dispersion and disaster recovery. The warm standby can be switched to immediately for disaster recovery after any queued records process (usually less than 15 minutes) Air Force believes operating in Azure Government Cloud with Micro Focus Development tools is more specialized and will require 100% contractor staff.","title":"Lessons Learned"},{"location":"modern/10-appendix-b/","text":"10.2 Appendix B: Sample Design 2 Automated Transformation (Code Conversion) and Refactoring of a USAF Mainframe Application to AWS Note: This is a simplified description of a complicated set of projects. Please contact the proper PMO to get further details. The PEO BES ILS-S program management office (PMO) led a successful modernization of the legacy COBOL-based Standard Base Supply System (SBSS) application running on UNISYS 2200 mainframes to a Java-based system running on x86 Red Hat Enterprise Linux (RHEL). The application that was modernized is a major defense program that provides a mission-critical defense capability used by nearly 20,000 users at over 250 global locations. The goals were to introduce agility, reduce costs, modernize the technical stack, and enhance security. This was accomplished using automated code transformation tools and techniques while maintaining all functionality, screens, and reports. The intermediate modernization hosting target was a DISA X86 virtualized environment and the long-term hosting target is AF Cloud One in AWS GovCloud (US). AWS GovCloud was chosen to meet DoD\u2019s stringent security and compliance requirements such as U.S. citizenship. Objectives A major component of the SBSS system is the 50+ years old legacy supply application, written in COBOL, that provides retail-level business logic. This application runs on the UNISYS mainframe and has proven to be difficult to change and manage. The DoD needed to modernize the application to drive down operating costs by moving to an open platform, while retaining all application functionality. In the past, attempts made to modernize the supply application failed due to the massive size and complexity of the task. In fact, modernizing the component was regarded as such a difficult task that it was highlighted in the 2003 book Modernizing Legacy Systems: Software Technologies, Engineering Processes, and Business Practices . After more than 50 years of operations, maintenance, and extensions, the applications\u2019 code base had become relatively poorly documented. The technical design of the existing system, which was needed to support the modernization effort, had to be derived from the existing system and code. Key characteristics of this application included: Annual operating costs in the tens of millions of dollars, largely attributable to mainframe hosting and maintenance costs. Over a million lines of COBOL Source Lines of Code (SLOC). A data management system, comprised of over a million lines of COBOL code, supporting approximately 500,000 transactions per day. Few remaining subject matter experts (SMEs). Difficulty finding qualified, affordable COBOL programmers. The application needed to be modernized and migrated to an affordable open system and hosting environment, with no down-time, data loss, functionality loss, performance loss, and minimal mission risk. The DoD had never done anything like this. Modernization Solution The project started by identifying and evaluating solution options: A total manual rewrite and re-architecting solution failed to meet the program\u2019s time constraints, had historically low success rates (high risk), and would have been too costly. A replacement solution was not selected because the DoD needed to retain all the current business rules. A COBOL emulator re-host solution was a stopgap measure that failed to reach the J2EE/RHEL/SQL DB architectural future state requirement. This analysis led to our decision to use a COBOL-to-Java code automated transformation and refactoring solution. This option would take a low-risk, incremental approach and apply a blended agile/traditional methodology and tools to ensure rapid, high-quality software delivery. Application Modernization Phases Once the COBOL-to-Java code automated transformation and refactoring solution was selected, a three-phase approach emerged to meet the entirety of the DoD\u2019s requirements and cost, schedule, and risk constraints. Phase 1: COBOL-to-Java code automated transformation and refactoring to x86/RHEL platform This was the most complex and risky phase, as we automatically transformed and refactored COBOL code from a UNISYS mainframe to Java code on a virtualized x86 RHEL platform while not losing any functionality or performance. The resulting Java code contained design remnants of COBOL, and development and test environments were moved to the AWS Cloud. Phase 2: Java code advanced refactoring to remove COBOL design overtones We refactored the Java codebase even more to remove residual COBOL remnants, operating system overtones, and we used architectural design patterns to improve code maintainability. Phase 3: Infrastructure moved to AWS GovCloud (US) We moved all remaining environments to AWS GovCloud (US) including staging and production. AWS GovCloud (US) allowed us to meet the many cyberthreat security requirements for the DoD. Figure B-1 shows our three-phrase modernization approach. The two Java logos illustrate the different Java phases. At the end of Phase 1, the Java program contains COBOL coding practices. At the end of Phase 2, the Java program is \u201cclean\u201d with COBOL remnants removed. [image here] Figure B-1 \u2013 Three-phase automated application modernization approach met the DoD\u2019s stringent requirements. Phase 1: Automated Transformation and Refactoring of COBOL to Java on x86 The modernization of the application involved a transformation of ~1.2M lines of COBOL code and ~10K lines of C code to Java to maintain current application capabilities, Graphical User Interface (GUI), and performance while migrating to a more affordable and sustainable x86 RHEL platform. The applications\u2019 COBOL online and batch applications were automatically transformed using TSRI JANUS Studio tool suite to run on a JEE platform using Java object-oriented software layers (data access, presentation, business logic) and design patterns to enable migration to a standard x86 architecture. Rather than simply transforming source COBOL code to target Java code, the TSRI JANUS Studio tool executes a mature automated transformation and refactoring process by first constructing a comprehensive Intermediate Object Model of the legacy system in an intermediate translation language. Once modeled within the tool transformation engine, technical SMEs employ an iterative process of applying rules and tuning to output the transformed code into the target Java language. The modernized Java software reused identifier names from the original COBOL application, allowing the component functional SMEs to read and understand the new Java code and routines more easily. Testing was accomplished using the existing test cases from the legacy application because their was no change in functionality. During this phase, the COBOL Data Management System network database code was transformed to COBOL with SQL. This COBOL and SQL code was then transformed to Java and SQL code (See Figure B-2 ). [image here] Figure B-2 \u2013 The component COBOL automated transformation and refactoring to Java. Phase 2: Advanced Refactoring to Remove COBOL Design Overtones After Phase 1, the resulting converted Java code contained COBOL design remnants, or COBOL overtones, that required personnel to have specialized skills to maintain the codebase. A plan was developed to identify and replace COBOL overtones with standard Java solutions. The refactoring approach used the TSRI JANUS Studio tool and a semi-automated refactoring method (See Figure B-3 ) that performs further code optimization, naming changes, and other enhancements to improve architecture, design, security, sustainability and performance. These techniques, along with the improved method synthesis algorithm, greatly improved the maintainability of the Java codebase. [image here] Figure B-3 \u2013 The supply application refactoring plan (to maintainable Java). Phase 3: Infrastructure Migration to AWS. After Phase 2 was completed, the entire application will be migrated to AF Cloud One on AWS GovCloud (US) including the development, testing, staging, production, and all support environments (See Figure B-4 ). AWS GovCloud (US) was selected because it aligned with the future technical direction of the system. This included cybersecurity, DevSecOps, and automated continuous integration (CI) and continuous delivery (CD) pipeline processes and DevSecOps Toolchain. The applications\u2019 architecture is being installed in AWS GovCloud (US) and continues to evolve. [image here] Figure B-4 \u2013 Amazon Web Services (AWS) GovCloud Hosting Design. Customer Benefits The application has been transformed from an expensive mainframe COBOL legacy system to a more affordable, modern maintainable Java-based system. All valuable existing business rules have been preserved in the modernized system, while development, test, and production environments were migrated to AWS providing flexibility at reduced cost. Lessons Learned This project demonstrated that the DoD can apply automated transformation and refactoring to modernize major legacy systems, including complex COBOL-based mainframes, and preserve the existing business rules within a cost-effective, open system architecture capable of migration to the cloud. Lessons learned during this project: When properly planned and executed, code conversions via automated refactoring provide a low-risk approach to modernizing legacy applications. Breaking efforts into clear phases (modernize, migrate, etc) keeps risk low and ensures project success. Moving from legacy COBOL to a modern architecture and language enable the application to benefit from modern tools and services. Agile development practices enable real-time course corrections and reduce delivery risk. Automation is crucial in order to transform millions of lines of code while preserving functionality, reducing risks, and reducing the project timeline. Migrating from a legacy proprietary mainframe and COBOL to an open Java platform allows access to a large pool of talented technology people to evolve the application.","title":"10.2 Appendix B: Sample Design 2"},{"location":"modern/10-appendix-b/#102-appendix-b-sample-design-2","text":"","title":"10.2 Appendix B: Sample Design 2"},{"location":"modern/10-appendix-b/#automated-transformation-code-conversion-and-refactoring-of-a-usaf-mainframe-application-to-aws","text":"Note: This is a simplified description of a complicated set of projects. Please contact the proper PMO to get further details. The PEO BES ILS-S program management office (PMO) led a successful modernization of the legacy COBOL-based Standard Base Supply System (SBSS) application running on UNISYS 2200 mainframes to a Java-based system running on x86 Red Hat Enterprise Linux (RHEL). The application that was modernized is a major defense program that provides a mission-critical defense capability used by nearly 20,000 users at over 250 global locations. The goals were to introduce agility, reduce costs, modernize the technical stack, and enhance security. This was accomplished using automated code transformation tools and techniques while maintaining all functionality, screens, and reports. The intermediate modernization hosting target was a DISA X86 virtualized environment and the long-term hosting target is AF Cloud One in AWS GovCloud (US). AWS GovCloud was chosen to meet DoD\u2019s stringent security and compliance requirements such as U.S. citizenship.","title":"Automated Transformation (Code Conversion) and Refactoring of a USAF Mainframe Application to AWS"},{"location":"modern/10-appendix-b/#objectives","text":"A major component of the SBSS system is the 50+ years old legacy supply application, written in COBOL, that provides retail-level business logic. This application runs on the UNISYS mainframe and has proven to be difficult to change and manage. The DoD needed to modernize the application to drive down operating costs by moving to an open platform, while retaining all application functionality. In the past, attempts made to modernize the supply application failed due to the massive size and complexity of the task. In fact, modernizing the component was regarded as such a difficult task that it was highlighted in the 2003 book Modernizing Legacy Systems: Software Technologies, Engineering Processes, and Business Practices . After more than 50 years of operations, maintenance, and extensions, the applications\u2019 code base had become relatively poorly documented. The technical design of the existing system, which was needed to support the modernization effort, had to be derived from the existing system and code. Key characteristics of this application included: Annual operating costs in the tens of millions of dollars, largely attributable to mainframe hosting and maintenance costs. Over a million lines of COBOL Source Lines of Code (SLOC). A data management system, comprised of over a million lines of COBOL code, supporting approximately 500,000 transactions per day. Few remaining subject matter experts (SMEs). Difficulty finding qualified, affordable COBOL programmers. The application needed to be modernized and migrated to an affordable open system and hosting environment, with no down-time, data loss, functionality loss, performance loss, and minimal mission risk. The DoD had never done anything like this.","title":"Objectives"},{"location":"modern/10-appendix-b/#modernization-solution","text":"The project started by identifying and evaluating solution options: A total manual rewrite and re-architecting solution failed to meet the program\u2019s time constraints, had historically low success rates (high risk), and would have been too costly. A replacement solution was not selected because the DoD needed to retain all the current business rules. A COBOL emulator re-host solution was a stopgap measure that failed to reach the J2EE/RHEL/SQL DB architectural future state requirement. This analysis led to our decision to use a COBOL-to-Java code automated transformation and refactoring solution. This option would take a low-risk, incremental approach and apply a blended agile/traditional methodology and tools to ensure rapid, high-quality software delivery.","title":"Modernization Solution"},{"location":"modern/10-appendix-b/#application-modernization-phases","text":"Once the COBOL-to-Java code automated transformation and refactoring solution was selected, a three-phase approach emerged to meet the entirety of the DoD\u2019s requirements and cost, schedule, and risk constraints. Phase 1: COBOL-to-Java code automated transformation and refactoring to x86/RHEL platform This was the most complex and risky phase, as we automatically transformed and refactored COBOL code from a UNISYS mainframe to Java code on a virtualized x86 RHEL platform while not losing any functionality or performance. The resulting Java code contained design remnants of COBOL, and development and test environments were moved to the AWS Cloud. Phase 2: Java code advanced refactoring to remove COBOL design overtones We refactored the Java codebase even more to remove residual COBOL remnants, operating system overtones, and we used architectural design patterns to improve code maintainability. Phase 3: Infrastructure moved to AWS GovCloud (US) We moved all remaining environments to AWS GovCloud (US) including staging and production. AWS GovCloud (US) allowed us to meet the many cyberthreat security requirements for the DoD. Figure B-1 shows our three-phrase modernization approach. The two Java logos illustrate the different Java phases. At the end of Phase 1, the Java program contains COBOL coding practices. At the end of Phase 2, the Java program is \u201cclean\u201d with COBOL remnants removed. [image here] Figure B-1 \u2013 Three-phase automated application modernization approach met the DoD\u2019s stringent requirements.","title":"Application Modernization Phases"},{"location":"modern/10-appendix-b/#phase-1-automated-transformation-and-refactoring-of-cobol-to-java-on-x86","text":"The modernization of the application involved a transformation of ~1.2M lines of COBOL code and ~10K lines of C code to Java to maintain current application capabilities, Graphical User Interface (GUI), and performance while migrating to a more affordable and sustainable x86 RHEL platform. The applications\u2019 COBOL online and batch applications were automatically transformed using TSRI JANUS Studio tool suite to run on a JEE platform using Java object-oriented software layers (data access, presentation, business logic) and design patterns to enable migration to a standard x86 architecture. Rather than simply transforming source COBOL code to target Java code, the TSRI JANUS Studio tool executes a mature automated transformation and refactoring process by first constructing a comprehensive Intermediate Object Model of the legacy system in an intermediate translation language. Once modeled within the tool transformation engine, technical SMEs employ an iterative process of applying rules and tuning to output the transformed code into the target Java language. The modernized Java software reused identifier names from the original COBOL application, allowing the component functional SMEs to read and understand the new Java code and routines more easily. Testing was accomplished using the existing test cases from the legacy application because their was no change in functionality. During this phase, the COBOL Data Management System network database code was transformed to COBOL with SQL. This COBOL and SQL code was then transformed to Java and SQL code (See Figure B-2 ). [image here] Figure B-2 \u2013 The component COBOL automated transformation and refactoring to Java.","title":"Phase 1: Automated Transformation and Refactoring of COBOL to Java on x86"},{"location":"modern/10-appendix-b/#phase-2-advanced-refactoring-to-remove-cobol-design-overtones","text":"After Phase 1, the resulting converted Java code contained COBOL design remnants, or COBOL overtones, that required personnel to have specialized skills to maintain the codebase. A plan was developed to identify and replace COBOL overtones with standard Java solutions. The refactoring approach used the TSRI JANUS Studio tool and a semi-automated refactoring method (See Figure B-3 ) that performs further code optimization, naming changes, and other enhancements to improve architecture, design, security, sustainability and performance. These techniques, along with the improved method synthesis algorithm, greatly improved the maintainability of the Java codebase. [image here] Figure B-3 \u2013 The supply application refactoring plan (to maintainable Java).","title":"Phase 2: Advanced Refactoring to Remove COBOL Design Overtones"},{"location":"modern/10-appendix-b/#phase-3-infrastructure-migration-to-aws","text":"After Phase 2 was completed, the entire application will be migrated to AF Cloud One on AWS GovCloud (US) including the development, testing, staging, production, and all support environments (See Figure B-4 ). AWS GovCloud (US) was selected because it aligned with the future technical direction of the system. This included cybersecurity, DevSecOps, and automated continuous integration (CI) and continuous delivery (CD) pipeline processes and DevSecOps Toolchain. The applications\u2019 architecture is being installed in AWS GovCloud (US) and continues to evolve. [image here] Figure B-4 \u2013 Amazon Web Services (AWS) GovCloud Hosting Design.","title":"Phase 3: Infrastructure Migration to AWS."},{"location":"modern/10-appendix-b/#customer-benefits","text":"The application has been transformed from an expensive mainframe COBOL legacy system to a more affordable, modern maintainable Java-based system. All valuable existing business rules have been preserved in the modernized system, while development, test, and production environments were migrated to AWS providing flexibility at reduced cost.","title":"Customer Benefits"},{"location":"modern/10-appendix-b/#lessons-learned","text":"This project demonstrated that the DoD can apply automated transformation and refactoring to modernize major legacy systems, including complex COBOL-based mainframes, and preserve the existing business rules within a cost-effective, open system architecture capable of migration to the cloud. Lessons learned during this project: When properly planned and executed, code conversions via automated refactoring provide a low-risk approach to modernizing legacy applications. Breaking efforts into clear phases (modernize, migrate, etc) keeps risk low and ensures project success. Moving from legacy COBOL to a modern architecture and language enable the application to benefit from modern tools and services. Agile development practices enable real-time course corrections and reduce delivery risk. Automation is crucial in order to transform millions of lines of code while preserving functionality, reducing risks, and reducing the project timeline. Migrating from a legacy proprietary mainframe and COBOL to an open Java platform allows access to a large pool of talented technology people to evolve the application.","title":"Lessons Learned"},{"location":"modern/11-1-checklist/","text":"11.1 Checklist for successful application modernization Our checklist of 7 things to consider for a successful AAM project is as follows: 1. Assess the current state of legacy systems. Legacy software does not always fall under \u201cold\u201d or \u201coutdated\u201d definitions. There are more aspects to assess when identifying the legacy. That is why you need to assess all systems in place to uncover the current and potential issues it can bring up soon. The assessment should be systematic and detailed: Study all aspects of your technology, from code and architecture to visual look and feel, considering your future business plans for product growth. 2. Select the modernization approach that would be the fastest to deliver value. Based on the assessment conducted at the first phase, choose the modernization approach that best fits your needs and will help you deliver results fast. Aside from the modernization approaches, consider existing products you can use instead. There is no need to reinvent the wheel if there is a SaaS solution available at a fraction of cost. Yet, if your system solves rather specific tasks or you want to be able to build more features on top of it, custom product development services might be right for you. In this case, adopting agile software development practices can help you speed up the process and deliver value fast. 3. Rethink the architecture and prioritize for simplicity. Legacy systems often fail to perform as needed due to their overly complex structure. When modernizing your system, less is more in terms of both architecture and functionality. Start by implementing only the most important features. Consider a microservices architecture approach to make your product scalable. Additionally, make sure the newly released application will work well with the rest of the tools used in your business by default. If you plan to change any of the tools soon, consider several possible options and keep their requirements in mind when building your application. 4. Choose the technology stack to deliver optimal performance and user experience. When reengineering your system, make sure you use a solid and future-ready technology stack. The choice of technologies should completely depend on the product specifics. Consult with your internal IT staff or address a professional tech consultancy. The right tech stack contributes to building a performant, reliable and efficient product. Adopt a solid quality assurance and testing process to deliver the best results. 5. Document for future system growth. To avoid the same mistakes that made you reengineer your current solution, introduce (or adopt best practices used by other companies) a set of coding standards and internal processes. Orderly documented and clean code make your software easy to understand, extend and maintain in the future. 6. Create a separate support and retirement schedule for your legacy system. Even if you have a brand-new system running like a clockwork, you will still need your legacy software, just in case. So, don\u2019t kill it all at once. Document and archive your solutions so you can easily access and refer to them when needed. Therefore, you need to support your legacy system for some time and plan for retiring your legacy system only when your new product is up and running. 7. Plan for training and system updates. Working with the old systems for years, your employees might need some time and guidance to master the new software. So be ready to invest in knowledge transfer and staff training for better performance and efficiency. Additionally, plan for regular system updates. If you fail to keep your product up to date, you will soon face another modernization challenge.","title":"11 1 checklist"},{"location":"modern/11-1-checklist/#111-checklist-for-successful-application-modernization","text":"Our checklist of 7 things to consider for a successful AAM project is as follows:","title":"11.1 Checklist for successful application modernization"},{"location":"modern/11-1-checklist/#1-assess-the-current-state-of-legacy-systems","text":"Legacy software does not always fall under \u201cold\u201d or \u201coutdated\u201d definitions. There are more aspects to assess when identifying the legacy. That is why you need to assess all systems in place to uncover the current and potential issues it can bring up soon. The assessment should be systematic and detailed: Study all aspects of your technology, from code and architecture to visual look and feel, considering your future business plans for product growth.","title":"1.  Assess the current state of legacy systems."},{"location":"modern/11-1-checklist/#2-select-the-modernization-approach-that-would-be-the-fastest-to-deliver-value","text":"Based on the assessment conducted at the first phase, choose the modernization approach that best fits your needs and will help you deliver results fast. Aside from the modernization approaches, consider existing products you can use instead. There is no need to reinvent the wheel if there is a SaaS solution available at a fraction of cost. Yet, if your system solves rather specific tasks or you want to be able to build more features on top of it, custom product development services might be right for you. In this case, adopting agile software development practices can help you speed up the process and deliver value fast.","title":"2. Select the modernization approach that would be the fastest to deliver value."},{"location":"modern/11-1-checklist/#3-rethink-the-architecture-and-prioritize-for-simplicity","text":"Legacy systems often fail to perform as needed due to their overly complex structure. When modernizing your system, less is more in terms of both architecture and functionality. Start by implementing only the most important features. Consider a microservices architecture approach to make your product scalable. Additionally, make sure the newly released application will work well with the rest of the tools used in your business by default. If you plan to change any of the tools soon, consider several possible options and keep their requirements in mind when building your application.","title":"3. Rethink the architecture and prioritize for simplicity."},{"location":"modern/11-1-checklist/#4-choose-the-technology-stack-to-deliver-optimal-performance-and-user-experience","text":"When reengineering your system, make sure you use a solid and future-ready technology stack. The choice of technologies should completely depend on the product specifics. Consult with your internal IT staff or address a professional tech consultancy. The right tech stack contributes to building a performant, reliable and efficient product. Adopt a solid quality assurance and testing process to deliver the best results.","title":"4. Choose the technology stack to deliver optimal performance and user experience."},{"location":"modern/11-1-checklist/#5-document-for-future-system-growth","text":"To avoid the same mistakes that made you reengineer your current solution, introduce (or adopt best practices used by other companies) a set of coding standards and internal processes. Orderly documented and clean code make your software easy to understand, extend and maintain in the future.","title":"5. Document for future system growth."},{"location":"modern/11-1-checklist/#6-create-a-separate-support-and-retirement-schedule-for-your-legacy-system","text":"Even if you have a brand-new system running like a clockwork, you will still need your legacy software, just in case. So, don\u2019t kill it all at once. Document and archive your solutions so you can easily access and refer to them when needed. Therefore, you need to support your legacy system for some time and plan for retiring your legacy system only when your new product is up and running.","title":"6. Create a separate support and retirement schedule for your legacy system."},{"location":"modern/11-1-checklist/#7-plan-for-training-and-system-updates","text":"Working with the old systems for years, your employees might need some time and guidance to master the new software. So be ready to invest in knowledge transfer and staff training for better performance and efficiency. Additionally, plan for regular system updates. If you fail to keep your product up to date, you will soon face another modernization challenge.","title":"7. Plan for training and system updates."},{"location":"modern/11-2-legacy-system/","text":"> 11.2 Legacy System Application Portfolio Assessment Framework Often dealing with legacy systems, organizations have developed their own approach to choosing an appropriate way to modernize business-critical software. Namely, we recommend taking several steps first to assess the existing application portfolio. 1. Technologies Analysis - The first step in Discover phase is to identify and analyze the technology stack of the existing product. Thus, we know if the programming language or frameworks used are still relevant and supported by the vendors. If the product relies completely on outdated technologies, the chances are we would need to completely rewrite it in the process of modernization. 2. Architecture Audit - In case the tech stack (or some parts of it) is still relevant, it is necessary to conduct an architecture audit. This will help you define the system elements which are functioning well and focus on the ones that need modernization. Plus, you will be able to see how different parts of the system interrelate, so that your future changes won\u2019t affect the whole product. 3. Code Review - Legacy software usually has an excessive codebase, requiring regular reviews and refactoring. If not treated properly, the software tends to \u201crot.\u201d This might lead to more design flaws and conflicts as you try to introduce new features or update some parts of the system. That is why, as a part of any modernization or changes, we typically conduct a complete code review, assessing the quality and \u201cupdateability\u201d of the system\u2019s source code. 4. UI/UX Review - The same principle applies to the UI and UX design. A thorough design review is required to understand which parts of the system interface need a \u201cfacelift.\u201d 5. Performance Testing - Performance testing aims at uncovering further potential issues with the legacy systems. Poor performance or major flaws can serve as a reason for a complete system modernization as well as selective improvements. 6. Current Requirements and Opportunities for Future Growth - While considering the current business needs and requirements articulated by the client, focus on opportunities for the future growth. Thus, PMO Product Owners can make an informed decision by providing a well-grounded and unbiased opinion on the software modernization options. Many organizations have adopted a proven Application Portfolio Analysis (APA) Framework approach developed by IBM to identify the cost saving and digital transformation opportunities available within their current legacy applications and asset base. For cloud migrations, we recommend supplementing the IBM APA process described herein to tailor it to the AWS Cloud Adoption Framework or Microsoft Azure Cloud Adoption Framework. We recommend using the cloud provider Application Discovery methods and automated tools to discover Apps on the customer network. AWS and Microsoft also provides APA methods and best practices tailored specifically to cloud adoption and cloud migration strategies on the AWS GovCloud or Azure Government cloud platforms respectively. APA Discovery Approach. The IBM APA discovery approach (see Figure C-1) is based on an application inventory on the customer\u2019s enterprise network. For each application, specific information is gathered on the Apps in order to perform analysis including comparisons. For Cloud adoption migrations use AWS Discovery Agent or Microsoft Assessment and Planning Toolkit tools to discover and inventory the Apps on the enterprise network. Another tool for Cloud adoption readiness assessment is the AWS Cloud Adoption Readiness Tool (CART). CART helps Air Force AAM project teams develop a plan for cloud migration and adoption. It enables answering 16 questions to generate a downloadable report that rates cloud adoption readiness of an application across areas of: business, people, process, platform, operations, and security. Each report provides recommendations to help plan an organization\u2019s unique cloud journey. URL: https://cart.splashthat.com/?sc_channel=sm&sc_campaign=Public_Sector&sc_publisher=LINKEDIN&sc_country=Global&sc_geo=GLOBAL&sc_outcome=lead_gen&trk=sm_O_CART2019_LINKEDIN&sc_content=CART&linkId=73513814 AAM Project teams should use the tool/method best aligned with the needs of their solution. [image here] Figure C-1. IBM\u2019s Application Portfolio Assessment Process. APA Analysis Approach. IBM\u2019s APA analysis approach is a best practice that collects and verifies the application discovery data and then enterprise or cloud architects conduct four major process steps (see Figure C-2, each of which is tailored to the customer\u2019s specific requirements. For example, for cloud migration adoption begin grouping applications based on patterns in the portfolio to enable identifying order of cloud migration and the migration strategy (i.e. which of the 6 R\u2019s of the cloud migration strategy will be used) for migrating the given pattern. The result of this analysis is a broad categorization of resources aligned by common traits. Special cases may also be identified that need special handling. APA methods are: (1) Quick - Address an enterprise\u2019s urgent need to cut costs associated with providing applications and applications support; (2) Opportunity identification is within 4 weeks and Value proposition for selected legacy application modernization opportunities is provided within 6 weeks; (3) Comprehensive - focuses on key levers of IT cost reduction: consolidation, standardization, automation and transformation; and finally (4) Pragmatic - identifies cost saving and digital transformation options that can be designed and implemented in the phased approach we have described in the AAM Playbook. [image here] Figure C-2. IBM\u2019s APA Analysis Approach is a Best Practice.","title":"> **11.2** Legacy System Application Portfolio Assessment Framework"},{"location":"modern/11-2-legacy-system/#112-legacy-system-application-portfolio-assessment-framework","text":"Often dealing with legacy systems, organizations have developed their own approach to choosing an appropriate way to modernize business-critical software. Namely, we recommend taking several steps first to assess the existing application portfolio. 1. Technologies Analysis - The first step in Discover phase is to identify and analyze the technology stack of the existing product. Thus, we know if the programming language or frameworks used are still relevant and supported by the vendors. If the product relies completely on outdated technologies, the chances are we would need to completely rewrite it in the process of modernization. 2. Architecture Audit - In case the tech stack (or some parts of it) is still relevant, it is necessary to conduct an architecture audit. This will help you define the system elements which are functioning well and focus on the ones that need modernization. Plus, you will be able to see how different parts of the system interrelate, so that your future changes won\u2019t affect the whole product. 3. Code Review - Legacy software usually has an excessive codebase, requiring regular reviews and refactoring. If not treated properly, the software tends to \u201crot.\u201d This might lead to more design flaws and conflicts as you try to introduce new features or update some parts of the system. That is why, as a part of any modernization or changes, we typically conduct a complete code review, assessing the quality and \u201cupdateability\u201d of the system\u2019s source code. 4. UI/UX Review - The same principle applies to the UI and UX design. A thorough design review is required to understand which parts of the system interface need a \u201cfacelift.\u201d 5. Performance Testing - Performance testing aims at uncovering further potential issues with the legacy systems. Poor performance or major flaws can serve as a reason for a complete system modernization as well as selective improvements. 6. Current Requirements and Opportunities for Future Growth - While considering the current business needs and requirements articulated by the client, focus on opportunities for the future growth. Thus, PMO Product Owners can make an informed decision by providing a well-grounded and unbiased opinion on the software modernization options. Many organizations have adopted a proven Application Portfolio Analysis (APA) Framework approach developed by IBM to identify the cost saving and digital transformation opportunities available within their current legacy applications and asset base. For cloud migrations, we recommend supplementing the IBM APA process described herein to tailor it to the AWS Cloud Adoption Framework or Microsoft Azure Cloud Adoption Framework. We recommend using the cloud provider Application Discovery methods and automated tools to discover Apps on the customer network. AWS and Microsoft also provides APA methods and best practices tailored specifically to cloud adoption and cloud migration strategies on the AWS GovCloud or Azure Government cloud platforms respectively. APA Discovery Approach. The IBM APA discovery approach (see Figure C-1) is based on an application inventory on the customer\u2019s enterprise network. For each application, specific information is gathered on the Apps in order to perform analysis including comparisons. For Cloud adoption migrations use AWS Discovery Agent or Microsoft Assessment and Planning Toolkit tools to discover and inventory the Apps on the enterprise network. Another tool for Cloud adoption readiness assessment is the AWS Cloud Adoption Readiness Tool (CART). CART helps Air Force AAM project teams develop a plan for cloud migration and adoption. It enables answering 16 questions to generate a downloadable report that rates cloud adoption readiness of an application across areas of: business, people, process, platform, operations, and security. Each report provides recommendations to help plan an organization\u2019s unique cloud journey. URL: https://cart.splashthat.com/?sc_channel=sm&sc_campaign=Public_Sector&sc_publisher=LINKEDIN&sc_country=Global&sc_geo=GLOBAL&sc_outcome=lead_gen&trk=sm_O_CART2019_LINKEDIN&sc_content=CART&linkId=73513814 AAM Project teams should use the tool/method best aligned with the needs of their solution. [image here] Figure C-1. IBM\u2019s Application Portfolio Assessment Process.","title":"&gt; 11.2 Legacy System Application Portfolio Assessment Framework"},{"location":"modern/11-2-legacy-system/#apa-analysis-approach","text":"IBM\u2019s APA analysis approach is a best practice that collects and verifies the application discovery data and then enterprise or cloud architects conduct four major process steps (see Figure C-2, each of which is tailored to the customer\u2019s specific requirements. For example, for cloud migration adoption begin grouping applications based on patterns in the portfolio to enable identifying order of cloud migration and the migration strategy (i.e. which of the 6 R\u2019s of the cloud migration strategy will be used) for migrating the given pattern. The result of this analysis is a broad categorization of resources aligned by common traits. Special cases may also be identified that need special handling. APA methods are: (1) Quick - Address an enterprise\u2019s urgent need to cut costs associated with providing applications and applications support; (2) Opportunity identification is within 4 weeks and Value proposition for selected legacy application modernization opportunities is provided within 6 weeks; (3) Comprehensive - focuses on key levers of IT cost reduction: consolidation, standardization, automation and transformation; and finally (4) Pragmatic - identifies cost saving and digital transformation options that can be designed and implemented in the phased approach we have described in the AAM Playbook. [image here] Figure C-2. IBM\u2019s APA Analysis Approach is a Best Practice.","title":"APA Analysis Approach."},{"location":"modern/11-3-security/","text":"11.3 SANS Security Roadmap \u2013 Securing Web Application Technologies Checklist [image here]","title":"11.3 SANS Security Roadmap"},{"location":"modern/11-3-security/#113-sans-security-roadmap-securing-web-application-technologies-checklist","text":"[image here]","title":"11.3 SANS Security Roadmap \u2013 Securing Web Application Technologies Checklist"},{"location":"modern/11-4-worksheet/","text":"11.4 BPD Tailoring Worksheet for Engineering and Manufacturing Development Phase, Production & Deployment Phase, and Operations & Support Phase (24 September, 2018) [worksheet here] For guidance and instruction on the Tailoring Worksheet, refer to the BPD Tailoring Guide. NOTE: For AAM Agile contract projects, the Agile (Scrum, Kanban, and XP) best practices described in the Agile and AAM Playbooks will replace the BPD IT Lean waterfall centric phases, reviews and documentation. One of the key AAM contract project assumptions is that the documentation work product artifacts of the legacy system application undergoing modernization and migration to the cloud currently exist, are in accordance with the BPD templates and have been reviewed and approved by the government PMO. If not, only documentation work products agreed to by the application Product Owner will be included in the application release Product Backlog. When a work product is marked with a checkmark (\u2714) or asterisk (*), that work product shall either be produced or if it already exists, updated as necessary. In either case, the work product must be consistent with the current release. \u2714 = Product will be or has been produced * = Product will be modified (justification required) N/A = Not Applicable (justification required) The \u201cJUSTIFICATION FOR TAILORING\u201d column of this template identifies products that shall be tailored out if the Preliminary Design Review (PDR) occurs after Milestone B. Refer to the BPD Tailoring Guide for conditions regarding when the PDR occurs in relation to Milestone B. NOTE: For AAM Agile contract projects, iterative Agile Scrum management practices, XP engineering practices, and product documentation artifacts maintained in the Jira Work Management Tool and Confluence Project Wiki. These work product artifacts will be substituted for the IT Lean reviews and document work product artifacts in the BPD Tailoring Worksheet. Every product delivered to the customer must have a Peer Review and Minutes. All meetings and reviews conducted will be formally documented with formal meeting minutes. Action items identified during meetings and reviews will be tracked to closure. Refer to the Peer Review Procedure. NOTE: For AAM Agile contract projects, Agile Product Backlog grooming, iterative Scrum Sprint Backlog Refinement, Sprint Demos, \u2018Definition of Done\u2019 criteria, sprint Retrospectives, and Release Integration (Minimum viable Product criteria) review and testing activities of the product user stories and features are performed with the Development Team, Product Owner and Stakeholders. These procedures will replace the BPD Peer Review Procedure. Review Lessons Learned Database Review the pertinent sections of the Lessons Learned Database. The database is available for help in avoiding previous pitfalls and for providing ideas that have worked well for others. It can be found on the BPD web site. Review Automated Application Modernization (AAM) Playbook Review the pertinent sections of the AAM Playbook for project guidance in terms of project organization, staffing, management and engineering practices, project phases, work items and deliverables. It can be found on the BES Playbooks web site: https://besplaybook.github.io/BESPlaybook/ . The following table prescribes work item products that are recommended for an AAM Agile contract project. ENGINEERING AND MANUFACTURING DEVELOPMENT PHASE Row No. \u2714, * or N/A Product References Justification for Tailoring 1 \u2714 Stakeholder List Stakeholder Identification and Assessment Template Stakeholder Communications plan 2 N/A Integrated Baseline Review (IBR) and Minutes IBR Procedure Using Scrum Management Practices 3 * Final Configuration Management Plan (CMP) Configuration Management Planning Procedure 4 N/A Intergroup Coordination Checklist Intergroup Coordination Checklist Template 5 N/A Initial Integrated Test Design (IITD) Artifacts IITD Procedure Tailor out if PDR occurs before Milestone B * Updated Integrated Test Team (ITT) Charter ITT Guide ITT Charter Template * Updated Test and Evaluation Master Plan (TEMP) TEMP Template * Updated Integrated Test Plan (ITP) ITP Template \u2714 Draft Test Scenarios, Test Cases, and Test Scripts Test Script Template Replaced with User Story or Feature Manual and Automated Test Scripts (to the extent Practical) and \u2018Definition of Done\u2019 N/A Updated Integrated Test Description (ITD) ITD Template See Above 6 N/A Work Breakdown Structure (WBS) WBS Procedure Replaced with Scrum Product Backlog and Sprint Backlog tasks and work items 7 \u2714 Refined Schedule and Cost 8 * Updated Project-Specific Training Plan Project-Specific Training Procedure 9 * Updated Risks Risk and Issue Management Process 10 N/A Updated Systems Engineering Plan Systems Engineering Plan Outline Replaced with Scrum Management and XP Engineering Practices Air Force Implementation of New Office of the Secretary of Defense (OSD) Templates Air Force Materiel Command Instruction (AFMCI) 63-1201 & applicable supplement 11 N/A Configuration Control Directive (CCD) CCD Form Replaced with CI/CD Pipeline Processes 12 N/A Functional Review Board (FRB) and minutes FRB Procedure Replaced by Product Owner and designated Stakeholders providing engineering support Row No. \u2714, * or N/A Product References Justification for Tailoring 13 N/A Software Development Plan (SDP) SDP Template Tailor out if PDR occurs before Milestone B 14 N/A General Requirements Specification (GRS) GRS Template Tailor out if PDR occurs before Milestone B 15 * Updated Requirements Traceability Matrix (RTM) RTM Template Provided in Jira format 16 * Updated Responses in Enterprise Information Technology Data Repository (EITDR) to Non-Security Portions of Security, Interoperability, Supportability, Sustainability, and Usability (SISSU) Questions EITDR Guide EITDR is now Information Technology Investment Portfolio Suite (ITIPS) 17 * Updated Responses to Information Assurance (IA) Controls in Enterprise Mission Assurance Support Service (eMASS) eMASS Portal Contact the IA Function for Assistance 18 N/A System Requirements Review (SRR) and Minutes SRR Procedure Replaced by Scrum Epics, Features and High-level User Stories and Work Items in the Product Backlog maintained by the Product Owner 19 N/A Updated GRS GRS Template Tailored Out 20 N/A System Functional Review (SFR) and Minutes SFR Procedure Replaced by weekly Product Backlog grooming by the Product Owner and Stakeholders 21 N/A Refined Functional Baseline (FBL) Tailor out if PDR occurs before Milestone B 22 * Updated Risks Risk and Issue Management Process 23 N/A Updated Cost Analysis Requirement Description (CARD) Replaced by Story Point estimates in t-shirt sizing and planning poker estimation. 24 * Updated Life Cycle Sustainment Plan (LCSP) Document Streamlining \u2013 LCSP Air Force Implementation of New OSD Templates 25 * Updated Interface Requirements Agreement (IRA) IRA Template 26 N/A Updated GRS GRS Template 27 * Updated RTM RTM Template Update from Jira 28 * Draft Database Specification (DS) DS Template Output from Data Conversion and Data Migration Tools 29 N/A Draft Design Document (DD) DD Template Tailor out if PDR occurs before Milestone B 30 * Updated Architecture Viewpoints Department of Defense Architecture Framework (DoDAF) \u201cAs-Is\u201d and \u201cTo-Be\u201d Architecture Runway Descriptions 31 * Updated Information Support Plan (ISP) ISP Guide 32 N/A PDR and Minutes PDR Procedure Tailor out if PDR occurs before Milestone B 33 N/A Post-Preliminary Design Review Assessment (Post-PDR A) and Minutes Post-PDR A Procedure Tailor out if PDR occurs before Milestone B 34 N/A Allocated Baseline (ABL) Tailor out if PDR occurs before Milestone B 35 N/A Draft Implementation Plan (IP) IP Template Replaced by AAM Project Plan 36 \u2714 Release Request Letter Release Request Letter and Instructions Form 37 \u2714 Final IRA IRA Template 38 N/A Updated GRS GRS Template 39 N/A Updated RTM RTM Template Replaced by Jira output 40 N/A Final DS DS Template Output from Data Conversion and Data Migration Tools 41 N/A Final DD DD Template Output from AAM Design stage: 1. To-Be Architecture Runway 2. Infrastructure Architecture Doc 3. Transformation & Refactoring Plan 4. Transformation Specification Doc 5. Baseline App Blueprint (source) 6. Product Backlog 42 N/A IITD Artifacts IITD Procedure * Updated ITT Charter ITT Guide ITT Charter Template * Updated TEMP TEMP Template * Updated ITP ITP Template N/A Updated Test Scenarios, Test Cases, and Test Scripts Test Script Template Replaced with User Story or Feature Manual and Automated Test Scripts (to the extent Practical) and \u2018Definition of Done\u2019 N/A Updated ITD ITD Template See above. 43 N/A Critical Design Review (CDR) and Minutes CDR Procedure Replaced by weekly Product Backlog grooming and Sprint Backlog refinement by the Development Team, Product Owner and Stakeholders 44 * Updated Risks Risk and Issue Management Process 45 N/A Updated CARD Replaced by Story Point estimates in Product Backlog (t-shirt sizing) and Sprint Backlog (planning poker estimation) 46 * Refined Schedule and Cost 47 * Updated LCSP Document Streamlining \u2013 LCSP Air Force Implementation of New OSD Templates 48 N/A Technology Readiness Assessment (TRA) (if required by the Milestone Decision Authority (MDA)) Improving TRA Effectiveness TRA Guidance Replaced by AAM Design stage process and Architecture Runway reports for \u201cTo-Be\u201d Cloud infrastructure architecture 49 * Final Responses in EITDR to Non-Security portions of SISSU Questions EITDR is now Information Technology Investment Portfolio Suite (ITIPS) 50 * Final Responses to IA Controls in eMASS eMASS Portal Contact the IA Function for Assistance 51 * Final Architecture Viewpoints Department of Defense Architecture Framework (DoDAF) \u201cAs-Is\u201d and \u201cTo-Be\u201d Architecture Runway Descriptions 52 * Final ISP ISP Guide 53 * Updated Program Protection Plan (PPP) Document Streamlining - PPP 54 N/A Engineering Go/No-Go Recommendation Memorandum Engineering Go/No-Go Recommendation Procedure Engineering Go/No-Go Recommendation Memorandum Template Replaced by Agile Product Backlog grooming and Sprint Backlog refinement by Product owner and Stakeholders before each Development Sprint 55 N/A Acquisition Decision Memorandum (ADM) for the Post-Critical Design Review Assessment (Post-CDR A) Post-CDR A Procedure Replaced by Agile practices 56 * Final IP IP Template Replaced by AAM Project Plan 57 * User Manual (UM) or on line help UM Template Updated by AAM contractor 58 N/A Operator Manual (OM) OM Template Not required, since Cloud Hosting Provider provides operations support 59 * Final ITP ITP Template 60 N/A Product Database Database Development Procedure Replaced by Data Migration Plan 61 * Product Components Individual Component Validation (ICV) Procedure Automated Unit Tests, Integration Tests, Functional Tests and Regression Tests 62 N/A Systems Infrastructure Systems Infrastructure Procedure Replaced by Cloud DevSecOps Infrastructure as Code practices 63 N/A IITD Artifacts IITD Procedure Replaced by Agile practices * Final ITT Charter ITT Guide ITT Charter Template * Final TEMP TEMP Template * Final ITP ITP Template * Final Test Scenarios, Test Cases, and Test Scripts Test Script Template Replaced with User Story or Feature Manual and Automated Test Scripts (to the extent Practical) and \u2018Definition of Done\u2019 * Final ITD ITD Template See above. 64 N/A Integrated Test Report (ITR) for Integrated Developmental Test and Evaluation (IDT&E) (Component Validation and Integration (CV&I) portion only) ITR Template CV&I Procedure Replaced by Sprint Demo and Release Integration Demo of User Stories (Definition of Done criteria) and Features (Minimum Viable Product criteria) 65 \u2714 Product Baseline (PBL) Maintained in Version Control System (GitLab) and Digital Artifact Repository (Artifactory) 66 \u2714 Final Release Package Turn-In and Release Guide Maintained in Version Control System (GitLab) and Digital Artifact Repository (Artifactory) 67 N/A Final GRS GRS Template Replaced with Agile practices 68 N/A Final RTM RTM Template Replaced with Jira outputs 69 N/A Test Readiness Review I (TRR I) and Minutes TRR I Procedure Replaced with final Release Integration feature testing with Product Owner and Stakeholders applying \u2018Minimum Viable Product\u2019 criteria. 70 \u2714 Lessons Learned Lessons Learned, Good Practices, Opportunities and Assistance Procedure AAM contractor. Engineering and Manufacturing Development Iteration \u2013 End Row No. \u2714, * or N/A Product References Justification for Tailoring 71 N/A ITR for IDT&E (includes both CV&I and Qualification Test and Evaluation (QT&E)) ITR Template QT&E Procedure Replaced by Production Release Validation activities: government UAT and Security Testing; User Training; Knowledge Transfer; Data Migration and Cutover 72 \u2714 Functional Configuration Audit (FCA) Report FCA Procedure AAM contractor. 73 N/A Operational Test Readiness Review (OTRR) and Minutes OTRR Procedure Replaced by Agile practices 74 N/A Updated CARD Replaced by Story Point estimates in Product Backlog (t-shirt sizing) and Sprint Backlog (planning poker estimation) 75 \u2714 Program Office Estimate (POE) Government PMO. 76 \u2714 Component Cost Assessment (CCA) Government PMO. 77 \u2714 Independent Cost Estimate (ICE) Government PMO. 78 \u2714 Title 40/Clinger-Cohen Act (CCA) Compliance and Component Chief Information Officer (CIO) Confirmation (for all Information Technology (IT)) See AFMAN 17-1402 Government PMO. 79 \u2714 Title 40/Clinger-Cohen Act (CCA) Department of Defense (DoD) CIO Confirmation (for Major Defense Acquisition Programs (MDAPs) and Major Automated Information Systems (MAIS)) See AFMAN 17-1402 Government PMO. 80 \u2714 Updated Programmatic Environment, Safety and Occupational Health Evaluation (PESHE) Government PMO. 81 \u2714 Updated National Environmental Policy Act (NEPA) Compliance Schedule (as required) Government PMO. 82 \u2714 Updated Defense Business System Certification and approval (if required) Government PMO. 83 N/A Engineering Go/No-Go Recommendation Memorandum Engineering Go/No-Go Recommendation Procedure Engineering Go/No-Go Recommendation Memorandum Template Replaced by Agile contract practices. 84 N/A ADM for Milestone C Replaced by Agile contract practices. 85 N/A Test Report for Operational Test and Evaluation (OT&E) (Conducted by the Operational Test Organization (OTO) as Documented in the TEMP or LCMP) Legacy App in Sustainment undergoing modernization. 86 N/A Physical Configuration Audit (PCA) Report App is hosted in the Cloud 87 N/A Operational Safety, Suitability, and Effectiveness (OSS&E) Baseline Document (OBD) (This OBD applies only to the first release of a new system. Subsequent OBDs are prepared annually.) Operational Safety, Suitability, and Effectiveness (OSS&E) Baseline Document (OBD) Template App is hosted in the Cloud 88 N/A Economic Analysis (MAIS only) Legacy App modernized for Cloud hosting 89 N/A Acquisition Strategy Technology Development Strategy/Acquisition Strategy Sample Outline Air Force Implementation of New OSD Templates Pre-Award Acquisition Strategy (AS) and Request for Proposal (RFP) Development Process Legacy App modernized for Cloud hosting 90 N/A Analysis of Alternatives (AoA) (MAIS only) AoA Study Plan Template Legacy App modernized for Cloud hosting 91 N/A Acquisition Strategy Plan (ASP) Acquisition Strategy Plan (ASP) Template - ACAT Acquisition Strategy Plan (ASP) Template Non-ACAT Legacy App modernized for Cloud hosting 92 N/A Draft Request for Information (RFI) (optional) for the Operations & Support Phase Contact the Contracting Function for Assistance Legacy App modernized for Cloud hosting 93 N/A Source Selection Plan Contact the Contracting Function for Assistance Legacy App modernized for Cloud hosting 94 N/A Draft Request for Proposal (RFP) for the Operations & Support Phase Contact the Contracting Function for Assistance Legacy App modernized for Cloud hosting 95 N/A Quick Pass and Acquisition Strategy Panel Review and Minutes Contact the Contracting Function for Assistance Legacy App modernized for Cloud hosting 96 N/A Final RFP for the Operations & Support Phase Contact the Contracting Function for Assistance Legacy App modernized for Cloud hosting 97 N/A Engineering Go/No-Go Recommendation Memorandum Engineering Go/No-Go Recommendation Procedure Engineering Go/No-Go Recommendation Memorandum Template Legacy App modernized for Cloud hosting Decision Point \u2013 Full Deployment Decision (FDD) (Refer to the FDD Procedure ) Row No. \u2714, * or N/A Product References Justification for Tailoring 98 N/A Updated PPP Document Streamlining - PPP Legacy App modernized for Cloud hosting 99 N/A ADM for FDDR ADM Template Legacy App modernized for Cloud hosting 100 N/A Lessons Learned Lessons Learned, Good Practices, Opportunities and Assistance Procedure Legacy App modernized for Cloud hosting 101 N/A Source Selection Decision Document (SSDD) Contact the Contracting Function for Assistance Legacy App modernized for Cloud hosting OPERATIONS & SUPPORT PHASE Row No. \u2714, * or N/A Product References Justification for Tailoring 102 * Updated Stakeholder List Stakeholder Identification and Assessment Template Government PMO. 103 \u2714 Release Request Letter Release Request Letter and Instructions Form AAM Contractor. 104 \u2714 Version Description Document (VDD) VDD Form AAM Contractor. 105 \u2714 Release Turn-in Certification Form Release Turn-in Certification Form AAM Contractor. 106 N/A Installed System Hardware and Software System Installation Procedure Legacy App modernized for Cloud hosting 107 \u2714 Products from completed system training (i.e., trained customers, users, and Help Desk personnel; archived training materials; and completed training critiques) System Training Procedure Provided prior to Cutover Begin Customer Support Process Row No. \u2714, * or N/A Product References Justification for Tailoring 108 N/A IBR and Minutes (if required) IBR Procedure Replaced by Agile practices and metrics. 109 \u2714 Products from continual customer support (i.e., resolved customer requests, Deficiency Reports (DRs), maintained Problem Management System database, and required or requested reports) Continual Customer Support Procedure Government PMO and Post production sustainment support contractor. 110 \u2714 In-Service Review (ISR) and Minutes In-Service Review Government PMO. 111 \u2714 Lessons Learned Lessons Learned, Good Practices, Opportunities and Assistance Procedure Government PMO.","title":"11.4 BPD Tailoring Worksheet"},{"location":"modern/11-4-worksheet/#114-bpd-tailoring-worksheet-for-engineering-and-manufacturing-development-phase-production-deployment-phase-and-operations-support-phase-24-september-2018","text":"[worksheet here] For guidance and instruction on the Tailoring Worksheet, refer to the BPD Tailoring Guide. NOTE: For AAM Agile contract projects, the Agile (Scrum, Kanban, and XP) best practices described in the Agile and AAM Playbooks will replace the BPD IT Lean waterfall centric phases, reviews and documentation. One of the key AAM contract project assumptions is that the documentation work product artifacts of the legacy system application undergoing modernization and migration to the cloud currently exist, are in accordance with the BPD templates and have been reviewed and approved by the government PMO. If not, only documentation work products agreed to by the application Product Owner will be included in the application release Product Backlog. When a work product is marked with a checkmark (\u2714) or asterisk (*), that work product shall either be produced or if it already exists, updated as necessary. In either case, the work product must be consistent with the current release. \u2714 = Product will be or has been produced * = Product will be modified (justification required) N/A = Not Applicable (justification required) The \u201cJUSTIFICATION FOR TAILORING\u201d column of this template identifies products that shall be tailored out if the Preliminary Design Review (PDR) occurs after Milestone B. Refer to the BPD Tailoring Guide for conditions regarding when the PDR occurs in relation to Milestone B. NOTE: For AAM Agile contract projects, iterative Agile Scrum management practices, XP engineering practices, and product documentation artifacts maintained in the Jira Work Management Tool and Confluence Project Wiki. These work product artifacts will be substituted for the IT Lean reviews and document work product artifacts in the BPD Tailoring Worksheet. Every product delivered to the customer must have a Peer Review and Minutes. All meetings and reviews conducted will be formally documented with formal meeting minutes. Action items identified during meetings and reviews will be tracked to closure. Refer to the Peer Review Procedure. NOTE: For AAM Agile contract projects, Agile Product Backlog grooming, iterative Scrum Sprint Backlog Refinement, Sprint Demos, \u2018Definition of Done\u2019 criteria, sprint Retrospectives, and Release Integration (Minimum viable Product criteria) review and testing activities of the product user stories and features are performed with the Development Team, Product Owner and Stakeholders. These procedures will replace the BPD Peer Review Procedure.","title":"11.4 BPD Tailoring Worksheet for Engineering and Manufacturing Development Phase, Production &amp; Deployment Phase, and Operations &amp; Support Phase (24 September, 2018)"},{"location":"modern/11-4-worksheet/#review-lessons-learned-database","text":"Review the pertinent sections of the Lessons Learned Database. The database is available for help in avoiding previous pitfalls and for providing ideas that have worked well for others. It can be found on the BPD web site.","title":"Review Lessons Learned Database"},{"location":"modern/11-4-worksheet/#review-automated-application-modernization-aam-playbook","text":"Review the pertinent sections of the AAM Playbook for project guidance in terms of project organization, staffing, management and engineering practices, project phases, work items and deliverables. It can be found on the BES Playbooks web site: https://besplaybook.github.io/BESPlaybook/ . The following table prescribes work item products that are recommended for an AAM Agile contract project.","title":"Review Automated Application Modernization (AAM) Playbook"},{"location":"modern/11-4-worksheet/#engineering-and-manufacturing-development-phase","text":"Row No. \u2714, * or N/A Product References Justification for Tailoring 1 \u2714 Stakeholder List Stakeholder Identification and Assessment Template Stakeholder Communications plan 2 N/A Integrated Baseline Review (IBR) and Minutes IBR Procedure Using Scrum Management Practices 3 * Final Configuration Management Plan (CMP) Configuration Management Planning Procedure 4 N/A Intergroup Coordination Checklist Intergroup Coordination Checklist Template 5 N/A Initial Integrated Test Design (IITD) Artifacts IITD Procedure Tailor out if PDR occurs before Milestone B * Updated Integrated Test Team (ITT) Charter ITT Guide ITT Charter Template * Updated Test and Evaluation Master Plan (TEMP) TEMP Template * Updated Integrated Test Plan (ITP) ITP Template \u2714 Draft Test Scenarios, Test Cases, and Test Scripts Test Script Template Replaced with User Story or Feature Manual and Automated Test Scripts (to the extent Practical) and \u2018Definition of Done\u2019 N/A Updated Integrated Test Description (ITD) ITD Template See Above 6 N/A Work Breakdown Structure (WBS) WBS Procedure Replaced with Scrum Product Backlog and Sprint Backlog tasks and work items 7 \u2714 Refined Schedule and Cost 8 * Updated Project-Specific Training Plan Project-Specific Training Procedure 9 * Updated Risks Risk and Issue Management Process 10 N/A Updated Systems Engineering Plan Systems Engineering Plan Outline Replaced with Scrum Management and XP Engineering Practices Air Force Implementation of New Office of the Secretary of Defense (OSD) Templates Air Force Materiel Command Instruction (AFMCI) 63-1201 & applicable supplement 11 N/A Configuration Control Directive (CCD) CCD Form Replaced with CI/CD Pipeline Processes 12 N/A Functional Review Board (FRB) and minutes FRB Procedure Replaced by Product Owner and designated Stakeholders providing engineering support Row No. \u2714, * or N/A Product References Justification for Tailoring 13 N/A Software Development Plan (SDP) SDP Template Tailor out if PDR occurs before Milestone B 14 N/A General Requirements Specification (GRS) GRS Template Tailor out if PDR occurs before Milestone B 15 * Updated Requirements Traceability Matrix (RTM) RTM Template Provided in Jira format 16 * Updated Responses in Enterprise Information Technology Data Repository (EITDR) to Non-Security Portions of Security, Interoperability, Supportability, Sustainability, and Usability (SISSU) Questions EITDR Guide EITDR is now Information Technology Investment Portfolio Suite (ITIPS) 17 * Updated Responses to Information Assurance (IA) Controls in Enterprise Mission Assurance Support Service (eMASS) eMASS Portal Contact the IA Function for Assistance 18 N/A System Requirements Review (SRR) and Minutes SRR Procedure Replaced by Scrum Epics, Features and High-level User Stories and Work Items in the Product Backlog maintained by the Product Owner 19 N/A Updated GRS GRS Template Tailored Out 20 N/A System Functional Review (SFR) and Minutes SFR Procedure Replaced by weekly Product Backlog grooming by the Product Owner and Stakeholders 21 N/A Refined Functional Baseline (FBL) Tailor out if PDR occurs before Milestone B 22 * Updated Risks Risk and Issue Management Process 23 N/A Updated Cost Analysis Requirement Description (CARD) Replaced by Story Point estimates in t-shirt sizing and planning poker estimation. 24 * Updated Life Cycle Sustainment Plan (LCSP) Document Streamlining \u2013 LCSP Air Force Implementation of New OSD Templates 25 * Updated Interface Requirements Agreement (IRA) IRA Template 26 N/A Updated GRS GRS Template 27 * Updated RTM RTM Template Update from Jira 28 * Draft Database Specification (DS) DS Template Output from Data Conversion and Data Migration Tools 29 N/A Draft Design Document (DD) DD Template Tailor out if PDR occurs before Milestone B 30 * Updated Architecture Viewpoints Department of Defense Architecture Framework (DoDAF) \u201cAs-Is\u201d and \u201cTo-Be\u201d Architecture Runway Descriptions 31 * Updated Information Support Plan (ISP) ISP Guide 32 N/A PDR and Minutes PDR Procedure Tailor out if PDR occurs before Milestone B 33 N/A Post-Preliminary Design Review Assessment (Post-PDR A) and Minutes Post-PDR A Procedure Tailor out if PDR occurs before Milestone B 34 N/A Allocated Baseline (ABL) Tailor out if PDR occurs before Milestone B 35 N/A Draft Implementation Plan (IP) IP Template Replaced by AAM Project Plan 36 \u2714 Release Request Letter Release Request Letter and Instructions Form 37 \u2714 Final IRA IRA Template 38 N/A Updated GRS GRS Template 39 N/A Updated RTM RTM Template Replaced by Jira output 40 N/A Final DS DS Template Output from Data Conversion and Data Migration Tools 41 N/A Final DD DD Template Output from AAM Design stage: 1. To-Be Architecture Runway 2. Infrastructure Architecture Doc 3. Transformation & Refactoring Plan 4. Transformation Specification Doc 5. Baseline App Blueprint (source) 6. Product Backlog 42 N/A IITD Artifacts IITD Procedure * Updated ITT Charter ITT Guide ITT Charter Template * Updated TEMP TEMP Template * Updated ITP ITP Template N/A Updated Test Scenarios, Test Cases, and Test Scripts Test Script Template Replaced with User Story or Feature Manual and Automated Test Scripts (to the extent Practical) and \u2018Definition of Done\u2019 N/A Updated ITD ITD Template See above. 43 N/A Critical Design Review (CDR) and Minutes CDR Procedure Replaced by weekly Product Backlog grooming and Sprint Backlog refinement by the Development Team, Product Owner and Stakeholders 44 * Updated Risks Risk and Issue Management Process 45 N/A Updated CARD Replaced by Story Point estimates in Product Backlog (t-shirt sizing) and Sprint Backlog (planning poker estimation) 46 * Refined Schedule and Cost 47 * Updated LCSP Document Streamlining \u2013 LCSP Air Force Implementation of New OSD Templates 48 N/A Technology Readiness Assessment (TRA) (if required by the Milestone Decision Authority (MDA)) Improving TRA Effectiveness TRA Guidance Replaced by AAM Design stage process and Architecture Runway reports for \u201cTo-Be\u201d Cloud infrastructure architecture 49 * Final Responses in EITDR to Non-Security portions of SISSU Questions EITDR is now Information Technology Investment Portfolio Suite (ITIPS) 50 * Final Responses to IA Controls in eMASS eMASS Portal Contact the IA Function for Assistance 51 * Final Architecture Viewpoints Department of Defense Architecture Framework (DoDAF) \u201cAs-Is\u201d and \u201cTo-Be\u201d Architecture Runway Descriptions 52 * Final ISP ISP Guide 53 * Updated Program Protection Plan (PPP) Document Streamlining - PPP 54 N/A Engineering Go/No-Go Recommendation Memorandum Engineering Go/No-Go Recommendation Procedure Engineering Go/No-Go Recommendation Memorandum Template Replaced by Agile Product Backlog grooming and Sprint Backlog refinement by Product owner and Stakeholders before each Development Sprint 55 N/A Acquisition Decision Memorandum (ADM) for the Post-Critical Design Review Assessment (Post-CDR A) Post-CDR A Procedure Replaced by Agile practices 56 * Final IP IP Template Replaced by AAM Project Plan 57 * User Manual (UM) or on line help UM Template Updated by AAM contractor 58 N/A Operator Manual (OM) OM Template Not required, since Cloud Hosting Provider provides operations support 59 * Final ITP ITP Template 60 N/A Product Database Database Development Procedure Replaced by Data Migration Plan 61 * Product Components Individual Component Validation (ICV) Procedure Automated Unit Tests, Integration Tests, Functional Tests and Regression Tests 62 N/A Systems Infrastructure Systems Infrastructure Procedure Replaced by Cloud DevSecOps Infrastructure as Code practices 63 N/A IITD Artifacts IITD Procedure Replaced by Agile practices * Final ITT Charter ITT Guide ITT Charter Template * Final TEMP TEMP Template * Final ITP ITP Template * Final Test Scenarios, Test Cases, and Test Scripts Test Script Template Replaced with User Story or Feature Manual and Automated Test Scripts (to the extent Practical) and \u2018Definition of Done\u2019 * Final ITD ITD Template See above. 64 N/A Integrated Test Report (ITR) for Integrated Developmental Test and Evaluation (IDT&E) (Component Validation and Integration (CV&I) portion only) ITR Template CV&I Procedure Replaced by Sprint Demo and Release Integration Demo of User Stories (Definition of Done criteria) and Features (Minimum Viable Product criteria) 65 \u2714 Product Baseline (PBL) Maintained in Version Control System (GitLab) and Digital Artifact Repository (Artifactory) 66 \u2714 Final Release Package Turn-In and Release Guide Maintained in Version Control System (GitLab) and Digital Artifact Repository (Artifactory) 67 N/A Final GRS GRS Template Replaced with Agile practices 68 N/A Final RTM RTM Template Replaced with Jira outputs 69 N/A Test Readiness Review I (TRR I) and Minutes TRR I Procedure Replaced with final Release Integration feature testing with Product Owner and Stakeholders applying \u2018Minimum Viable Product\u2019 criteria. 70 \u2714 Lessons Learned Lessons Learned, Good Practices, Opportunities and Assistance Procedure AAM contractor.","title":"ENGINEERING AND MANUFACTURING DEVELOPMENT PHASE"},{"location":"modern/11-4-worksheet/#engineering-and-manufacturing-development-iteration-end","text":"Row No. \u2714, * or N/A Product References Justification for Tailoring 71 N/A ITR for IDT&E (includes both CV&I and Qualification Test and Evaluation (QT&E)) ITR Template QT&E Procedure Replaced by Production Release Validation activities: government UAT and Security Testing; User Training; Knowledge Transfer; Data Migration and Cutover 72 \u2714 Functional Configuration Audit (FCA) Report FCA Procedure AAM contractor. 73 N/A Operational Test Readiness Review (OTRR) and Minutes OTRR Procedure Replaced by Agile practices 74 N/A Updated CARD Replaced by Story Point estimates in Product Backlog (t-shirt sizing) and Sprint Backlog (planning poker estimation) 75 \u2714 Program Office Estimate (POE) Government PMO. 76 \u2714 Component Cost Assessment (CCA) Government PMO. 77 \u2714 Independent Cost Estimate (ICE) Government PMO. 78 \u2714 Title 40/Clinger-Cohen Act (CCA) Compliance and Component Chief Information Officer (CIO) Confirmation (for all Information Technology (IT)) See AFMAN 17-1402 Government PMO. 79 \u2714 Title 40/Clinger-Cohen Act (CCA) Department of Defense (DoD) CIO Confirmation (for Major Defense Acquisition Programs (MDAPs) and Major Automated Information Systems (MAIS)) See AFMAN 17-1402 Government PMO. 80 \u2714 Updated Programmatic Environment, Safety and Occupational Health Evaluation (PESHE) Government PMO. 81 \u2714 Updated National Environmental Policy Act (NEPA) Compliance Schedule (as required) Government PMO. 82 \u2714 Updated Defense Business System Certification and approval (if required) Government PMO. 83 N/A Engineering Go/No-Go Recommendation Memorandum Engineering Go/No-Go Recommendation Procedure Engineering Go/No-Go Recommendation Memorandum Template Replaced by Agile contract practices. 84 N/A ADM for Milestone C Replaced by Agile contract practices. 85 N/A Test Report for Operational Test and Evaluation (OT&E) (Conducted by the Operational Test Organization (OTO) as Documented in the TEMP or LCMP) Legacy App in Sustainment undergoing modernization. 86 N/A Physical Configuration Audit (PCA) Report App is hosted in the Cloud 87 N/A Operational Safety, Suitability, and Effectiveness (OSS&E) Baseline Document (OBD) (This OBD applies only to the first release of a new system. Subsequent OBDs are prepared annually.) Operational Safety, Suitability, and Effectiveness (OSS&E) Baseline Document (OBD) Template App is hosted in the Cloud 88 N/A Economic Analysis (MAIS only) Legacy App modernized for Cloud hosting 89 N/A Acquisition Strategy Technology Development Strategy/Acquisition Strategy Sample Outline Air Force Implementation of New OSD Templates Pre-Award Acquisition Strategy (AS) and Request for Proposal (RFP) Development Process Legacy App modernized for Cloud hosting 90 N/A Analysis of Alternatives (AoA) (MAIS only) AoA Study Plan Template Legacy App modernized for Cloud hosting 91 N/A Acquisition Strategy Plan (ASP) Acquisition Strategy Plan (ASP) Template - ACAT Acquisition Strategy Plan (ASP) Template Non-ACAT Legacy App modernized for Cloud hosting 92 N/A Draft Request for Information (RFI) (optional) for the Operations & Support Phase Contact the Contracting Function for Assistance Legacy App modernized for Cloud hosting 93 N/A Source Selection Plan Contact the Contracting Function for Assistance Legacy App modernized for Cloud hosting 94 N/A Draft Request for Proposal (RFP) for the Operations & Support Phase Contact the Contracting Function for Assistance Legacy App modernized for Cloud hosting 95 N/A Quick Pass and Acquisition Strategy Panel Review and Minutes Contact the Contracting Function for Assistance Legacy App modernized for Cloud hosting 96 N/A Final RFP for the Operations & Support Phase Contact the Contracting Function for Assistance Legacy App modernized for Cloud hosting 97 N/A Engineering Go/No-Go Recommendation Memorandum Engineering Go/No-Go Recommendation Procedure Engineering Go/No-Go Recommendation Memorandum Template Legacy App modernized for Cloud hosting","title":"Engineering and Manufacturing Development Iteration \u2013 End"},{"location":"modern/11-4-worksheet/#decision-point-full-deployment-decision-fdd-refer-to-the-fdd-procedure","text":"Row No. \u2714, * or N/A Product References Justification for Tailoring 98 N/A Updated PPP Document Streamlining - PPP Legacy App modernized for Cloud hosting 99 N/A ADM for FDDR ADM Template Legacy App modernized for Cloud hosting 100 N/A Lessons Learned Lessons Learned, Good Practices, Opportunities and Assistance Procedure Legacy App modernized for Cloud hosting 101 N/A Source Selection Decision Document (SSDD) Contact the Contracting Function for Assistance Legacy App modernized for Cloud hosting","title":"Decision Point \u2013 Full Deployment Decision (FDD) (Refer to the FDD Procedure)"},{"location":"modern/11-4-worksheet/#operations-support-phase","text":"Row No. \u2714, * or N/A Product References Justification for Tailoring 102 * Updated Stakeholder List Stakeholder Identification and Assessment Template Government PMO. 103 \u2714 Release Request Letter Release Request Letter and Instructions Form AAM Contractor. 104 \u2714 Version Description Document (VDD) VDD Form AAM Contractor. 105 \u2714 Release Turn-in Certification Form Release Turn-in Certification Form AAM Contractor. 106 N/A Installed System Hardware and Software System Installation Procedure Legacy App modernized for Cloud hosting 107 \u2714 Products from completed system training (i.e., trained customers, users, and Help Desk personnel; archived training materials; and completed training critiques) System Training Procedure Provided prior to Cutover","title":"OPERATIONS &amp; SUPPORT PHASE"},{"location":"modern/11-4-worksheet/#begin-customer-support-process","text":"Row No. \u2714, * or N/A Product References Justification for Tailoring 108 N/A IBR and Minutes (if required) IBR Procedure Replaced by Agile practices and metrics. 109 \u2714 Products from continual customer support (i.e., resolved customer requests, Deficiency Reports (DRs), maintained Problem Management System database, and required or requested reports) Continual Customer Support Procedure Government PMO and Post production sustainment support contractor. 110 \u2714 In-Service Review (ISR) and Minutes In-Service Review Government PMO. 111 \u2714 Lessons Learned Lessons Learned, Good Practices, Opportunities and Assistance Procedure Government PMO.","title":"Begin Customer Support Process"},{"location":"modern/2-1-intro/","text":"2.1 Introduction In April 2016, Air Force (AF) Logistics (A4) published the \u201cUS Air Force Enterprise Logistics Flight Plan v2.0\u201d (ELFP) and a subordinate document titled the \u201cEnterprise Logistics Technology Annex\u201d (ELTA) was published in June 2016. This plan and annex describe the 2035 future state of AF Enterprise Logistics \u201csynthesized logistics information\u201d. To achieve the longer-term ELFP and ELTA goals, a series of enabling initiatives was defined to achieve necessary foundational near-term milestones. The \u201cEnterprise Logistics IT (ELIT) Automated Application Modernization (AAM) Playbook Chapter\u201d is one of these initiatives. Automated Application Modernization (AAM) applies automated tools to efficiently transform proprietary, closed legacy applications and systems into modern applications, aligned with current AF standards, and hosted on open platforms that enable technical integration and interoperability with other authorized applications. Further, modernized applications, if modernized correctly, should be more secure, easier to upgrade, componentize, functionally modernize, share information with, integrate easier with third-party products (such as reporting tools), and less expensive to maintain and operate. The Automated Application Modernization Playbook Chapter will provide the Air Force (AF) with approaches and methodologies to convert, transform, and migrate legacy systems to modern, open, standards-based platforms using AF standard programming languages such as Java and Microsoft C#.NET. For example, the modernization of the AF Logistics Standard Base Supply System (SBSS), that provided a major set of application functionality for Integrated Logistics System \u2013 Supply (ILS-S), was converted from a UNISYS 2200-based COBOL application to a well-designed RHEL-based Java application. This project provided many benefits including: an open system Architecture Runway, cost reduction, technical improvements, improved user experience, and improved mission integration. This Playbook Chapter leverages this experience, and others, to create a set of plays that can be applied to modernize a wide variety of applications.","title":"2.1 Introduction"},{"location":"modern/2-1-intro/#21-introduction","text":"In April 2016, Air Force (AF) Logistics (A4) published the \u201cUS Air Force Enterprise Logistics Flight Plan v2.0\u201d (ELFP) and a subordinate document titled the \u201cEnterprise Logistics Technology Annex\u201d (ELTA) was published in June 2016. This plan and annex describe the 2035 future state of AF Enterprise Logistics \u201csynthesized logistics information\u201d. To achieve the longer-term ELFP and ELTA goals, a series of enabling initiatives was defined to achieve necessary foundational near-term milestones. The \u201cEnterprise Logistics IT (ELIT) Automated Application Modernization (AAM) Playbook Chapter\u201d is one of these initiatives. Automated Application Modernization (AAM) applies automated tools to efficiently transform proprietary, closed legacy applications and systems into modern applications, aligned with current AF standards, and hosted on open platforms that enable technical integration and interoperability with other authorized applications. Further, modernized applications, if modernized correctly, should be more secure, easier to upgrade, componentize, functionally modernize, share information with, integrate easier with third-party products (such as reporting tools), and less expensive to maintain and operate. The Automated Application Modernization Playbook Chapter will provide the Air Force (AF) with approaches and methodologies to convert, transform, and migrate legacy systems to modern, open, standards-based platforms using AF standard programming languages such as Java and Microsoft C#.NET. For example, the modernization of the AF Logistics Standard Base Supply System (SBSS), that provided a major set of application functionality for Integrated Logistics System \u2013 Supply (ILS-S), was converted from a UNISYS 2200-based COBOL application to a well-designed RHEL-based Java application. This project provided many benefits including: an open system Architecture Runway, cost reduction, technical improvements, improved user experience, and improved mission integration. This Playbook Chapter leverages this experience, and others, to create a set of plays that can be applied to modernize a wide variety of applications.","title":"2.1 Introduction"},{"location":"modern/2-2-problem/","text":"2.2 Problem Statement The AF has many legacy and outdated systems that collectively are comprised of tens of millions of source lines of code (SLOC). Many of these legacy and outdated systems are on proprietary and \u201cclosed\u201d platforms (mainframe and client/server) that prevent functions (business logic) and data contained within them from being readily accessed, integrated or interoperated with, extended or improved. These systems contain valuable, business-critical logic and data that drive the AF and support numerous missions. This functionality needs to be unlocked so it can be used in conjunction with the other AF applications to improve business and mission effectiveness. Other issues with the AF\u2019s legacy applications and systems include: poor cyber posture, current platform and language limitations, poor user experiences and user interfaces, poor performance, difficult to find labor skills for legacy technologies, expensive hosting platforms and difficult to modernize.","title":"2.2 Problem Statement"},{"location":"modern/2-2-problem/#22-problem-statement","text":"The AF has many legacy and outdated systems that collectively are comprised of tens of millions of source lines of code (SLOC). Many of these legacy and outdated systems are on proprietary and \u201cclosed\u201d platforms (mainframe and client/server) that prevent functions (business logic) and data contained within them from being readily accessed, integrated or interoperated with, extended or improved. These systems contain valuable, business-critical logic and data that drive the AF and support numerous missions. This functionality needs to be unlocked so it can be used in conjunction with the other AF applications to improve business and mission effectiveness. Other issues with the AF\u2019s legacy applications and systems include: poor cyber posture, current platform and language limitations, poor user experiences and user interfaces, poor performance, difficult to find labor skills for legacy technologies, expensive hosting platforms and difficult to modernize.","title":"2.2 Problem Statement"},{"location":"modern/2-3-purpose/","text":"2.3 Purpose This AAM Playbook Chapter is a continuation of effort by the BES PEO to establish modern practices and methods to accelerate software development and deployment of value for Logistics Information Systems, Business Systems and its end users. Preceded by playbooks for Agile and Automated Testing, and User Experience, this playbook aims to provide approaches, methods, and tools to apply automation to efficiently modernize legacy applications. Once legacy applications are modernized to the AF standard, the value of the business logic and data can be much more easily be shared with other applications increasing the completeness and accuracy of information and, ultimately, improving mission effectiveness. This Playbook Chapter serves as a \u201cliving document,\u201d delivering value in the present while providing a foundation for future updates and enhancements as the state of technology and the needs of stakeholders and users served by Logistics Information Systems continually evolve.","title":"2.3 Purpose"},{"location":"modern/2-3-purpose/#23-purpose","text":"This AAM Playbook Chapter is a continuation of effort by the BES PEO to establish modern practices and methods to accelerate software development and deployment of value for Logistics Information Systems, Business Systems and its end users. Preceded by playbooks for Agile and Automated Testing, and User Experience, this playbook aims to provide approaches, methods, and tools to apply automation to efficiently modernize legacy applications. Once legacy applications are modernized to the AF standard, the value of the business logic and data can be much more easily be shared with other applications increasing the completeness and accuracy of information and, ultimately, improving mission effectiveness. This Playbook Chapter serves as a \u201cliving document,\u201d delivering value in the present while providing a foundation for future updates and enhancements as the state of technology and the needs of stakeholders and users served by Logistics Information Systems continually evolve.","title":"2.3 Purpose"},{"location":"modern/2-4-scope/","text":"2.4 Scope The AAM Playbook Chapter describes approaches and methods to apply automation to modernize legacy applications and systems from their current platform and language to a sustainable platforms and language that can be more readily improved, integrated and interfaced with. Prescriptive requirements are described that can be incorporated into the PMO\u2019s application modernization PWS Section 3 - Description of Services which sets forth the AAM Activity and Task requirements. This playbook chapter includes: Application Modernization Guidance Limitations of Automated Modernization Organizational Support Requirements and Lessons Architectural Standard for Application Modernization Modernization Tools Modernization Approaches and Methods Application Modernization Factory Concept of Operations (CONOPs) Conclusions and Recommendations","title":"2.4 Scope"},{"location":"modern/2-4-scope/#24-scope","text":"The AAM Playbook Chapter describes approaches and methods to apply automation to modernize legacy applications and systems from their current platform and language to a sustainable platforms and language that can be more readily improved, integrated and interfaced with. Prescriptive requirements are described that can be incorporated into the PMO\u2019s application modernization PWS Section 3 - Description of Services which sets forth the AAM Activity and Task requirements. This playbook chapter includes: Application Modernization Guidance Limitations of Automated Modernization Organizational Support Requirements and Lessons Architectural Standard for Application Modernization Modernization Tools Modernization Approaches and Methods Application Modernization Factory Concept of Operations (CONOPs) Conclusions and Recommendations","title":"2.4 Scope"},{"location":"modern/2-5-audience/","text":"2.5 Audience While this playbook can provide value to all personnel involved in a software modernization project, the primary audience for this playbook are those individuals who are responsible for the planning, management and development of projects that employ or might benefit from automated application modernization approaches and methodologies. For program managers and those in similar roles, this playbook will provide a foundation of knowledge to enable more effective planning and support for programs where automated application modernization methodologies might be employed. For software engineers and those in similar roles, this playbook will provide a valuable resource for design patterns and guidelines from which legacy applications can be efficiently modernized, enabling faster design decisions and more rapid deployment while ensuring consistency and quality across all digital experiences delivered by Logistics Information Systems.","title":"2.5 Audience"},{"location":"modern/2-5-audience/#25-audience","text":"While this playbook can provide value to all personnel involved in a software modernization project, the primary audience for this playbook are those individuals who are responsible for the planning, management and development of projects that employ or might benefit from automated application modernization approaches and methodologies. For program managers and those in similar roles, this playbook will provide a foundation of knowledge to enable more effective planning and support for programs where automated application modernization methodologies might be employed. For software engineers and those in similar roles, this playbook will provide a valuable resource for design patterns and guidelines from which legacy applications can be efficiently modernized, enabling faster design decisions and more rapid deployment while ensuring consistency and quality across all digital experiences delivered by Logistics Information Systems.","title":"2.5 Audience"},{"location":"modern/2-6-benefits/","text":"2.6 Benefits The AAM Playbook Chapter provides the following benefits and provides a foundation of an enduring AF application modernization practice: Efficiently Modernizes AF Legacy applications to a current AF standard (for example the AF CCE application standard) so they can interoperate with other modern AF applications Drives down sustainment costs by moving to more affordable software and hosting solutions Provides an Automated Application Modernization Approach and Methods to transform AF applications Identifies potential organizational, non-technical dependencies or barriers and how to mitigate them Provides examples of several successful modernization projects (and, to contrast, several example projects that were not successful) Provides a listing of proven automated modernization tools and how to use them. Could become basis for application modernization \u201cAssembly Line\u201d or Center of Excellence (CoE). For applications: lower sustainment and upgrade costs, easier to maintain and improve, easier to integrate with apps/data, easier to rationalize","title":"2.6 Benefits"},{"location":"modern/2-6-benefits/#26-benefits","text":"The AAM Playbook Chapter provides the following benefits and provides a foundation of an enduring AF application modernization practice: Efficiently Modernizes AF Legacy applications to a current AF standard (for example the AF CCE application standard) so they can interoperate with other modern AF applications Drives down sustainment costs by moving to more affordable software and hosting solutions Provides an Automated Application Modernization Approach and Methods to transform AF applications Identifies potential organizational, non-technical dependencies or barriers and how to mitigate them Provides examples of several successful modernization projects (and, to contrast, several example projects that were not successful) Provides a listing of proven automated modernization tools and how to use them. Could become basis for application modernization \u201cAssembly Line\u201d or Center of Excellence (CoE). For applications: lower sustainment and upgrade costs, easier to maintain and improve, easier to integrate with apps/data, easier to rationalize","title":"2.6 Benefits"},{"location":"modern/3-0-overview/","text":"3. Automated Application Modernization AAM is a system and software engineering approach that uses automated tools to efficiently modernize applications. AAM relies on software baseline configuration discovery tools, software code and database conversion tools, and re-platforming tools to perform the actual application software transformation. For these tools to produce high quality results, functional and technical subject matter experts must work together to ensure the translation rules are properly identified and included in the AAM tools.","title":"3.0 Overview"},{"location":"modern/3-0-overview/#3-automated-application-modernization","text":"AAM is a system and software engineering approach that uses automated tools to efficiently modernize applications. AAM relies on software baseline configuration discovery tools, software code and database conversion tools, and re-platforming tools to perform the actual application software transformation. For these tools to produce high quality results, functional and technical subject matter experts must work together to ensure the translation rules are properly identified and included in the AAM tools.","title":"3. Automated Application Modernization"},{"location":"modern/3-1-guidance/","text":"3.1 Guidance AAM is commonly used when an application portfolio owner needs to keep a legacy application in service and the application requires an overhaul to comply with DoD and Air Force consolidation, technical, cyber, and other requirements. In the AF, functional domain portfolio application rationalization has led to identification of applications that need consolidation, rehost, refactor, redevelopment, retirement, and so on. When an application is identified for transformation through the rationalization process, AAM should be considered as a solution option","title":"3.1 Guidance"},{"location":"modern/3-1-guidance/#31-guidance","text":"AAM is commonly used when an application portfolio owner needs to keep a legacy application in service and the application requires an overhaul to comply with DoD and Air Force consolidation, technical, cyber, and other requirements. In the AF, functional domain portfolio application rationalization has led to identification of applications that need consolidation, rehost, refactor, redevelopment, retirement, and so on. When an application is identified for transformation through the rationalization process, AAM should be considered as a solution option","title":"3.1 Guidance"},{"location":"modern/3-10-limitations/","text":"3.10 Limitations Using automated tools to transform and modernize legacy applications requires domain Functional SME technical expert support to provide the proper transformation inputs to the tools so expected results are achieved. Solving some legacy technical challenges will require a separate focus and specialized tools. For example, migrating legacy database structures, data, stored procedures, triggers and other advanced database functionality will require technical and functional data experts and specialized tools to accomplish the database modernization and migration.","title":"3.10 Limitations"},{"location":"modern/3-10-limitations/#310-limitations","text":"Using automated tools to transform and modernize legacy applications requires domain Functional SME technical expert support to provide the proper transformation inputs to the tools so expected results are achieved. Solving some legacy technical challenges will require a separate focus and specialized tools. For example, migrating legacy database structures, data, stored procedures, triggers and other advanced database functionality will require technical and functional data experts and specialized tools to accomplish the database modernization and migration.","title":"3.10 Limitations"},{"location":"modern/3-2-standards/","text":"3.2 Standards Before the project begins, it is necessary to identify the functional, data, interoperability, and technical standards that will be used for the modernized application. These standards constrain the possible solutions and ensures the final selected solution will align with DoD and AF IT standards and direction. Standards related to modernization include: PEO BES BPD best practices , PEO BES and AF DevOps processes and tools (DevSecOps, Automated Release Process, Automated Testing, and CI/CD pipelines), AF Common Computing Environment (AF CCE) application architectures and standards, and other AF enterprise and IEEE standards as applicable to specific IT modernization projects. The AF has been evolving to some application standards, although a single standard does not exist. The following table provides some Architecture Runway technologies commonly used within the AF. (Also see AF CCE\u2019s technology standards.) Category Commonly Used Technology Operating Systems Windows, Linux Programming Languages Java, C# Databases Oracle RDBMS, SQL Server, Cloud DBaaS Cloud Environments AWS, Azure","title":"3.2 Standards"},{"location":"modern/3-2-standards/#32-standards","text":"Before the project begins, it is necessary to identify the functional, data, interoperability, and technical standards that will be used for the modernized application. These standards constrain the possible solutions and ensures the final selected solution will align with DoD and AF IT standards and direction. Standards related to modernization include: PEO BES BPD best practices , PEO BES and AF DevOps processes and tools (DevSecOps, Automated Release Process, Automated Testing, and CI/CD pipelines), AF Common Computing Environment (AF CCE) application architectures and standards, and other AF enterprise and IEEE standards as applicable to specific IT modernization projects. The AF has been evolving to some application standards, although a single standard does not exist. The following table provides some Architecture Runway technologies commonly used within the AF. (Also see AF CCE\u2019s technology standards.) Category Commonly Used Technology Operating Systems Windows, Linux Programming Languages Java, C# Databases Oracle RDBMS, SQL Server, Cloud DBaaS Cloud Environments AWS, Azure","title":"3.2 Standards"},{"location":"modern/3-3-common/","text":"3.3 Common Use Case Within the AF, it has become common to refactor and migrate applications from older, more expensive, on-premise hosting environments into the commercial cloud using the AF CCE and other environments (refer to the latest AF CCE documentation for details). The mission of AF CCE is to migrate applications to the cloud and comply with technical requirements. The AF CCE performs enough technical application refactoring, so the application will technically operate in the AF CCE cloud environment (AWS or Azure). AF CCE\u2019s initial strategy was to start by refactoring and migrating simpler applications first (those that require less refactoring and transformation) and then build on their success and lessons learned to tackle more complex legacy application refactoring and migrations. The AF CCE does not perform refactoring beyond what is required to migrate the application to one of the AF CCE environments (currently AWS and Azure). This means that in general AF CCE will not perform code conversion transformations, database transformations, functional improvements, and so on (unless required for migration). Before any AAM project is undertaken, the application PMO should consult with the AF CCE PMO to understand what they can do for your application in terms of refactoring, modernization, and migration. Also, it is important to understand which PMO will pay for which activities, tasks, architectural components (e.g. the DISA SCCA security tier), and solution development and deployment tools. Application PMO\u2019s should consider what it makes sense for AF CCE to do, and when, so the application modernization project goals are achieved. More complex legacy application modernization projects, include mainframe applications, those using older coding languages, those using older or specialized client server/hardware or operating systems require a modernization project to transform the application from its legacy state to a desired modern state. An example of a project that applied AAM to transform an application is the PEO BES AF Logistics project that transformed the AF Standard Base Supply System (SBSS) to the AF Integrated Logistics System \u2013 Supply (ILS-S). The SBSS transformation consisted of a series of projects that led to a transformed state and a refactored state. Looking at SBSS to ILS-S from a broad perspective over time, the legacy AF SBSS was a complex UNISYS 2200-based COBOL application running in DISA DECC, through the series of projects this application was re-factored into the ILS-S which is now an improved Java application that runs on the X86 platform and is being migrated into AF CCE\u2019s AWS GovCloud. Another example is the AF Integrated Maintenance Data System (IMDS), using a simpler approach, which is currently being refactored and re-platformed from a UNISYS 2200 Mainframe, UNISYS COBOL application hosted in DISA DECC to a Windows Server operating system-based Microfocus COBOL application running in AF CCE\u2019s Azure Government cloud on native Azure SQL Database. Both the ILS-S and IMDS modernization examples were driven by AF domain needs and a portfolio application rationalization assessment. The AF determined, at the point of time when decisions were made, that ILS-S needed a more complete overhaul, while IMDS would best benefit by re-platforming the application.","title":"3.3 Common Use Case"},{"location":"modern/3-3-common/#33-common-use-case","text":"Within the AF, it has become common to refactor and migrate applications from older, more expensive, on-premise hosting environments into the commercial cloud using the AF CCE and other environments (refer to the latest AF CCE documentation for details). The mission of AF CCE is to migrate applications to the cloud and comply with technical requirements. The AF CCE performs enough technical application refactoring, so the application will technically operate in the AF CCE cloud environment (AWS or Azure). AF CCE\u2019s initial strategy was to start by refactoring and migrating simpler applications first (those that require less refactoring and transformation) and then build on their success and lessons learned to tackle more complex legacy application refactoring and migrations. The AF CCE does not perform refactoring beyond what is required to migrate the application to one of the AF CCE environments (currently AWS and Azure). This means that in general AF CCE will not perform code conversion transformations, database transformations, functional improvements, and so on (unless required for migration). Before any AAM project is undertaken, the application PMO should consult with the AF CCE PMO to understand what they can do for your application in terms of refactoring, modernization, and migration. Also, it is important to understand which PMO will pay for which activities, tasks, architectural components (e.g. the DISA SCCA security tier), and solution development and deployment tools. Application PMO\u2019s should consider what it makes sense for AF CCE to do, and when, so the application modernization project goals are achieved. More complex legacy application modernization projects, include mainframe applications, those using older coding languages, those using older or specialized client server/hardware or operating systems require a modernization project to transform the application from its legacy state to a desired modern state. An example of a project that applied AAM to transform an application is the PEO BES AF Logistics project that transformed the AF Standard Base Supply System (SBSS) to the AF Integrated Logistics System \u2013 Supply (ILS-S). The SBSS transformation consisted of a series of projects that led to a transformed state and a refactored state. Looking at SBSS to ILS-S from a broad perspective over time, the legacy AF SBSS was a complex UNISYS 2200-based COBOL application running in DISA DECC, through the series of projects this application was re-factored into the ILS-S which is now an improved Java application that runs on the X86 platform and is being migrated into AF CCE\u2019s AWS GovCloud. Another example is the AF Integrated Maintenance Data System (IMDS), using a simpler approach, which is currently being refactored and re-platformed from a UNISYS 2200 Mainframe, UNISYS COBOL application hosted in DISA DECC to a Windows Server operating system-based Microfocus COBOL application running in AF CCE\u2019s Azure Government cloud on native Azure SQL Database. Both the ILS-S and IMDS modernization examples were driven by AF domain needs and a portfolio application rationalization assessment. The AF determined, at the point of time when decisions were made, that ILS-S needed a more complete overhaul, while IMDS would best benefit by re-platforming the application.","title":"3.3 Common Use Case"},{"location":"modern/3-4-approaches/","text":"3.4 Migration Approaches 6 Application Migration Strategies: \u201cThe 6 R\u2019s\u201d (adapted from: https://aws.amazon.com/blogs/enterprise-strategy/6-strategies-for-migrating-applications-to-the-cloud/ ) The 6 most common application migration strategies we see are: 1. Rehosting \u200a\u2014\u200aAlso known as \u201clift-and-shift.\u201d Many early cloud projects gravitate toward net new development using cloud-native capabilities, but in a large legacy migration scenario where the organization is looking to scale its migration quickly to meet a business case, we find that most applications are rehosted. GE Oil & Gas, for instance, found that, even without implementing any cloud optimizations, it could save roughly 30 percent of its costs by rehosting. Most rehosting can be automated with tools (e.g. AWS VM Import/Export, Racemi), although some customers prefer to do this manually as they learn how to apply their legacy systems to the new cloud platform. We\u2019ve also found that applications are easier to optimize/re-architect once they\u2019re already running in the cloud. Partly because your organization will have developed better skills to do so, and partly because the hard part\u200a\u2014\u200amigrating the application, data, and traffic\u200a\u2014\u200ahas already been done. 2. Re-platforming \u200a\u2014\u200aSometimes referred to as \u201clift-tinker-and-shift.\u201d Here you might make a few cloud (or other) optimizations to achieve some tangible benefit, but y ou aren\u2019t otherwise changing the core architecture of the application. You may be looking to reduce the amount of time you spend managing database instances by migrating to a database-as-a-service platform like Amazon Relational Database Service (Amazon RDS) or migrating your application to a fully managed platform like Amazon Elastic Beanstalk. A large media company we work with migrated hundreds of web servers it ran on-premises to AWS, and, in the process, it moved from WebLogic (a Java application container that requires an expensive license) to Apache Tomcat, an open-source equivalent. This media company saved millions in licensing costs on top of the savings and agility it gained by migrating to AWS. 3. Repurchasing \u200a\u2014\u200aMoving to a different product. Most commonly repurchasing is used to move to a SaaS platform. Moving a CRM to Salesforce.com, an HR system to Workday, a CMS to Drupal, and so on. 4. Refactoring / Re-architecting \u200a\u2014\u200aRe-imagining how the application is architected and developed, typically using cloud-native features. This is typically driven by a strong business need to add features, scale, or performance that would otherwise be difficult to achieve in the application\u2019s existing environment. Are you looking to migrate from a monolithic architecture to a service-oriented (or server-less) architecture to boost agility or improve business continuity (I\u2019ve heard stories of mainframe fan belts being ordered on e-bay)? This pattern tends to be the most expensive, but, if you have a good product-market fit, it can also be the most beneficial. 5. Retire\u200a \u2014\u200aDecommission and dispose of. Once you\u2019ve discovered everything in your environment, you might ask each functional area who owns each application. We\u2019ve found that as much as 10% (I\u2019ve seen 20%) of an enterprise IT portfolio is no longer useful and can simply be turned off. These savings can boost the business case, direct your team\u2019s scarce attention to the things that people use, and lessen the surface area you must secure. 6. Retain \u200a\u2014\u200aUsually this means \u201crevisit\u201d or do nothing (for now). Maybe you\u2019re still riding out some depreciation, aren\u2019t ready to prioritize an application that was recently upgraded or are otherwise not inclined to migrate some applications. You should only migrate what makes sense for the business; and, as the gravity of your portfolio changes from on-premises to the cloud, you\u2019ll probably have fewer reasons to retain. AAM mostly focuses on Migration Approach #4: Refactoring / Re-architecting legacy systems, but also is relevant to Migration Approach #2: Re-platforming. [image here] Figure 3-1: Six most common application migration strategies. Excerpted from AWS Migration Whitepaper, AWS Professional Services, March 2018.","title":"3.4 Approaches"},{"location":"modern/3-4-approaches/#34-migration-approaches","text":"","title":"3.4 Migration Approaches"},{"location":"modern/3-4-approaches/#6-application-migration-strategies-the-6-rs","text":"(adapted from: https://aws.amazon.com/blogs/enterprise-strategy/6-strategies-for-migrating-applications-to-the-cloud/ ) The 6 most common application migration strategies we see are:","title":"6 Application Migration Strategies: \u201cThe 6 R\u2019s\u201d"},{"location":"modern/3-4-approaches/#1-rehosting-also-known-as-lift-and-shift","text":"Many early cloud projects gravitate toward net new development using cloud-native capabilities, but in a large legacy migration scenario where the organization is looking to scale its migration quickly to meet a business case, we find that most applications are rehosted. GE Oil & Gas, for instance, found that, even without implementing any cloud optimizations, it could save roughly 30 percent of its costs by rehosting. Most rehosting can be automated with tools (e.g. AWS VM Import/Export, Racemi), although some customers prefer to do this manually as they learn how to apply their legacy systems to the new cloud platform. We\u2019ve also found that applications are easier to optimize/re-architect once they\u2019re already running in the cloud. Partly because your organization will have developed better skills to do so, and partly because the hard part\u200a\u2014\u200amigrating the application, data, and traffic\u200a\u2014\u200ahas already been done.","title":"1. Rehosting\u200a\u2014\u200aAlso known as \u201clift-and-shift.\u201d"},{"location":"modern/3-4-approaches/#2-re-platforming-sometimes-referred-to-as-lift-tinker-and-shift","text":"Here you might make a few cloud (or other) optimizations to achieve some tangible benefit, but y ou aren\u2019t otherwise changing the core architecture of the application. You may be looking to reduce the amount of time you spend managing database instances by migrating to a database-as-a-service platform like Amazon Relational Database Service (Amazon RDS) or migrating your application to a fully managed platform like Amazon Elastic Beanstalk. A large media company we work with migrated hundreds of web servers it ran on-premises to AWS, and, in the process, it moved from WebLogic (a Java application container that requires an expensive license) to Apache Tomcat, an open-source equivalent. This media company saved millions in licensing costs on top of the savings and agility it gained by migrating to AWS.","title":"2. Re-platforming\u200a\u2014\u200aSometimes referred to as \u201clift-tinker-and-shift.\u201d"},{"location":"modern/3-4-approaches/#3-repurchasing-moving-to-a-different-product","text":"Most commonly repurchasing is used to move to a SaaS platform. Moving a CRM to Salesforce.com, an HR system to Workday, a CMS to Drupal, and so on.","title":"3. Repurchasing\u200a\u2014\u200aMoving to a different product."},{"location":"modern/3-4-approaches/#4-refactoring-re-architecting-re-imagining-how-the-application-is-architected-and-developed-typically-using-cloud-native-features","text":"This is typically driven by a strong business need to add features, scale, or performance that would otherwise be difficult to achieve in the application\u2019s existing environment. Are you looking to migrate from a monolithic architecture to a service-oriented (or server-less) architecture to boost agility or improve business continuity (I\u2019ve heard stories of mainframe fan belts being ordered on e-bay)? This pattern tends to be the most expensive, but, if you have a good product-market fit, it can also be the most beneficial.","title":"4. Refactoring / Re-architecting\u200a\u2014\u200aRe-imagining how the application is architected and developed, typically using cloud-native features."},{"location":"modern/3-4-approaches/#5-retire-decommission-and-dispose-of","text":"Once you\u2019ve discovered everything in your environment, you might ask each functional area who owns each application. We\u2019ve found that as much as 10% (I\u2019ve seen 20%) of an enterprise IT portfolio is no longer useful and can simply be turned off. These savings can boost the business case, direct your team\u2019s scarce attention to the things that people use, and lessen the surface area you must secure.","title":"5. Retire\u200a\u2014\u200aDecommission and dispose of."},{"location":"modern/3-4-approaches/#6-retain-usually-this-means-revisit-or-do-nothing-for-now","text":"Maybe you\u2019re still riding out some depreciation, aren\u2019t ready to prioritize an application that was recently upgraded or are otherwise not inclined to migrate some applications. You should only migrate what makes sense for the business; and, as the gravity of your portfolio changes from on-premises to the cloud, you\u2019ll probably have fewer reasons to retain. AAM mostly focuses on Migration Approach #4: Refactoring / Re-architecting legacy systems, but also is relevant to Migration Approach #2: Re-platforming. [image here] Figure 3-1: Six most common application migration strategies. Excerpted from AWS Migration Whitepaper, AWS Professional Services, March 2018.","title":"6. Retain\u200a\u2014\u200aUsually this means \u201crevisit\u201d or do nothing (for now)."},{"location":"modern/3-5-methodologies/","text":"3.5 Methodologies Once it has been determined by the application owner that the application needs to be modernized by refactoring and/or re-architecting to meet requirements or regulations, there are several methodologies to consider: Agile Methodology (SAFe): See Chapter 5 \u2013 Software Life Cycle Processes Application Analysis and Assessment: Before undertaking any AAM project, ensure the application is fully analyzed and understood. This is necessary to make decisions about how to proceed with the design of the application\u2019s future state and how to achieve the required future state: Use a Discovery tool to document the configuration of the production application and system Use a tool such as Silver Thread to determine the quality and identify the shortcomings of the application and system architecture Automated Code Conversion: Automated Code Conversion is a type of refactoring that transforms an existing code baseline into a new and improved code baseline. This approach can be used for many scenarios. Basically, the legacy code is converted to a desired language. For example, COBOL to Java. Automated Code Conversion can also be used to improve a current code baseline. For example, Java to refactored Java. Note: Automated Code Conversion converts the code to a new code baseline. The database, interfaces, etc must be dealt with as well so the application works properly post code conversion. Underlying application architecture issues will persist if not directly addressed as part of the code conversion. Re-platforming: Re-platforming is a type of refactoring that simply migrates an application from one platform to another. This is usually done to get off legacy platform and onto modern cloud type platforms. Re-platforming moves an application from one platform to another. For example, consider moving an application off the GCSS-AF platform to a cloud provided Platform as a Service (PaaS). In this example, the application may be migrated to a new operating system (ie: Solaris to Linux), the application\u2019s database may be migrated from on-premise hosted Oracle RDBMS to a cloud Database as a Service (DBaaS). Methodology Benefits Drawbacks Agile Methodology (SAFe) - Provides an Agile contracts acquisition approach that implements iterative, timeboxed Agile development methodologies of Scrum, Kanban and XP. - Requires specialized SAFe training to support Agile Teams, programs, and Program Portfolio Management. Application Analysis and Assessment - Provides true view of application and challenges - Takes time (~4 - 8 weeks) - Requires specialized Discovery tools and skills Automated Code Conversion - Retains and reuses valuable legacy business logic -Use iterative conversions to improve code baseline and app architecture - Does not address underlying app architecture issues, deeper refactoring required Re-Platforming - Migrate to new platform quickly -Perhaps migrate to cloud -Likely reduce cost via migration to cloud and use of \u201cas-a-services\u201d - Only re-platforms application, additional refactoring is required to correct architectural and other defects","title":"3.5 Methodologies"},{"location":"modern/3-5-methodologies/#35-methodologies","text":"Once it has been determined by the application owner that the application needs to be modernized by refactoring and/or re-architecting to meet requirements or regulations, there are several methodologies to consider:","title":"3.5 Methodologies"},{"location":"modern/3-5-methodologies/#agile-methodology-safe","text":"See Chapter 5 \u2013 Software Life Cycle Processes","title":"Agile Methodology (SAFe):"},{"location":"modern/3-5-methodologies/#application-analysis-and-assessment","text":"Before undertaking any AAM project, ensure the application is fully analyzed and understood. This is necessary to make decisions about how to proceed with the design of the application\u2019s future state and how to achieve the required future state: Use a Discovery tool to document the configuration of the production application and system Use a tool such as Silver Thread to determine the quality and identify the shortcomings of the application and system architecture","title":"Application Analysis and Assessment:"},{"location":"modern/3-5-methodologies/#automated-code-conversion","text":"Automated Code Conversion is a type of refactoring that transforms an existing code baseline into a new and improved code baseline. This approach can be used for many scenarios. Basically, the legacy code is converted to a desired language. For example, COBOL to Java. Automated Code Conversion can also be used to improve a current code baseline. For example, Java to refactored Java. Note: Automated Code Conversion converts the code to a new code baseline. The database, interfaces, etc must be dealt with as well so the application works properly post code conversion. Underlying application architecture issues will persist if not directly addressed as part of the code conversion.","title":"Automated Code Conversion:"},{"location":"modern/3-5-methodologies/#re-platforming","text":"Re-platforming is a type of refactoring that simply migrates an application from one platform to another. This is usually done to get off legacy platform and onto modern cloud type platforms. Re-platforming moves an application from one platform to another. For example, consider moving an application off the GCSS-AF platform to a cloud provided Platform as a Service (PaaS). In this example, the application may be migrated to a new operating system (ie: Solaris to Linux), the application\u2019s database may be migrated from on-premise hosted Oracle RDBMS to a cloud Database as a Service (DBaaS). Methodology Benefits Drawbacks Agile Methodology (SAFe) - Provides an Agile contracts acquisition approach that implements iterative, timeboxed Agile development methodologies of Scrum, Kanban and XP. - Requires specialized SAFe training to support Agile Teams, programs, and Program Portfolio Management. Application Analysis and Assessment - Provides true view of application and challenges - Takes time (~4 - 8 weeks) - Requires specialized Discovery tools and skills Automated Code Conversion - Retains and reuses valuable legacy business logic -Use iterative conversions to improve code baseline and app architecture - Does not address underlying app architecture issues, deeper refactoring required Re-Platforming - Migrate to new platform quickly -Perhaps migrate to cloud -Likely reduce cost via migration to cloud and use of \u201cas-a-services\u201d - Only re-platforms application, additional refactoring is required to correct architectural and other defects","title":"Re-platforming:"},{"location":"modern/3-6-patterns/","text":"3.6 Patterns Microservices: The microservice architectural style is an approach to developing a single application as a suite of small services, each running in its own process and communicating with lightweight mechanisms, often an HTTP resource API. These services are built around business capabilities and independently deployable by fully automated deployment machinery. There is a bare minimum of centralized management of these services, which may be written in different programming languages and use different data storage technologies. (-Martin Fowler) Microservices are both an architecture and an approach to writing software. With microservices, applications are broken down into their smallest components, independent from each other. Instead of a traditional, monolithic, approach to apps, where everything is built into a single piece, microservices are all separated and work together to accomplish the same tasks. Each of these components, or processes, is a microservice. This approach to software development values granularity, being lightweight, and the ability to share similar process across multiple apps. It is a major component of optimizing application development towards a cloud-native model. Why use a microservice-based infrastructure? The goal is, simply put, to deliver quality software, faster. Using microservices is a means to that end, but there are other considerations too. Breaking your apps into microservices isn\u2019t enough, you've got to manage them, orchestrate them, and deal with the data they create and modify. (adapted from: https://www.redhat.com/en/topics/microservices) Strangler Pattern: This is an evolutionary pattern for modernization a legacy application where elements of the application or system are incrementally or iteratively replaced with new components. This is done until the entire application is basically modernized. Incrementally migrate a legacy system by gradually replacing specific pieces of functionality with new applications and services. As features from the legacy system are replaced, the new system eventually replaces all the old system's features, strangling the old system and allowing you to decommission it.","title":"3.6 Patterns"},{"location":"modern/3-6-patterns/#36-patterns","text":"","title":"3.6 Patterns"},{"location":"modern/3-6-patterns/#microservices","text":"The microservice architectural style is an approach to developing a single application as a suite of small services, each running in its own process and communicating with lightweight mechanisms, often an HTTP resource API. These services are built around business capabilities and independently deployable by fully automated deployment machinery. There is a bare minimum of centralized management of these services, which may be written in different programming languages and use different data storage technologies. (-Martin Fowler) Microservices are both an architecture and an approach to writing software. With microservices, applications are broken down into their smallest components, independent from each other. Instead of a traditional, monolithic, approach to apps, where everything is built into a single piece, microservices are all separated and work together to accomplish the same tasks. Each of these components, or processes, is a microservice. This approach to software development values granularity, being lightweight, and the ability to share similar process across multiple apps. It is a major component of optimizing application development towards a cloud-native model. Why use a microservice-based infrastructure? The goal is, simply put, to deliver quality software, faster. Using microservices is a means to that end, but there are other considerations too. Breaking your apps into microservices isn\u2019t enough, you've got to manage them, orchestrate them, and deal with the data they create and modify. (adapted from: https://www.redhat.com/en/topics/microservices)","title":"Microservices:"},{"location":"modern/3-6-patterns/#strangler-pattern","text":"This is an evolutionary pattern for modernization a legacy application where elements of the application or system are incrementally or iteratively replaced with new components. This is done until the entire application is basically modernized. Incrementally migrate a legacy system by gradually replacing specific pieces of functionality with new applications and services. As features from the legacy system are replaced, the new system eventually replaces all the old system's features, strangling the old system and allowing you to decommission it.","title":"Strangler Pattern:"},{"location":"modern/3-7-barriers/","text":"3.7 Barriers and Challenges Ensure AF senior stakeholders agree on the application\u2019s future. This should be an outcome of the AF domain portfolio application rationalization assessment process. Ensure AF senior stakeholders agree on the required (and desired) outcomes for the modernization project. Ensure this is clearly and concisely documented and communicated to stakeholders. Ensure the application baseline is accurately documented. It is best to use an auto discovery tool against the existing production application to create a model of the application. At a minimum, ensure the application code, database, interfaces, network constructs, and cyber/identity and access management mechanisms are documented and understood.","title":"3.7 Barriers and Challenges"},{"location":"modern/3-7-barriers/#37-barriers-and-challenges","text":"Ensure AF senior stakeholders agree on the application\u2019s future. This should be an outcome of the AF domain portfolio application rationalization assessment process. Ensure AF senior stakeholders agree on the required (and desired) outcomes for the modernization project. Ensure this is clearly and concisely documented and communicated to stakeholders. Ensure the application baseline is accurately documented. It is best to use an auto discovery tool against the existing production application to create a model of the application. At a minimum, ensure the application code, database, interfaces, network constructs, and cyber/identity and access management mechanisms are documented and understood.","title":"3.7 Barriers and Challenges"},{"location":"modern/3-8-recommendations/","text":"3.8 Recommendations Ensure AF senior stakeholders agree on the application\u2019s future. This should be an outcome of the AF domain portfolio application rationalization assessment process. Ensure AF senior stakeholders agree on the required (and desired) outcomes for the modernization project. Ensure this is clearly and concisely documented and communicated to stakeholders. Ensure the application baseline is accurately documented. It is best to use an auto discovery tool against the existing production application to create a model of the application. At a minimum, ensure the application code, database, interfaces, network constructs, and cyber/identity and access management mechanisms are documented and understood.","title":"3.8 Recommendations"},{"location":"modern/3-8-recommendations/#38-recommendations","text":"Ensure AF senior stakeholders agree on the application\u2019s future. This should be an outcome of the AF domain portfolio application rationalization assessment process. Ensure AF senior stakeholders agree on the required (and desired) outcomes for the modernization project. Ensure this is clearly and concisely documented and communicated to stakeholders. Ensure the application baseline is accurately documented. It is best to use an auto discovery tool against the existing production application to create a model of the application. At a minimum, ensure the application code, database, interfaces, network constructs, and cyber/identity and access management mechanisms are documented and understood.","title":"3.8 Recommendations"},{"location":"modern/3-9-lessons/","text":"3.9 Lessons Using proof of concepts for critical complex project steps greatly increases probability of project success. Proof of concepts should be intentionally included in the overall project plan and schedule. Application owners are driven by functional requirements and may not be able to take the time to perform the AAM project. Application owners are driven to deliver functional capabilities to users and keep the application solution technically viable and as free as possible from technical debt. This causes application modernizations to require a series of projects where technical improvements are performed with functional releases.","title":"3.9 Lessons"},{"location":"modern/3-9-lessons/#39-lessons","text":"Using proof of concepts for critical complex project steps greatly increases probability of project success. Proof of concepts should be intentionally included in the overall project plan and schedule. Application owners are driven by functional requirements and may not be able to take the time to perform the AAM project. Application owners are driven to deliver functional capabilities to users and keep the application solution technically viable and as free as possible from technical debt. This causes application modernizations to require a series of projects where technical improvements are performed with functional releases.","title":"3.9 Lessons"},{"location":"modern/4-1-tooltypes/","text":"4.1 Tool Types The types of Computer Aided Software Engineering (CASE) tools that will be needed during an AAM project are described below. Automated Application Modernization (AAM) Tools: Code Conversion: Converts code from one language to another (ie: COBOL to Java) Refactoring: Converts existing code to best practice code (ie: older C# to improved and remodeled C#) Re-platforming: Moves an application from one operating environment to another (ie: Solaris or HP-UX to Linux) Database Connectors Enabling Tools: Baseline Configuration Discovery Tools (Discovery) Baseline Health and Quality (Quality) DevOps, DevSecOps, CI/CD Tools (DevOps) Automated Test Tools (AT) Static and Dynamic Application Security Test Tools Performance Testing Tools","title":"4.1 Tool Types"},{"location":"modern/4-1-tooltypes/#41-tool-types","text":"The types of Computer Aided Software Engineering (CASE) tools that will be needed during an AAM project are described below.","title":"4.1 Tool Types"},{"location":"modern/4-1-tooltypes/#automated-application-modernization-aam-tools","text":"Code Conversion: Converts code from one language to another (ie: COBOL to Java) Refactoring: Converts existing code to best practice code (ie: older C# to improved and remodeled C#) Re-platforming: Moves an application from one operating environment to another (ie: Solaris or HP-UX to Linux) Database Connectors","title":"Automated Application Modernization (AAM) Tools:"},{"location":"modern/4-1-tooltypes/#enabling-tools","text":"Baseline Configuration Discovery Tools (Discovery) Baseline Health and Quality (Quality) DevOps, DevSecOps, CI/CD Tools (DevOps) Automated Test Tools (AT) Static and Dynamic Application Security Test Tools Performance Testing Tools","title":"Enabling Tools:"},{"location":"modern/4-2-toolmatrix/","text":"4.2 Tool Matrix The following tools represent some of the better tools available in the market. This list is not comprehensive, there are many software improvement tools available. Tool Vendor Tool Type Used in AF? Description BMC Helix Discovery BMC Discovery Not known Discovers configurations and dependencies in on-premise and cloud environments. ServiceNow Discovery ServiceNow Discovery Not known Discovers configurations and dependencies in on-premise and cloud environments. Micro Focus Universal Discovery & CMDB Micro Focus Discovery Not known More than 180 out-of-the-box discovery patterns and Configuration Management Database (CMDB) for application assessment and rationalization Janus Suite TSRI AAM Yes, on SBSS to ILS-S transformation (UNISYS COBOL to RHEL/Java in AWS) Converts many legacy languages to many popular languages. Capable of automated refactoring. CTU (COBOL to Universal) Modern Systems AAM Not known Converts COBOL to many popular languages. Micro Focus Code Conversion Micro Focus AAM Yes, for IMDS conversion from UNISYS COBOL to Microfocus COBOL in Azure Converts COBOL to many popular languages. Asysco Migration Technology (AMT) Asysco AAM Not known Converts UNISYS COBOL to C#/VB.NET and the legacy file system or database to SQL Server Astadia XGEN and OpenMCS Astadia AAM Not known Mainframe Cloud Framework for AWS with Rules-Based Transformation Engine for COBOL, XGEN code conversion to Java, C#. ResQSoft Engineer ResQSoft AAM Not known Code conversion and automated baseline improvement. HP ALM & UFT HP AT Yes, PEO BES standard Automated Testing JUnit Open Source AT Yes, ILS-S Automated Unit Testing Framework for Java NUnit Open Source AT Not Known Automated Unit Testing Framework for .NET Selenium Open Source AT Yes, ILS-S Automated Testing Framework Cucumber Open source AT Yes, ILS-S Automated Testing approach which supports Behavior Driven Development (BDD) AF CCE Suite Atlassian DevOps Yes, for AF CCE applications. Provides Jira and Confluence Agile project work management DevOps solution. CodeMRI Silver Thread Code Quality Yes Examines the health and quality of a code baseline. Application Intelligence Platform (AIP) CAST Code and system quality Currently used in AFLCMC/HIA with expected expansion to all of BES Examines source code quality including data linkages to modules and database. Also produces and helps enforce an architecture model.","title":"4.2 Tool Matrix"},{"location":"modern/4-2-toolmatrix/#42-tool-matrix","text":"The following tools represent some of the better tools available in the market. This list is not comprehensive, there are many software improvement tools available. Tool Vendor Tool Type Used in AF? Description BMC Helix Discovery BMC Discovery Not known Discovers configurations and dependencies in on-premise and cloud environments. ServiceNow Discovery ServiceNow Discovery Not known Discovers configurations and dependencies in on-premise and cloud environments. Micro Focus Universal Discovery & CMDB Micro Focus Discovery Not known More than 180 out-of-the-box discovery patterns and Configuration Management Database (CMDB) for application assessment and rationalization Janus Suite TSRI AAM Yes, on SBSS to ILS-S transformation (UNISYS COBOL to RHEL/Java in AWS) Converts many legacy languages to many popular languages. Capable of automated refactoring. CTU (COBOL to Universal) Modern Systems AAM Not known Converts COBOL to many popular languages. Micro Focus Code Conversion Micro Focus AAM Yes, for IMDS conversion from UNISYS COBOL to Microfocus COBOL in Azure Converts COBOL to many popular languages. Asysco Migration Technology (AMT) Asysco AAM Not known Converts UNISYS COBOL to C#/VB.NET and the legacy file system or database to SQL Server Astadia XGEN and OpenMCS Astadia AAM Not known Mainframe Cloud Framework for AWS with Rules-Based Transformation Engine for COBOL, XGEN code conversion to Java, C#. ResQSoft Engineer ResQSoft AAM Not known Code conversion and automated baseline improvement. HP ALM & UFT HP AT Yes, PEO BES standard Automated Testing JUnit Open Source AT Yes, ILS-S Automated Unit Testing Framework for Java NUnit Open Source AT Not Known Automated Unit Testing Framework for .NET Selenium Open Source AT Yes, ILS-S Automated Testing Framework Cucumber Open source AT Yes, ILS-S Automated Testing approach which supports Behavior Driven Development (BDD) AF CCE Suite Atlassian DevOps Yes, for AF CCE applications. Provides Jira and Confluence Agile project work management DevOps solution. CodeMRI Silver Thread Code Quality Yes Examines the health and quality of a code baseline. Application Intelligence Platform (AIP) CAST Code and system quality Currently used in AFLCMC/HIA with expected expansion to all of BES Examines source code quality including data linkages to modules and database. Also produces and helps enforce an architecture model.","title":"4.2 Tool Matrix"},{"location":"modern/5-0-overview/","text":"5. Software Life Cycle Processes The BES BPD provides a directory of standardized life cycle management processes, templates, guides, forms and checklists artifacts the BES PMOs can apply to their acquisition projects. However, these standardized processes have not kept pace with the rapidly evolving changes in systems and software engineering and preferred Agile development methodologies. To simplify selection of the life cycle processes needed for AAM project contract acquisitions, the IEEE 12207:2017 Systems and software engineering\u2014Software life cycle processes standard is the recommended for BES PMOs to adopt as best practices. Many current Air Force PMOs currently use the IEEE 12207 standard in their application software development acquisitions to define their required life cycle processes in the Performance Work Statement (PWS). This is because IEEE 12207:2017 has evolved to address changes in systems and software engineering, including: Internet, big data, software as a service, the cloud, virtual systems Highly complex integrated systems of systems Software construction through object-oriented, encapsulated, containerized methods Different ways of implementing software vs one-off custom/contract SW development (i.e, COTS integration, use of open source, native cloud services, microservices). Using iterative, continuous, concurrent processes and methods (i.e. Agile, Continuous Integration (CI), test-driven development) Automation of software application development methods and tools (i.e. automated application modernization, integrated development environments, test automation frameworks) Continuous Delivery (CD) release methods (i.e. DevSecOps) Organizations that are aspire to be highly agile and responsive to customer dynamics complete more of their projects successfully than their slower-moving counterparts \u2014 64 percent versus 49 percent, thus, \u201cAgile\u201d methods actually can be applied within a variety of life cycle models. While Agile methods are common in executing an \u201cevolutionary\u201d life cycle model, they can be used in other life cycle models such as the \u201citerative development\u201d model at various stages. What the Agile methods have in common is an emphasis on continuous inspection and collaboration in the rapid production of working software in an environment where changes, including changes to requirements, are expected (See the Playbooks Website: https://arraybesplaybooks.github.io/ArrayBESPlaybook/ maintained by Isobar). The 12207:2017 software life cycle processes describe the activities that can be performed during the life cycle of a software system into four process groups. Each of the life cycle processes within those groups is described in terms of its purpose and desired outcomes with a set of related activities and tasks that can be performed to achieve those outcomes. The four process groups and the software life cycle processes included in each group are depicted in Figure 5-1 . These recommended IEEE 12207:2017 life cycle processes are not intended to preclude or discourage the use of additional processes that organizations find useful (i.e. BES BPD, CMMI-DEV and ITIL v3 processes) nor to determine the order in which the processes are performed during the system life cycle or any of its stages. The intent is to focus the life cycle processes used in an AAM acquisition to the minimum set required for AAM project success. These processes will be reflected in the BES BPD Tailoring Worksheet for AAM Projects Template which will be an Appendix to this document and can be used by PMOs to quickly develop their acquisition PWS Description of Services and required CDRL artifacts focused on an Agile contract acquisition. Figure 5-1. Software Life Cycle Processes (Excerpted from IEEE 12207:2017) A description of each process group is excerpted from IEEE 12207:2017 and rephrased as follows (Full descriptions of each life cycle process activities, tasks and outcomes is described in the IEEE 12207 standard):","title":"5.0 Overview"},{"location":"modern/5-0-overview/#5-software-life-cycle-processes","text":"The BES BPD provides a directory of standardized life cycle management processes, templates, guides, forms and checklists artifacts the BES PMOs can apply to their acquisition projects. However, these standardized processes have not kept pace with the rapidly evolving changes in systems and software engineering and preferred Agile development methodologies. To simplify selection of the life cycle processes needed for AAM project contract acquisitions, the IEEE 12207:2017 Systems and software engineering\u2014Software life cycle processes standard is the recommended for BES PMOs to adopt as best practices. Many current Air Force PMOs currently use the IEEE 12207 standard in their application software development acquisitions to define their required life cycle processes in the Performance Work Statement (PWS). This is because IEEE 12207:2017 has evolved to address changes in systems and software engineering, including: Internet, big data, software as a service, the cloud, virtual systems Highly complex integrated systems of systems Software construction through object-oriented, encapsulated, containerized methods Different ways of implementing software vs one-off custom/contract SW development (i.e, COTS integration, use of open source, native cloud services, microservices). Using iterative, continuous, concurrent processes and methods (i.e. Agile, Continuous Integration (CI), test-driven development) Automation of software application development methods and tools (i.e. automated application modernization, integrated development environments, test automation frameworks) Continuous Delivery (CD) release methods (i.e. DevSecOps) Organizations that are aspire to be highly agile and responsive to customer dynamics complete more of their projects successfully than their slower-moving counterparts \u2014 64 percent versus 49 percent, thus, \u201cAgile\u201d methods actually can be applied within a variety of life cycle models. While Agile methods are common in executing an \u201cevolutionary\u201d life cycle model, they can be used in other life cycle models such as the \u201citerative development\u201d model at various stages. What the Agile methods have in common is an emphasis on continuous inspection and collaboration in the rapid production of working software in an environment where changes, including changes to requirements, are expected (See the Playbooks Website: https://arraybesplaybooks.github.io/ArrayBESPlaybook/ maintained by Isobar). The 12207:2017 software life cycle processes describe the activities that can be performed during the life cycle of a software system into four process groups. Each of the life cycle processes within those groups is described in terms of its purpose and desired outcomes with a set of related activities and tasks that can be performed to achieve those outcomes. The four process groups and the software life cycle processes included in each group are depicted in Figure 5-1 . These recommended IEEE 12207:2017 life cycle processes are not intended to preclude or discourage the use of additional processes that organizations find useful (i.e. BES BPD, CMMI-DEV and ITIL v3 processes) nor to determine the order in which the processes are performed during the system life cycle or any of its stages. The intent is to focus the life cycle processes used in an AAM acquisition to the minimum set required for AAM project success. These processes will be reflected in the BES BPD Tailoring Worksheet for AAM Projects Template which will be an Appendix to this document and can be used by PMOs to quickly develop their acquisition PWS Description of Services and required CDRL artifacts focused on an Agile contract acquisition. Figure 5-1. Software Life Cycle Processes (Excerpted from IEEE 12207:2017) A description of each process group is excerpted from IEEE 12207:2017 and rephrased as follows (Full descriptions of each life cycle process activities, tasks and outcomes is described in the IEEE 12207 standard):","title":"5. Software Life Cycle Processes"},{"location":"modern/5-1-best/","text":"5.1 Agreement Processes The PEO BES PMOs are producers of software application systems on behalf of users. The PMOs (acting as an acquirer) can task contractors (acting as a supplier) for products or services. This is achieved using agreements (i.e. Task Order Contracts). Agreements allow both acquirers and suppliers to realize value and support business strategies for their organizations. The Agreement processes are organizational acquisition processes defined in the PEO BES Business Process directory (BPD) that apply outside of the span of a project\u2019s life, as well as for a project\u2019s lifespan. Figure 5-1 lists the processes contained in this process group.","title":"5.1 Agreement Processes"},{"location":"modern/5-1-best/#51-agreement-processes","text":"The PEO BES PMOs are producers of software application systems on behalf of users. The PMOs (acting as an acquirer) can task contractors (acting as a supplier) for products or services. This is achieved using agreements (i.e. Task Order Contracts). Agreements allow both acquirers and suppliers to realize value and support business strategies for their organizations. The Agreement processes are organizational acquisition processes defined in the PEO BES Business Process directory (BPD) that apply outside of the span of a project\u2019s life, as well as for a project\u2019s lifespan. Figure 5-1 lists the processes contained in this process group.","title":"5.1 Agreement Processes"},{"location":"modern/5-2-organizational/","text":"5.2 Organizational Project-enabling Processes The Organizational Project\u2010Enabling processes are concerned with providing the resources to enable the project to meet the needs and expectations of the PEO BES PMO organization\u2019s stakeholders. The Organizational Project\u2010Enabling processes are typically concerned at a strategic level with the management and improvement of the organization\u2019s business or undertaking, with the provision and deployment of resources and assets, and with its management of risks in competitive or uncertain situations. The Organizational Project\u2010Enabling processes are defined in the PEO BES BPD and apply outside the span of a project\u2019s life, as well as during a project\u2019s lifespan. The Organizational Project\u2010Enabling processes establish the environment in which projects are conducted. The PEO BES PMOs establishes the processes and life cycle models to be tailored for use by projects; establishes, redirects, or cancels projects; provides resources required, including human and financial; and sets and monitors the quality measures for software systems and other deliverables that are developed by projects for internal and external customers. Figure 5-1 lists the processes contained in this process group.","title":"5.2 Organizational Project-enabling Processes"},{"location":"modern/5-2-organizational/#52-organizational-project-enabling-processes","text":"The Organizational Project\u2010Enabling processes are concerned with providing the resources to enable the project to meet the needs and expectations of the PEO BES PMO organization\u2019s stakeholders. The Organizational Project\u2010Enabling processes are typically concerned at a strategic level with the management and improvement of the organization\u2019s business or undertaking, with the provision and deployment of resources and assets, and with its management of risks in competitive or uncertain situations. The Organizational Project\u2010Enabling processes are defined in the PEO BES BPD and apply outside the span of a project\u2019s life, as well as during a project\u2019s lifespan. The Organizational Project\u2010Enabling processes establish the environment in which projects are conducted. The PEO BES PMOs establishes the processes and life cycle models to be tailored for use by projects; establishes, redirects, or cancels projects; provides resources required, including human and financial; and sets and monitors the quality measures for software systems and other deliverables that are developed by projects for internal and external customers. Figure 5-1 lists the processes contained in this process group.","title":"5.2 Organizational Project-enabling Processes"},{"location":"modern/5-3-techmanage/","text":"5.3 Technical Management Processes The Technical Management processes are concerned with managing the resources and assets allocated by organization management and with applying them to fulfill the agreements into which the organization or organizations enter. The Technical Management processes relate to the technical effort of projects, in particular to project planning in terms of cost, schedule and outcome achievements, to the assessment of actions to help ensure that they comply with plans and performance criteria and to the identification and selection of corrective actions that recover shortfalls in progress and achievement. These processes are used to establish and perform technical plans for the project, manage information across the technical team, assess technical progress against the plans for the software system, products, or services, control technical tasks through to completion, and aid in decision\u2010making. NOTE 1: Technical management is \u2018the application of technical and administrative resources to plan, organize and control engineering functions\u2019. Typically, several projects will co\u2010exist in any one organization. The Technical Management processes can be employed at a corporate level to meet internal needs. Figure 5-1 lists the processes contained in this process group. NOTE 2: Technical Management processes are applied during the performance of each Technical process.","title":"5.3 Technical Management processes"},{"location":"modern/5-3-techmanage/#53-technical-management-processes","text":"The Technical Management processes are concerned with managing the resources and assets allocated by organization management and with applying them to fulfill the agreements into which the organization or organizations enter. The Technical Management processes relate to the technical effort of projects, in particular to project planning in terms of cost, schedule and outcome achievements, to the assessment of actions to help ensure that they comply with plans and performance criteria and to the identification and selection of corrective actions that recover shortfalls in progress and achievement. These processes are used to establish and perform technical plans for the project, manage information across the technical team, assess technical progress against the plans for the software system, products, or services, control technical tasks through to completion, and aid in decision\u2010making. NOTE 1: Technical management is \u2018the application of technical and administrative resources to plan, organize and control engineering functions\u2019. Typically, several projects will co\u2010exist in any one organization. The Technical Management processes can be employed at a corporate level to meet internal needs. Figure 5-1 lists the processes contained in this process group. NOTE 2: Technical Management processes are applied during the performance of each Technical process.","title":"5.3 Technical Management Processes"},{"location":"modern/5-4-tech/","text":"5.4 Technical processes The Technical processes are concerned with technical actions throughout the life cycle. Technical processes transform the needs of stakeholders into a product or service. By applying that product or operating that service, technical processes, provide sustainable performance, when and where needed in order to meet the stakeholder requirements and achieve customer satisfaction. The Technical processes are applied in order to create and use a software system, whether it is in the form of a model or is an operational product. The Technical processes apply at any level in a hierarchy of software system structure and at any stage in the life cycle. Figure 5-1 lists the processes contained in this process group.","title":"5.4 Technical Processes"},{"location":"modern/5-4-tech/#54-technical-processes","text":"The Technical processes are concerned with technical actions throughout the life cycle. Technical processes transform the needs of stakeholders into a product or service. By applying that product or operating that service, technical processes, provide sustainable performance, when and where needed in order to meet the stakeholder requirements and achieve customer satisfaction. The Technical processes are applied in order to create and use a software system, whether it is in the form of a model or is an operational product. The Technical processes apply at any level in a hierarchy of software system structure and at any stage in the life cycle. Figure 5-1 lists the processes contained in this process group.","title":"5.4 Technical processes"},{"location":"modern/5-5-application/","text":"5.5 Process Application The life cycle processes defined in IEEE 12207:2017 and excerpted herein can be used by PEO BES PMOs when acquiring, using, creating, or supplying a software system. They can be applied at any level in a system\u2019s hierarchy and at any stage in the life Cycle and specified in the acquisition PWS. The functions these processes perform are defined in terms of specific purposes, outcomes and the set of activities and tasks that constitute the process. It is beyond the scope of the Automated Application Modernization (AAM) Playbook to replicate the descriptions of theses software life cycle processes, their activities, tasks and outcomes, however, each life cycle process in Figure 5-1 can be invoked, as required, at any time throughout the Agile evolutionary and iterative life cycle models. The order that the processes are presented does not imply any prescriptive order in their use. However, sequential relationships are introduced by the definition of the Agile evolutionary and iterative life cycle models. The detailed purpose and timing of use of these processes throughout the life cycle are influenced by multiple factors, including PEO BES PMO\u2019s social, cultural, organizational and technical considerations, each of which can vary during the life of a software system. The Agile evolutionary lifecycle is thus created through a selection and application of processes that will normally possess concurrent, iterative, and time\u2010dependent characteristics. Concurrent use of processes often exists within a project (e.g., when design actions and preparatory actions for building a software system are performed at the same time), and between projects (e.g., when system elements are designed at the same time under different project responsibilities). When the application of the same process or set of processes is repeated on the same system, the application is referred to as iterative. The iterative use of processes is important for the progressive refinement of process outputs, e.g., the interaction between successive verification actions and integration actions can incrementally build confidence in the conformance of the product. Iteration is not only appropriate but also expected. New information is created by the application of a process or set of processes. Typically, this information takes the form of issues with respect to requirements, analyzed risks or opportunities that are tracked in the projects Application Life Cycle Management tool. Such issues can evolve into new user stories and tasks that are entered into the product backlog and should be resolved before completing the activities of a process or set of processes.","title":"5.5 Process Application"},{"location":"modern/5-5-application/#55-process-application","text":"The life cycle processes defined in IEEE 12207:2017 and excerpted herein can be used by PEO BES PMOs when acquiring, using, creating, or supplying a software system. They can be applied at any level in a system\u2019s hierarchy and at any stage in the life Cycle and specified in the acquisition PWS. The functions these processes perform are defined in terms of specific purposes, outcomes and the set of activities and tasks that constitute the process. It is beyond the scope of the Automated Application Modernization (AAM) Playbook to replicate the descriptions of theses software life cycle processes, their activities, tasks and outcomes, however, each life cycle process in Figure 5-1 can be invoked, as required, at any time throughout the Agile evolutionary and iterative life cycle models. The order that the processes are presented does not imply any prescriptive order in their use. However, sequential relationships are introduced by the definition of the Agile evolutionary and iterative life cycle models. The detailed purpose and timing of use of these processes throughout the life cycle are influenced by multiple factors, including PEO BES PMO\u2019s social, cultural, organizational and technical considerations, each of which can vary during the life of a software system. The Agile evolutionary lifecycle is thus created through a selection and application of processes that will normally possess concurrent, iterative, and time\u2010dependent characteristics. Concurrent use of processes often exists within a project (e.g., when design actions and preparatory actions for building a software system are performed at the same time), and between projects (e.g., when system elements are designed at the same time under different project responsibilities). When the application of the same process or set of processes is repeated on the same system, the application is referred to as iterative. The iterative use of processes is important for the progressive refinement of process outputs, e.g., the interaction between successive verification actions and integration actions can incrementally build confidence in the conformance of the product. Iteration is not only appropriate but also expected. New information is created by the application of a process or set of processes. Typically, this information takes the form of issues with respect to requirements, analyzed risks or opportunities that are tracked in the projects Application Life Cycle Management tool. Such issues can evolve into new user stories and tasks that are entered into the product backlog and should be resolved before completing the activities of a process or set of processes.","title":"5.5 Process Application"},{"location":"modern/5-6-agile/","text":"5.6 Application of Life Cycle Processes to Agile Evolutionary and Iterative Life Cycle Models A PEO BES PMOs Program Manager selects a system life cycle model (see the BES BPD Document N0. SWGD041 - System Development Life Cycle Methodologies Guide, 13 September 2017) based on the nature of the program and application, the methods and tools to be used, and the required controls and deliverable artifacts. The selected life cycle methodology is coordinated with the customer, stakeholders and senior management and is reflected in the acquisition PWS. PEO BES PMO organizations that adopt agile methods use the BPD Tailoring Worksheet (see Appendix A - Tailoring Worksheet for AAM Projects Template) to tailor the application of the life cycle processes identified in Figure 5-1 , including organizational, technical management, and technical processes. An example of a BPD Tailoring Worksheet Checklist for life cycle processes is provided in Appendix A. The sequence of the lifecycle processes is determined by project objectives and by selection of the Agile Framework (i.e. SAFe) and life cycle model (Scrum, Kanban, XP). An agile project, because it transforms or combines activities while creating or improving working software, will find it more appropriate to claim full conformance of the life cycle processes to outcomes rather than activities and tasks. Full conformance to outcomes is achieved by demonstrating that all of the outcomes of the declared set of IEEE 12207 life cycle processes in the PWS have been achieved. In AAM agile projects, the SAFe life cycle stages of concept exploration, development, construction, testing, transition, and retirement of legacy software can be performed concurrently for successive iterations. Agile projects perform re-planning concurrently with the activities mentioned above. During the Product Planning and Features Mapping in a Sprint 0 (see Figure 5-2 ), the product owner and stakeholders engage in release planning sessions to prioritize the Epics, Features and User Story items in the product backlog assigned to an AAM release. Then at the beginning of each sprint, the Development Team works with the Product Owner to refine User Stories, estimate their size, break them out into Tasks, and prioritize the Sprint Backlog. In Agile methods, re-planning is performed in release planning and sprint planning points between designated iterations (e.g., sprints or pre\u2010defined time\u2010boxed cadences) so that each of these iterations can be treated as a stage. Besides applying a highly iterative and evolutionary Agile life cycle model, the BES PMO adopting agile methods may have specific practices for the Project Planning and Project Assessment and Control processes (i.e. see Figure 5-2 - Evolutionary, Iterative Agile Development Life Cycle Model ) that are applicable to how they plan, schedule, monitor and control acquisition task order execution. Rather than establishing major control points at the transition between stages or processes, agile projects often hold less formal checkpoints or retrospective reviews at the end of a time\u2010boxed cycle to agree on improvements for the next cycle. Each iteration includes design, development, and test activities (test\u2010driven development). After a sprint of approximately four weeks or longer, new working software elements are accepted as \u201cdone\u201d \u2014 completely developed, verified (tested) and validated. Lessons learned and process improvements are identified, and work begins on another sprint. Continuing learning, risk management, and process improvement can be facilitated by continuous release planning and sprint planning meetings to perform backlog refinement that are initiated for each iteration and retrospective meetings held at the end of each iteration. Exhibit 5-2: Evolutionary, Iterative Agile Development Life Cycle Model. Agile methods emphasize the Stakeholder Needs and Requirements Definition process to facilitate change through a high degree of ongoing Product Owner and stakeholder involvement. In SAFe contract agile acquisition projects, key stakeholders, such as the PMO or Product Owners (user representatives), are not just approvers of information, measurements, and evaluation reports, they are involved in every technical process, including the BES BPD Tailoring Worksheet process at the beginning of the project. They are closely involved in requirements management, at each iteration, by bringing new requirements and changes in priorities and participating when prioritized requirements are selected from a product backlog of undeveloped features and user stories and further refined for development in Release Planning. The iterative approach encourages flexibility to add, reprioritize, or defer requirements which are recognized as being within the general scope of the project. Also, product owner and stakeholder involvement in the approval of tested software in each iteration means that validation is continual throughout the project. With the incremental definition of evolving requirements, the concept of project scope differs in an agile project from projects where scope is defined by a predetermined baseline of specified requirements. In Agile projects, defined product scope is initially tied to high\u2010level Epics and User Story fundamental requirements. More detailed levels of product definition are refined as additional knowledge is gained throughout construction. Agile level of effort work efforts may also control scope through time\u2010boxed schedules or resource\u2010limited teams. This approach is particularly appropriate for software maintenance efforts, where the extent or content of corrective or adaptive work is not fully specified initially. The preparation of specifications, design artifacts, and information items or documentation during AAM agile projects is often limited, while software developers apply their time and skills to transform a scenario or narrative of a function (\u201cuser story\u201d) into a working, testable software feature. Rather than preparing elaborate review packages for briefing at infrequent major milestone reviews, the team meets with the product owner and stakeholders frequently to present informal evidence of completing features (a set of user stories) and to agree on the content of the next iteration. Documented information items focus on what will be needed for transition, operation and maintenance, such as operator and end\u2010user documentation and baselines of tested and released versions of software with test automation plans, test cases, test scripts and cybersecurity artifacts. Projects reuse organizational procedures for configuration and release management, verification, and incident and problem management. Where possible, bidirectional traceability is enabled and enforced by integrated automated systems and procedures for requirements management, architecture and design, configuration management, and measurement that are approved by the PMO for use on the AAM project.","title":"5.6 Application of Life Cycle Processes to Agile Evolutionary and Iterative Life Cycle Models"},{"location":"modern/5-6-agile/#56-application-of-life-cycle-processes-to-agile-evolutionary-and-iterative-life-cycle-models","text":"A PEO BES PMOs Program Manager selects a system life cycle model (see the BES BPD Document N0. SWGD041 - System Development Life Cycle Methodologies Guide, 13 September 2017) based on the nature of the program and application, the methods and tools to be used, and the required controls and deliverable artifacts. The selected life cycle methodology is coordinated with the customer, stakeholders and senior management and is reflected in the acquisition PWS. PEO BES PMO organizations that adopt agile methods use the BPD Tailoring Worksheet (see Appendix A - Tailoring Worksheet for AAM Projects Template) to tailor the application of the life cycle processes identified in Figure 5-1 , including organizational, technical management, and technical processes. An example of a BPD Tailoring Worksheet Checklist for life cycle processes is provided in Appendix A. The sequence of the lifecycle processes is determined by project objectives and by selection of the Agile Framework (i.e. SAFe) and life cycle model (Scrum, Kanban, XP). An agile project, because it transforms or combines activities while creating or improving working software, will find it more appropriate to claim full conformance of the life cycle processes to outcomes rather than activities and tasks. Full conformance to outcomes is achieved by demonstrating that all of the outcomes of the declared set of IEEE 12207 life cycle processes in the PWS have been achieved. In AAM agile projects, the SAFe life cycle stages of concept exploration, development, construction, testing, transition, and retirement of legacy software can be performed concurrently for successive iterations. Agile projects perform re-planning concurrently with the activities mentioned above. During the Product Planning and Features Mapping in a Sprint 0 (see Figure 5-2 ), the product owner and stakeholders engage in release planning sessions to prioritize the Epics, Features and User Story items in the product backlog assigned to an AAM release. Then at the beginning of each sprint, the Development Team works with the Product Owner to refine User Stories, estimate their size, break them out into Tasks, and prioritize the Sprint Backlog. In Agile methods, re-planning is performed in release planning and sprint planning points between designated iterations (e.g., sprints or pre\u2010defined time\u2010boxed cadences) so that each of these iterations can be treated as a stage. Besides applying a highly iterative and evolutionary Agile life cycle model, the BES PMO adopting agile methods may have specific practices for the Project Planning and Project Assessment and Control processes (i.e. see Figure 5-2 - Evolutionary, Iterative Agile Development Life Cycle Model ) that are applicable to how they plan, schedule, monitor and control acquisition task order execution. Rather than establishing major control points at the transition between stages or processes, agile projects often hold less formal checkpoints or retrospective reviews at the end of a time\u2010boxed cycle to agree on improvements for the next cycle. Each iteration includes design, development, and test activities (test\u2010driven development). After a sprint of approximately four weeks or longer, new working software elements are accepted as \u201cdone\u201d \u2014 completely developed, verified (tested) and validated. Lessons learned and process improvements are identified, and work begins on another sprint. Continuing learning, risk management, and process improvement can be facilitated by continuous release planning and sprint planning meetings to perform backlog refinement that are initiated for each iteration and retrospective meetings held at the end of each iteration. Exhibit 5-2: Evolutionary, Iterative Agile Development Life Cycle Model. Agile methods emphasize the Stakeholder Needs and Requirements Definition process to facilitate change through a high degree of ongoing Product Owner and stakeholder involvement. In SAFe contract agile acquisition projects, key stakeholders, such as the PMO or Product Owners (user representatives), are not just approvers of information, measurements, and evaluation reports, they are involved in every technical process, including the BES BPD Tailoring Worksheet process at the beginning of the project. They are closely involved in requirements management, at each iteration, by bringing new requirements and changes in priorities and participating when prioritized requirements are selected from a product backlog of undeveloped features and user stories and further refined for development in Release Planning. The iterative approach encourages flexibility to add, reprioritize, or defer requirements which are recognized as being within the general scope of the project. Also, product owner and stakeholder involvement in the approval of tested software in each iteration means that validation is continual throughout the project. With the incremental definition of evolving requirements, the concept of project scope differs in an agile project from projects where scope is defined by a predetermined baseline of specified requirements. In Agile projects, defined product scope is initially tied to high\u2010level Epics and User Story fundamental requirements. More detailed levels of product definition are refined as additional knowledge is gained throughout construction. Agile level of effort work efforts may also control scope through time\u2010boxed schedules or resource\u2010limited teams. This approach is particularly appropriate for software maintenance efforts, where the extent or content of corrective or adaptive work is not fully specified initially. The preparation of specifications, design artifacts, and information items or documentation during AAM agile projects is often limited, while software developers apply their time and skills to transform a scenario or narrative of a function (\u201cuser story\u201d) into a working, testable software feature. Rather than preparing elaborate review packages for briefing at infrequent major milestone reviews, the team meets with the product owner and stakeholders frequently to present informal evidence of completing features (a set of user stories) and to agree on the content of the next iteration. Documented information items focus on what will be needed for transition, operation and maintenance, such as operator and end\u2010user documentation and baselines of tested and released versions of software with test automation plans, test cases, test scripts and cybersecurity artifacts. Projects reuse organizational procedures for configuration and release management, verification, and incident and problem management. Where possible, bidirectional traceability is enabled and enforced by integrated automated systems and procedures for requirements management, architecture and design, configuration management, and measurement that are approved by the PMO for use on the AAM project.","title":"5.6 Application of Life Cycle Processes to Agile Evolutionary and Iterative Life Cycle Models"},{"location":"modern/6-0-overview/","text":"6. Project Guidance Agile development methods are recommended for AAM projects. There are several key differences between the agile approach to project team organization and the traditional project team approach described in the BPD Roles and Project Organization Guide, dated 24 Sept 2018. Agile teams are \"whole teams\" that have sufficient skills within the team itself to perform agile AAM contracts successfully. The implication is that the AAM agile development team has the requisite development skills, language skills, user interface skills, integration skills and testing skills and does not rely on external experts or teams of experts to perform development sprints. There also has been significant training on SAFe for Government in HI which is still ongoing. This SAFe training is optimized for government organizations applying lean agile practices in a government project context and the training applies to the Full SAFe framework Portfolio, Large Solution, Program, and Teams organization principles. Organizations adopting the Full SAFe for Government agile contracts require a significant amount of training, which is out of the PMO\u2019s personnel training budget. Since not all PMOs would be amenable to paying for the needed SAFe training, in this AAM Playbooks section we drill down to the AAM project organization structure required to execute small and large AAM agile contract projects and describe the project functional roles in a less prescriptive PMO friendly manner that can be incorporated into a PMO\u2019s AAM agile contract acquisition PWS. In addition, we summarize the AAM project phases and work items that the PMOs can use for PWS Section 3 Requirements to populate the description of required activities and tasks. We then present typical risks to look for in an AAM project.","title":"6.0 Overview"},{"location":"modern/6-0-overview/#6-project-guidance","text":"Agile development methods are recommended for AAM projects. There are several key differences between the agile approach to project team organization and the traditional project team approach described in the BPD Roles and Project Organization Guide, dated 24 Sept 2018. Agile teams are \"whole teams\" that have sufficient skills within the team itself to perform agile AAM contracts successfully. The implication is that the AAM agile development team has the requisite development skills, language skills, user interface skills, integration skills and testing skills and does not rely on external experts or teams of experts to perform development sprints. There also has been significant training on SAFe for Government in HI which is still ongoing. This SAFe training is optimized for government organizations applying lean agile practices in a government project context and the training applies to the Full SAFe framework Portfolio, Large Solution, Program, and Teams organization principles. Organizations adopting the Full SAFe for Government agile contracts require a significant amount of training, which is out of the PMO\u2019s personnel training budget. Since not all PMOs would be amenable to paying for the needed SAFe training, in this AAM Playbooks section we drill down to the AAM project organization structure required to execute small and large AAM agile contract projects and describe the project functional roles in a less prescriptive PMO friendly manner that can be incorporated into a PMO\u2019s AAM agile contract acquisition PWS. In addition, we summarize the AAM project phases and work items that the PMOs can use for PWS Section 3 Requirements to populate the description of required activities and tasks. We then present typical risks to look for in an AAM project.","title":"6. Project Guidance"},{"location":"modern/6-1-project/","text":"6.1 Project Team AAM Agile project teams are formed from development specialists who are cross-trained on one or more technical specialties (e.g. system architecture, cybersecurity, automated code transformation, Java programming, SQL database development, continuous integration, automated testing ...) so that they can contribute to the team and they also have a general knowledge of the business domain in which they work. Agile teams are stable and program management understands that changing team structures; for example, this iteration Jeff is part of the development team but next iteration Jeff's pulled off to help another team, is detrimental to project success. Program Managers strive to keep teams as stable as possible. 6.1.1 Small Agile Project Teams Figure 5-3 overviews the structure of a small AAM agile team best suited for re-hosting (transform lite, lift and shift) projects. The Project Management leadership team and a team of developers, led by the team lead, works closely with a government PMO product owner and stakeholders to build high-quality working system features using iterative sprints with support on a just-in-time basis from the Engineering Support team members. Figure 5-3. Small agile Team organization Structure The small agile project team common agile roles are: Project Manager: on agile team projects, the project manager\u2019s tasks include: Project financials; Assessment, Measurement and Status reporting; Project governance; Change management; Identification of missing roles and/or resources; Business stakeholder communication; Risk communication and management; Project planning and scheduling and Quality Assurance. Development Team: There are several roles on the development team, which have different names depending on the methodology being followed, common to agile teams. Roles are not positions; any given person takes on one or more functional roles and can switch roles over time. The common agile development team roles are: Team lead/architecture owner. This role, called \u201cScrum Master\u201d in Scrum or team coach or project lead in other methods, is responsible for facilitating the team, obtaining resources for it, and protecting it from problems. This role encompasses the soft skills of project management but not the technical management ones such as: project planning, project assessment and control, decision management, measurement and quality assurance activities which are better left to the project manager as described above. Team member. This role, sometimes referred to as developer or programmer, is responsible for the creation and delivery of a system. This includes requirements, business analysis, design, programming, automated code transformation, code refactoring, testing, and release implementation activities, as well as others. Product Owner. The product owner represents the government stakeholders and provides the voice of the users. This is the one person who is responsible for a release prioritized work item list (called a product backlog in Scrum), for making decisions in a timely manner, and for providing information in a timely manner. The range of stakeholders a product owner represents is depicted in Figure 5-4 and is scaled to the AAM project size. Stakeholder. A stakeholder is anyone who is a direct user, indirect user, manager of users, senior manager, operations staff member, the \"PMO\" who funds the project, support (help desk) staff member, auditors, program/portfolio manager, and developers working on other systems that integrate or interact with the one under development, or maintenance professionals potentially affected by the development and/or deployment of a software project. Figure 5-4. Product Owner Represents a Large Range of Stakeholders. Engineering Support Team: The development team often requires technical specialists to help modernize, design, transform, build and refactor applications. The common Engineering Support Team roles are: Technical experts. The agile team needs the help of technical experts, such as: enterprise architects; cybersecurity engineers for RMF processes and cybersecurity static and dynamic application security testing; automated code transformation specialists; DBA\u2019s for database design; DevSecOps for CI/CD infrastructure and software builds; configuration management specialists to maintain CM, code version control and artifact repository; and automated testing experts to build test scripts. Technical experts are brought in on an as-needed, temporary basis, to help the team and to transfer their skills to one or more developers on the team. Functional SME experts. The product owner represents a wide range of stakeholders (see Figure 5-3 ), not just end users, and in practice it isn't reasonable to expect them to be experts at every single nuance in the business or mission domain. As a result the product owner will sometimes bring in Functional SMEs to work with the team, perhaps a supply expert to explain the details of a requirement or the sponsoring executive to explain the vision for the project. Independent tester. Effective agile teams often have an independent test team working integral to the team or in parallel that implements automated testing frameworks and automated testing tools and verifies and validates the agile development team\u2019s work throughout the development life cycle. 6.1.2 Large Agile Project Teams When the size of an AAM agile development team gets to be more than twenty, which may be required for a complex re-platform (transformation and refactor) project, program/project managers need to take a \u201cteam of teams\u201d approach. The strategy is to organize the larger team into a collection of smaller teams organized around the architecture of the system. Each subteam is responsible for one or more subsystems, enabling them to work as a small agile team responsible for delivering working software on a timely basis. Figure 5-5 describes the organization of large agile teams. Figure 5-5. Large agile Project Team The additional roles on agile teams at larger scale include: Architecture owner. This person is responsible for facilitating architectural decisions on a sub-team and is part of the architecture owner team which is responsible for the overall architectural runway direction of the project. The architecture owner leads their sub-team through initial architecture envisioning for their sub-systems and will be involved with the initial architecture envisioning for the system as a whole (as part of the architecture owner team, see description of activities below). Architecture owners are different than traditional architects in that they are not solely responsible for setting the architectural direction but instead facilitate its creation and evolution. DevSecOps integrator. The AAM agile subteams are typically responsible for one or more subsystems (i.e. applications modules and the database), and the larger the overall team generally the larger and more complicated the system being built. In these situations the overall AAM team assigns a DevSecOps Engineer in the role of integrator who is responsible for building the Development, Test, Staging and Production environments for the various subsystems. DevSecOps Engineers work closely with the internal or independent test team, who perform system integration and cybersecurity testing regularly throughout the project. As Figure 5-5 indicates, on large agile teams the Leadership Team needs to provide project governance and coordinate several critical activities: Scaled up Project management activities. At scale it isn\u2019t sufficient to simply focus on a project leadership team and allow self-organization to address the technical aspects of project management. This may work on the individual subteams, but across the entire program/project the technical aspects of project management, such as dependency management, contract management, resource tracking, and vendor management become critical. The program/project management team of Large AAM Agile Project Teams ( Figure 5-5 ) is comprised of the team leads from the various subteams. Their goal is to coordinate the management aspects of the overall team. This team holds a short coordination meeting each day, referred to as a \u201cscrum of scrums\u201d in the Scrum methodology, where current status is shared among the subteams and issues are identified. Technical/architectural activities. The architecture ownership team is comprised of the architecture owners from the subteams and is responsible for architecture envisioning at the beginning of the project to identify the initial technical direction and provide a basis for organizing the subteams. In the first week of the project (sometimes several weeks on more complex projects) their goal is to identify the subsystems and their interfaces, a strategy called \u201cVision and Product Portfolio Management\u201d which results in the development of the Architectural Runway. The Architectural Runway is the existing code components and technical infrastructure needed to implement near-term features without excessive redesign and delay. The purpose of the Architecture Runway is to reduce the coupling between subsystems and thereby reduce the amount of coordination required by subteams. Once the architectural layers and interfaces are well defined it is possible for the individual subteams to focus on implementing the AAM project applications of those subsystems. Enterprise Architects define architecture at the Portfolio Level, while at the subteam level, System and Solution Architects/Systems Engineering typically define architecture at the Program and Large Solution levels. The architects help provide the guidance needed to support the analysis, estimation, and implementation of the affected elements\u2014subsystems, components, functions, protocols, internal system functions\u2014to have the architecture necessary to support the near-term features and capabilities on the Product Roadmap. Throughout the project the architecture team will meet on a regular basis to share ideas and resolve technical issues, particularly those surrounding changes to the interfaces of subsystems. They may choose to meet daily, this is particularly common at the beginning of the project, but as the architecture stabilizes it is common to see them meet once or twice a week. Requirements/product ownership activities. The product ownership team is comprised of the product owners of each subteam and is responsible for coordinating the requirements effort across the subteams. They will need to negotiate requirements with the larger body of stakeholders whom they represent and apportion the requirements items among the subteams product backlogs appropriately. They\u2019ll also need to negotiate the inevitable disputes between subteams as to who should do what and what a requirement actually means. They also manage the requirements dependencies between subteams and strive to minimize overlapping work between subteams. System integration activities. System integration is important for any size of project team, but it is often absolutely critical on large AAM agile project teams (which often address complex problems). The complexities of large projects often necessitate the addition of a DevSecOps Engineer to the team to configure, build, integrate and manage the CI/CD pipeline Development, Test, Staging and Production infrastructure environments which may be on-premises or cloud-based. System integration occurs throughout the entire agile life cycle, not just at the end of the project during the system integration test phase of a traditional project.","title":"6.1 Project Team"},{"location":"modern/6-1-project/#61-project-team","text":"AAM Agile project teams are formed from development specialists who are cross-trained on one or more technical specialties (e.g. system architecture, cybersecurity, automated code transformation, Java programming, SQL database development, continuous integration, automated testing ...) so that they can contribute to the team and they also have a general knowledge of the business domain in which they work. Agile teams are stable and program management understands that changing team structures; for example, this iteration Jeff is part of the development team but next iteration Jeff's pulled off to help another team, is detrimental to project success. Program Managers strive to keep teams as stable as possible.","title":"6.1  Project Team"},{"location":"modern/6-1-project/#611-small-agile-project-teams","text":"Figure 5-3 overviews the structure of a small AAM agile team best suited for re-hosting (transform lite, lift and shift) projects. The Project Management leadership team and a team of developers, led by the team lead, works closely with a government PMO product owner and stakeholders to build high-quality working system features using iterative sprints with support on a just-in-time basis from the Engineering Support team members. Figure 5-3. Small agile Team organization Structure The small agile project team common agile roles are: Project Manager: on agile team projects, the project manager\u2019s tasks include: Project financials; Assessment, Measurement and Status reporting; Project governance; Change management; Identification of missing roles and/or resources; Business stakeholder communication; Risk communication and management; Project planning and scheduling and Quality Assurance. Development Team: There are several roles on the development team, which have different names depending on the methodology being followed, common to agile teams. Roles are not positions; any given person takes on one or more functional roles and can switch roles over time. The common agile development team roles are: Team lead/architecture owner. This role, called \u201cScrum Master\u201d in Scrum or team coach or project lead in other methods, is responsible for facilitating the team, obtaining resources for it, and protecting it from problems. This role encompasses the soft skills of project management but not the technical management ones such as: project planning, project assessment and control, decision management, measurement and quality assurance activities which are better left to the project manager as described above. Team member. This role, sometimes referred to as developer or programmer, is responsible for the creation and delivery of a system. This includes requirements, business analysis, design, programming, automated code transformation, code refactoring, testing, and release implementation activities, as well as others. Product Owner. The product owner represents the government stakeholders and provides the voice of the users. This is the one person who is responsible for a release prioritized work item list (called a product backlog in Scrum), for making decisions in a timely manner, and for providing information in a timely manner. The range of stakeholders a product owner represents is depicted in Figure 5-4 and is scaled to the AAM project size. Stakeholder. A stakeholder is anyone who is a direct user, indirect user, manager of users, senior manager, operations staff member, the \"PMO\" who funds the project, support (help desk) staff member, auditors, program/portfolio manager, and developers working on other systems that integrate or interact with the one under development, or maintenance professionals potentially affected by the development and/or deployment of a software project. Figure 5-4. Product Owner Represents a Large Range of Stakeholders. Engineering Support Team: The development team often requires technical specialists to help modernize, design, transform, build and refactor applications. The common Engineering Support Team roles are: Technical experts. The agile team needs the help of technical experts, such as: enterprise architects; cybersecurity engineers for RMF processes and cybersecurity static and dynamic application security testing; automated code transformation specialists; DBA\u2019s for database design; DevSecOps for CI/CD infrastructure and software builds; configuration management specialists to maintain CM, code version control and artifact repository; and automated testing experts to build test scripts. Technical experts are brought in on an as-needed, temporary basis, to help the team and to transfer their skills to one or more developers on the team. Functional SME experts. The product owner represents a wide range of stakeholders (see Figure 5-3 ), not just end users, and in practice it isn't reasonable to expect them to be experts at every single nuance in the business or mission domain. As a result the product owner will sometimes bring in Functional SMEs to work with the team, perhaps a supply expert to explain the details of a requirement or the sponsoring executive to explain the vision for the project. Independent tester. Effective agile teams often have an independent test team working integral to the team or in parallel that implements automated testing frameworks and automated testing tools and verifies and validates the agile development team\u2019s work throughout the development life cycle.","title":"6.1.1 Small Agile Project Teams"},{"location":"modern/6-1-project/#612-large-agile-project-teams","text":"When the size of an AAM agile development team gets to be more than twenty, which may be required for a complex re-platform (transformation and refactor) project, program/project managers need to take a \u201cteam of teams\u201d approach. The strategy is to organize the larger team into a collection of smaller teams organized around the architecture of the system. Each subteam is responsible for one or more subsystems, enabling them to work as a small agile team responsible for delivering working software on a timely basis. Figure 5-5 describes the organization of large agile teams. Figure 5-5. Large agile Project Team The additional roles on agile teams at larger scale include: Architecture owner. This person is responsible for facilitating architectural decisions on a sub-team and is part of the architecture owner team which is responsible for the overall architectural runway direction of the project. The architecture owner leads their sub-team through initial architecture envisioning for their sub-systems and will be involved with the initial architecture envisioning for the system as a whole (as part of the architecture owner team, see description of activities below). Architecture owners are different than traditional architects in that they are not solely responsible for setting the architectural direction but instead facilitate its creation and evolution. DevSecOps integrator. The AAM agile subteams are typically responsible for one or more subsystems (i.e. applications modules and the database), and the larger the overall team generally the larger and more complicated the system being built. In these situations the overall AAM team assigns a DevSecOps Engineer in the role of integrator who is responsible for building the Development, Test, Staging and Production environments for the various subsystems. DevSecOps Engineers work closely with the internal or independent test team, who perform system integration and cybersecurity testing regularly throughout the project. As Figure 5-5 indicates, on large agile teams the Leadership Team needs to provide project governance and coordinate several critical activities: Scaled up Project management activities. At scale it isn\u2019t sufficient to simply focus on a project leadership team and allow self-organization to address the technical aspects of project management. This may work on the individual subteams, but across the entire program/project the technical aspects of project management, such as dependency management, contract management, resource tracking, and vendor management become critical. The program/project management team of Large AAM Agile Project Teams ( Figure 5-5 ) is comprised of the team leads from the various subteams. Their goal is to coordinate the management aspects of the overall team. This team holds a short coordination meeting each day, referred to as a \u201cscrum of scrums\u201d in the Scrum methodology, where current status is shared among the subteams and issues are identified. Technical/architectural activities. The architecture ownership team is comprised of the architecture owners from the subteams and is responsible for architecture envisioning at the beginning of the project to identify the initial technical direction and provide a basis for organizing the subteams. In the first week of the project (sometimes several weeks on more complex projects) their goal is to identify the subsystems and their interfaces, a strategy called \u201cVision and Product Portfolio Management\u201d which results in the development of the Architectural Runway. The Architectural Runway is the existing code components and technical infrastructure needed to implement near-term features without excessive redesign and delay. The purpose of the Architecture Runway is to reduce the coupling between subsystems and thereby reduce the amount of coordination required by subteams. Once the architectural layers and interfaces are well defined it is possible for the individual subteams to focus on implementing the AAM project applications of those subsystems. Enterprise Architects define architecture at the Portfolio Level, while at the subteam level, System and Solution Architects/Systems Engineering typically define architecture at the Program and Large Solution levels. The architects help provide the guidance needed to support the analysis, estimation, and implementation of the affected elements\u2014subsystems, components, functions, protocols, internal system functions\u2014to have the architecture necessary to support the near-term features and capabilities on the Product Roadmap. Throughout the project the architecture team will meet on a regular basis to share ideas and resolve technical issues, particularly those surrounding changes to the interfaces of subsystems. They may choose to meet daily, this is particularly common at the beginning of the project, but as the architecture stabilizes it is common to see them meet once or twice a week. Requirements/product ownership activities. The product ownership team is comprised of the product owners of each subteam and is responsible for coordinating the requirements effort across the subteams. They will need to negotiate requirements with the larger body of stakeholders whom they represent and apportion the requirements items among the subteams product backlogs appropriately. They\u2019ll also need to negotiate the inevitable disputes between subteams as to who should do what and what a requirement actually means. They also manage the requirements dependencies between subteams and strive to minimize overlapping work between subteams. System integration activities. System integration is important for any size of project team, but it is often absolutely critical on large AAM agile project teams (which often address complex problems). The complexities of large projects often necessitate the addition of a DevSecOps Engineer to the team to configure, build, integrate and manage the CI/CD pipeline Development, Test, Staging and Production infrastructure environments which may be on-premises or cloud-based. System integration occurs throughout the entire agile life cycle, not just at the end of the project during the system integration test phase of a traditional project.","title":"6.1.2 Large Agile Project Teams"},{"location":"modern/6-2-personnel/","text":"6.2 Key Personnel Many PEO BES PMOs use a key personnel clause in their agile contract acquisition PWS to identify labor category positions of personnel who are considered essential for the contract or tasks order performance. In AAM contracts for modernization of a legacy application, the following positions are considered key personnel. Program/Project Manager Technical Lead (Scrum Master) Senior Software Architect Automated Code Transformation and Refactoring Expert Database Specialist for Data/Database Migration Automation Test Engineer Expert","title":"6.2 Key Personnel"},{"location":"modern/6-2-personnel/#62-key-personnel","text":"Many PEO BES PMOs use a key personnel clause in their agile contract acquisition PWS to identify labor category positions of personnel who are considered essential for the contract or tasks order performance. In AAM contracts for modernization of a legacy application, the following positions are considered key personnel. Program/Project Manager Technical Lead (Scrum Master) Senior Software Architect Automated Code Transformation and Refactoring Expert Database Specialist for Data/Database Migration Automation Test Engineer Expert","title":"6.2 Key Personnel"},{"location":"modern/6-3-project-phases/","text":"6.3 AAM Project Phases and Work Items Specific AAM project patterns with larger volumes, such as re-hosting, offer the opportunity to define methods and tools for moving data and application components using factory-like processes. Every AAM project in the execution phase of a migration follows the same six-step process Framework phases: Discover, Design, Build, Integrate, Validate, and Cutover. Work items, tasks and deliverables are defined for each phase. Success Items to consider: Make sure the team is familiar with agile practices. An iterative approach to maximize immediate requirements gathering to avoid doing up front work that will be out of date by the time you are ready to use it. The Cloud Center of Excellence (CCoE) plays a key role in sharing best practices and lessons learned across the different migration teams. Implementation is executed in iterative Development Sprints. 6.3.1 Discover In the Discover stage, the application portfolio analysis; product planning and features mapping; and the product roadmap and product backlog are confirmed with the App Product Owner and used by the contractor team to understand the current and future architectures. If needed, more data is collected about the application. There are two categories of information: Business Information and Technical Information. Examples of business information are application product owner, product roadmap, product backlog, cutover plans, and operation runbooks. Examples of technical information are \u201cAs Is\u201d server statistics, connectivity, process information, data flow, system architecture and technology stack(s). As Is\u201d information can be captured via tools and the output reports confirmed with the application product owner. The data is then analyzed, and a Modernization/Migration plan for that application is confirmed with both the sprint team and the application product owner. Deliverable Discovery work items include: Confirmed Product Road Map and Product Backlog Discovery Tool reports on \u201cAs Is\u201d App hosting environment Application Inventory Report - precise inventory of the legacy system source code App Modernization/Migration Plan 6.3.2 Design In the Design stage, the target state is developed and \u201cTo Be\u201d architecture runway is documented. The target state includes the Cloud architecture, application architecture, and supporting architecture runway infrastructure, software, operational components and processes. A member of the sprint team and engineering team uses the information collected during the Discover stage to design the application for the targeted Cloud environment. AAM Design stage project work items depend on the migration pattern. For re-hosting (Lift and Shift), an infrastructure architecture document outlines what cloud services to use. The document also includes information about compute, storage, network, failover, backup/recovery, cybersecurity, identity and access management elements, system monitoring, and how the application will consume external resources. For re-platforming (code transformation & refactoring) we add the application transformation and refactoring processes, tools setup, application blueprint, data migration and additional cloud infrastructure components required to deploy a modernized Cloud-ready App. The Application Blueprint (Legacy Documentation) is a detailed presentation of the structure and flow of the customer\u2019s legacy code. The presentation includes Code and Design Metrics, Navigation Indices, Control Flow Diagrams, Structure Charts, Data Element Tables, State Machine Models, State Transition Tables, Cause Effect Graphs, and hyper-linked legacy code in HTML format. Deliverable Design deliverable work items include: \u201cTo Be\u201d Architecture Runway Infrastructure Architecture Document Transformation and Refactoring Plan Transformation Specification Document Baseline Application Blueprint (Legacy Documentation) Product Backlog of Legacy code modules/components The next three AAM stages are performed iteratively in 2-week Development Sprints whereby the Legacy Application Code Modules/Components are selected from the Product Backload, refined, estimated and entered into the Sprint Backlog in a Sprint Planning session. Then the Development Sprint Build, Integrate and Validate process stages are performed on the Code Modules/Components pulled from the Sprint Backlog. 6.3.3 Build In the Build stage of the Development Sprint, the modernization and migration design created during the Design stage is executed iteratively. The required people, tools, and reusable templates are identified and are given to the migration teams. A migration team is selected based on the migration strategy chosen for the application. For the re-host (lift and shift) migration pattern, code transformation may be optional. The cloud ready App release code is installed in the Cloud CI/CD pipeline Development, Test, Staging and Production environments and the cloud migration Build, Integrate and Validate iterations are performed using cloud native processes. Code transformation steps can be added, for example; to move a legacy mainframe COBOL application to a Micro Focus COBOL application that can run on open systems Windows or Linux platforms. For re-platforming (code transformation & refactoring) migration pattern, there are additional steps described in the Transformation and Refactoring Plan. First the selected transformation tool suite is Set-Up to be able to ingest and parse the customer\u2019s legacy code. Next in the Transformation process, code modules are pulled from the sprint backlog and the transformation tool is executed on the code modules to rewrite the customer\u2019s legacy code into a compilable and linkable target code-of-choice with all external system calls \u201cstubbed out\u201d. The UI screens will also be converted in this process. The customer\u2019s legacy database is automatically rewritten into a target database structure-of-choice. Automated Re-Factoring is run to identify and remove dead and redundant code to improve system maintainability without changing the customer\u2019s legacy system\u2019s functionality. Next opportunities for code improvement and performance optimization are identified and the transformation toolset is setup and used to make those re-factorings in a uniform and traceable manner. Finally, Semi-Automatic Re-Factoring is run to identify further opportunities for hand-coded improvement and performance optimization as specified by the customer\u2019s Product Owner and the subject matter expert stakeholders. Unit tests, integration tests, functional, security and regression tests are run iteratively in the CI pipeline Development and Test environments and a sprint Demo with the Product Owner is held at the end of each Development Sprint iteration. A Target Language Transformation Blueprint document is developed to provide a detailed presentation of the structure and flow of the modernized App code to support future code maintenance, system restructuring and/or enhancement. It includes Code and Design Metrics, Navigation Indices, Control Flow Diagrams, Structure Charts, Data Element Tables, State Machine Models, State Transition Tables, Cause Effect Graphs and side-by-side views of hyper-linked source and target code in HTML format. Deliverable Build work items deliverables include: Source to Target Transformation Blueprint document Transformation Blueprint (Final documentation) - detailed structure and flow of the modernized code Test Plans Test Cases Test Scripts \u2013 automated to the extent practical 6.3.5 Validate In the Validate stage at the end of the final Development Sprint, Release Integration tasks are performed whereby the application goes through the CI/CD pipeline series of specific tests in the Staging environment (i.e. build verification, functional, security, performance, disaster recovery, and business continuity tests) are demonstrated to the Product Owner and Stakeholders before being finalized and released for the Cutover stage. Test teams evaluate release integration, verify rollout and rollback plans, data migration plans and evaluate performance baselines. Rollback procedures are defined by application within a rollback playbook, which consists of an operations communication plan for users that defines integration, data migration, application, and performance impacts. Testers complete business acceptance criteria by running parallel testing for pre-migrated and migrated applications. Minimum Viable Product validation is performed by the Product Owner and Stakeholders. Validate work items deliverables include: Rollout Plans Data Migration Plans Training Plans and Materials Rollback Procedures Cutover Plan User Acceptance Test (UAT) Plan UAT Test Scripts (automated as much as practical) Security Test Scripts (automated as much as practical) Test Reports 6.3.6 Cutover In the Cutover stage, the cutover plan that was agreed upon by the migration team and application product owner is executed. Data Migration and any updated User Training tasks are performed at this stage. A User Acceptance Test and Security Testing for ATO are performed in the CD pipeline Staging environment at this stage to support a successful cutover. Following successful government UAT and Security testing and correction of all Priority 1 and 2 defects, the application release is deployed to the production environment and rolled out to users. In the event of a release failure during cutover, rollback procedures in the cutover plan are executed. Defects causing the release failure are corrected by developers in the CI pipeline and the App release is recycled through the CD pipeline Staging environment before release to Production and Cutover.","title":"6.3 AAM Project Phases and Work Items"},{"location":"modern/6-3-project-phases/#63-aam-project-phases-and-work-items","text":"Specific AAM project patterns with larger volumes, such as re-hosting, offer the opportunity to define methods and tools for moving data and application components using factory-like processes. Every AAM project in the execution phase of a migration follows the same six-step process Framework phases: Discover, Design, Build, Integrate, Validate, and Cutover. Work items, tasks and deliverables are defined for each phase. Success Items to consider: Make sure the team is familiar with agile practices. An iterative approach to maximize immediate requirements gathering to avoid doing up front work that will be out of date by the time you are ready to use it. The Cloud Center of Excellence (CCoE) plays a key role in sharing best practices and lessons learned across the different migration teams. Implementation is executed in iterative Development Sprints.","title":"6.3 AAM Project Phases and Work Items"},{"location":"modern/6-3-project-phases/#631-discover","text":"In the Discover stage, the application portfolio analysis; product planning and features mapping; and the product roadmap and product backlog are confirmed with the App Product Owner and used by the contractor team to understand the current and future architectures. If needed, more data is collected about the application. There are two categories of information: Business Information and Technical Information. Examples of business information are application product owner, product roadmap, product backlog, cutover plans, and operation runbooks. Examples of technical information are \u201cAs Is\u201d server statistics, connectivity, process information, data flow, system architecture and technology stack(s). As Is\u201d information can be captured via tools and the output reports confirmed with the application product owner. The data is then analyzed, and a Modernization/Migration plan for that application is confirmed with both the sprint team and the application product owner. Deliverable Discovery work items include: Confirmed Product Road Map and Product Backlog Discovery Tool reports on \u201cAs Is\u201d App hosting environment Application Inventory Report - precise inventory of the legacy system source code App Modernization/Migration Plan","title":"6.3.1 Discover"},{"location":"modern/6-3-project-phases/#632-design","text":"In the Design stage, the target state is developed and \u201cTo Be\u201d architecture runway is documented. The target state includes the Cloud architecture, application architecture, and supporting architecture runway infrastructure, software, operational components and processes. A member of the sprint team and engineering team uses the information collected during the Discover stage to design the application for the targeted Cloud environment. AAM Design stage project work items depend on the migration pattern. For re-hosting (Lift and Shift), an infrastructure architecture document outlines what cloud services to use. The document also includes information about compute, storage, network, failover, backup/recovery, cybersecurity, identity and access management elements, system monitoring, and how the application will consume external resources. For re-platforming (code transformation & refactoring) we add the application transformation and refactoring processes, tools setup, application blueprint, data migration and additional cloud infrastructure components required to deploy a modernized Cloud-ready App. The Application Blueprint (Legacy Documentation) is a detailed presentation of the structure and flow of the customer\u2019s legacy code. The presentation includes Code and Design Metrics, Navigation Indices, Control Flow Diagrams, Structure Charts, Data Element Tables, State Machine Models, State Transition Tables, Cause Effect Graphs, and hyper-linked legacy code in HTML format. Deliverable Design deliverable work items include: \u201cTo Be\u201d Architecture Runway Infrastructure Architecture Document Transformation and Refactoring Plan Transformation Specification Document Baseline Application Blueprint (Legacy Documentation) Product Backlog of Legacy code modules/components The next three AAM stages are performed iteratively in 2-week Development Sprints whereby the Legacy Application Code Modules/Components are selected from the Product Backload, refined, estimated and entered into the Sprint Backlog in a Sprint Planning session. Then the Development Sprint Build, Integrate and Validate process stages are performed on the Code Modules/Components pulled from the Sprint Backlog.","title":"6.3.2 Design"},{"location":"modern/6-3-project-phases/#633-build","text":"In the Build stage of the Development Sprint, the modernization and migration design created during the Design stage is executed iteratively. The required people, tools, and reusable templates are identified and are given to the migration teams. A migration team is selected based on the migration strategy chosen for the application. For the re-host (lift and shift) migration pattern, code transformation may be optional. The cloud ready App release code is installed in the Cloud CI/CD pipeline Development, Test, Staging and Production environments and the cloud migration Build, Integrate and Validate iterations are performed using cloud native processes. Code transformation steps can be added, for example; to move a legacy mainframe COBOL application to a Micro Focus COBOL application that can run on open systems Windows or Linux platforms. For re-platforming (code transformation & refactoring) migration pattern, there are additional steps described in the Transformation and Refactoring Plan. First the selected transformation tool suite is Set-Up to be able to ingest and parse the customer\u2019s legacy code. Next in the Transformation process, code modules are pulled from the sprint backlog and the transformation tool is executed on the code modules to rewrite the customer\u2019s legacy code into a compilable and linkable target code-of-choice with all external system calls \u201cstubbed out\u201d. The UI screens will also be converted in this process. The customer\u2019s legacy database is automatically rewritten into a target database structure-of-choice. Automated Re-Factoring is run to identify and remove dead and redundant code to improve system maintainability without changing the customer\u2019s legacy system\u2019s functionality. Next opportunities for code improvement and performance optimization are identified and the transformation toolset is setup and used to make those re-factorings in a uniform and traceable manner. Finally, Semi-Automatic Re-Factoring is run to identify further opportunities for hand-coded improvement and performance optimization as specified by the customer\u2019s Product Owner and the subject matter expert stakeholders. Unit tests, integration tests, functional, security and regression tests are run iteratively in the CI pipeline Development and Test environments and a sprint Demo with the Product Owner is held at the end of each Development Sprint iteration. A Target Language Transformation Blueprint document is developed to provide a detailed presentation of the structure and flow of the modernized App code to support future code maintenance, system restructuring and/or enhancement. It includes Code and Design Metrics, Navigation Indices, Control Flow Diagrams, Structure Charts, Data Element Tables, State Machine Models, State Transition Tables, Cause Effect Graphs and side-by-side views of hyper-linked source and target code in HTML format. Deliverable Build work items deliverables include: Source to Target Transformation Blueprint document Transformation Blueprint (Final documentation) - detailed structure and flow of the modernized code Test Plans Test Cases Test Scripts \u2013 automated to the extent practical","title":"6.3.3 Build"},{"location":"modern/6-3-project-phases/#635-validate","text":"In the Validate stage at the end of the final Development Sprint, Release Integration tasks are performed whereby the application goes through the CI/CD pipeline series of specific tests in the Staging environment (i.e. build verification, functional, security, performance, disaster recovery, and business continuity tests) are demonstrated to the Product Owner and Stakeholders before being finalized and released for the Cutover stage. Test teams evaluate release integration, verify rollout and rollback plans, data migration plans and evaluate performance baselines. Rollback procedures are defined by application within a rollback playbook, which consists of an operations communication plan for users that defines integration, data migration, application, and performance impacts. Testers complete business acceptance criteria by running parallel testing for pre-migrated and migrated applications. Minimum Viable Product validation is performed by the Product Owner and Stakeholders. Validate work items deliverables include: Rollout Plans Data Migration Plans Training Plans and Materials Rollback Procedures Cutover Plan User Acceptance Test (UAT) Plan UAT Test Scripts (automated as much as practical) Security Test Scripts (automated as much as practical) Test Reports","title":"6.3.5 Validate"},{"location":"modern/6-3-project-phases/#636-cutover","text":"In the Cutover stage, the cutover plan that was agreed upon by the migration team and application product owner is executed. Data Migration and any updated User Training tasks are performed at this stage. A User Acceptance Test and Security Testing for ATO are performed in the CD pipeline Staging environment at this stage to support a successful cutover. Following successful government UAT and Security testing and correction of all Priority 1 and 2 defects, the application release is deployed to the production environment and rolled out to users. In the event of a release failure during cutover, rollback procedures in the cutover plan are executed. Defects causing the release failure are corrected by developers in the CI pipeline and the App release is recycled through the CD pipeline Staging environment before release to Production and Cutover.","title":"6.3.6 Cutover"},{"location":"modern/6-4-risk/","text":"6.4 Risk Identification and Mitigation Strategy Risks are inherent in any complex legacy application modernization project no matter which migration strategy and transformation toolset is used. Some of these risks have been described by a group of Carnegie Mellon University researchers in the report \u201cWhy Reengineering Projects Fail\u201d, dated April 1999 which lists the reasons for legacy modernization effort failure. Key risks and their mitigation strategy are set forth in Figure xx. Legacy Application Modernization Risk Mitigation Strategy The organization inadvertently adopts a flawed or incomplete modernization strategy. Adopt six-step process framework: Discover, Design, Build, Integrate, Validate, and Cutover and associated Checklists. The organization does not effectively use outside consultants and outside contractors. The Framework and its associated Checklists can provide a starting point for discovery assessment and analysis activities and tasks to build the business case and AAM Plans Cultural issues - workforce is tied to old technologies with inadequate training programs. Just-in-time AAM Training Sessions and Cloud Migration Training provided by AAM contractor project team. The organization does not have its legacy system code baseline under control. Discovery tools are adopted in the Discover phase to analyze and report on \u201cas is\u201d code base and hosting environment. There is too little elicitation and validation of requirements. Design phase generates and validates the application transformation and refactoring processes, tools setup, application blueprints, architecture, data migration and additional cloud infrastructure components required to deploy a modernized Cloud-ready App. Software architecture is not a primary application modernization consideration Design phase generates \u201cTo Be\u201d Architecture Runway and Infrastructure Architecture Document. There is no notion of a separate and distinct \u201capplication modernization process.\u201d Major application modernization considerations such as defining the operational system concept, migration strategy, and software architecture for the target system are resolved in the Design phase before the actual transformation and refactoring occur before executing the Build, Integrate and Validate stages in the development Sprints. There is inadequate planning or inadequate resolve to follow the plans. The iterative Build, Integrate and Validate Development Sprint iterations develop Just-in-time plans to support Transformation, Refactoring, Integration and Test tasks. Organizational issues - upper management pre-determines solution space before analyzing the system and the involving the AAM project team Adopt six-step process framework: Discover, Design, Build, Integrate, Validate, and Cutover; follow checklists of tasks, work items & deliverables; and adopt Agile iterative Development Sprint execution practices with Demos to the Product Owner to give upper management confidence in the AAM project direction and execution. In summary successful AAM projects require a solid modernization strategy, architecture design and attention to implementation detail.","title":"6.4 Risk Identification and Mitigation Strategy"},{"location":"modern/6-4-risk/#64-risk-identification-and-mitigation-strategy","text":"Risks are inherent in any complex legacy application modernization project no matter which migration strategy and transformation toolset is used. Some of these risks have been described by a group of Carnegie Mellon University researchers in the report \u201cWhy Reengineering Projects Fail\u201d, dated April 1999 which lists the reasons for legacy modernization effort failure. Key risks and their mitigation strategy are set forth in Figure xx. Legacy Application Modernization Risk Mitigation Strategy The organization inadvertently adopts a flawed or incomplete modernization strategy. Adopt six-step process framework: Discover, Design, Build, Integrate, Validate, and Cutover and associated Checklists. The organization does not effectively use outside consultants and outside contractors. The Framework and its associated Checklists can provide a starting point for discovery assessment and analysis activities and tasks to build the business case and AAM Plans Cultural issues - workforce is tied to old technologies with inadequate training programs. Just-in-time AAM Training Sessions and Cloud Migration Training provided by AAM contractor project team. The organization does not have its legacy system code baseline under control. Discovery tools are adopted in the Discover phase to analyze and report on \u201cas is\u201d code base and hosting environment. There is too little elicitation and validation of requirements. Design phase generates and validates the application transformation and refactoring processes, tools setup, application blueprints, architecture, data migration and additional cloud infrastructure components required to deploy a modernized Cloud-ready App. Software architecture is not a primary application modernization consideration Design phase generates \u201cTo Be\u201d Architecture Runway and Infrastructure Architecture Document. There is no notion of a separate and distinct \u201capplication modernization process.\u201d Major application modernization considerations such as defining the operational system concept, migration strategy, and software architecture for the target system are resolved in the Design phase before the actual transformation and refactoring occur before executing the Build, Integrate and Validate stages in the development Sprints. There is inadequate planning or inadequate resolve to follow the plans. The iterative Build, Integrate and Validate Development Sprint iterations develop Just-in-time plans to support Transformation, Refactoring, Integration and Test tasks. Organizational issues - upper management pre-determines solution space before analyzing the system and the involving the AAM project team Adopt six-step process framework: Discover, Design, Build, Integrate, Validate, and Cutover; follow checklists of tasks, work items & deliverables; and adopt Agile iterative Development Sprint execution practices with Demos to the Product Owner to give upper management confidence in the AAM project direction and execution. In summary successful AAM projects require a solid modernization strategy, architecture design and attention to implementation detail.","title":"6.4 Risk Identification and Mitigation Strategy"},{"location":"modern/7-0-overview/","text":"7.0 Determining the Best Application Modernization Solution In Section 3.4 Migration Approaches the 6R strategies for application modernization were briefly described. In this section, the top four application modernization solutions are identified and described; the Analysis of Alternatives (AoA) main objectives and principle trade off project metrics for each alternative are set forth; and each application modernization solution was assessed with respect to these objectives and metrics to give BES PMOs the perspective needed to select an application modernization solution that best fits their mission requirements, timelines, budget constraints and technical risk tolerance.","title":"7.0 Overview"},{"location":"modern/7-0-overview/#70-determining-the-best-application-modernization-solution","text":"In Section 3.4 Migration Approaches the 6R strategies for application modernization were briefly described. In this section, the top four application modernization solutions are identified and described; the Analysis of Alternatives (AoA) main objectives and principle trade off project metrics for each alternative are set forth; and each application modernization solution was assessed with respect to these objectives and metrics to give BES PMOs the perspective needed to select an application modernization solution that best fits their mission requirements, timelines, budget constraints and technical risk tolerance.","title":"7.0 Determining the Best Application Modernization Solution"},{"location":"modern/7-1-solutions/","text":"7.1 Identifying Viable Solutions In this section we address the top four alternative application modernization solutions: Code Rewrite, Lift & Shift, Code Transformation, and Replacement with a COTS package. Code Rewrite Rewriting code means re-implementing all application functionality in a newer programming language. It results in a new system that is strongly aligned with the BES PMO\u2019s application owner business requirements. However, it is a time consuming and labor-intensive alternative, especially when the rewrite is done from scratch using modern Integrated Development Environments or Low Code/No Code Platforms are used to minimize code development and test. Outsourcing to off shore countries like India and Pakistan lowers rewriting costs for commercial customers, however, because of national security implications of the Air Force PEO BES logistics and business systems the outsourcing solution must be must be in CONUS and executed by US citizens. In an effort to manage the high risk of failure for these projects, implementation of changes needs to be halted during the Code Rewrite, which seriously impacts the AF PMO application owner\u2019s mission and user base. Code Rewrite requires a full specification of the business functional, technical and non-functional requirements. Business operations, underlying technology stacks, Air Force RMF and Assessment and Authorization Cybersecurity policies and procedures, end user functionality and UI/UX look and feel are all subject to change. Testing is therefore incredibly complex. Code Rewrites come with a high risk of introducing new bugs, security flaws, and regression of previously fixed bugs. When rewriting legacy applications cost increases enormously in the short term (3-5 years), business alignment is improved but only in the longer term (3+ years). Lift & Shift Lift & Shift transfers the legacy application to an open system Windows or Linux environment. The application stays as is, with all functionality and underlying software infrastructure safely preserved. Only the underlying hardware is changed from proprietary chip sets (i.e. IBM or UNISYS mainframe, SPARC, PowerPC or Itanium platforms) to open systems x86 platforms. If Code Transformation is used (e.g. mainframe COBOL to Micro Focus COBOL (x86), there are minimal code changes and refactoring. In comparison to Code Rewrite, Lift & Shift is considerably quicker and cheaper. However, the legacy source code underneath stays the same and an emulator is used to enable running the legacy application in the new environment. This does not solve the initial problem but instead prolongs the inevitable. Lift & Shift brings significantly lower project risk than Code Rewrite. Cost decrease is realized in short term with typical positive ROI in around 2.5 years. The preservation of the customer\u2019s legacy application has no impact on business alignment and risk reduction is not achieved due to the same dependency on legacy language skills. This results in limited flexibility in adapting new technology such as mobile and Cloud. To improve innovation another migration is needed to a new environment. As most cost reduction has already been realized with the first migration, building a business case for a second migration will be much harder. Code Transformation and Refactoring Legacy code automated transformation generates a new code base based on the legacy application which is refactored to use modern architecture design patterns and open system components. Semantically equivalent to the original, the new application is native, readable and maintainable in old and new languages. Similar to Lift & Shift, Code Transformation preserves all the business functionality and applications as is. The difference lies in the replacement of the underlying legacy technology with open systems components. Code Transformation and refactoring eliminates legacy lock-in and legacy language skills dependency and significantly increases the ability to adopt new developments such as Cloud, mobile and microservices. Code Transformation and refactoring offers about the same cost structure and a longer implementation time than Lift & Shift. The replacement of the underlying system results in a lower infrastructure TCO. Development in the legacy system is fully supported, offering an optional stepping stone to modern programming languages. Since Code Transformation does not change the business functionality, interfaces and end user functions, organizational impact is limited to IT change and regression testing. Business alignment and agility is considerably improved as new technologies allow for faster development, testing and deployment. Code Transformation allows for competitive innovation at the cost and speed of Lift & Shift. Replacement with COTS Package Replacing a current, tailor made mainframe application by a commercial off the shelf application sounds easy. Just purchase a turnkey application (i.e. IBM TRIRIGA, Oracle eBusiness Suite, SAP ERP), configure the App for the use cases, migrate all the data and off you go. However, how standard is the application? How much RICE-W code is required? What mission advantage does the legacy application bring to BES logistics and business operations? How easy is the transition considering this is a migration that will only be done once: for a PMO\u2019s specific business applications, workflows and support environment? At the very least, a package replacement requires a business functional requirements specification, technical specifications and a gap analysis between the current system and the package. In terms of organizational change, this approach is very similar to a rewrite in that every aspect of the organization changes with a significant test effort as a result. A COTS replacement only makes sense when the mainframe application you want to replace is non-differentiating and industry-standard. Extensive customization as RICE-W will drastically increase costs as well as risk. These projects often go over budget and take much longer than expected.","title":"7.1 Identifying Viable Solutions"},{"location":"modern/7-1-solutions/#71-identifying-viable-solutions","text":"In this section we address the top four alternative application modernization solutions: Code Rewrite, Lift & Shift, Code Transformation, and Replacement with a COTS package.","title":"7.1 Identifying Viable Solutions"},{"location":"modern/7-1-solutions/#code-rewrite","text":"Rewriting code means re-implementing all application functionality in a newer programming language. It results in a new system that is strongly aligned with the BES PMO\u2019s application owner business requirements. However, it is a time consuming and labor-intensive alternative, especially when the rewrite is done from scratch using modern Integrated Development Environments or Low Code/No Code Platforms are used to minimize code development and test. Outsourcing to off shore countries like India and Pakistan lowers rewriting costs for commercial customers, however, because of national security implications of the Air Force PEO BES logistics and business systems the outsourcing solution must be must be in CONUS and executed by US citizens. In an effort to manage the high risk of failure for these projects, implementation of changes needs to be halted during the Code Rewrite, which seriously impacts the AF PMO application owner\u2019s mission and user base. Code Rewrite requires a full specification of the business functional, technical and non-functional requirements. Business operations, underlying technology stacks, Air Force RMF and Assessment and Authorization Cybersecurity policies and procedures, end user functionality and UI/UX look and feel are all subject to change. Testing is therefore incredibly complex. Code Rewrites come with a high risk of introducing new bugs, security flaws, and regression of previously fixed bugs. When rewriting legacy applications cost increases enormously in the short term (3-5 years), business alignment is improved but only in the longer term (3+ years).","title":"Code Rewrite"},{"location":"modern/7-1-solutions/#lift-shift","text":"Lift & Shift transfers the legacy application to an open system Windows or Linux environment. The application stays as is, with all functionality and underlying software infrastructure safely preserved. Only the underlying hardware is changed from proprietary chip sets (i.e. IBM or UNISYS mainframe, SPARC, PowerPC or Itanium platforms) to open systems x86 platforms. If Code Transformation is used (e.g. mainframe COBOL to Micro Focus COBOL (x86), there are minimal code changes and refactoring. In comparison to Code Rewrite, Lift & Shift is considerably quicker and cheaper. However, the legacy source code underneath stays the same and an emulator is used to enable running the legacy application in the new environment. This does not solve the initial problem but instead prolongs the inevitable. Lift & Shift brings significantly lower project risk than Code Rewrite. Cost decrease is realized in short term with typical positive ROI in around 2.5 years. The preservation of the customer\u2019s legacy application has no impact on business alignment and risk reduction is not achieved due to the same dependency on legacy language skills. This results in limited flexibility in adapting new technology such as mobile and Cloud. To improve innovation another migration is needed to a new environment. As most cost reduction has already been realized with the first migration, building a business case for a second migration will be much harder.","title":"Lift &amp; Shift"},{"location":"modern/7-1-solutions/#code-transformation-and-refactoring","text":"Legacy code automated transformation generates a new code base based on the legacy application which is refactored to use modern architecture design patterns and open system components. Semantically equivalent to the original, the new application is native, readable and maintainable in old and new languages. Similar to Lift & Shift, Code Transformation preserves all the business functionality and applications as is. The difference lies in the replacement of the underlying legacy technology with open systems components. Code Transformation and refactoring eliminates legacy lock-in and legacy language skills dependency and significantly increases the ability to adopt new developments such as Cloud, mobile and microservices. Code Transformation and refactoring offers about the same cost structure and a longer implementation time than Lift & Shift. The replacement of the underlying system results in a lower infrastructure TCO. Development in the legacy system is fully supported, offering an optional stepping stone to modern programming languages. Since Code Transformation does not change the business functionality, interfaces and end user functions, organizational impact is limited to IT change and regression testing. Business alignment and agility is considerably improved as new technologies allow for faster development, testing and deployment. Code Transformation allows for competitive innovation at the cost and speed of Lift & Shift.","title":"Code Transformation and Refactoring"},{"location":"modern/7-1-solutions/#replacement-with-cots-package","text":"Replacing a current, tailor made mainframe application by a commercial off the shelf application sounds easy. Just purchase a turnkey application (i.e. IBM TRIRIGA, Oracle eBusiness Suite, SAP ERP), configure the App for the use cases, migrate all the data and off you go. However, how standard is the application? How much RICE-W code is required? What mission advantage does the legacy application bring to BES logistics and business operations? How easy is the transition considering this is a migration that will only be done once: for a PMO\u2019s specific business applications, workflows and support environment? At the very least, a package replacement requires a business functional requirements specification, technical specifications and a gap analysis between the current system and the package. In terms of organizational change, this approach is very similar to a rewrite in that every aspect of the organization changes with a significant test effort as a result. A COTS replacement only makes sense when the mainframe application you want to replace is non-differentiating and industry-standard. Extensive customization as RICE-W will drastically increase costs as well as risk. These projects often go over budget and take much longer than expected.","title":"Replacement with COTS Package"},{"location":"modern/7-2-alternatives/","text":"7.2 Analysis of Alternatives (AoA) Guidance An Analysis of Alternatives needs to performed due to the impact of the application modernization solution strategy on the life cycle costs, project timeline, system performance, RMF/A & A process, security controls compliance, authority to operate (ATO), FAIR and FISCAM auditing. A high-level AoA comparison of the application modernization key objectives using the CMMI-DEV ML3 formal Decision Analysis and Resolution (DAR) process is provided in the following table. Key Objectives Code Rewrite Lift & Shift Code Transformation Standard package Cost increase Huge increase on short term (3 \u2013 5 years) Short term increase with typical ROI in 2.5 years Short term increase with typical ROI in 2.5 years High increase on short term (3 years) Business alignment Improved on longer term (3+ years) Not improved since legacy code is preserved Improved on shorter term (1+ years) Improved on longer term (3+ years) Cost avoidance Not achieved due to long term project execution time line Achieved due to 1 year project execution time line Achieved due to 2 year project execution time line Not achieved due to long term project execution time line Risk reduction Not achieved due to long term project execution Not achieved as legacy Code is preserved Achieved as legacy dependency is removed Not achieved due to long term project execution A detailed AoA comparison of the impact of each modernization solution on the BES PMO Application Project Metrics is presented in the table below. (1 is very low and 5 is very high) Project Metric Code Rewrite Lift & Shift Code Transformation Standard package TCO reduction 1 5 5 3 Time to Market (TTM) impact 5 1 2 5 IT Security Risk 5 1 1 5 IT Agility 2 3 1 3 IT Cost 5 2 1 3 Project Risk 5 1 3 5 Project Cost 5 2 3 5 Project Duration 5 1 2 5 From this high level AoA and further more detailed trade-off comparisons, we see the modernization strategy of \u201clift and shift\u201d to IaaS services is more cost-effective than on-premises, however, it can be more costly to run applications in the cloud with IaaS services than if organizations were to transform, refactor and re-platform the application to use cloud native PaaS services. The \u201ccode transformation (and refactoring)\u201d modernization strategy is time-consuming and resource-intensive, yet it can offer the lowest monthly spend of the four approaches, since organizations that refactor are able to modify their applications and infrastructure to take full advantage of cloud-native PaaS service features and to maximize operational cost efficiency in the cloud to offer the lowest total recurring monthly cost. Code Rewrite and COTS Standard Packages are the least cost effective, are more resource intensive, have the longest project durations and highest record of modernization project failure. These approaches are not recommended for BES PMOs application modernization projects. Therefore, legacy application modernization use cases amenable to AAM solutions are: Appendix A: Sample Design 1 Re-host (transform, lift and shift) i.e. legacy COBOL (mainframe) to modern COBOL (X86 processor) code transformation and emulation of the mainframe transaction processing environment on a modern Cloud Windows or Linux infrastructure and RDBMS to achieve portability of the Legacy System as is with minimal refactoring. Appendix B: Sample Design 2 Re-platform (transform and refactor to new platform) i.e. legacy COBOL to modern Java code transformation preserving all the business processes and business rules and architecting the application to run on an open systems Windows or Linux Cloud infrastructure and RDBMS.","title":"7.2 Analysis of Alternatives (AoA) Guidance"},{"location":"modern/7-2-alternatives/#72-analysis-of-alternatives-aoa-guidance","text":"An Analysis of Alternatives needs to performed due to the impact of the application modernization solution strategy on the life cycle costs, project timeline, system performance, RMF/A & A process, security controls compliance, authority to operate (ATO), FAIR and FISCAM auditing. A high-level AoA comparison of the application modernization key objectives using the CMMI-DEV ML3 formal Decision Analysis and Resolution (DAR) process is provided in the following table. Key Objectives Code Rewrite Lift & Shift Code Transformation Standard package Cost increase Huge increase on short term (3 \u2013 5 years) Short term increase with typical ROI in 2.5 years Short term increase with typical ROI in 2.5 years High increase on short term (3 years) Business alignment Improved on longer term (3+ years) Not improved since legacy code is preserved Improved on shorter term (1+ years) Improved on longer term (3+ years) Cost avoidance Not achieved due to long term project execution time line Achieved due to 1 year project execution time line Achieved due to 2 year project execution time line Not achieved due to long term project execution time line Risk reduction Not achieved due to long term project execution Not achieved as legacy Code is preserved Achieved as legacy dependency is removed Not achieved due to long term project execution A detailed AoA comparison of the impact of each modernization solution on the BES PMO Application Project Metrics is presented in the table below. (1 is very low and 5 is very high) Project Metric Code Rewrite Lift & Shift Code Transformation Standard package TCO reduction 1 5 5 3 Time to Market (TTM) impact 5 1 2 5 IT Security Risk 5 1 1 5 IT Agility 2 3 1 3 IT Cost 5 2 1 3 Project Risk 5 1 3 5 Project Cost 5 2 3 5 Project Duration 5 1 2 5 From this high level AoA and further more detailed trade-off comparisons, we see the modernization strategy of \u201clift and shift\u201d to IaaS services is more cost-effective than on-premises, however, it can be more costly to run applications in the cloud with IaaS services than if organizations were to transform, refactor and re-platform the application to use cloud native PaaS services. The \u201ccode transformation (and refactoring)\u201d modernization strategy is time-consuming and resource-intensive, yet it can offer the lowest monthly spend of the four approaches, since organizations that refactor are able to modify their applications and infrastructure to take full advantage of cloud-native PaaS service features and to maximize operational cost efficiency in the cloud to offer the lowest total recurring monthly cost. Code Rewrite and COTS Standard Packages are the least cost effective, are more resource intensive, have the longest project durations and highest record of modernization project failure. These approaches are not recommended for BES PMOs application modernization projects. Therefore, legacy application modernization use cases amenable to AAM solutions are:","title":"7.2 Analysis of Alternatives (AoA) Guidance"},{"location":"modern/7-2-alternatives/#appendix-a-sample-design-1","text":"Re-host (transform, lift and shift) i.e. legacy COBOL (mainframe) to modern COBOL (X86 processor) code transformation and emulation of the mainframe transaction processing environment on a modern Cloud Windows or Linux infrastructure and RDBMS to achieve portability of the Legacy System as is with minimal refactoring.","title":"Appendix A: Sample Design 1"},{"location":"modern/7-2-alternatives/#appendix-b-sample-design-2","text":"Re-platform (transform and refactor to new platform) i.e. legacy COBOL to modern Java code transformation preserving all the business processes and business rules and architecting the application to run on an open systems Windows or Linux Cloud infrastructure and RDBMS.","title":"Appendix B: Sample Design 2"},{"location":"modern/8-0-overview/","text":"8.0 Solution Design and Implementation This section is intended for both PMO government Engineering Support teams and contractor solution architects and developers who are building solutions that will be deployed on Cloud infrastructure platforms. We provide architectural design principles and advice on how to design and implement AAM solutions to provide applications that are secure, reliable, high performing, and cost efficient. We include a discussion on how to take advantage of attributes that are specific to the dynamic nature of cloud computing (elasticity, infrastructure automation, etc.). In the following subsections we discuss an AAM approach for the most prevalent and successful modernization use cases \u2013 rehosting (lift and shift) and re-platforming (code transformation & refactoring). First, we address the project planning and discovery requirements, then we discuss design principles and architectural design patterns that apply to AAM projects. Next we address the solution technical design and cybersecurity design considerations for AAM projects. Finally, we present the solution implementation and deployment of AAM applications to production in the cloud environment.","title":"8.0 Overview"},{"location":"modern/8-0-overview/#80-solution-design-and-implementation","text":"This section is intended for both PMO government Engineering Support teams and contractor solution architects and developers who are building solutions that will be deployed on Cloud infrastructure platforms. We provide architectural design principles and advice on how to design and implement AAM solutions to provide applications that are secure, reliable, high performing, and cost efficient. We include a discussion on how to take advantage of attributes that are specific to the dynamic nature of cloud computing (elasticity, infrastructure automation, etc.). In the following subsections we discuss an AAM approach for the most prevalent and successful modernization use cases \u2013 rehosting (lift and shift) and re-platforming (code transformation & refactoring). First, we address the project planning and discovery requirements, then we discuss design principles and architectural design patterns that apply to AAM projects. Next we address the solution technical design and cybersecurity design considerations for AAM projects. Finally, we present the solution implementation and deployment of AAM applications to production in the cloud environment.","title":"8.0 Solution Design and Implementation"},{"location":"modern/8-1-planning/","text":"8.1 Project Planning and Discovery In this section we discuss AAM project planning and discovery requirements. Project planning describes project goals, selects the appropriate personnel, creates project release plans, and establishes schedules and metrics for monitoring and controlling project execution. The Discovery phase sets the stage for successful delivery. During this phase, the PMO\u2019s AAM contractor collaborates with the PMO\u2019s application stakeholders and the government Engineering Support team to perform discovery of the application code base, as is system architecture and database architecture. Project Planning The primary objective of the project plan is to provide a roadmap to guide the overall application modernization effort. This includes managing the scope, activities and tasks, resource plan, schedule, issues and risks, coordination and communication to all stakeholders. Working on the project plan early can organize the project as multiple teams work on Discovery, Design, Transformation and Deployment of the applications and database migration. The project plan considers critical factors such as the transformation order for applications, when resources are needed, and tracking the progress of the application modernization. We recommend using agile methodologies, project control best practices, a robust business communication plan, and a well-defined delivery approach. Recommended project plan activities include: 1 Define Agile project management methods and tools to be used during the application modernization. 2 Define and create the Stakeholder Communication Plan, including reporting and escalation procedures. 3 Develop a project plan defining project phases, activities and tasks, timelines, cost estimates, resources and roles and responsibilities matrix (e.g., RACI) and risk/mitigation log to manage the risks that occur during the project. 4 Procure and deploy project management tools (e.g. Atlassian Jira) to support the delivery of the project. 5 Identify key resources and leads for each of the migration work streams defined in this section. 6 Facilitate the coordination of the activities and tasks outlined in the project plan. Discovery During the Discovery phase Sprint 0, AAM contractors perform tool \u2018Set-Up\u2019 by modifying the AAM toolset to ingest the legacy code, and model and analyze the legacy system to provide a detailed evaluation of the existing system\u2019s design and application architecture. An Internal and External Dependency Analysis is performed to identify internal external interfaces and identify missing definitions. A baseline transformation specification is generated to identify gaps in the transformation rule sets for generating the source languages. The application architecture and baseline transformation specification enable BES PMO stakeholder and government Engineering Support team to review the AAM tool set-up to ensure it provides analytics and metrics for building a detailed understanding of the design and architecture of the target system which will guide subsequent AAM design and implementation sprints. The conclusion of this task is the generation of an inventory report. Product Backlog The product backlog of application code modules to be transformed and refactored is built by conducting a deep analysis of apps modules discovery data. The Transformation tool SME runs the discovery tool, analyzes and prioritizes the application modules and gathers information about the current architecture and database for each application module. The Transformation tool SME develops the future architecture and captures workload details to execute a streamlined transformation and data migration. It is not important to get through every application module before beginning execution of the plan. To be agile, do a deep analysis of the first two to three prioritized apps modules, and then begin the transformation. Continue deeper analyses of the next applications modules while the first applications modules are being refactored and integrated with other software components and the target relational database.","title":"8.1 Project Planning and Discovery"},{"location":"modern/8-1-planning/#81-project-planning-and-discovery","text":"In this section we discuss AAM project planning and discovery requirements. Project planning describes project goals, selects the appropriate personnel, creates project release plans, and establishes schedules and metrics for monitoring and controlling project execution. The Discovery phase sets the stage for successful delivery. During this phase, the PMO\u2019s AAM contractor collaborates with the PMO\u2019s application stakeholders and the government Engineering Support team to perform discovery of the application code base, as is system architecture and database architecture.","title":"8.1 Project Planning and Discovery"},{"location":"modern/8-1-planning/#project-planning","text":"The primary objective of the project plan is to provide a roadmap to guide the overall application modernization effort. This includes managing the scope, activities and tasks, resource plan, schedule, issues and risks, coordination and communication to all stakeholders. Working on the project plan early can organize the project as multiple teams work on Discovery, Design, Transformation and Deployment of the applications and database migration. The project plan considers critical factors such as the transformation order for applications, when resources are needed, and tracking the progress of the application modernization. We recommend using agile methodologies, project control best practices, a robust business communication plan, and a well-defined delivery approach. Recommended project plan activities include: 1 Define Agile project management methods and tools to be used during the application modernization. 2 Define and create the Stakeholder Communication Plan, including reporting and escalation procedures. 3 Develop a project plan defining project phases, activities and tasks, timelines, cost estimates, resources and roles and responsibilities matrix (e.g., RACI) and risk/mitigation log to manage the risks that occur during the project. 4 Procure and deploy project management tools (e.g. Atlassian Jira) to support the delivery of the project. 5 Identify key resources and leads for each of the migration work streams defined in this section. 6 Facilitate the coordination of the activities and tasks outlined in the project plan.","title":"Project Planning"},{"location":"modern/8-1-planning/#discovery","text":"During the Discovery phase Sprint 0, AAM contractors perform tool \u2018Set-Up\u2019 by modifying the AAM toolset to ingest the legacy code, and model and analyze the legacy system to provide a detailed evaluation of the existing system\u2019s design and application architecture. An Internal and External Dependency Analysis is performed to identify internal external interfaces and identify missing definitions. A baseline transformation specification is generated to identify gaps in the transformation rule sets for generating the source languages. The application architecture and baseline transformation specification enable BES PMO stakeholder and government Engineering Support team to review the AAM tool set-up to ensure it provides analytics and metrics for building a detailed understanding of the design and architecture of the target system which will guide subsequent AAM design and implementation sprints. The conclusion of this task is the generation of an inventory report.","title":"Discovery"},{"location":"modern/8-1-planning/#product-backlog","text":"The product backlog of application code modules to be transformed and refactored is built by conducting a deep analysis of apps modules discovery data. The Transformation tool SME runs the discovery tool, analyzes and prioritizes the application modules and gathers information about the current architecture and database for each application module. The Transformation tool SME develops the future architecture and captures workload details to execute a streamlined transformation and data migration. It is not important to get through every application module before beginning execution of the plan. To be agile, do a deep analysis of the first two to three prioritized apps modules, and then begin the transformation. Continue deeper analyses of the next applications modules while the first applications modules are being refactored and integrated with other software components and the target relational database.","title":"Product Backlog"},{"location":"modern/8-2-design-principles/","text":"8.2 Design Principles In this section, we provide design patterns and architectural options that can be applied to the AAM project use cases that are targeted for automated application modernization and migration to the Cloud. Scalability Systems that are expected to grow over time need to be built on top of a scalable architecture. Such an architecture can support growth in users, traffic, or data size with no decrease in performance. It should provide that scale in a linear manner where adding extra resources results in at least a proportional increase in ability to serve additional load. Growth should introduce economies of scale, and cost should follow the same dimension of proportional increases in monthly costs. While cloud computing provides virtually unlimited on-demand capacity, the design needs to be able to take advantage of those resources seamlessly. Disposable Resources Instead of Fixed Servers In a traditional infrastructure environment, you have to work with fixed resources due to the upfront cost and lead time of introducing new hardware. This would drive practices like manually logging in to servers to configure software or fix issues, hardcoding IP addresses, running tests or processing jobs sequentially etc. When designing for the cloud Solution Architects have the opportunity to reset that mindset so that architects take advantage of the dynamically provisioned nature of cloud computing. Architects think of servers and other components as temporary resources. Launch as many as you need, and use them only for as long as they are needed. The problem of configuration drift can be solved with the cloud immutable infrastructure pattern. With this approach a server, once launched, is never updated throughout its lifetime. Instead, when there is a problem or a need for an update, the server is replaced with a new one that has the latest configuration. In this way, resources are always in a consistent (and tested) state and rollbacks become easier to perform. Automation. In a traditional IT infrastructure, system administrators would often have to manually react to a variety of events. When deploying on the cloud there is a lot of opportunity for automation, so that both the system\u2019s stability and the efficiency of the DevOps and SysOps team is improved. When deploying a new environment for development, test, staging, and deployment or increasing capacity of an existing system to cope with extra load, it is important that DevOps Engineers make this an automated and repeatable process that avoids long lead times and is not prone to human error. Since cloud assets are programmable, DevOps Engineers can apply Infrastructure as Code (IaS) techniques, practices, and tools from software development to make the whole infrastructure reusable, maintainable, extensible, and testable. In addition, common cloud features enable automation to support SysOps administration, for example: \u2022 Auto Scaling: You can maintain application availability and scale your cloud computing capacity up or down automatically according to conditions you define. Auto Scaling can also automatically increase the number of VM instances during demand spikes to maintain performance and decrease capacity during less busy periods to optimize costs. \u2022 System Management Alarms: You can create alarms that sends SMS message when a particular metric goes beyond a specified threshold for a specified number of periods. \u2022 System Management Events: You can set up delivery of a near real-time stream of system events that describe changes in cloud resources. Using simple rules that you can set up in a couple of minutes, you can easily route each type of event to one or more System Management Console Dashboards or Logs for subsequent analysis. Loose Coupling As application complexity increases, a desirable attribute of an IT system is well-design interfaces that enable Apps to be broken into smaller, loosely coupled components (i.e. services or microservices). This means that IT systems should be designed in a way that reduces interdependencies\u2014a change or a failure in one component should not cascade to other components. One way to reduce interdependencies in a system is to allow the various components to interact with each other only through specific, technology-agnostic interfaces (e.g., SOAP or RESTful APIs). In that way, technical implementation detail is hidden so that teams can modify the underlying implementation without affecting other components. As long as those interfaces maintain backwards compatibility, deployments of difference components are decoupled. Other methods include: (1) service discovery such as the Web Services Universal Description, Discovery, and Integration (UDDI) XML-based registry; (2) Asynchronous integration - another form of loose coupling between services suitable for any interaction that does not need an immediate response and where an acknowledgement that a request has been registered will suffice; and (3) Graceful Failure - another way to increase loose coupling by building applications to handle component failure in a graceful manner and identifying features to reduce the impact on end users. Removing Single Points of Failure Production systems typically come with defined or implicit objectives in terms of uptime. A system is highly available when it can withstand the failure of single or multiple components (e.g., hard disks, servers, network links etc.). Solution Architects implement cloud features to automate recovery and reduce disruption at every layer of the architecture. Solution Architects build automation into both detecting and reacting to failure. Cloud services can be configured to perform health checks and mask failure by routing traffic to healthy endpoint components. In addition, Auto Scaling can be configured to automatically replace unhealthy nodes. Data replication techniques can be adopted to increase data durability and availability. Synchronous replication is not recommended for most Apps due to performance issues. Asynchronous replication decouples the primary node from its replicas at the expense of introducing replication lag, however, asynchronous replicas are used to horizontally scale the system\u2019s read capacity for queries that can tolerate that replication lag. It can also be used to increase data durability when some loss of recent transactions can be tolerated during a failover. Quorum-based replication combines synchronous and asynchronous replication to overcome the challenges of large-scale distributed database systems. Security. Most of the security tools and techniques used in a traditional IT on-premises infrastructure can be used in the cloud. At the same time, cloud adoption allows App Owners to improve security in a variety of ways. Cloud platforms allows you to formalize the design of security controls in the platform itself. It simplifies system use for system and database administrators and those running IT SysOps. Cloud adoption makes the IT environment much easier to monitor and audit security controls in a continuous manner.","title":"8.2 Design Principles"},{"location":"modern/8-2-design-principles/#82-design-principles","text":"In this section, we provide design patterns and architectural options that can be applied to the AAM project use cases that are targeted for automated application modernization and migration to the Cloud.","title":"8.2 Design Principles"},{"location":"modern/8-2-design-principles/#scalability","text":"Systems that are expected to grow over time need to be built on top of a scalable architecture. Such an architecture can support growth in users, traffic, or data size with no decrease in performance. It should provide that scale in a linear manner where adding extra resources results in at least a proportional increase in ability to serve additional load. Growth should introduce economies of scale, and cost should follow the same dimension of proportional increases in monthly costs. While cloud computing provides virtually unlimited on-demand capacity, the design needs to be able to take advantage of those resources seamlessly.","title":"Scalability"},{"location":"modern/8-2-design-principles/#disposable-resources-instead-of-fixed-servers","text":"In a traditional infrastructure environment, you have to work with fixed resources due to the upfront cost and lead time of introducing new hardware. This would drive practices like manually logging in to servers to configure software or fix issues, hardcoding IP addresses, running tests or processing jobs sequentially etc. When designing for the cloud Solution Architects have the opportunity to reset that mindset so that architects take advantage of the dynamically provisioned nature of cloud computing. Architects think of servers and other components as temporary resources. Launch as many as you need, and use them only for as long as they are needed. The problem of configuration drift can be solved with the cloud immutable infrastructure pattern. With this approach a server, once launched, is never updated throughout its lifetime. Instead, when there is a problem or a need for an update, the server is replaced with a new one that has the latest configuration. In this way, resources are always in a consistent (and tested) state and rollbacks become easier to perform.","title":"Disposable Resources Instead of Fixed Servers"},{"location":"modern/8-2-design-principles/#automation","text":"In a traditional IT infrastructure, system administrators would often have to manually react to a variety of events. When deploying on the cloud there is a lot of opportunity for automation, so that both the system\u2019s stability and the efficiency of the DevOps and SysOps team is improved. When deploying a new environment for development, test, staging, and deployment or increasing capacity of an existing system to cope with extra load, it is important that DevOps Engineers make this an automated and repeatable process that avoids long lead times and is not prone to human error. Since cloud assets are programmable, DevOps Engineers can apply Infrastructure as Code (IaS) techniques, practices, and tools from software development to make the whole infrastructure reusable, maintainable, extensible, and testable. In addition, common cloud features enable automation to support SysOps administration, for example: \u2022 Auto Scaling: You can maintain application availability and scale your cloud computing capacity up or down automatically according to conditions you define. Auto Scaling can also automatically increase the number of VM instances during demand spikes to maintain performance and decrease capacity during less busy periods to optimize costs. \u2022 System Management Alarms: You can create alarms that sends SMS message when a particular metric goes beyond a specified threshold for a specified number of periods. \u2022 System Management Events: You can set up delivery of a near real-time stream of system events that describe changes in cloud resources. Using simple rules that you can set up in a couple of minutes, you can easily route each type of event to one or more System Management Console Dashboards or Logs for subsequent analysis.","title":"Automation."},{"location":"modern/8-2-design-principles/#loose-coupling","text":"As application complexity increases, a desirable attribute of an IT system is well-design interfaces that enable Apps to be broken into smaller, loosely coupled components (i.e. services or microservices). This means that IT systems should be designed in a way that reduces interdependencies\u2014a change or a failure in one component should not cascade to other components. One way to reduce interdependencies in a system is to allow the various components to interact with each other only through specific, technology-agnostic interfaces (e.g., SOAP or RESTful APIs). In that way, technical implementation detail is hidden so that teams can modify the underlying implementation without affecting other components. As long as those interfaces maintain backwards compatibility, deployments of difference components are decoupled. Other methods include: (1) service discovery such as the Web Services Universal Description, Discovery, and Integration (UDDI) XML-based registry; (2) Asynchronous integration - another form of loose coupling between services suitable for any interaction that does not need an immediate response and where an acknowledgement that a request has been registered will suffice; and (3) Graceful Failure - another way to increase loose coupling by building applications to handle component failure in a graceful manner and identifying features to reduce the impact on end users.","title":"Loose Coupling"},{"location":"modern/8-2-design-principles/#removing-single-points-of-failure","text":"Production systems typically come with defined or implicit objectives in terms of uptime. A system is highly available when it can withstand the failure of single or multiple components (e.g., hard disks, servers, network links etc.). Solution Architects implement cloud features to automate recovery and reduce disruption at every layer of the architecture. Solution Architects build automation into both detecting and reacting to failure. Cloud services can be configured to perform health checks and mask failure by routing traffic to healthy endpoint components. In addition, Auto Scaling can be configured to automatically replace unhealthy nodes. Data replication techniques can be adopted to increase data durability and availability. Synchronous replication is not recommended for most Apps due to performance issues. Asynchronous replication decouples the primary node from its replicas at the expense of introducing replication lag, however, asynchronous replicas are used to horizontally scale the system\u2019s read capacity for queries that can tolerate that replication lag. It can also be used to increase data durability when some loss of recent transactions can be tolerated during a failover. Quorum-based replication combines synchronous and asynchronous replication to overcome the challenges of large-scale distributed database systems.","title":"Removing Single Points of Failure"},{"location":"modern/8-2-design-principles/#security","text":"Most of the security tools and techniques used in a traditional IT on-premises infrastructure can be used in the cloud. At the same time, cloud adoption allows App Owners to improve security in a variety of ways. Cloud platforms allows you to formalize the design of security controls in the platform itself. It simplifies system use for system and database administrators and those running IT SysOps. Cloud adoption makes the IT environment much easier to monitor and audit security controls in a continuous manner.","title":"Security."},{"location":"modern/8-3-design/","text":"8.3 Design In this section we describe design guidance for AAM projects use cases that are targeted for automated application modernization and migration to the Cloud. 8.3.1 Technical Design In the Design stage, the target architecture is developed and documented. The target architecture includes application architecture, and supporting operational components and processes. Members of the sprint team and contractor engineering support team use the information collected during the Discover stage (see Section 8.1) to design the application for the targeted cloud environment. This work depends on the migration pattern and includes a cloud infrastructure architecture document that outlines what services to use. The document also includes information about data flow, foundational elements, database migration, monitoring design, and how the application will consume external resources. In a typical design phase workflow, the \u201clegacy\u201d Application Blueprint report generated in the Discover phase is used to enable a detailed evaluation of the existing system\u2019s design and architecture. The following tasks are performed: Baseline Transformation (Developer-ready): The Application modules are run through the Transformation Engine toolset to generate a detailed initial or baseline transformation of the modernized application. The legacy code is automatically rewritten into the target code with all external operating system calls \u201cstubbed out\u201d. The Application Blueprint and Baseline Transformation Blueprint allow inspection of the baseline App modernization rule set and provide a detailed understanding of the design and architecture of the target system. This is necessary to support planning of the Target Architecture Design, which will guide subsequent steps in the refinement of the AAM process. Target Architecture Design: Definition and development of a detailed plan for implementing the new system\u2019s architecture. This architecture design activity is conducted with the customer\u2019s Product Owner and engineering support Team of architects and analysts and the AAM contractor project engineering team cloud architects and application developers. The deliverable is the Infrastructure Architecture Document. Internal and External Dependency Analysis: This is a detailed analysis of all internal dependencies to aid in iterative development and testing of subsystems of the application in Development Sprints. Transformation Blueprint (Baseline Documentation): A detailed presentation of the structure and flow of the modernized code that supports future code maintenance and any system restructuring and/or enhancement. As defined, the presentation includes Transformed Code and Design Metrics, Navigation Indices, Control Flow Diagrams, Structure Charts, Data Element Tables, State Machine Models, State Transition Tables, Cause Effect Graphs, and hyper-linked source and target code in HTML format. 8.3.2 Cybersecurity Considerations It is considered a best practice to run Static Application Security Test (SAST) tools and Dynamic Application Security Test (DAST) tools on the modernized code to validate developers have applied secure coding standards and the required security controls are properly implemented. DAST tools provide penetration testing and verify that cybersecurity vulnerabilities (i.e. the OWASP Top 10) have been tested for and remediated. The Air Force Common Computing Environment program worked with Amazon AWS and Microsoft Azure to implement the Defense Information System Agency (DISA) add on cloud security features to AWS GovCloud and Azure Government. These add-ons consist of Virtual Data Center Security Stack (VDSS) which provides traditional DMZ security for web applications and a next generation firewall for VPN access to protect cloud hosted workloads. Also implemented in the cloud were DISA\u2019s Virtual Data Center Managed Services (VDMS) to provide cloud connected management and security tools and privileged user access and management for DoD networks and users.","title":"8.3 Design"},{"location":"modern/8-3-design/#83-design","text":"In this section we describe design guidance for AAM projects use cases that are targeted for automated application modernization and migration to the Cloud.","title":"8.3 Design"},{"location":"modern/8-3-design/#831-technical-design","text":"In the Design stage, the target architecture is developed and documented. The target architecture includes application architecture, and supporting operational components and processes. Members of the sprint team and contractor engineering support team use the information collected during the Discover stage (see Section 8.1) to design the application for the targeted cloud environment. This work depends on the migration pattern and includes a cloud infrastructure architecture document that outlines what services to use. The document also includes information about data flow, foundational elements, database migration, monitoring design, and how the application will consume external resources. In a typical design phase workflow, the \u201clegacy\u201d Application Blueprint report generated in the Discover phase is used to enable a detailed evaluation of the existing system\u2019s design and architecture. The following tasks are performed: Baseline Transformation (Developer-ready): The Application modules are run through the Transformation Engine toolset to generate a detailed initial or baseline transformation of the modernized application. The legacy code is automatically rewritten into the target code with all external operating system calls \u201cstubbed out\u201d. The Application Blueprint and Baseline Transformation Blueprint allow inspection of the baseline App modernization rule set and provide a detailed understanding of the design and architecture of the target system. This is necessary to support planning of the Target Architecture Design, which will guide subsequent steps in the refinement of the AAM process. Target Architecture Design: Definition and development of a detailed plan for implementing the new system\u2019s architecture. This architecture design activity is conducted with the customer\u2019s Product Owner and engineering support Team of architects and analysts and the AAM contractor project engineering team cloud architects and application developers. The deliverable is the Infrastructure Architecture Document. Internal and External Dependency Analysis: This is a detailed analysis of all internal dependencies to aid in iterative development and testing of subsystems of the application in Development Sprints. Transformation Blueprint (Baseline Documentation): A detailed presentation of the structure and flow of the modernized code that supports future code maintenance and any system restructuring and/or enhancement. As defined, the presentation includes Transformed Code and Design Metrics, Navigation Indices, Control Flow Diagrams, Structure Charts, Data Element Tables, State Machine Models, State Transition Tables, Cause Effect Graphs, and hyper-linked source and target code in HTML format.","title":"8.3.1 Technical Design"},{"location":"modern/8-3-design/#832-cybersecurity-considerations","text":"It is considered a best practice to run Static Application Security Test (SAST) tools and Dynamic Application Security Test (DAST) tools on the modernized code to validate developers have applied secure coding standards and the required security controls are properly implemented. DAST tools provide penetration testing and verify that cybersecurity vulnerabilities (i.e. the OWASP Top 10) have been tested for and remediated. The Air Force Common Computing Environment program worked with Amazon AWS and Microsoft Azure to implement the Defense Information System Agency (DISA) add on cloud security features to AWS GovCloud and Azure Government. These add-ons consist of Virtual Data Center Security Stack (VDSS) which provides traditional DMZ security for web applications and a next generation firewall for VPN access to protect cloud hosted workloads. Also implemented in the cloud were DISA\u2019s Virtual Data Center Managed Services (VDMS) to provide cloud connected management and security tools and privileged user access and management for DoD networks and users.","title":"8.3.2 Cybersecurity Considerations"},{"location":"modern/8-4-implementation/","text":"8.4 Implementation The Build, Integrate, and Validate phases are performed in tandem in multiple Development Sprints. The legacy code modules undergo Transformation, Refactoring, Testing and Release Integration tasks. Cutover is performed after all development tests have been completed and the modernized application is ready for government acceptance testing. 8.4.1 Build In the Build phase the legacy code modules in the product backlog are assigned to Sprint Teams to undergo Transformation, Refactoring, and Testing tasks. Transformation Task The Transformation Engine automatically rewrites the legacy application from the source into object-oriented platform-specific code. This code also couples the generated code to the relational databases. The Transformation generates object-oriented code in the agreed modern implementation languages (typically Java or C#.NET). It also accurately converts all internal and external interfaces in accordance with the Target Architecture Design by means of external interface resolution or enhancement of the Deployment Cloud Architecture. Resolution of these external interfaces involves writing code that replaces the functionality of the original legacy services with modernized application logic and replacement services on the target platform middleware (e.g. .NET, JSP or ASP framework services). The implementation of the replacement APIs is undertaken by the sprint team developers. Deployment-Ready Compilation assures that the functionally equivalent modernized code module cleanly compiles and links in the target language with the target side framework classes and with API s whose implementations interface with target side framework classes. Unit tests are performed on the completed code. Refactoring Task The sprint team developers refactor the transformed code modules to improve the modernized App\u2019s design, architecture, maintainability and enhance its performance. All semi-automated and automated refactoring operations are carried out to generate redesigned code modules and re-architected application tiers. The design and architecture of the application is captured as it evolves and the series of refactoring operations are applied. Automatic Re-Factoring identifies and remove dead and redundant code by the automated Transformation Engine toolset to improve system maintainability without changing the customer\u2019s legacy system\u2019s functionality. Semi-Automatic and Custom Re-Factoring is used to identify further opportunities for code performance optimization and refinements and enhancements to improve design and architecture. These refactoring work items are specified by the customer\u2019s Product Owner and subject matter experts, and are used to make improvements in a uniform and traceable manner. The sprint team developers are supported by the Transformation SME who assists in the set up and adaptation of the Transformation Engine tool set and hand-coding refactoring process to the customer-specific requirements. The Transformation SME also supports integration of the system with data base and middle tier software components and provides training to the sprint team developers on the tool set. The sprint team developers and Transformation SME runs The Transformation Engine refactoring rule on the target source code modules of the modernized application. The code is regression tested after application of each refactoring operation to verify that the refactoring operation has been applied without loss or distortion of functionality. The Developers perform defect and issue resolution on the refactored modules. 8.4.2 Integrate The output from the Transformation Engine generate default facade pattern objects, (or application programmer interface -APIs) with classes and methods (function prototypes) that are similar in form to the legacy application\u2019s original external interfaces. External interface resolution tasks set up the Transformation Engine to replace default APIs with native APIs implemented in the target architecture host environment interfaces. This task typically involves the Transformation Engine SME working with sprint team developers to build specialized transformation rule sets to replace legacy operating system services interfaces with native framework classes in the target architecture host environment. The database conversion is accomplished by converting legacy database schema into SQL (Oracle Database or SQL Server) relational database structures, adaptation of the modernized application to use the transformed schema, extraction of metadata and data from the database and adaptation and export of this metadata and data into the target data set, with roundtrip validation to prove the equivalence to the original data base. Integration, Functional and Regression Tests are performed on completed target code modules or components to demonstrate \u2018definition of done\u2019 for the target code components interfaces. Any Continuous Integration/Continuous Deployment (CI/CD) pipeline testing process which executes from a non-mainframe platform (such as from a T27 client platform) can be kept unchanged and follow DevSecOps best practices and use the Air Force Common Computing Environment (CCE) DevSecOps Toolchain. 8.4.3 Validate The final Development Sprint iteration merges the latest baseline of the code at the end of the modernization process create the final release integration. All delta areas are identified and regression tests are performed on the needed areas that have changed. The \u201cmodernized\u201d system documentation is generated and a final Transformation Blueprint is delivered to the customer. During the final release integration, the sprint team demonstrates the modernized system to the Product Owner and stakeholders who validate that \u2018definition of done\u2019 and \u201cminimum viable product\u2019 checklist criteria have been completed. The sprint team supports transitioning the system into production. For complex modernized systems the release integration may require several iterations, more exhaustive testing and additional refactoring to achieve final customer acceptance. 8.4.4 Cutover Final Testing During this phase the project sprint team Developers and Testers support User Acceptance Testing and Security Testing (to achieve ATO) of the modernized system in the Staging environment with a subset of the eventual end users or super users. During this phase the sprint team developers and testers will support system rework or Priority 1 and Priority 2 defects and recycle the modernized system release back to Staging environment for validation the defects have been fixed. Documentation During Cutover the sprint team and technical support team support finalization of any system and user documentation. Some documentation is written during Development Sprint iterations, but it typically isn't finalized until the system release itself has been finalized to avoid unnecessary rework. Documentation is treated like any other work item requirement. It is priced, prioritized, and placed in the sprint backlog as a task supported by the Product Owner and Stakeholders. Knowledge Transfer Training of end users, operations staff, and technical support staff is conducted to enable users to work effectively with the modernized system. The final task in Cutover phase is Data migration and then the system is deployed to Production for a shakedown period. The AAM contractor\u2019s Sprint team and technical support team provides support to the operations staff as they place the system into production and resolve any Post-Production issues that may arise.","title":"8.4 Implementation"},{"location":"modern/8-4-implementation/#84-implementation","text":"The Build, Integrate, and Validate phases are performed in tandem in multiple Development Sprints. The legacy code modules undergo Transformation, Refactoring, Testing and Release Integration tasks. Cutover is performed after all development tests have been completed and the modernized application is ready for government acceptance testing.","title":"8.4 Implementation"},{"location":"modern/8-4-implementation/#841-build","text":"In the Build phase the legacy code modules in the product backlog are assigned to Sprint Teams to undergo Transformation, Refactoring, and Testing tasks.","title":"8.4.1 Build"},{"location":"modern/8-4-implementation/#transformation-task","text":"The Transformation Engine automatically rewrites the legacy application from the source into object-oriented platform-specific code. This code also couples the generated code to the relational databases. The Transformation generates object-oriented code in the agreed modern implementation languages (typically Java or C#.NET). It also accurately converts all internal and external interfaces in accordance with the Target Architecture Design by means of external interface resolution or enhancement of the Deployment Cloud Architecture. Resolution of these external interfaces involves writing code that replaces the functionality of the original legacy services with modernized application logic and replacement services on the target platform middleware (e.g. .NET, JSP or ASP framework services). The implementation of the replacement APIs is undertaken by the sprint team developers. Deployment-Ready Compilation assures that the functionally equivalent modernized code module cleanly compiles and links in the target language with the target side framework classes and with API s whose implementations interface with target side framework classes. Unit tests are performed on the completed code.","title":"Transformation Task"},{"location":"modern/8-4-implementation/#refactoring-task","text":"The sprint team developers refactor the transformed code modules to improve the modernized App\u2019s design, architecture, maintainability and enhance its performance. All semi-automated and automated refactoring operations are carried out to generate redesigned code modules and re-architected application tiers. The design and architecture of the application is captured as it evolves and the series of refactoring operations are applied. Automatic Re-Factoring identifies and remove dead and redundant code by the automated Transformation Engine toolset to improve system maintainability without changing the customer\u2019s legacy system\u2019s functionality. Semi-Automatic and Custom Re-Factoring is used to identify further opportunities for code performance optimization and refinements and enhancements to improve design and architecture. These refactoring work items are specified by the customer\u2019s Product Owner and subject matter experts, and are used to make improvements in a uniform and traceable manner. The sprint team developers are supported by the Transformation SME who assists in the set up and adaptation of the Transformation Engine tool set and hand-coding refactoring process to the customer-specific requirements. The Transformation SME also supports integration of the system with data base and middle tier software components and provides training to the sprint team developers on the tool set. The sprint team developers and Transformation SME runs The Transformation Engine refactoring rule on the target source code modules of the modernized application. The code is regression tested after application of each refactoring operation to verify that the refactoring operation has been applied without loss or distortion of functionality. The Developers perform defect and issue resolution on the refactored modules.","title":"Refactoring Task"},{"location":"modern/8-4-implementation/#842-integrate","text":"The output from the Transformation Engine generate default facade pattern objects, (or application programmer interface -APIs) with classes and methods (function prototypes) that are similar in form to the legacy application\u2019s original external interfaces. External interface resolution tasks set up the Transformation Engine to replace default APIs with native APIs implemented in the target architecture host environment interfaces. This task typically involves the Transformation Engine SME working with sprint team developers to build specialized transformation rule sets to replace legacy operating system services interfaces with native framework classes in the target architecture host environment. The database conversion is accomplished by converting legacy database schema into SQL (Oracle Database or SQL Server) relational database structures, adaptation of the modernized application to use the transformed schema, extraction of metadata and data from the database and adaptation and export of this metadata and data into the target data set, with roundtrip validation to prove the equivalence to the original data base. Integration, Functional and Regression Tests are performed on completed target code modules or components to demonstrate \u2018definition of done\u2019 for the target code components interfaces. Any Continuous Integration/Continuous Deployment (CI/CD) pipeline testing process which executes from a non-mainframe platform (such as from a T27 client platform) can be kept unchanged and follow DevSecOps best practices and use the Air Force Common Computing Environment (CCE) DevSecOps Toolchain.","title":"8.4.2 Integrate"},{"location":"modern/8-4-implementation/#843-validate","text":"The final Development Sprint iteration merges the latest baseline of the code at the end of the modernization process create the final release integration. All delta areas are identified and regression tests are performed on the needed areas that have changed. The \u201cmodernized\u201d system documentation is generated and a final Transformation Blueprint is delivered to the customer. During the final release integration, the sprint team demonstrates the modernized system to the Product Owner and stakeholders who validate that \u2018definition of done\u2019 and \u201cminimum viable product\u2019 checklist criteria have been completed. The sprint team supports transitioning the system into production. For complex modernized systems the release integration may require several iterations, more exhaustive testing and additional refactoring to achieve final customer acceptance.","title":"8.4.3 Validate"},{"location":"modern/8-4-implementation/#844-cutover","text":"","title":"8.4.4 Cutover"},{"location":"modern/8-4-implementation/#final-testing","text":"During this phase the project sprint team Developers and Testers support User Acceptance Testing and Security Testing (to achieve ATO) of the modernized system in the Staging environment with a subset of the eventual end users or super users. During this phase the sprint team developers and testers will support system rework or Priority 1 and Priority 2 defects and recycle the modernized system release back to Staging environment for validation the defects have been fixed.","title":"Final Testing"},{"location":"modern/8-4-implementation/#documentation","text":"During Cutover the sprint team and technical support team support finalization of any system and user documentation. Some documentation is written during Development Sprint iterations, but it typically isn't finalized until the system release itself has been finalized to avoid unnecessary rework. Documentation is treated like any other work item requirement. It is priced, prioritized, and placed in the sprint backlog as a task supported by the Product Owner and Stakeholders.","title":"Documentation"},{"location":"modern/8-4-implementation/#knowledge-transfer","text":"Training of end users, operations staff, and technical support staff is conducted to enable users to work effectively with the modernized system. The final task in Cutover phase is Data migration and then the system is deployed to Production for a shakedown period. The AAM contractor\u2019s Sprint team and technical support team provides support to the operations staff as they place the system into production and resolve any Post-Production issues that may arise.","title":"Knowledge Transfer"},{"location":"modern/9-0-overview/","text":"9.0 Measurement and Metrics Service level metrics recommended for a modernized application Service Desk (or Help Desk) are provided in Figure 9.1 . SLA Metrics Description SLA KPI Number of downtime events in the last 12 months (by App) 2 Average amount of downtime per App event in the last 12 months 2 hours Longest App downtime event 4 hours Critical application availability (by App) 99.5% Length of time to recover from last App downtime event 4 hours Number of unplanned App change implementations (emergency and urgent by month) Trend Graph Percentage reduction in the number of App major incidents (IT hosting infrastructure) 20% Reduction in Problem Backlog (by App) 50% Time taken to complete Root Cause Analysis (Average time in days for Tier 2 & Tier 3) 7 days Trouble Ticket Volume (# Tier 1 and Tier 2 by month) Trend Graph First Call Resolution Rate (Tier 1 and Tier 2 % by month) Trend Graph End User Satisfaction Rate (% by month) Trend Graph SLA Compliance Rate (% by month) Trend Graph Figure 9.1. Proposed Service Desk SLA Metrics (Tier 2 and 3). We recommend the Service Desk tool be configured to provide critical incident management notification and workflows to manage a critical incident; for example, an App release failure into production \u2013 an event which disrupts one or more App services. We recommend standardizing incident status and reporting mechanisms via a Service Desk tool Dashboard based on the KPIs in Figure 9-1 . The tool\u2019s Applications Dashboard will enable PMO development and sustainment contractor project teams to manage, monitor, coordinate and communicate status of application performance to PMO stakeholders in a centralized, government-approved format.","title":"9.0 Overview"},{"location":"modern/9-0-overview/#90-measurement-and-metrics","text":"Service level metrics recommended for a modernized application Service Desk (or Help Desk) are provided in Figure 9.1 . SLA Metrics Description SLA KPI Number of downtime events in the last 12 months (by App) 2 Average amount of downtime per App event in the last 12 months 2 hours Longest App downtime event 4 hours Critical application availability (by App) 99.5% Length of time to recover from last App downtime event 4 hours Number of unplanned App change implementations (emergency and urgent by month) Trend Graph Percentage reduction in the number of App major incidents (IT hosting infrastructure) 20% Reduction in Problem Backlog (by App) 50% Time taken to complete Root Cause Analysis (Average time in days for Tier 2 & Tier 3) 7 days Trouble Ticket Volume (# Tier 1 and Tier 2 by month) Trend Graph First Call Resolution Rate (Tier 1 and Tier 2 % by month) Trend Graph End User Satisfaction Rate (% by month) Trend Graph SLA Compliance Rate (% by month) Trend Graph Figure 9.1. Proposed Service Desk SLA Metrics (Tier 2 and 3). We recommend the Service Desk tool be configured to provide critical incident management notification and workflows to manage a critical incident; for example, an App release failure into production \u2013 an event which disrupts one or more App services. We recommend standardizing incident status and reporting mechanisms via a Service Desk tool Dashboard based on the KPIs in Figure 9-1 . The tool\u2019s Applications Dashboard will enable PMO development and sustainment contractor project teams to manage, monitor, coordinate and communicate status of application performance to PMO stakeholders in a centralized, government-approved format.","title":"9.0 Measurement and Metrics"},{"location":"testing/1-1-purpose/","text":"1.1 Purpose AF/A4 published the \"US Air Force Enterprise Logistics Flight Plan v2.0\" (ELFP) in April 2016 and the subordinate document \"Enterprise Logistics Technology Annex\" (ELTA) in June of 2016. This plan and annex describe the desired \"synthesized logistics information\" future state of US Air Force (AF) Enterprise Logistics in 2035. BES believes that in order to maintain a path and schedule to achieve those long-term goals, a series of enabling initiatives are needed to accelerate current progress in order to achieve the necessary near-term milestones. It is the intent of the Business and Enterprise System (BES) to include the resulting Playbooks into the BES Process Directory (BPD) to ensure all members of Air Force Program Executive Office (AFPEO) BES, at all operating locations, have quick easy access to standard processes and templates for Defense Business System programs. DoD continues to recognize the need to apply automated software testing processes and procedures in a more consistent and repeatable manner. The Director of Operational Test & Evaluation (DOT&E) annual reports dating back to 2013 and earlier, show a concerted effort to improve the adoption rate of automation across the DoD. The National Defense Authorization Act (NDAA) for FY 2018 commissioned an Automated Testing Technologies study. There continues to be strong interest across the Services to investigate ways in which automation adoption and momentum can be increased. Defense Acquisition Policy, DoD Instruction 5000.02 and 5000.75 through AFMAN 63-144 contain language that encourages the use of automated testing. With the move towards more flexible and agile approaches to software development comes a greater urgency to implement test automation. This playbook addresses the desire to adopt test automation with practical, experienced-based methods and best practices. Automation Playbook Benefits Defines a common understanding of automation processes and terminology Establishes automation best practices to facilitate adoption by AF community Explains the various roles needed to start and maintain test automation Defines an overall architecture of automation applicable across projects and programs Helps programs understand how to migrate from manual to automated testing","title":"1.1 Purpose"},{"location":"testing/1-1-purpose/#11-purpose","text":"AF/A4 published the \"US Air Force Enterprise Logistics Flight Plan v2.0\" (ELFP) in April 2016 and the subordinate document \"Enterprise Logistics Technology Annex\" (ELTA) in June of 2016. This plan and annex describe the desired \"synthesized logistics information\" future state of US Air Force (AF) Enterprise Logistics in 2035. BES believes that in order to maintain a path and schedule to achieve those long-term goals, a series of enabling initiatives are needed to accelerate current progress in order to achieve the necessary near-term milestones. It is the intent of the Business and Enterprise System (BES) to include the resulting Playbooks into the BES Process Directory (BPD) to ensure all members of Air Force Program Executive Office (AFPEO) BES, at all operating locations, have quick easy access to standard processes and templates for Defense Business System programs. DoD continues to recognize the need to apply automated software testing processes and procedures in a more consistent and repeatable manner. The Director of Operational Test & Evaluation (DOT&E) annual reports dating back to 2013 and earlier, show a concerted effort to improve the adoption rate of automation across the DoD. The National Defense Authorization Act (NDAA) for FY 2018 commissioned an Automated Testing Technologies study. There continues to be strong interest across the Services to investigate ways in which automation adoption and momentum can be increased. Defense Acquisition Policy, DoD Instruction 5000.02 and 5000.75 through AFMAN 63-144 contain language that encourages the use of automated testing. With the move towards more flexible and agile approaches to software development comes a greater urgency to implement test automation. This playbook addresses the desire to adopt test automation with practical, experienced-based methods and best practices.","title":"1.1 Purpose"},{"location":"testing/1-1-purpose/#automation-playbook-benefits","text":"Defines a common understanding of automation processes and terminology Establishes automation best practices to facilitate adoption by AF community Explains the various roles needed to start and maintain test automation Defines an overall architecture of automation applicable across projects and programs Helps programs understand how to migrate from manual to automated testing","title":"Automation Playbook Benefits"},{"location":"testing/1-2-audience/","text":"1.2 Audience This playbook is intended for those individuals responsible for the management and engineering of test automation. It provides managers with the knowledge that will help them support programs looking to implement automation and it will provide engineers with the information they will need to successfully plan the implementation of a test automation solution. The approach is holistic in that it broadly defines many factors, not just technical ones, that are necessary to understand and apply when moving towards automation.","title":"1.2 Audience"},{"location":"testing/1-2-audience/#12-audience","text":"This playbook is intended for those individuals responsible for the management and engineering of test automation. It provides managers with the knowledge that will help them support programs looking to implement automation and it will provide engineers with the information they will need to successfully plan the implementation of a test automation solution. The approach is holistic in that it broadly defines many factors, not just technical ones, that are necessary to understand and apply when moving towards automation.","title":"1.2 Audience"},{"location":"testing/1-3-benefits/","text":"1.3 Benefits of Automated Testing An investment in automation can reap many rewards to the test team and overall project. There are primary and secondary benefits to using automated tools. Primary Benefits The primary benefits to using automation for testing can be summarized as follows: Faster test execution More reliable/repeatable test execution Increased quality from greater test coverage due to additional tests Facilitates testing of more complex scenarios Less error-prone than manual testing More consistent than manual testing Provides for unattended 24/7 test execution Ability to create additional test conditions from single script Reusability of tests within and across test events Ability to test more in the same or shorter time schedule Testing across a variety of software/hardware platforms Allows for the possibility of testing that which could not be tested manually Allows for increased frequency of testing Allows more effective use of testing resources (i.e. more test design, less manual execution) Secondary Benefits Secondary benefits for using automated test tools consist of support activities for testing, rather than the testing itself. These include: User account creation in advance of testing Database seeding with required test data Creation/management of test datasets Test environment configuration setup Pre-test initialization activities Post-test clean-up activities Automated data analysis of concluded test events Project and Program Benefits The use of automation brings benefits beyond testing to the project and program. These include: Improved software quality Earlier defect detection Fewer defects sent to next testing phase Greater efficiency in accomplishing testing Greater relevance of timely test results Reduced risk of deployment Improved test reporting Facilitated identification of defect root causes Reduced test execution cost Shortened test execution period Improved consistency of test executions Better adapted to iterative development where more frequent testing is required Improved feedback related to application quality Improved system reliability through repeatability and consistency of tests","title":"1.3 Benefits of Automated Testing"},{"location":"testing/1-3-benefits/#13-benefits-of-automated-testing","text":"An investment in automation can reap many rewards to the test team and overall project. There are primary and secondary benefits to using automated tools.","title":"1.3 Benefits of Automated Testing"},{"location":"testing/1-3-benefits/#primary-benefits","text":"The primary benefits to using automation for testing can be summarized as follows: Faster test execution More reliable/repeatable test execution Increased quality from greater test coverage due to additional tests Facilitates testing of more complex scenarios Less error-prone than manual testing More consistent than manual testing Provides for unattended 24/7 test execution Ability to create additional test conditions from single script Reusability of tests within and across test events Ability to test more in the same or shorter time schedule Testing across a variety of software/hardware platforms Allows for the possibility of testing that which could not be tested manually Allows for increased frequency of testing Allows more effective use of testing resources (i.e. more test design, less manual execution)","title":"Primary Benefits"},{"location":"testing/1-3-benefits/#secondary-benefits","text":"Secondary benefits for using automated test tools consist of support activities for testing, rather than the testing itself. These include: User account creation in advance of testing Database seeding with required test data Creation/management of test datasets Test environment configuration setup Pre-test initialization activities Post-test clean-up activities Automated data analysis of concluded test events","title":"Secondary Benefits"},{"location":"testing/1-3-benefits/#project-and-program-benefits","text":"The use of automation brings benefits beyond testing to the project and program. These include: Improved software quality Earlier defect detection Fewer defects sent to next testing phase Greater efficiency in accomplishing testing Greater relevance of timely test results Reduced risk of deployment Improved test reporting Facilitated identification of defect root causes Reduced test execution cost Shortened test execution period Improved consistency of test executions Better adapted to iterative development where more frequent testing is required Improved feedback related to application quality Improved system reliability through repeatability and consistency of tests","title":"Project and Program Benefits"},{"location":"testing/10-1-momentum/","text":"10.1 Building Momentum in Test Automation Test automation is not a static activity. Due to its nature, it is not as robust as a full-on software application solution. Automation may require review, evaluation, and tweaking from time to time in order that it continues to support testing activities. Therefore, there should always be someone assigned to monitor and maintain the test automation solution. Automation is additive. From the initial scripts that are automated, more scripts can be developed or reused. In this way, automation helps us build capability similar to stacking bricks to build a wall. Initial automation will be purpose-built, while later automation may be more about stringing prior automated scripts into larger and more complex business processes. Automation can also help with pre- and post-testing activities, as described in section 2.1. These activities often take time to carry out and the use of automation will help reduce the overall test execution activity time. Often other projects with similar technology will benefit from the automation developed. It is far easier to adapt an automation solution to another program than to build it again from scratch.","title":"10.1 Building Momentum in Test Automation"},{"location":"testing/10-1-momentum/#101-building-momentum-in-test-automation","text":"Test automation is not a static activity. Due to its nature, it is not as robust as a full-on software application solution. Automation may require review, evaluation, and tweaking from time to time in order that it continues to support testing activities. Therefore, there should always be someone assigned to monitor and maintain the test automation solution. Automation is additive. From the initial scripts that are automated, more scripts can be developed or reused. In this way, automation helps us build capability similar to stacking bricks to build a wall. Initial automation will be purpose-built, while later automation may be more about stringing prior automated scripts into larger and more complex business processes. Automation can also help with pre- and post-testing activities, as described in section 2.1. These activities often take time to carry out and the use of automation will help reduce the overall test execution activity time. Often other projects with similar technology will benefit from the automation developed. It is far easier to adapt an automation solution to another program than to build it again from scratch.","title":"10.1 Building Momentum in Test Automation"},{"location":"testing/10-2-landscape/","text":"10.2 Keeping Abreast of the Technology Landscape Software development continues to evolve and the SUT will, over time, incorporate these technology updates. The test automation solution must anticipate and adapt to these changes so that automation continues to work reliably and efficiently. It is recommended to perform a tool evaluation on a regular basis (every 2 years is recommended). Many tools, whether COTS, GOTS, or OSS regularly have incremental updates made to them. Before automatically updating the tool to the latest version, it is best to find out what improvements were made to the tool and if those improvements have any impact to the project using those tools. If it makes sense to make the update, this should first be tested in a separate environment to ensure that the update functions properly and does not inadvertently affect any other software or components previously installed. Generally, the latest release will have the latest security updates and features so updates are recommended. When an automated framework is built with modularity in mind, specific components of the framework can be swapped out or swapped in without having to re-write the entire framework. For example, a project that originally used browsers has now migrated to native mobile applications as well. The requirement now is to also support native mobile apps. This could potentially be accomplished in one of several ways: Identify if current tool in use also supports mobile apps Identify add-in component that supports mobile apps Identify new tool that supports mobile apps Each condition allows for a different approach to adding mobile app support to the framework.","title":"10.2 Keeping Abreast of the Technology Landscape"},{"location":"testing/10-2-landscape/#102-keeping-abreast-of-the-technology-landscape","text":"Software development continues to evolve and the SUT will, over time, incorporate these technology updates. The test automation solution must anticipate and adapt to these changes so that automation continues to work reliably and efficiently. It is recommended to perform a tool evaluation on a regular basis (every 2 years is recommended). Many tools, whether COTS, GOTS, or OSS regularly have incremental updates made to them. Before automatically updating the tool to the latest version, it is best to find out what improvements were made to the tool and if those improvements have any impact to the project using those tools. If it makes sense to make the update, this should first be tested in a separate environment to ensure that the update functions properly and does not inadvertently affect any other software or components previously installed. Generally, the latest release will have the latest security updates and features so updates are recommended. When an automated framework is built with modularity in mind, specific components of the framework can be swapped out or swapped in without having to re-write the entire framework. For example, a project that originally used browsers has now migrated to native mobile applications as well. The requirement now is to also support native mobile apps. This could potentially be accomplished in one of several ways: Identify if current tool in use also supports mobile apps Identify add-in component that supports mobile apps Identify new tool that supports mobile apps Each condition allows for a different approach to adding mobile app support to the framework.","title":"10.2 Keeping Abreast of the Technology Landscape"},{"location":"testing/10-3-improvements/","text":"10.3 Continuous Improvement Activities The areas that most benefit from ongoing inspection, review, and improvement will include: Functional script design Functional tests can be analyzed for their overall construction. This will include identifying areas of duplication with other scripts and extracting common functionality which can be better served by calling a shared component. Scripts that are excessively long will likely benefit from modularization. Error trapping Often, things go wrong during testing. This may include predicted and unpredicted errors. When errors occur they can cause havoc with automated tests. One approach to address this is through the use of error trapping. With error trapping we can direct abnormal application behavior to a known state. This is helpful when we have a large number of tests queued up and we do not want to hold up the next testing activity. Timing When executing tests we want the behavior to mimic real user interactions with the system. In order to do this we may need to slow down the rate at which automation interacts with the SUT. Adding a static number of seconds to pause the automation is not recommended as these static pauses can add up and eventually slow down test execution. A better approach is to use dynamic wait statements. These are often implemented by observing the attribute of a control. For example, if we want to make sure that the screen is ready to accept our order, we could dynamically interrogate the order field to make sure it is ready to accept input. This way, whether it takes .05 seconds or 3 seconds, the automation will wait the appropriate time before continuing with the order. Code Base Treat your automation code as any other software development project. This includes frequent reviews, coding guidelines, documentation, and the use of developers to help with some of the more challenging components. Performance After using automation for some time we may find that we are no longer able to execute all of our testing on an overnight run. This will require examining just what scripts are being executed, and evaluating if some of these no longer provide the value they once did and need to be re-written or merged into other more efficient scripts. Performance can also be measured at the component level, where much of the I/O activity occurs. You may want to evaluate if you we using resources effectively. For example, are you writing temporary results to a disk? If so, you may consider writing them to RAM which is much quicker. Script performance will also be affected with timing, as described above. Audit and reporting Understanding of what occurred during test execution can be enhance by audit logs and reporting. Audit logs can be developed that provide a level of granularity that helps us understand everything about our test execution. For example, we could develop a logging function that lets us know what windows were present at any time that the test was running. This make give us clues to windows that were not closed, messaging pop-ups that were not accounted for, or starting conditions that did not meet our expectations. Reporting requirements will come from stakeholders and once they start receiving information they will likely want additional information from the SUT and similar information but expressed differently. Satisfying the needs of stakeholders is an important part of keeping an automation solution viable.","title":"10.3 Continuous Improvement Activities"},{"location":"testing/10-3-improvements/#103-continuous-improvement-activities","text":"The areas that most benefit from ongoing inspection, review, and improvement will include:","title":"10.3 Continuous Improvement Activities"},{"location":"testing/10-3-improvements/#functional-script-design","text":"Functional tests can be analyzed for their overall construction. This will include identifying areas of duplication with other scripts and extracting common functionality which can be better served by calling a shared component. Scripts that are excessively long will likely benefit from modularization.","title":"Functional script design"},{"location":"testing/10-3-improvements/#error-trapping","text":"Often, things go wrong during testing. This may include predicted and unpredicted errors. When errors occur they can cause havoc with automated tests. One approach to address this is through the use of error trapping. With error trapping we can direct abnormal application behavior to a known state. This is helpful when we have a large number of tests queued up and we do not want to hold up the next testing activity.","title":"Error trapping"},{"location":"testing/10-3-improvements/#timing","text":"When executing tests we want the behavior to mimic real user interactions with the system. In order to do this we may need to slow down the rate at which automation interacts with the SUT. Adding a static number of seconds to pause the automation is not recommended as these static pauses can add up and eventually slow down test execution. A better approach is to use dynamic wait statements. These are often implemented by observing the attribute of a control. For example, if we want to make sure that the screen is ready to accept our order, we could dynamically interrogate the order field to make sure it is ready to accept input. This way, whether it takes .05 seconds or 3 seconds, the automation will wait the appropriate time before continuing with the order.","title":"Timing"},{"location":"testing/10-3-improvements/#code-base","text":"Treat your automation code as any other software development project. This includes frequent reviews, coding guidelines, documentation, and the use of developers to help with some of the more challenging components.","title":"Code Base"},{"location":"testing/10-3-improvements/#performance","text":"After using automation for some time we may find that we are no longer able to execute all of our testing on an overnight run. This will require examining just what scripts are being executed, and evaluating if some of these no longer provide the value they once did and need to be re-written or merged into other more efficient scripts. Performance can also be measured at the component level, where much of the I/O activity occurs. You may want to evaluate if you we using resources effectively. For example, are you writing temporary results to a disk? If so, you may consider writing them to RAM which is much quicker. Script performance will also be affected with timing, as described above.","title":"Performance"},{"location":"testing/10-3-improvements/#audit-and-reporting","text":"Understanding of what occurred during test execution can be enhance by audit logs and reporting. Audit logs can be developed that provide a level of granularity that helps us understand everything about our test execution. For example, we could develop a logging function that lets us know what windows were present at any time that the test was running. This make give us clues to windows that were not closed, messaging pop-ups that were not accounted for, or starting conditions that did not meet our expectations. Reporting requirements will come from stakeholders and once they start receiving information they will likely want additional information from the SUT and similar information but expressed differently. Satisfying the needs of stakeholders is an important part of keeping an automation solution viable.","title":"Audit and reporting"},{"location":"testing/10-4-process/","text":"10.4 Making the Process Repeatable Ultimately, we want to learn from our efforts and know that we can do this again for the next project. Repeatability of the process requires a sound overall design, clear implementation, and useful documentation. As the automation evolves, all aspects of its design need to be understood and documented so that as testers are rotated into and out of a program there is a permanence to the automation that was built.","title":"10.4 Making the Process Repeatable"},{"location":"testing/10-4-process/#104-making-the-process-repeatable","text":"Ultimately, we want to learn from our efforts and know that we can do this again for the next project. Repeatability of the process requires a sound overall design, clear implementation, and useful documentation. As the automation evolves, all aspects of its design need to be understood and documented so that as testers are rotated into and out of a program there is a permanence to the automation that was built.","title":"10.4 Making the Process Repeatable"},{"location":"testing/11-1-resources/","text":"11.1 Appendix A: Resources THE FOLLOWING RESOURCES PROVIDE CERTIFICATION AND ACCREDITED TRAINING FOR SOFTWARE TESTING AND TEST AUTOMATION TOPICS: International Software Testing Qualification Board https://www.istqb.org/ As of June 2018, ISTQB has administered over 830,000 exams and issued more than 605,000 certifications in over 120 countries world-wide. The scheme relies on a Body of Knowledge (Syllabi and Glossary) and exam rules that are applied consistently all over the world, with exams and supporting material being available in many languages. American Software Testing Qualification Board https://www.astqb.org/ The mission of ASTQB is to promote professionalism in Software Testing in the United States. We do this by providing and administering quality exams for the ISTQB, ASTQB and IQBBA certifications, by supporting and facilitating software training providers in delivering high quality courses, by actively engaging in the ISTQB working groups, and by supporting efforts to develop and encourage people who are already in or are entering the software testing profession. ASQ https://asq.org/cert/software-quality-engineer With individual and organizational members around the world, ASQ has the reputation and reach to bring together the diverse quality champions who are transforming the world's corporations, organizations and communities to meet tomorrow's critical challenges. The Certified Software Quality Engineer understands software quality development and implementation, software inspection, testing, verification and validation, and implements software development and maintenance processes and methods. QAI Global http://www.qaiusa.com/software-certifications/software-testing-certifications/ As the IT industry becomes more competitive, the ability for management to distinguish professional and skilled individuals in the field becomes mandatory. QAI Global Institute is the global program administrator for the International Software Certification Board (ISCB). Software Certifications has become recognized worldwide as the standard for information technology quality professionals - having certified over 50,000 professionals. ISCB test centers are located in 135 countries across 6 continents. Software certifications cover five major domains and provide eleven professional certifications. These internationally-recognized, examination-based and vendor-independent programs provide full career paths for professionals at all levels. THE FOLLOWING RESOURCES PROVIDE REPORTING ON AUTOMATED TEST TOOL TOPICS: Magic Quadrant for Software Testing Tools https://www.gartner.com/home The need to support faster time to market with higher quality is driving the demand for effective functional test automation tools. We evaluate vendors in this space to help application leaders who are modernizing software development select test automation tools that best match their needs. (note: may require subscription for access to reports) Carnegie Melon University Software Engineering Institute - The Importance of Automated Testing in Open Systems Architecture Initiatives https://insights.sei.cmu.edu/sei_blog/2014/03/the-importance-of-automated-testing-in-open-systems-architecture-initiatives.html The Better Buying Power 2.0 initiative is a concerted effort by the United States Department of Defense to achieve greater efficiencies in the development, sustainment, and re-competition of major defense acquisition programs through cost control, elimination of unproductive processes and bureaucracy, and promotion of open competition. Carnegie Melon University Software Engineering Institute - Five Keys to Effective Agile Test Automation for Government Programs https://resources.sei.cmu.edu/library/asset-view.cfm?assetid=503507 In this discussion-focused webinar, Bob Binder and SuZ Miller will discuss 5 key questions that government organizations contemplating embarking on adopting automated test techniques and tools in an Agile environment are likely to have. THE FOLLOWING RESOURCES PROVIDE FOR COLLABORATIVE DISCUSSIONS AROUND TEST TOOL TOPICS: SW Test Academy https://www.swtestacademy.com/ SW Test Academy (STA) is focused on mainly technical testing topics. In this site, you can find comprehensive descriptions and examples of test automation, performance testing, mobile testing, web service testing, API testing, DevOps, continuous integration, and similar topics. QA Testing Tools http://qatestingtools.com/ QA Testing Tools is an innovative platform and is the only website that gives you an Opportunity to read technical reviews on every software-testing tool, simultaneously giving you in-depth technical information, and comparison tables that direct you towards the most suitable group of tools to fulfill your requirements. Automate the Planet https://www.automatetheplanet.com/resources/ Learn how to write automated tests through working real-world examples. Stack Overflow https://stackoverflow.com/ Each month, over 50 million developers come to Stack Overflow to learn, share their knowledge, and build their careers. Software Testing and Quality Assurance Forums http://www.sqaforums.com/forums/ The online community for software testing and quality assurance professionals. Open Source Testing http://www.opensourcetesting.org/ The open source testing site aims to boost the profile of open source testing tools within the testing industry, principally by providing users with an easy to use gateway to information on the wide range of open source testing tools available. Test Automation Group on LinkedIn https://www.linkedin.com/groups/86204 LinkedIn is the world's largest professional network with more than 562 million users in more than 200 countries and territories worldwide. The Test Automation LinkedIn group is for people that are interested in QA test automation. The following issues can be found in the group discussions: Automation frameworks, Selenium, QTP, Web automation, Automation ROI, TestComplete, XUnit, JUnit, NUnit, JSystem, Automation strategics, Mobile testing (Android, iPhone, Blackberry), Load, agile, jobs and more! (Note: There are several additional groups in LinkedIn that cover test automation topics and specific tools)","title":"11.1 Appendix A: Resources"},{"location":"testing/11-1-resources/#111-appendix-a-resources","text":"","title":"11.1 Appendix A: Resources"},{"location":"testing/11-1-resources/#the-following-resources-provide-certification-and-accredited-training-for-software-testing-and-test-automation-topics","text":"","title":"THE FOLLOWING RESOURCES PROVIDE CERTIFICATION AND ACCREDITED TRAINING FOR SOFTWARE TESTING AND TEST AUTOMATION TOPICS:"},{"location":"testing/11-1-resources/#international-software-testing-qualification-board","text":"https://www.istqb.org/ As of June 2018, ISTQB has administered over 830,000 exams and issued more than 605,000 certifications in over 120 countries world-wide. The scheme relies on a Body of Knowledge (Syllabi and Glossary) and exam rules that are applied consistently all over the world, with exams and supporting material being available in many languages.","title":"International Software Testing Qualification Board"},{"location":"testing/11-1-resources/#american-software-testing-qualification-board","text":"https://www.astqb.org/ The mission of ASTQB is to promote professionalism in Software Testing in the United States. We do this by providing and administering quality exams for the ISTQB, ASTQB and IQBBA certifications, by supporting and facilitating software training providers in delivering high quality courses, by actively engaging in the ISTQB working groups, and by supporting efforts to develop and encourage people who are already in or are entering the software testing profession.","title":"American Software Testing Qualification Board"},{"location":"testing/11-1-resources/#asq","text":"https://asq.org/cert/software-quality-engineer With individual and organizational members around the world, ASQ has the reputation and reach to bring together the diverse quality champions who are transforming the world's corporations, organizations and communities to meet tomorrow's critical challenges. The Certified Software Quality Engineer understands software quality development and implementation, software inspection, testing, verification and validation, and implements software development and maintenance processes and methods.","title":"ASQ"},{"location":"testing/11-1-resources/#qai-global","text":"http://www.qaiusa.com/software-certifications/software-testing-certifications/ As the IT industry becomes more competitive, the ability for management to distinguish professional and skilled individuals in the field becomes mandatory. QAI Global Institute is the global program administrator for the International Software Certification Board (ISCB). Software Certifications has become recognized worldwide as the standard for information technology quality professionals - having certified over 50,000 professionals. ISCB test centers are located in 135 countries across 6 continents. Software certifications cover five major domains and provide eleven professional certifications. These internationally-recognized, examination-based and vendor-independent programs provide full career paths for professionals at all levels.","title":"QAI Global"},{"location":"testing/11-1-resources/#the-following-resources-provide-reporting-on-automated-test-tool-topics","text":"","title":"THE FOLLOWING RESOURCES PROVIDE REPORTING ON AUTOMATED TEST TOOL TOPICS:"},{"location":"testing/11-1-resources/#magic-quadrant-for-software-testing-tools","text":"https://www.gartner.com/home The need to support faster time to market with higher quality is driving the demand for effective functional test automation tools. We evaluate vendors in this space to help application leaders who are modernizing software development select test automation tools that best match their needs. (note: may require subscription for access to reports)","title":"Magic Quadrant for Software Testing Tools"},{"location":"testing/11-1-resources/#carnegie-melon-university-software-engineering-institute-the-importance-of-automated-testing-in-open-systems-architecture-initiatives","text":"https://insights.sei.cmu.edu/sei_blog/2014/03/the-importance-of-automated-testing-in-open-systems-architecture-initiatives.html The Better Buying Power 2.0 initiative is a concerted effort by the United States Department of Defense to achieve greater efficiencies in the development, sustainment, and re-competition of major defense acquisition programs through cost control, elimination of unproductive processes and bureaucracy, and promotion of open competition.","title":"Carnegie Melon University Software Engineering Institute - The Importance of Automated Testing in Open Systems Architecture Initiatives"},{"location":"testing/11-1-resources/#carnegie-melon-university-software-engineering-institute-five-keys-to-effective-agile-test-automation-for-government-programs","text":"https://resources.sei.cmu.edu/library/asset-view.cfm?assetid=503507 In this discussion-focused webinar, Bob Binder and SuZ Miller will discuss 5 key questions that government organizations contemplating embarking on adopting automated test techniques and tools in an Agile environment are likely to have.","title":"Carnegie Melon University Software Engineering Institute - Five Keys to Effective Agile Test Automation for Government Programs"},{"location":"testing/11-1-resources/#the-following-resources-provide-for-collaborative-discussions-around-test-tool-topics","text":"","title":"THE FOLLOWING RESOURCES PROVIDE FOR COLLABORATIVE DISCUSSIONS AROUND TEST TOOL TOPICS:"},{"location":"testing/11-1-resources/#sw-test-academy","text":"https://www.swtestacademy.com/ SW Test Academy (STA) is focused on mainly technical testing topics. In this site, you can find comprehensive descriptions and examples of test automation, performance testing, mobile testing, web service testing, API testing, DevOps, continuous integration, and similar topics.","title":"SW Test Academy"},{"location":"testing/11-1-resources/#qa-testing-tools","text":"http://qatestingtools.com/ QA Testing Tools is an innovative platform and is the only website that gives you an Opportunity to read technical reviews on every software-testing tool, simultaneously giving you in-depth technical information, and comparison tables that direct you towards the most suitable group of tools to fulfill your requirements.","title":"QA Testing Tools"},{"location":"testing/11-1-resources/#automate-the-planet","text":"https://www.automatetheplanet.com/resources/ Learn how to write automated tests through working real-world examples.","title":"Automate the Planet"},{"location":"testing/11-1-resources/#stack-overflow","text":"https://stackoverflow.com/ Each month, over 50 million developers come to Stack Overflow to learn, share their knowledge, and build their careers.","title":"Stack Overflow"},{"location":"testing/11-1-resources/#software-testing-and-quality-assurance-forums","text":"http://www.sqaforums.com/forums/ The online community for software testing and quality assurance professionals.","title":"Software Testing and Quality Assurance Forums"},{"location":"testing/11-1-resources/#open-source-testing","text":"http://www.opensourcetesting.org/ The open source testing site aims to boost the profile of open source testing tools within the testing industry, principally by providing users with an easy to use gateway to information on the wide range of open source testing tools available.","title":"Open Source Testing"},{"location":"testing/11-1-resources/#test-automation-group-on-linkedin","text":"https://www.linkedin.com/groups/86204 LinkedIn is the world's largest professional network with more than 562 million users in more than 200 countries and territories worldwide. The Test Automation LinkedIn group is for people that are interested in QA test automation. The following issues can be found in the group discussions: Automation frameworks, Selenium, QTP, Web automation, Automation ROI, TestComplete, XUnit, JUnit, NUnit, JSystem, Automation strategics, Mobile testing (Android, iPhone, Blackberry), Load, agile, jobs and more! (Note: There are several additional groups in LinkedIn that cover test automation topics and specific tools)","title":"Test Automation Group on LinkedIn"},{"location":"testing/11-2-tools/","text":"11.2 Appendix B: Test Tools KEY: M - Test Management/Reporting F - Functional/Regression Testing P - Performance Testing/Monitoring S - Security Testing","title":"11.2 Appendix B: Test Tools"},{"location":"testing/11-2-tools/#112-appendix-b-test-tools","text":"KEY: M - Test Management/Reporting F - Functional/Regression Testing P - Performance Testing/Monitoring S - Security Testing","title":"11.2 Appendix B: Test Tools"},{"location":"testing/2-1-what/","text":"2.1 What is Automation? Automation, in its simplest form, is the mechanization of a manual process that allows for that process to operate automatically. There are many applications of automation, and there are many ways in which we can test. Using automation allows us to mechanize an otherwise manual process for testing. There are many additional uses for automation, that are not specifically for testing, that can be performed with automated test tools. Examples of these may include pre-test activities such as creating user accounts and building data sets, which will ultimately be used in automated testing. Functional and regression test activities are those most frequently targeted for the use of automated testing. Additional uses for automation of tests include API testing, performance testing, security testing, and automation of test management activities.","title":"2.1 What is Automation?"},{"location":"testing/2-1-what/#21-what-is-automation","text":"Automation, in its simplest form, is the mechanization of a manual process that allows for that process to operate automatically. There are many applications of automation, and there are many ways in which we can test. Using automation allows us to mechanize an otherwise manual process for testing. There are many additional uses for automation, that are not specifically for testing, that can be performed with automated test tools. Examples of these may include pre-test activities such as creating user accounts and building data sets, which will ultimately be used in automated testing. Functional and regression test activities are those most frequently targeted for the use of automated testing. Additional uses for automation of tests include API testing, performance testing, security testing, and automation of test management activities.","title":"2.1 What is Automation?"},{"location":"testing/2-2-lifecycle/","text":"2.2 Automation in Software Lifecycle Methodologies Software development methodologies are evolving from traditional Waterfall to more recent Agile approaches. Testing is part of the overall software development process. When implementing testing automation, it must align with and conform to the project management methodology. In projects using Waterfall project management, cycles for development are long and the automation team can plan accordingly. This would include setting up many of the functions and components and building an automation framework. With Agile projects, there isn't as much time within each sprint to build out a complete automation framework so alternate solutions should be identified.","title":"2.2 Automation in Software Lifecycle Methodologies"},{"location":"testing/2-2-lifecycle/#22-automation-in-software-lifecycle-methodologies","text":"Software development methodologies are evolving from traditional Waterfall to more recent Agile approaches. Testing is part of the overall software development process. When implementing testing automation, it must align with and conform to the project management methodology. In projects using Waterfall project management, cycles for development are long and the automation team can plan accordingly. This would include setting up many of the functions and components and building an automation framework. With Agile projects, there isn't as much time within each sprint to build out a complete automation framework so alternate solutions should be identified.","title":"2.2 Automation in Software Lifecycle Methodologies"},{"location":"testing/2-3-benefits/","text":"2.3 Benefits to AF The AF is continually enhancing, upgrading, and/or replacing software systems and applications to meet mission and user needs. This presents an ideal opportunity to introduce test automation practices so that future iterations of the software development process will show greater: testing efficiency through faster execution testing effectiveness through additional functional coverage test repeatability through programmed execution improvement in timely reporting of system quality","title":"2.3 Benefits to AF"},{"location":"testing/2-3-benefits/#23-benefits-to-af","text":"The AF is continually enhancing, upgrading, and/or replacing software systems and applications to meet mission and user needs. This presents an ideal opportunity to introduce test automation practices so that future iterations of the software development process will show greater: testing efficiency through faster execution testing effectiveness through additional functional coverage test repeatability through programmed execution improvement in timely reporting of system quality","title":"2.3 Benefits to AF"},{"location":"testing/2-4-pitfalls/","text":"2.4 Avoiding Pitfalls Individuals involved in testing and test automation come from various walks of life. There is no Tester University or College of Automation. This creates a situation where there is a lack of consistency and knowledge that someone in this line of work should know in order to perform effectively. Over time there have been training and certification programs in DoD and industry that support the need for skills and knowledge of career testers and automators. However, success in automation is not solely a technical challenge. It is a multifaceted discipline requiring management, engineering, and other disciplines. This Test Automation Playbook will guide the AF on how to best approach automated testing.","title":"2.4 Avoiding Pitfalls"},{"location":"testing/2-4-pitfalls/#24-avoiding-pitfalls","text":"Individuals involved in testing and test automation come from various walks of life. There is no Tester University or College of Automation. This creates a situation where there is a lack of consistency and knowledge that someone in this line of work should know in order to perform effectively. Over time there have been training and certification programs in DoD and industry that support the need for skills and knowledge of career testers and automators. However, success in automation is not solely a technical challenge. It is a multifaceted discipline requiring management, engineering, and other disciplines. This Test Automation Playbook will guide the AF on how to best approach automated testing.","title":"2.4 Avoiding Pitfalls"},{"location":"testing/3-1-acquisitions/","text":"3.1 Acquisitions Automated testing is an integral part of modern software development. As such, requirements for automated testing should be identified in the requirement document (e.g., Statement of Objective or Statement of Work). It is essential to establish best practices as requirements at the onset of all new software acquisitions, not only to ensure they are delivered during execution, but to ensure quality vendors respond. The DoD 5000 already prescribes such requirements. Specifically, DoD Instruction (DoDI) 5000.02 defines, under DT&E Planning Considerations, the requirement to \"develop a software test automation strategy\" and under OT&E for software, for regression tests to be \"preferably automated.\" This policy, now superseded by policy 5000.75 for business systems and implemented with AFMAN 63-144, includes a directive to \"Employ effective use of integrated testing and automated software test tools.\" Acquisition guidelines should be stated at the objective level, however, they should allow for the ability for the contractor to recommend industry best testing tools that may be implemented with Government approval. The goal is to obtain the best solution for the program and the Government. Many contracting organizations with automation skills have honed the techniques necessary to deliver quality, reliable automated test solutions. If it is envisioned that government will take over the use and management of the automated testing suite, guidelines for training and transitioning of the solution should be required as part of the Statement of Objective or Statement of Work. If a different technology is envisioned for any continuation of test automation, then the test data used to drive the automation should be delivered in a standardized manner that allows for reusability and adaptability to another automated solution.","title":"3.1 Acquisitions"},{"location":"testing/3-1-acquisitions/#31-acquisitions","text":"Automated testing is an integral part of modern software development. As such, requirements for automated testing should be identified in the requirement document (e.g., Statement of Objective or Statement of Work). It is essential to establish best practices as requirements at the onset of all new software acquisitions, not only to ensure they are delivered during execution, but to ensure quality vendors respond. The DoD 5000 already prescribes such requirements. Specifically, DoD Instruction (DoDI) 5000.02 defines, under DT&E Planning Considerations, the requirement to \"develop a software test automation strategy\" and under OT&E for software, for regression tests to be \"preferably automated.\" This policy, now superseded by policy 5000.75 for business systems and implemented with AFMAN 63-144, includes a directive to \"Employ effective use of integrated testing and automated software test tools.\" Acquisition guidelines should be stated at the objective level, however, they should allow for the ability for the contractor to recommend industry best testing tools that may be implemented with Government approval. The goal is to obtain the best solution for the program and the Government. Many contracting organizations with automation skills have honed the techniques necessary to deliver quality, reliable automated test solutions. If it is envisioned that government will take over the use and management of the automated testing suite, guidelines for training and transitioning of the solution should be required as part of the Statement of Objective or Statement of Work. If a different technology is envisioned for any continuation of test automation, then the test data used to drive the automation should be delivered in a standardized manner that allows for reusability and adaptability to another automated solution.","title":"3.1 Acquisitions"},{"location":"testing/3-2-management/","text":"3.2 Management Support The role of management, at all levels, is key to the success of test automation in AF programs. Management can: Identify projects and programs where automation would likely provide benefits to the overall testing process Identify staff (government or contractors) who can be targeted to deliver automated solutions Identify relevant training and certification to ready staff for automation Anticipate funding requirements for test automation resources (people, tools, environments, process adjustment) Ensure that an adequate assessment of test tools takes place through market research and evaluation Provide equipment and environments in which to develop and execute automation Adopt cross-enterprise \"Best Practices\" for sharing of test automation methods and technology Define contract structures and CLINs that promote use of automation 3.2.1 Identifying and Funding Resources From a funding perspective, there are three areas a manager should consider when planning for test automation. People Who will be tasked to do the automation? And who will be implementing the testing tools framework? Government staff? Contractors? A combination? This needs to be decided on up front as it will affect the process by which these resources are identified and the timeframe under which they can be brought in to accomplish the work, including any training time required prior to project start. If the automation skillset is not easily found within government, a first step might be to contract the work out to an organization with expertise in this area. This will save time and money, and avoid missteps. Test Tools Software test tools have costs associated with licenses, maintenance, training, and support. Even tools that are open source software will require maintenance, training, and possibly support. However, the absence of an initial license fee may provide a significant cost savings (see section 6.3). This playbook will describe industry standard testing tools and the trade-offs between open source versus Commercial-Off-The-Shelf (COTS) software. Test Environments Test environments where automated tools reside can include: - An individual tester's workstation - A test lab with specific computers dedicated to automation - A server with virtual machine images - A cloud-based setup - A cloud-based service (SaaS)","title":"3.2 Management Support"},{"location":"testing/3-2-management/#32-management-support","text":"The role of management, at all levels, is key to the success of test automation in AF programs. Management can: Identify projects and programs where automation would likely provide benefits to the overall testing process Identify staff (government or contractors) who can be targeted to deliver automated solutions Identify relevant training and certification to ready staff for automation Anticipate funding requirements for test automation resources (people, tools, environments, process adjustment) Ensure that an adequate assessment of test tools takes place through market research and evaluation Provide equipment and environments in which to develop and execute automation Adopt cross-enterprise \"Best Practices\" for sharing of test automation methods and technology Define contract structures and CLINs that promote use of automation","title":"3.2 Management Support"},{"location":"testing/3-2-management/#321-identifying-and-funding-resources","text":"From a funding perspective, there are three areas a manager should consider when planning for test automation.","title":"3.2.1 Identifying and Funding Resources"},{"location":"testing/3-2-management/#people","text":"Who will be tasked to do the automation? And who will be implementing the testing tools framework? Government staff? Contractors? A combination? This needs to be decided on up front as it will affect the process by which these resources are identified and the timeframe under which they can be brought in to accomplish the work, including any training time required prior to project start. If the automation skillset is not easily found within government, a first step might be to contract the work out to an organization with expertise in this area. This will save time and money, and avoid missteps.","title":"People"},{"location":"testing/3-2-management/#test-tools","text":"Software test tools have costs associated with licenses, maintenance, training, and support. Even tools that are open source software will require maintenance, training, and possibly support. However, the absence of an initial license fee may provide a significant cost savings (see section 6.3). This playbook will describe industry standard testing tools and the trade-offs between open source versus Commercial-Off-The-Shelf (COTS) software.","title":"Test Tools"},{"location":"testing/3-2-management/#test-environments","text":"Test environments where automated tools reside can include: - An individual tester's workstation - A test lab with specific computers dedicated to automation - A server with virtual machine images - A cloud-based setup - A cloud-based service (SaaS)","title":"Test Environments"},{"location":"testing/3-3-technical/","text":"3.3 Technical Support Developer The software developer plays a key role in supporting the test automation team. The developer has first-hand knowledge of the tools and methods used to construct the software and system. This information will help guide the automation team in the evaluation and selection of tools that are compatible with the tools selected by the development team. Often developers can further aid the automation effort (and associated maintenance) by using uniquely identifiable names for objects/controls displayed by the software application. This is equally applicable to client-based or browser-based solutions. The key point here is that a little forethought by the developers can go a long way to facilitate the recognition of objects/controls by the automation team. For example, we avoid a common scenario where the properties of an application for a user \"name\" and user \"account\" show up as U25523 and A00056 within the automation tool rather than USER_NAME and USER_ACCOUNT. Database Administrator Data forms a large part of tests, and test automation amplifies this. The role of the Database Administrator is key in assisting the needs of the automation team. These may include: Assistance in configuring and selecting a database which emulates a production-like database The ability to restore or revert a database to an earlier condition for retesting Assistance in executing direct queries against the database in order to validate application behavior Systems Administrator The System Administrator (SA) ensures that the system, including software, network, and interfaces are available to the test automation team. Additionally, the SA controls the updates (patches, security releases, etc.) that are applied to the servers on which the test automation solution runs. This coordination is very important as any changes to the underlying system may have consequences to the reliability of the test automation solution, with the possibility that it ceases to function. The SA will also help the automation team with any updates to automation software that need to installed on the testing infrastructure and can assist the test automation team by providing an environment that emulates a production-like environment.","title":"3.3 Technical Support"},{"location":"testing/3-3-technical/#33-technical-support","text":"","title":"3.3 Technical Support"},{"location":"testing/3-3-technical/#developer","text":"The software developer plays a key role in supporting the test automation team. The developer has first-hand knowledge of the tools and methods used to construct the software and system. This information will help guide the automation team in the evaluation and selection of tools that are compatible with the tools selected by the development team. Often developers can further aid the automation effort (and associated maintenance) by using uniquely identifiable names for objects/controls displayed by the software application. This is equally applicable to client-based or browser-based solutions. The key point here is that a little forethought by the developers can go a long way to facilitate the recognition of objects/controls by the automation team. For example, we avoid a common scenario where the properties of an application for a user \"name\" and user \"account\" show up as U25523 and A00056 within the automation tool rather than USER_NAME and USER_ACCOUNT.","title":"Developer"},{"location":"testing/3-3-technical/#database-administrator","text":"Data forms a large part of tests, and test automation amplifies this. The role of the Database Administrator is key in assisting the needs of the automation team. These may include: Assistance in configuring and selecting a database which emulates a production-like database The ability to restore or revert a database to an earlier condition for retesting Assistance in executing direct queries against the database in order to validate application behavior","title":"Database Administrator"},{"location":"testing/3-3-technical/#systems-administrator","text":"The System Administrator (SA) ensures that the system, including software, network, and interfaces are available to the test automation team. Additionally, the SA controls the updates (patches, security releases, etc.) that are applied to the servers on which the test automation solution runs. This coordination is very important as any changes to the underlying system may have consequences to the reliability of the test automation solution, with the possibility that it ceases to function. The SA will also help the automation team with any updates to automation software that need to installed on the testing infrastructure and can assist the test automation team by providing an environment that emulates a production-like environment.","title":"Systems Administrator"},{"location":"testing/3-4-domain/","text":"3.4 Domain Support The Business User, Business Analyst, Product Owner, and other similar roles are subject matter experts (SMEs) when it comes to understanding how the software should work and what it needs to do in order to meet stated requirements, objectives and defined user stories. Domain knowledge is hard to come by and usually comes from individuals who have had or continue to have direct roles in using the business functionality that a system provides. These are the go-to people when a thorough understanding of use cases is required.","title":"3.4 Domain Support"},{"location":"testing/3-4-domain/#34-domain-support","text":"The Business User, Business Analyst, Product Owner, and other similar roles are subject matter experts (SMEs) when it comes to understanding how the software should work and what it needs to do in order to meet stated requirements, objectives and defined user stories. Domain knowledge is hard to come by and usually comes from individuals who have had or continue to have direct roles in using the business functionality that a system provides. These are the go-to people when a thorough understanding of use cases is required.","title":"3.4 Domain Support"},{"location":"testing/3-5-team/","text":"3.5 Automation Team Members The roles of the core automation team are important to define up front. The individuals filling those roles should have the necessary skills and experience to properly implement a maintainable, expandable automation solution. They should also be current on industry standards and have the ability to provide recommendations for changes based on the environment and user needs. The following roles can be assigned to individuals or could be performed by one or more individuals, depending on the complexity of the software project. Test Automation Architect The Automation Architect is the senior Subject Matter Expert (SME) in automation and is responsible for the overall design and implementation of a test automation solution. The automation architecture will be dependent on many factors, including: complexity of the system or software under test (SUT); number of interfaces to other systems or subsystems; richness of the Integrated Development Environment (IDE) controls; and technical level of automation team. The Architect needs to have a broad vision of what current and forthcoming requirements for automation may be based on for overall system architectures. Selecting appropriate tools to meet a diverse set of needs and understanding how multiple tools may need to be integrated for complex testing and reporting requirements will need to be considered as part of the planning process. Test Automation Engineer The Test Automation Engineer is an intermediate-level technical individual who is responsible for developing and maintaining automation components and subsystems. This may include development of purpose-built functions, creation of function libraries, and documentation of the test automation components. As new requirements for automation are defined (e.g. a new \"calendar\" control being added) the automation engineer makes the appropriate updates/additions to the test automation solution, including documentation, to incorporate the new functionality. There may be multiple roles for an automation engineer which may include: Development of input/output (I/O) functions Development of test interfaces to external systems Development of user interface (UI) component test functions Development of navigational paradigms across the application Development of timing and synchronization requirements Development of logging and reporting functions Test Automation User The Test Automation User is the individual or individuals who are the \"customer\" of the test automation solution. They need not be concerned with the technical implementation of a test automation solution, but rather with the ability to use automation to execute tests and report findings. A properly designed test automation solution will allow a user to select a test, the corresponding data set, and run the test. At the conclusion of the test execution, the user should be presented with a report indicating the pass/fail status of the test and any information gathered as a result of a passed/failed test. Often the user of test automation will be a manual tester, a business analyst, or another individual with a strong understanding of the software or system and the requirements that it needs to meet. These individuals may not have programming backgrounds and would not be productive or motivated to take on the role of an automation engineer. By identifying and assigning roles based on skills we are able to keep each individual fully productive and motivated and allow automation to be used by the team, not just by select technical individuals.","title":"3.5 Automation Team Members"},{"location":"testing/3-5-team/#35-automation-team-members","text":"The roles of the core automation team are important to define up front. The individuals filling those roles should have the necessary skills and experience to properly implement a maintainable, expandable automation solution. They should also be current on industry standards and have the ability to provide recommendations for changes based on the environment and user needs. The following roles can be assigned to individuals or could be performed by one or more individuals, depending on the complexity of the software project.","title":"3.5 Automation Team Members"},{"location":"testing/3-5-team/#test-automation-architect","text":"The Automation Architect is the senior Subject Matter Expert (SME) in automation and is responsible for the overall design and implementation of a test automation solution. The automation architecture will be dependent on many factors, including: complexity of the system or software under test (SUT); number of interfaces to other systems or subsystems; richness of the Integrated Development Environment (IDE) controls; and technical level of automation team. The Architect needs to have a broad vision of what current and forthcoming requirements for automation may be based on for overall system architectures. Selecting appropriate tools to meet a diverse set of needs and understanding how multiple tools may need to be integrated for complex testing and reporting requirements will need to be considered as part of the planning process.","title":"Test Automation Architect"},{"location":"testing/3-5-team/#test-automation-engineer","text":"The Test Automation Engineer is an intermediate-level technical individual who is responsible for developing and maintaining automation components and subsystems. This may include development of purpose-built functions, creation of function libraries, and documentation of the test automation components. As new requirements for automation are defined (e.g. a new \"calendar\" control being added) the automation engineer makes the appropriate updates/additions to the test automation solution, including documentation, to incorporate the new functionality. There may be multiple roles for an automation engineer which may include: Development of input/output (I/O) functions Development of test interfaces to external systems Development of user interface (UI) component test functions Development of navigational paradigms across the application Development of timing and synchronization requirements Development of logging and reporting functions","title":"Test Automation Engineer"},{"location":"testing/3-5-team/#test-automation-user","text":"The Test Automation User is the individual or individuals who are the \"customer\" of the test automation solution. They need not be concerned with the technical implementation of a test automation solution, but rather with the ability to use automation to execute tests and report findings. A properly designed test automation solution will allow a user to select a test, the corresponding data set, and run the test. At the conclusion of the test execution, the user should be presented with a report indicating the pass/fail status of the test and any information gathered as a result of a passed/failed test. Often the user of test automation will be a manual tester, a business analyst, or another individual with a strong understanding of the software or system and the requirements that it needs to meet. These individuals may not have programming backgrounds and would not be productive or motivated to take on the role of an automation engineer. By identifying and assigning roles based on skills we are able to keep each individual fully productive and motivated and allow automation to be used by the team, not just by select technical individuals.","title":"Test Automation User"},{"location":"testing/4-1-tools/","text":"4.1 Tools Target Areas Test automation tools support the full software development lifecycle. There is likely a tool for every aspect of software that is developed. Tools are categorized by types of testing they can perform. Test types can span multiple test levels (e.g. component, integration, system, etc.). The following represents broad categories of functionality that test tools are capable of. 4.1.1 Functional & Regression Testing By far the most common use of automation is to test application functionality. This can include new functionality added in a release or retesting of existing functionality. In both cases the goal is to use automation to test the functionality of an application or system. Applications use a variety of user interfaces. Most common today is the graphical user interface (GUI) that make up a large proportion of existing interfaces. All modern computers, tablets, and smartphones use a GUI (e.g. Windows, MacOS, Android, iOS, etc.). Historically, interfaces to systems were very crude and text based (e.g. Mainframe, Terminal, etc.). Some continue to be that way as the text based interface has very low overhead required by some applications or underlying hardware. Interface (UI or GUI) testing test tools must be able to recognize the interface graphical or otherwise, and the fields or objects on that interface. Where there is a standard implementation of the interface the test tool can easily recognize and interact with the fields or objects. For fully graphical interfaces there are a number of significant elements which can be tested or verified for each object or control. For example, a simple text field where a user enters a name can have many attributes: value (what data is in the field); focus (is this the field where the cursor is at); enabled (can we interact with this field); etc. Challenges: Not all interfaces are implemented consistently and some objects within an application may not be recognized by automation Use of third-party controls embedded into an interface can cause challenges in automation Some automation may need to be custom-coded. This requires programming skill and knowledge that should be performed by individuals with this level of experience. Migrating from one tool to another can pose challenges Adapting to changing technology (browser, OS, etc.) requires tools that are compatible Best Practices: Understand the full suite of technology that is being implemented for the SUT. Don't take a vendor or a reviewer as the last word on compatibility without the using the tool in its intended environment to ensure it is compatible. Look at tools that are compatible with the level of skill in the organization 4.1.2 API Testing Application Programming Interface (API) testing is testing that does not involve a user interface (e.g., text or graphical interface). This is often referred to as client-less testing or non-GUI testing. It simply means that there is no direct user interface by which the tester interacts. However, data is still passed to the application, the application responds, and these interactions can be measured, verified, and reported on with automated test tools. Most applications that have a UI or GUI also are communicating at the API level. With API testing, rather than interacting with an object or control, we interact with a function or service. In order to do so we need to understand the structure of data that the function or service is expected to respond with. If we send the wrong data structure will it identify it as an error or do something unexpectedly? If we send data and receive no return data, what does that tell us? There needs to be a full understanding of what the function or service is supposed to do so that verification can be effective. This includes an understanding of knowing what the function or service is not supposed to do as well. Challenges: Working with functions and services can be a little like working in the dark because you don't have the familiar context of UI controls Tools that are compatible with the implemented services Tools that can test APIs across devices and operating systems APIs may degrade in performance with multiple simultaneous calls to them Best Practices: Understand what you are testing and get the full specification before you start Make sure that you change only one variable at a time to understand the effect of changes Have some known baseline test interfaces to start with in order to realize the expected behavior Work closely with the API developer or vendor who implemented the function or service to fully understand the expected behavior and to report any unusual or missing return data values. 4.1.3 Performance Testing Performance testing is not concerned directly with testing functionality, but rather testing that functionality under load. Hence it is categorized as non-functional testing. Performance testing is difficult to impossible to do without test tools. In years past, rooms full of people and computers attempted to do performance testing but the cost was high, the consistency was low, and the breadth of testing left much to be desired. Modern performance testing tools simulate those same people on those same computers. Now, however, all the people and all the computers can be contained within one powerful computer. For extremely large simulations with heavy loads, performance testing can be distributed across multiple computers. Performance testing tools have 3 areas of functionality: Main controller The controller function starts tests, ramps them up or down, and stops tests. The controller function schedules the testing event and runs the operational profiles (often referred to as a scenarios) to simulate the conditions of a system in use. User Script The user script is the recorded or programmed sequence of events, or operational profile, that mimic the way in which a user interacts with a system. Running the same user script concurrently is how the test tool simulates multiple users performing the same function. User scripts often contain timing information (or wait statements as they are often called) that help regulate the speed of execution to something representative of a human user. Otherwise, scripts could run at speeds far faster than how real users interact with a system, which would not accurately represent the performance of the system. Reporting and Analysis Performance test tools need to have robust reporting and analysis capabilities in order to accurately convey what has transpired. Reporting will include transactional timing information (e.g., how long it took for a search to return) and aggregate data (e.g., all searches on average took no more than 3 seconds to complete). Reporting can also include system resource utilization (e.g., caching, CPU, queues, etc.) and analysis can help correlate how system resources are impacted by heavy transactional use. Cross analysis reporting aides in comparing subsequent test runs in order to evaluate effects on changes. Challenges: Finding an environment that mimics production is difficult and expensive Test tools can be very expensive Performance testing can affect other users sharing that environment Improperly created setup tests may yield no errors when actual errors exist Erroneous results can result from lack of proper correlation or using the wrong database Best Practices: Work with stakeholders to accurately define the various operational profiles Do not make multiple changes between tests as it makes it difficult to know each impact Test each operational profile individually and under load first before adding other profiles Keep scripts and data updated to reflect current changes in SUT Look at the test logs for errors that may not be present in the reports 4.1.4 Security Testing Security testing tools help analyze and test applications for possible security vulnerabilities. There are 3 areas of interest for security testing: static, dynamic, and interactive [ref: Gartner Magic Quadrant for Application Security Testing]. Static analysis refers to looking at the application code from the inside, not when executed. Dynamic analysis is performing testing against a running application. There is overlap with the security qualities identified in static and dynamic security testing and interactive tests span both. Therefore it is advisable to begin security testing early in the software development lifecycle, as code is developed so that it can be assessed. Static Application Security Testing Static application security testing (SAST) of an application refers to analyzing the underlying application code for vulnerabilities. This may include source code, byte code, or binaries. Due to the visibility of the code these tests are often referred to as \"white box\" tests. Scanning of code can be accomplished before any code is compiled. Examining code can assist in uncovering vulnerabilities including SQL Injection, Buffer Overflows, Cross-Site Scripting, and Cross-Site Request Forgery. Dynamic Application Security Testing Dynamic Application Security Testing (DAST) provides applications that are running to be analyzed for possible security flaws. These may include traditional client server applications of web-based applications. DAST has no visibility to the underlying application and therefore is referred to as \"black box\" testing. Interactive Application Security Testing Interactive Application Security Testing (IAST) allows visibility of possible vulnerabilities simultaneously within the application, often through the use of an agent within the runtime environment, and externally via application interfaces. This can include penetration testing which includes the scanning of ports for vulnerabilities. A set of complementary and overlapping vulnerabilities can be identified with SAST, DAST, and IAST tools at different phase of the software development lifecycle. However, automated tools cannot find all vulnerabilities so be careful to not get a false sense of security. A comprehensive guide for cyber security testing can be found at [ref: DoD Cybersecurity Test and Evaluation Guidebook, version 2.0] Blue team - penetration test. Red team - hacker to break into application. Red team in a box. Additional references for web application security available at: www.owasp.org. Challenges: Getting developers to use SAST tools early on Tools may have difficulty parsing through code Tools will not find all vulnerabilities Understand the tool capabilities and how to properly set up for testing Best Practices: Use tools regularly during development before code base becomes to large Security folks being proactive and helping program early Run tools on test and production environments Use a combination of best-in-class tools Identify and perform tests manually which tools may miss Decide what tests need to be run through automation. Automate when necessary as setup may take a lot of effort 4.1.5 Test Management Test Management tools provide for collaboration and reporting of test events. These tools can be a one-stop repository of manual and automated tests, documentation, data files, and more. Test Management tools should provide a level of configuration management for the many test artifacts in use. Additionally, these tools should allow for the classification of a test event by version so that all components used for a test can be traced back to each individual component version and state. This is extremely important as it's not uncommon to have to revert to an earlier release of testing should the current release find problems. Test Management tools often include a defect management module that allows manual and automated tests to create entries for defects. The defects can be assigned to owners and alerts can be configured to inform owners of the stages the defect is going through (e.g. identification, remediation, re-test, etc.) Challenges: Identifying a solution that meets all your needs (e.g. requirements traceability, test case storage, defect cataloging, version control, etc.) Getting buy-in from team to keep data current Best Practices: Plan out what features, functions, and customization will be necessary for your organization Make fields of important information required entry or selectable to aid in queries searching and reporting Produce targeted reporting and dashboards to meet stakeholder needs Identify areas of commonality to produce consolidated reporting (RTM). Combining so everybody sees the same source of truth. Allow ability to run canned reports as needed.","title":"4.1 Tools Target Areas"},{"location":"testing/4-1-tools/#41-tools-target-areas","text":"Test automation tools support the full software development lifecycle. There is likely a tool for every aspect of software that is developed. Tools are categorized by types of testing they can perform. Test types can span multiple test levels (e.g. component, integration, system, etc.). The following represents broad categories of functionality that test tools are capable of.","title":"4.1 Tools Target Areas"},{"location":"testing/4-1-tools/#411-functional-regression-testing","text":"By far the most common use of automation is to test application functionality. This can include new functionality added in a release or retesting of existing functionality. In both cases the goal is to use automation to test the functionality of an application or system. Applications use a variety of user interfaces. Most common today is the graphical user interface (GUI) that make up a large proportion of existing interfaces. All modern computers, tablets, and smartphones use a GUI (e.g. Windows, MacOS, Android, iOS, etc.). Historically, interfaces to systems were very crude and text based (e.g. Mainframe, Terminal, etc.). Some continue to be that way as the text based interface has very low overhead required by some applications or underlying hardware. Interface (UI or GUI) testing test tools must be able to recognize the interface graphical or otherwise, and the fields or objects on that interface. Where there is a standard implementation of the interface the test tool can easily recognize and interact with the fields or objects. For fully graphical interfaces there are a number of significant elements which can be tested or verified for each object or control. For example, a simple text field where a user enters a name can have many attributes: value (what data is in the field); focus (is this the field where the cursor is at); enabled (can we interact with this field); etc.","title":"4.1.1 Functional &amp; Regression Testing"},{"location":"testing/4-1-tools/#challenges","text":"Not all interfaces are implemented consistently and some objects within an application may not be recognized by automation Use of third-party controls embedded into an interface can cause challenges in automation Some automation may need to be custom-coded. This requires programming skill and knowledge that should be performed by individuals with this level of experience. Migrating from one tool to another can pose challenges Adapting to changing technology (browser, OS, etc.) requires tools that are compatible","title":"Challenges:"},{"location":"testing/4-1-tools/#best-practices","text":"Understand the full suite of technology that is being implemented for the SUT. Don't take a vendor or a reviewer as the last word on compatibility without the using the tool in its intended environment to ensure it is compatible. Look at tools that are compatible with the level of skill in the organization","title":"Best Practices:"},{"location":"testing/4-1-tools/#412-api-testing","text":"Application Programming Interface (API) testing is testing that does not involve a user interface (e.g., text or graphical interface). This is often referred to as client-less testing or non-GUI testing. It simply means that there is no direct user interface by which the tester interacts. However, data is still passed to the application, the application responds, and these interactions can be measured, verified, and reported on with automated test tools. Most applications that have a UI or GUI also are communicating at the API level. With API testing, rather than interacting with an object or control, we interact with a function or service. In order to do so we need to understand the structure of data that the function or service is expected to respond with. If we send the wrong data structure will it identify it as an error or do something unexpectedly? If we send data and receive no return data, what does that tell us? There needs to be a full understanding of what the function or service is supposed to do so that verification can be effective. This includes an understanding of knowing what the function or service is not supposed to do as well.","title":"4.1.2 API Testing"},{"location":"testing/4-1-tools/#challenges_1","text":"Working with functions and services can be a little like working in the dark because you don't have the familiar context of UI controls Tools that are compatible with the implemented services Tools that can test APIs across devices and operating systems APIs may degrade in performance with multiple simultaneous calls to them","title":"Challenges:"},{"location":"testing/4-1-tools/#best-practices_1","text":"Understand what you are testing and get the full specification before you start Make sure that you change only one variable at a time to understand the effect of changes Have some known baseline test interfaces to start with in order to realize the expected behavior Work closely with the API developer or vendor who implemented the function or service to fully understand the expected behavior and to report any unusual or missing return data values.","title":"Best Practices:"},{"location":"testing/4-1-tools/#413-performance-testing","text":"Performance testing is not concerned directly with testing functionality, but rather testing that functionality under load. Hence it is categorized as non-functional testing. Performance testing is difficult to impossible to do without test tools. In years past, rooms full of people and computers attempted to do performance testing but the cost was high, the consistency was low, and the breadth of testing left much to be desired. Modern performance testing tools simulate those same people on those same computers. Now, however, all the people and all the computers can be contained within one powerful computer. For extremely large simulations with heavy loads, performance testing can be distributed across multiple computers. Performance testing tools have 3 areas of functionality:","title":"4.1.3 Performance Testing"},{"location":"testing/4-1-tools/#main-controller","text":"The controller function starts tests, ramps them up or down, and stops tests. The controller function schedules the testing event and runs the operational profiles (often referred to as a scenarios) to simulate the conditions of a system in use.","title":"Main controller"},{"location":"testing/4-1-tools/#user-script","text":"The user script is the recorded or programmed sequence of events, or operational profile, that mimic the way in which a user interacts with a system. Running the same user script concurrently is how the test tool simulates multiple users performing the same function. User scripts often contain timing information (or wait statements as they are often called) that help regulate the speed of execution to something representative of a human user. Otherwise, scripts could run at speeds far faster than how real users interact with a system, which would not accurately represent the performance of the system.","title":"User Script"},{"location":"testing/4-1-tools/#reporting-and-analysis","text":"Performance test tools need to have robust reporting and analysis capabilities in order to accurately convey what has transpired. Reporting will include transactional timing information (e.g., how long it took for a search to return) and aggregate data (e.g., all searches on average took no more than 3 seconds to complete). Reporting can also include system resource utilization (e.g., caching, CPU, queues, etc.) and analysis can help correlate how system resources are impacted by heavy transactional use. Cross analysis reporting aides in comparing subsequent test runs in order to evaluate effects on changes.","title":"Reporting and Analysis"},{"location":"testing/4-1-tools/#challenges_2","text":"Finding an environment that mimics production is difficult and expensive Test tools can be very expensive Performance testing can affect other users sharing that environment Improperly created setup tests may yield no errors when actual errors exist Erroneous results can result from lack of proper correlation or using the wrong database","title":"Challenges:"},{"location":"testing/4-1-tools/#best-practices_2","text":"Work with stakeholders to accurately define the various operational profiles Do not make multiple changes between tests as it makes it difficult to know each impact Test each operational profile individually and under load first before adding other profiles Keep scripts and data updated to reflect current changes in SUT Look at the test logs for errors that may not be present in the reports","title":"Best Practices:"},{"location":"testing/4-1-tools/#414-security-testing","text":"Security testing tools help analyze and test applications for possible security vulnerabilities. There are 3 areas of interest for security testing: static, dynamic, and interactive [ref: Gartner Magic Quadrant for Application Security Testing]. Static analysis refers to looking at the application code from the inside, not when executed. Dynamic analysis is performing testing against a running application. There is overlap with the security qualities identified in static and dynamic security testing and interactive tests span both. Therefore it is advisable to begin security testing early in the software development lifecycle, as code is developed so that it can be assessed.","title":"4.1.4 Security Testing"},{"location":"testing/4-1-tools/#static-application-security-testing","text":"Static application security testing (SAST) of an application refers to analyzing the underlying application code for vulnerabilities. This may include source code, byte code, or binaries. Due to the visibility of the code these tests are often referred to as \"white box\" tests. Scanning of code can be accomplished before any code is compiled. Examining code can assist in uncovering vulnerabilities including SQL Injection, Buffer Overflows, Cross-Site Scripting, and Cross-Site Request Forgery.","title":"Static Application Security Testing"},{"location":"testing/4-1-tools/#dynamic-application-security-testing","text":"Dynamic Application Security Testing (DAST) provides applications that are running to be analyzed for possible security flaws. These may include traditional client server applications of web-based applications. DAST has no visibility to the underlying application and therefore is referred to as \"black box\" testing.","title":"Dynamic Application Security Testing"},{"location":"testing/4-1-tools/#interactive-application-security-testing","text":"Interactive Application Security Testing (IAST) allows visibility of possible vulnerabilities simultaneously within the application, often through the use of an agent within the runtime environment, and externally via application interfaces. This can include penetration testing which includes the scanning of ports for vulnerabilities. A set of complementary and overlapping vulnerabilities can be identified with SAST, DAST, and IAST tools at different phase of the software development lifecycle. However, automated tools cannot find all vulnerabilities so be careful to not get a false sense of security. A comprehensive guide for cyber security testing can be found at [ref: DoD Cybersecurity Test and Evaluation Guidebook, version 2.0] Blue team - penetration test. Red team - hacker to break into application. Red team in a box. Additional references for web application security available at: www.owasp.org.","title":"Interactive Application Security Testing"},{"location":"testing/4-1-tools/#challenges_3","text":"Getting developers to use SAST tools early on Tools may have difficulty parsing through code Tools will not find all vulnerabilities Understand the tool capabilities and how to properly set up for testing","title":"Challenges:"},{"location":"testing/4-1-tools/#best-practices_3","text":"Use tools regularly during development before code base becomes to large Security folks being proactive and helping program early Run tools on test and production environments Use a combination of best-in-class tools Identify and perform tests manually which tools may miss Decide what tests need to be run through automation. Automate when necessary as setup may take a lot of effort","title":"Best Practices:"},{"location":"testing/4-1-tools/#415-test-management","text":"Test Management tools provide for collaboration and reporting of test events. These tools can be a one-stop repository of manual and automated tests, documentation, data files, and more. Test Management tools should provide a level of configuration management for the many test artifacts in use. Additionally, these tools should allow for the classification of a test event by version so that all components used for a test can be traced back to each individual component version and state. This is extremely important as it's not uncommon to have to revert to an earlier release of testing should the current release find problems. Test Management tools often include a defect management module that allows manual and automated tests to create entries for defects. The defects can be assigned to owners and alerts can be configured to inform owners of the stages the defect is going through (e.g. identification, remediation, re-test, etc.)","title":"4.1.5 Test Management"},{"location":"testing/4-1-tools/#challenges_4","text":"Identifying a solution that meets all your needs (e.g. requirements traceability, test case storage, defect cataloging, version control, etc.) Getting buy-in from team to keep data current","title":"Challenges:"},{"location":"testing/4-1-tools/#best-practices_4","text":"Plan out what features, functions, and customization will be necessary for your organization Make fields of important information required entry or selectable to aid in queries searching and reporting Produce targeted reporting and dashboards to meet stakeholder needs Identify areas of commonality to produce consolidated reporting (RTM). Combining so everybody sees the same source of truth. Allow ability to run canned reports as needed.","title":"Best Practices:"},{"location":"testing/4-2-levels/","text":"4.2 Test Levels Government systems cover a broad range of testing levels. Some of these are contractor-focused test deliverables. Others are joint contractor-government, and yet others are government-only tests. Automation can be used at many test levels but provides greater value at lower levels. The following table summarizes the test levels, methods, role, and feasibility of automation: White Box White Box texting defines a testing approach that provides visibility to the program code as part of the test event. This allows the tester to understand the underlying structure of the software system or component under test. Testing at this level exposes design and implementation methods (and potential flaws) used to construct the software. The goal to understand and validate the individual lines of code, to the extent possible. Software construction with excessive levels of branching or nesting often cannot be easily tested. Black Box Black Box testing defines an approach to testing that focuses on the functionality of the software under test. The tester exercises the software much as a user would interact with the software and thus attempts to validate if the expected features and functionality have been properly implemented, based on a specification or user story. This technique complements the White Box approach as the system is tested from two different perspectives. Gray Box Gray Box testing combines elements of White and Black Box testing in order to simultaneously identify any defects in application usage that are due to poorly implemented coding constructs. Feasibility of Automation Software Tests Automation is generally easier to implement earlier in smaller, contained, software components. Developers can make good use of automation to test incremental code updates, functions, and components. There are many tools for developers that not only automate test execution but that also provide assessments of the code quality and complexity. These should be run first while modules are still manageable rather than when software has been integrated and combined with other systems, where analysis becomes much more difficult on a significantly larger code base. System Tests Automated system tests verify and validate system behavior. Although there may be some reuse from automation at the earlier software test level, system tests by and large are Black Box tests where the activity is focused on functional requirements that the software must meet. Often these will focus more on testing the system through interfaces (graphical user interface, API, etc.). Mission Tests As the system grows and becomes integrated with other systems, automation can still play a part. For example in a System-of-Systems test automation can be used to drive the individual subsystems comprising the System-of-Systems solution. This automation solution will help coordinate or synchronize the execution of various systems under test. However, this is a broad vs deep application of test automation, as it pertains to functionality. Finally, as systems are migrated to a production environment we lose the ability to test and automate.","title":"4.2 Test Levels"},{"location":"testing/4-2-levels/#42-test-levels","text":"Government systems cover a broad range of testing levels. Some of these are contractor-focused test deliverables. Others are joint contractor-government, and yet others are government-only tests. Automation can be used at many test levels but provides greater value at lower levels. The following table summarizes the test levels, methods, role, and feasibility of automation:","title":"4.2 Test Levels"},{"location":"testing/4-2-levels/#white-box","text":"White Box texting defines a testing approach that provides visibility to the program code as part of the test event. This allows the tester to understand the underlying structure of the software system or component under test. Testing at this level exposes design and implementation methods (and potential flaws) used to construct the software. The goal to understand and validate the individual lines of code, to the extent possible. Software construction with excessive levels of branching or nesting often cannot be easily tested.","title":"White Box"},{"location":"testing/4-2-levels/#black-box","text":"Black Box testing defines an approach to testing that focuses on the functionality of the software under test. The tester exercises the software much as a user would interact with the software and thus attempts to validate if the expected features and functionality have been properly implemented, based on a specification or user story. This technique complements the White Box approach as the system is tested from two different perspectives.","title":"Black Box"},{"location":"testing/4-2-levels/#gray-box","text":"Gray Box testing combines elements of White and Black Box testing in order to simultaneously identify any defects in application usage that are due to poorly implemented coding constructs.","title":"Gray Box"},{"location":"testing/4-2-levels/#feasibility-of-automation","text":"","title":"Feasibility of Automation"},{"location":"testing/4-2-levels/#software-tests","text":"Automation is generally easier to implement earlier in smaller, contained, software components. Developers can make good use of automation to test incremental code updates, functions, and components. There are many tools for developers that not only automate test execution but that also provide assessments of the code quality and complexity. These should be run first while modules are still manageable rather than when software has been integrated and combined with other systems, where analysis becomes much more difficult on a significantly larger code base.","title":"Software Tests"},{"location":"testing/4-2-levels/#system-tests","text":"Automated system tests verify and validate system behavior. Although there may be some reuse from automation at the earlier software test level, system tests by and large are Black Box tests where the activity is focused on functional requirements that the software must meet. Often these will focus more on testing the system through interfaces (graphical user interface, API, etc.).","title":"System Tests"},{"location":"testing/4-2-levels/#mission-tests","text":"As the system grows and becomes integrated with other systems, automation can still play a part. For example in a System-of-Systems test automation can be used to drive the individual subsystems comprising the System-of-Systems solution. This automation solution will help coordinate or synchronize the execution of various systems under test. However, this is a broad vs deep application of test automation, as it pertains to functionality. Finally, as systems are migrated to a production environment we lose the ability to test and automate.","title":"Mission Tests"},{"location":"testing/4-3-types/","text":"4.3 Test Types Functional Tests Functional tests are those tests that evaluate if a system is performing according to a specification or requirement, often detailed in a use case or user story. Functional tests look at the system behavior as a guide to what the system should be do. Non-Functional Tests Non-Functional Tests evaluate the characteristics of a system and include performance testing, security testing, and other testing that does not directly test system functionality. However, as in the case of performance testing, we do exercise a functional test under load to examine its characteristics for the purposes of acquiring timing/performance information. Structural/architectural Structural/architectural testing is a white box testing activity which is concerned with coverage of code within modules and functions. The structure is tested to meet all possible conditions that the code provides for. Any code not exercised from the tests would require specific test conditions to be created, thus improving the overall coverage of code within the module or function. Retesting/regression When changes are made to a system or component, testing should be done in order to ensure the system or component continues to operate as expected. This can include testing done after a defect has been fixed to ensure that the fix was applied correctly, or testing done as a result new features added to the system and where existing features need to continue to operate as expected. Each these test types can be executed across test levels, where applicable. Also, there may be opportunities to reuse tests if designed as part of the automation strategy. For example, tests developed at the system test level may be re-used at the mission test level.","title":"4.3 Test Types"},{"location":"testing/4-3-types/#43-test-types","text":"","title":"4.3 Test Types"},{"location":"testing/4-3-types/#functional-tests","text":"Functional tests are those tests that evaluate if a system is performing according to a specification or requirement, often detailed in a use case or user story. Functional tests look at the system behavior as a guide to what the system should be do.","title":"Functional Tests"},{"location":"testing/4-3-types/#non-functional-tests","text":"Non-Functional Tests evaluate the characteristics of a system and include performance testing, security testing, and other testing that does not directly test system functionality. However, as in the case of performance testing, we do exercise a functional test under load to examine its characteristics for the purposes of acquiring timing/performance information.","title":"Non-Functional Tests"},{"location":"testing/4-3-types/#structuralarchitectural","text":"Structural/architectural testing is a white box testing activity which is concerned with coverage of code within modules and functions. The structure is tested to meet all possible conditions that the code provides for. Any code not exercised from the tests would require specific test conditions to be created, thus improving the overall coverage of code within the module or function.","title":"Structural/architectural"},{"location":"testing/4-3-types/#retestingregression","text":"When changes are made to a system or component, testing should be done in order to ensure the system or component continues to operate as expected. This can include testing done after a defect has been fixed to ensure that the fix was applied correctly, or testing done as a result new features added to the system and where existing features need to continue to operate as expected. Each these test types can be executed across test levels, where applicable. Also, there may be opportunities to reuse tests if designed as part of the automation strategy. For example, tests developed at the system test level may be re-used at the mission test level.","title":"Retesting/regression"},{"location":"testing/5-1-approach/","text":"5.1 Approaches to Test Automation Many approaches are available for how automated tools are used. Some involve using the tool functionality as-is with little to no modification or customization. This is what is usually done by test groups with less technically skilled testers. Where more technically skilled testers exist, more customizable solutions are created. While these ultimately offer greater flexibility, they also require greater up-front investment and continued skilled resources to maintain and expand the automated solution. The following represent common approaches to automation. Capture/replay Capture/replay or record/replay is a technique which directly uses the test automation tool's built-in feature to allow a user session to be \"captured\" as the tester interacts with the SUT. Often this is what a vendor might demonstrate as capability with a controlled sample application. After the user keystrokes are captured, they are faithfully replayed by the test tool. While this makes for a very effective demonstration of ultimate simplicity, the application of capture/replay in real-world complex applications often doesn't fair as well. In most cases, using capture/replay in moderate to complex system will likely not yield a successful playback of the initially recorded script. This is due to the fact that most tools are not sophisticated enough to understand all the nuances and the multiple parameters and values that are changing dynamically as a user navigates across an application. For tests that are recorded, the maintenance becomes quite difficult to achieve once the number of tests is in the double digits or higher. Each captured script is unique to the others and needs to be individually maintained. This becomes very time consuming and inefficient. Data driven As the name implies, the data driven test technique aims to use data, external to the tool, to drive the test execution. The remaining techniques below are all variations or adaptations of driving tests with data. In its simplest form, data driven tests replace the specific (static) values that were used for one iteration of a test with a set of data that can be used for many iterations of the same test. With the proper application of specification-based test techniques test datasets can be constructed that minimize the number of tests require for the maximum coverage. Keyword driven The keyword-driven approach at its core also uses data to drive tests but the keyword descriptor is a meaningful action for the system to perform. For example, to test a system with parts that need to be placed in inventory, taken out of inventory, or repaired, a keyword driven script may use the keywords \"check in\", \"check out\", and \"repair\" for any given part number. The way a keyword driven script works is that test cases are developed using keywords and the corresponding values for each keyword. Then, the test automation solution parses those keywords and values and lets pre-defined scripts navigate in a pre-determined manner, through the application in order to execute the desired functionality. Process driven The process driven approach also uses data to drive tests, but the data it defines is more detailed than that of the keyword approach. This approach requires the definition of the following in order to create a test script: control, instruction, data. The \"control\" identifies the application window/object which needs to be interrogated. The \"instruction\" may include: input, verification, navigation, timing, etc. The \"data\" would be the relevant data for the given instruction in the context of the window/object. The process driven approach therefore is the most abstracted model as its very design is built around externalizing all data. The benefit this approach brings is highly reusable function libraries. Model driven A model driven approach for testing is derived from a model based design methodology. With modeling, the desired behavior of a SUT can be represented. From this behavior design test cases can be derived and then specific data can be created to make these tests executable. Model based techniques can facilitate creating tests which can then be used under automated control. The following table compares popular approaches to automation, where LOW/MED/HIGH indicates the degree in achieving that characteristic:","title":"5.1 Approaches to Test Automation"},{"location":"testing/5-1-approach/#51-approaches-to-test-automation","text":"Many approaches are available for how automated tools are used. Some involve using the tool functionality as-is with little to no modification or customization. This is what is usually done by test groups with less technically skilled testers. Where more technically skilled testers exist, more customizable solutions are created. While these ultimately offer greater flexibility, they also require greater up-front investment and continued skilled resources to maintain and expand the automated solution. The following represent common approaches to automation.","title":"5.1 Approaches to Test Automation"},{"location":"testing/5-1-approach/#capturereplay","text":"Capture/replay or record/replay is a technique which directly uses the test automation tool's built-in feature to allow a user session to be \"captured\" as the tester interacts with the SUT. Often this is what a vendor might demonstrate as capability with a controlled sample application. After the user keystrokes are captured, they are faithfully replayed by the test tool. While this makes for a very effective demonstration of ultimate simplicity, the application of capture/replay in real-world complex applications often doesn't fair as well. In most cases, using capture/replay in moderate to complex system will likely not yield a successful playback of the initially recorded script. This is due to the fact that most tools are not sophisticated enough to understand all the nuances and the multiple parameters and values that are changing dynamically as a user navigates across an application. For tests that are recorded, the maintenance becomes quite difficult to achieve once the number of tests is in the double digits or higher. Each captured script is unique to the others and needs to be individually maintained. This becomes very time consuming and inefficient.","title":"Capture/replay"},{"location":"testing/5-1-approach/#data-driven","text":"As the name implies, the data driven test technique aims to use data, external to the tool, to drive the test execution. The remaining techniques below are all variations or adaptations of driving tests with data. In its simplest form, data driven tests replace the specific (static) values that were used for one iteration of a test with a set of data that can be used for many iterations of the same test. With the proper application of specification-based test techniques test datasets can be constructed that minimize the number of tests require for the maximum coverage.","title":"Data driven"},{"location":"testing/5-1-approach/#keyword-driven","text":"The keyword-driven approach at its core also uses data to drive tests but the keyword descriptor is a meaningful action for the system to perform. For example, to test a system with parts that need to be placed in inventory, taken out of inventory, or repaired, a keyword driven script may use the keywords \"check in\", \"check out\", and \"repair\" for any given part number. The way a keyword driven script works is that test cases are developed using keywords and the corresponding values for each keyword. Then, the test automation solution parses those keywords and values and lets pre-defined scripts navigate in a pre-determined manner, through the application in order to execute the desired functionality.","title":"Keyword driven"},{"location":"testing/5-1-approach/#process-driven","text":"The process driven approach also uses data to drive tests, but the data it defines is more detailed than that of the keyword approach. This approach requires the definition of the following in order to create a test script: control, instruction, data. The \"control\" identifies the application window/object which needs to be interrogated. The \"instruction\" may include: input, verification, navigation, timing, etc. The \"data\" would be the relevant data for the given instruction in the context of the window/object. The process driven approach therefore is the most abstracted model as its very design is built around externalizing all data. The benefit this approach brings is highly reusable function libraries.","title":"Process driven"},{"location":"testing/5-1-approach/#model-driven","text":"A model driven approach for testing is derived from a model based design methodology. With modeling, the desired behavior of a SUT can be represented. From this behavior design test cases can be derived and then specific data can be created to make these tests executable. Model based techniques can facilitate creating tests which can then be used under automated control. The following table compares popular approaches to automation, where LOW/MED/HIGH indicates the degree in achieving that characteristic:","title":"Model driven"},{"location":"testing/5-2-architecture/","text":"5.2 Overall Architectural Considerations The International Software Testing Qualifications Board (ISTQB) has published a body of knowledge (BoK) and glossary that comprise the syllabus for the Advanced Level Test Automation Engineer certification. This BoK contains a general test automation architecture (GTAA) from which a purpose-built test automation architecture (TAA) can be derived. The Generic Test Automation Architecture GTAA (Source: ISTQB Advanced Level Test Automation Engineer Syllabus) The defined layers of the GTAA include: test generation, test definition, test execution, and test adaptation. This generic architecture can be thought of as a catalog of functionality from which we select those capabilities required for a given project or program. Test Generation Layer Test cases, whether for manual or automated testing must be developed. The development process might include a test case generator for systems that are fully integrated with requirements and design. Some advanced development environments will included system modeling from which high-level test cases can be generated. Use of advanced model based testing techniques and tools can provide an efficient method of preparing an initial set of test cases for automation. Test Definition Layer The Test Definition Layer provides support to help define high- and low-level test cases and test procedures. Data needed for test procedures would be generated at this layer. This can include the data needed for keywords used access libraries when a keyword-driven approach is used. Test libraries can include purpose built test sequences and reusable components for our automation solution. Test Execution Layer The execution layer represents that portion of our automated solution that \"runs\" the tests. We often think of the various test tools available as test execution tools. At their core is the capability to execute a test. This applies equally to COTS, GOTS, and OSS test tool solutions, as discussed in Section 6.3.1. Within the execution layer we have two additional components: test reporting and test logging. The test reporting function provides us with information regarding the SUT so that we can ascertain if the SUT if performing as our tests expect it to. This will alert us to changes in the SUT, although it will not necessarily identify the root cause, which may be SUT, data, or environment related. The test logs will help us identify where some of the errors may be originating from, when providing information at a very granular level. The logs can also provide us with information regarding the operation of our Test Automation Framework components and libraries. Errors in any of these should be written out to the log files so that corrective action can be taken. Test Adaptation Layer Test tool solutions must be compatible to work with the intended environment. This can include a graphical user interface (e.g., browser, mobile app, desktop app, etc.) or a messaging interface. Most systems that we are testing will often contain several interfaces which need to be exercised for thoroughness in testing. By analyzing the SUT architecture we gain an understanding of what interfaces exist, and what are requirements are for testing them. Test tools often provide support for multiple interfaces. However, additional interface testing requirements can be met through other test tools or by developing such capability. Test Automation & Framework The 4 layers discussed above all encompass a test automation solution. This ranges from the test script definitions through the automated execution via a given interface. We can think of the Test Automation Framework as those purpose built testware components that allow us to define data inputs, execute tests, and produce reports. The idea behind a framework is that it should be built with reusable components and not contain embedded application data. This will allow for greatest reuse, and ease of maintenance. Configuration Management There are many artifacts that comprise our test automation solution. In order to keep them manageable, we need to understand what version of what component we are using. This applies equally to test data, test automation functions and libraries, test reporting, and test environments (which may include OS patches, security updates, and updated DLLs). By having this understanding and control we are able to revert to a known working environment quickly. Test Management Test management is there to support the development and maintenance of the test automation solution. This includes providing the proper funding, staffing, tools, and environments in order to be successful. Project Management Test automation is a project, often requiring significant development tasks. As such it needs to be planned, and executed with tasks, milestones, people, and resources. Different development lifecycle methodologies will affect the approach and timing of developing an automated solution, as discussed in Chapter 7. 5.2.1 Understanding the system architecture Enterprise systems are built with a multitude of servers and other specialized components with which they interface. A first step in understanding what needs to be tested and what can potentially be automated is to understand the overall system architecture, or enterprise system architecture (ESA). Most systems receive an input (e.g., a user request for data) and route that request through a multitude of servers, that may include application servers, web servers, database servers, and report servers. A good test strategy is to isolate the various requests as they go from one server to another and identify a way to test each individual component in addition to creating an end-to-end test. Automated tools exist that support multiple protocols and that can act as stubs to simulate behavior between systems or components. 5.2.2 Defining interface components Software and systems communicate with one another often via a protocol across an interface. Understanding what interfaces the SUT communicates with will help determine the testing requirement for that interface. Once the interface has been identified, the communications protocol needs to be established in order to simulate data over that interface. Common interfaces and protocols include: Graphical User Interface Text User Interface Applications Programming Interface (API) Services (including web services) Database (ODBC, etc.) A test automation engineer will need to gather the specification for the interface in order that testing can simulate, or emulate the given interface. 5.2.3 Creating a purpose-built architecture The GTAA, as described above, allows for flexibility in the creation of a purpose built Test Automation Architecture (TAA). By understanding the various components that make up our SUT, we can devise a TAA that fits our needs. For example, if we use model based testing, we may already have a solution for the test generation layer in creating our high-level test cases. Otherwise, we need to define the manual process by which these are created. Once we start building our test cases and corresponding data we need to define a repository where these will be stored. This repository should be under configuration control in order to support the versioning of data by release. For test execution, we may already have a robust test tool with pre-made logging and reporting functions. Otherwise, we'll need to develop these to cover those specific needs. A broad overview of interfaces, as described in section 6.2.2 will guide us as to what tools we'll need to support interface testing.","title":"5.2 Overall Architectural Considerations"},{"location":"testing/5-2-architecture/#52-overall-architectural-considerations","text":"The International Software Testing Qualifications Board (ISTQB) has published a body of knowledge (BoK) and glossary that comprise the syllabus for the Advanced Level Test Automation Engineer certification. This BoK contains a general test automation architecture (GTAA) from which a purpose-built test automation architecture (TAA) can be derived.","title":"5.2 Overall Architectural Considerations"},{"location":"testing/5-2-architecture/#the-generic-test-automation-architecture-gtaa","text":"(Source: ISTQB Advanced Level Test Automation Engineer Syllabus) The defined layers of the GTAA include: test generation, test definition, test execution, and test adaptation. This generic architecture can be thought of as a catalog of functionality from which we select those capabilities required for a given project or program.","title":"The Generic Test Automation Architecture GTAA"},{"location":"testing/5-2-architecture/#test-generation-layer","text":"Test cases, whether for manual or automated testing must be developed. The development process might include a test case generator for systems that are fully integrated with requirements and design. Some advanced development environments will included system modeling from which high-level test cases can be generated. Use of advanced model based testing techniques and tools can provide an efficient method of preparing an initial set of test cases for automation.","title":"Test Generation Layer"},{"location":"testing/5-2-architecture/#test-definition-layer","text":"The Test Definition Layer provides support to help define high- and low-level test cases and test procedures. Data needed for test procedures would be generated at this layer. This can include the data needed for keywords used access libraries when a keyword-driven approach is used. Test libraries can include purpose built test sequences and reusable components for our automation solution.","title":"Test Definition Layer"},{"location":"testing/5-2-architecture/#test-execution-layer","text":"The execution layer represents that portion of our automated solution that \"runs\" the tests. We often think of the various test tools available as test execution tools. At their core is the capability to execute a test. This applies equally to COTS, GOTS, and OSS test tool solutions, as discussed in Section 6.3.1. Within the execution layer we have two additional components: test reporting and test logging. The test reporting function provides us with information regarding the SUT so that we can ascertain if the SUT if performing as our tests expect it to. This will alert us to changes in the SUT, although it will not necessarily identify the root cause, which may be SUT, data, or environment related. The test logs will help us identify where some of the errors may be originating from, when providing information at a very granular level. The logs can also provide us with information regarding the operation of our Test Automation Framework components and libraries. Errors in any of these should be written out to the log files so that corrective action can be taken.","title":"Test Execution Layer"},{"location":"testing/5-2-architecture/#test-adaptation-layer","text":"Test tool solutions must be compatible to work with the intended environment. This can include a graphical user interface (e.g., browser, mobile app, desktop app, etc.) or a messaging interface. Most systems that we are testing will often contain several interfaces which need to be exercised for thoroughness in testing. By analyzing the SUT architecture we gain an understanding of what interfaces exist, and what are requirements are for testing them. Test tools often provide support for multiple interfaces. However, additional interface testing requirements can be met through other test tools or by developing such capability.","title":"Test Adaptation Layer"},{"location":"testing/5-2-architecture/#test-automation-framework","text":"The 4 layers discussed above all encompass a test automation solution. This ranges from the test script definitions through the automated execution via a given interface. We can think of the Test Automation Framework as those purpose built testware components that allow us to define data inputs, execute tests, and produce reports. The idea behind a framework is that it should be built with reusable components and not contain embedded application data. This will allow for greatest reuse, and ease of maintenance.","title":"Test Automation &amp; Framework"},{"location":"testing/5-2-architecture/#configuration-management","text":"There are many artifacts that comprise our test automation solution. In order to keep them manageable, we need to understand what version of what component we are using. This applies equally to test data, test automation functions and libraries, test reporting, and test environments (which may include OS patches, security updates, and updated DLLs). By having this understanding and control we are able to revert to a known working environment quickly.","title":"Configuration Management"},{"location":"testing/5-2-architecture/#test-management","text":"Test management is there to support the development and maintenance of the test automation solution. This includes providing the proper funding, staffing, tools, and environments in order to be successful.","title":"Test Management"},{"location":"testing/5-2-architecture/#project-management","text":"Test automation is a project, often requiring significant development tasks. As such it needs to be planned, and executed with tasks, milestones, people, and resources. Different development lifecycle methodologies will affect the approach and timing of developing an automated solution, as discussed in Chapter 7.","title":"Project Management"},{"location":"testing/5-2-architecture/#521-understanding-the-system-architecture","text":"Enterprise systems are built with a multitude of servers and other specialized components with which they interface. A first step in understanding what needs to be tested and what can potentially be automated is to understand the overall system architecture, or enterprise system architecture (ESA). Most systems receive an input (e.g., a user request for data) and route that request through a multitude of servers, that may include application servers, web servers, database servers, and report servers. A good test strategy is to isolate the various requests as they go from one server to another and identify a way to test each individual component in addition to creating an end-to-end test. Automated tools exist that support multiple protocols and that can act as stubs to simulate behavior between systems or components.","title":"5.2.1 Understanding the system architecture"},{"location":"testing/5-2-architecture/#522-defining-interface-components","text":"Software and systems communicate with one another often via a protocol across an interface. Understanding what interfaces the SUT communicates with will help determine the testing requirement for that interface. Once the interface has been identified, the communications protocol needs to be established in order to simulate data over that interface. Common interfaces and protocols include: Graphical User Interface Text User Interface Applications Programming Interface (API) Services (including web services) Database (ODBC, etc.) A test automation engineer will need to gather the specification for the interface in order that testing can simulate, or emulate the given interface.","title":"5.2.2 Defining interface components"},{"location":"testing/5-2-architecture/#523-creating-a-purpose-built-architecture","text":"The GTAA, as described above, allows for flexibility in the creation of a purpose built Test Automation Architecture (TAA). By understanding the various components that make up our SUT, we can devise a TAA that fits our needs. For example, if we use model based testing, we may already have a solution for the test generation layer in creating our high-level test cases. Otherwise, we need to define the manual process by which these are created. Once we start building our test cases and corresponding data we need to define a repository where these will be stored. This repository should be under configuration control in order to support the versioning of data by release. For test execution, we may already have a robust test tool with pre-made logging and reporting functions. Otherwise, we'll need to develop these to cover those specific needs. A broad overview of interfaces, as described in section 6.2.2 will guide us as to what tools we'll need to support interface testing.","title":"5.2.3 Creating a purpose-built architecture"},{"location":"testing/5-3-evaluation/","text":"5.3 Evaluation and Selection of Test Tools 5.3.1 Tool choices Testing tools are available from a number of sources. These include: commercial vendors, open source, and custom built. Each source brings with it possible benefits and limitations. For example, a commercial test tool may be rich in features and offer good support, but require a significant initial and ongoing financial investment for license, maintenance, and support. An open source solution may provide the functionality needed at a given moment, but may lack the ability to expand to meet future needs. Custom solutions, which are either contracted out or developed by the government, will be purpose-built and target key areas needing automation. However, the burden of maintaining, correcting, and expanding such a solution will fall to the government to direct either through internal resources or through additional contractor funding. Appendix B: Test Tools provides a listing of tools frequently found to perform well. Each project will have its own needs and will need to evaluate the fit to a given requirement. Open Source Software (OSS) The OSS category of software products has many options available for the various functional and non-functional requirements for test automation (as described in Chapter 4 Scope of test automation). OSS test tools are updated by a community of contributors, and keeping abreast of the changes ensures that the tool is functioning optimally. Many OSS test tools are have been developed to support a specific environment. For example, there are tools to support browser based testing and tools for mobile application testing. A few tools may provide support for multiple environments, but that is more commonly seen in commercial test tools. (see Defense Acquisition Policy, DoD Instruction 5000.75) OSS test tools have expanded rapidly over the years and can meet many enterprise testing needs. The U.S. Government supports the use of OSS solutions to meet information technology needs, as addressed in the Federal Source Code Policy (https://sourcecode.cio.gov/). Commercial off the Shelf (COTS) Commercial software testing tools developed and supported by vendors have been around for many years. These tools tend to be fully featured and often support multiple environments (e.g., browsers, terminals, API, mobile, etc.). Ideally, there would be one tool that offers the tester capabilities to test all software. In reality, even those tools that cover a wide range of environments may support some better than others. So when evaluating a tool across multiple environments, a separate evaluation will need to be made to see how well each environment is supported. By using a paid license and maintenance model, COTS tools provide for research and development to fund a steady stream of improvements, feature additions, and defect patching. A well-funded organization has the resources to do this and keep the tools current. COTS vendors often have multiple test tools in their catalog to support various testing activity (e.g. functional testing, load testing, test management). These tools are often integrated with one another, such as keeping all test artifacts under configuration version control through a test management module. Government of-the-shelf (GOTS) The GOTS solution is one that has been engineered to meet a specific need. Most often this level of effort is only undertaken when an exhaustive evaluation of existing COTS and OSS solutions shows no matches. The GOTS solution Government directed and can be developed internally with technical staff or via subcontract to an external entity. These solutions vary in scope and features and it is often difficult to know what may be available as no centralized catalog exists that lists them. See Appendix B: Test Tools for commonly used test tools by government and industry. 5.3.2 Test tool evaluation In order to properly evaluate test automation tools we need to make sure we identify the correct quality criteria that will help identify the proper fit for the project or program. Environment Each environment presents unique opportunities and challenges for the implementation of test automation tools. Environments may include multiple platforms to support workstations, laptops, and mobile tables and phones. Each of these platforms often will run a different operating system and the software implementation, whether native or through a browser (which are also native to the device), will dictate the functionality to that platform. When evaluating test automation tools, we need to be aware of our complete needs for the environment, including all platforms and devices that ultimately might be required. Be aware that tools perform differently across devices so a prioritization of which device testing should be automated first will help ensure that those most critical platforms can be implemented successfully. Test Types Types and test levels are discussed in sections 4.2 and 4.3 and need to be considering when evaluating test automation tools. This includes defining the types of tests that are candidates for automation across test levels. Tools are purpose built, and each combination of test type/test level may require re-evaluation of a given test tool selected for a prior test type/test level pairing. Technology Test tools exist to support a variety of older and current technologies (e.g. terminals, text UIs, graphical UIs, browsers, etc.) Some tools support many technologies within one product suite. These are most often COTS tools (see section 6.3.1) where a vendor's tools evolve technology to meet continuing technology needs. However, a bundled solution suite may not necessarily contain \"best-in-class\" for each technology that is supported. An a-la-carte approach to find a specific tool for each technology stack that needs testing may ultimately provide a more satisfactory solution, even where integration amongst disparate tools may be required. Language Most tools provide customization through programmability. In this way they are similar to Interactive Development Environments (IDEs) used by developers to design and build applications. With automation we are building an application too, one that when run automates the execution of testing. Common languages used by test tools include Java, Python, C#, C++, VBScript, etc., with some tools supporting multiple languages. Languages offer a range of features and flexibility and a range of effort to learn them. Identifying tools with the right balance of features and flexibility as they pertain to the knowledge and skills in the organization are key to using a specified tool effectively. Reporting When we look at the reporting features of tools we want evaluate both test reporting and logging functionality. The logging function which is often undervalued or not evaluated and is important in determining if errors occurred specific to the automation of tests. The logging function is an audit trail that can be examined to know exactly what occurred doing execution, irrespective of any application criteria being examined. Often the logging function can be customizable to provide specific information that may be required for analysis. For reporting, features should include meaningful displays of data and analysis from which decisions can be made. These may require additional test runs in order to show varying parameters or cumulative data. Most tools have a basic level of on-demand reporting but the better tools will allow for the customization of reporting. Dashboards also provide reporting, most often in a graphical or table based approach where application health is readily displayed. Where other reporting systems exist, exporting data from the tool may be necessary in order to integrate the results with project-level metrics required by project management for planning and reporting purposes. Ease of Use Test tools should be intuitive and easy to understand and use. They should be well documented so that common answers to questions and techniques can be quickly identified. For example, one may need to know what function is used to verify the content on a calendar widget or how to export a test report in csv format. Although some test tools may claim that there is no need to use scripting for test development, most medium to complex test requirements will likely require a level of scripting that makes the test perform to meet standards and requirements. Therefore, \"ease of use\" is a relative term. For those automators with strong programming skills it will be easy to develop scripts with a test tool. However, for the traditional manual tester, the requirement to write program code may be difficult and counterproductive to their domain-specific skills. Sourcing As defined in section 6.3.1 tools are available form a variety of sources. These can include COTS, GOTS, and OSS. Each category may have very good solutions. The solution needs to include the sourcing of the tool, the training required for the tool, the ongoing maintenance requirements to the tool, and the support available for the tool (in the form of technical support, product updates, etc.) Support Support for test tools can be available from many sources. Vendors often have dedicated support sites that allow logging of issues. These are normally restricted to customers paying for support, either directly or indirectly via maintenance contracts. Additionally forums exist on the internet that focus specifically on particular testing tools. These forums may not be a reliable place for answers as contributions are made by volunteers who may or may not have the knowledge to answer correctly. Investment Test tools from commercial entities have a variety of licensing fees structures. These can include individual, per seat, and floating, among others. Understanding the intended usage by your team will help define which license structure that is best for you. Additionally, commercial entities have support and maintenance fees. Support allows for technical questions or issues to be submitted and responded to, while maintenance usually provides for minor and major updates to the testing tool. Working with the most recent version of a tool will often help resolve technical issues (e.g., compatibility, defects, etc.). Training should also be included as a cost, both for vendor and open source solutions. EVALUATION TABLES Evaluation of the above criteria can be reduced to a table indicating the relative importance for each category, with a total weight at 100%. As tools are evaluated, completing the table helps to compare one tool against another tool objectively. (sample values for illustration) Categories should be rated for how closely they meet the intended requirements. A score allows the category to show a strength or weakness in meeting the category requirement. Use of a scoring system ranging from 0 to 5 where each value indicates alignment to the requirement score. Finally, no tool evaluation is complete without trying the tool out in the intended environment where there is a need to automate. This will ensure that the tool really does work as intended. 5.3.3 Proof-of-concept A proof of concept (PoC) is the first step in understanding if a given test tool meets the anticipated needs of the project. With a PoC we want to ensure that the technology that we've provisionally selected actually works in the intended environment. This is key as any prior demonstration of the tool, however capable, needs to now show the same capability in the intended environment. 5.3.4 Test tool prototypes A prototype takes the PoC further along by automating a narrowly defined set of functionality from a system where automation is to take hold. The prototype helps the project team understand the complexities of implementation in a timeframe that will not drain excessive resources or funding. The prototype shows the way ahead and serves to realign expectations of how long it actually takes to get test built for automation. The lessons learned from the prototype will bring greater efficiency to the next phase of automation. 5.3.5 Tool training and support Success in automation requires an overall understanding of testing, technology, and the features and functions of specific testing tools in meeting the stated requirements. Appendix B: Test Tools provides a listing of tools that have been shown to be successful across projects and programs. Appendix A: Resources provides additional resources that cover education and certification around testing best practices and test tools. Combining education and certification with hands-on test tool knowledge empowers the test team to develop purpose-built solutions that align with project and program needs.","title":"5.3 Evaluation and Selection of Test Tools"},{"location":"testing/5-3-evaluation/#53-evaluation-and-selection-of-test-tools","text":"","title":"5.3 Evaluation and Selection of Test Tools"},{"location":"testing/5-3-evaluation/#531-tool-choices","text":"Testing tools are available from a number of sources. These include: commercial vendors, open source, and custom built. Each source brings with it possible benefits and limitations. For example, a commercial test tool may be rich in features and offer good support, but require a significant initial and ongoing financial investment for license, maintenance, and support. An open source solution may provide the functionality needed at a given moment, but may lack the ability to expand to meet future needs. Custom solutions, which are either contracted out or developed by the government, will be purpose-built and target key areas needing automation. However, the burden of maintaining, correcting, and expanding such a solution will fall to the government to direct either through internal resources or through additional contractor funding. Appendix B: Test Tools provides a listing of tools frequently found to perform well. Each project will have its own needs and will need to evaluate the fit to a given requirement.","title":"5.3.1 Tool choices"},{"location":"testing/5-3-evaluation/#open-source-software-oss","text":"The OSS category of software products has many options available for the various functional and non-functional requirements for test automation (as described in Chapter 4 Scope of test automation). OSS test tools are updated by a community of contributors, and keeping abreast of the changes ensures that the tool is functioning optimally. Many OSS test tools are have been developed to support a specific environment. For example, there are tools to support browser based testing and tools for mobile application testing. A few tools may provide support for multiple environments, but that is more commonly seen in commercial test tools. (see Defense Acquisition Policy, DoD Instruction 5000.75) OSS test tools have expanded rapidly over the years and can meet many enterprise testing needs. The U.S. Government supports the use of OSS solutions to meet information technology needs, as addressed in the Federal Source Code Policy (https://sourcecode.cio.gov/).","title":"Open Source Software (OSS)"},{"location":"testing/5-3-evaluation/#commercial-off-the-shelf-cots","text":"Commercial software testing tools developed and supported by vendors have been around for many years. These tools tend to be fully featured and often support multiple environments (e.g., browsers, terminals, API, mobile, etc.). Ideally, there would be one tool that offers the tester capabilities to test all software. In reality, even those tools that cover a wide range of environments may support some better than others. So when evaluating a tool across multiple environments, a separate evaluation will need to be made to see how well each environment is supported. By using a paid license and maintenance model, COTS tools provide for research and development to fund a steady stream of improvements, feature additions, and defect patching. A well-funded organization has the resources to do this and keep the tools current. COTS vendors often have multiple test tools in their catalog to support various testing activity (e.g. functional testing, load testing, test management). These tools are often integrated with one another, such as keeping all test artifacts under configuration version control through a test management module.","title":"Commercial off the Shelf (COTS)"},{"location":"testing/5-3-evaluation/#government-of-the-shelf-gots","text":"The GOTS solution is one that has been engineered to meet a specific need. Most often this level of effort is only undertaken when an exhaustive evaluation of existing COTS and OSS solutions shows no matches. The GOTS solution Government directed and can be developed internally with technical staff or via subcontract to an external entity. These solutions vary in scope and features and it is often difficult to know what may be available as no centralized catalog exists that lists them. See Appendix B: Test Tools for commonly used test tools by government and industry.","title":"Government of-the-shelf (GOTS)"},{"location":"testing/5-3-evaluation/#532-test-tool-evaluation","text":"In order to properly evaluate test automation tools we need to make sure we identify the correct quality criteria that will help identify the proper fit for the project or program.","title":"5.3.2 Test tool evaluation"},{"location":"testing/5-3-evaluation/#environment","text":"Each environment presents unique opportunities and challenges for the implementation of test automation tools. Environments may include multiple platforms to support workstations, laptops, and mobile tables and phones. Each of these platforms often will run a different operating system and the software implementation, whether native or through a browser (which are also native to the device), will dictate the functionality to that platform. When evaluating test automation tools, we need to be aware of our complete needs for the environment, including all platforms and devices that ultimately might be required. Be aware that tools perform differently across devices so a prioritization of which device testing should be automated first will help ensure that those most critical platforms can be implemented successfully.","title":"Environment"},{"location":"testing/5-3-evaluation/#test-types","text":"Types and test levels are discussed in sections 4.2 and 4.3 and need to be considering when evaluating test automation tools. This includes defining the types of tests that are candidates for automation across test levels. Tools are purpose built, and each combination of test type/test level may require re-evaluation of a given test tool selected for a prior test type/test level pairing.","title":"Test Types"},{"location":"testing/5-3-evaluation/#technology","text":"Test tools exist to support a variety of older and current technologies (e.g. terminals, text UIs, graphical UIs, browsers, etc.) Some tools support many technologies within one product suite. These are most often COTS tools (see section 6.3.1) where a vendor's tools evolve technology to meet continuing technology needs. However, a bundled solution suite may not necessarily contain \"best-in-class\" for each technology that is supported. An a-la-carte approach to find a specific tool for each technology stack that needs testing may ultimately provide a more satisfactory solution, even where integration amongst disparate tools may be required.","title":"Technology"},{"location":"testing/5-3-evaluation/#language","text":"Most tools provide customization through programmability. In this way they are similar to Interactive Development Environments (IDEs) used by developers to design and build applications. With automation we are building an application too, one that when run automates the execution of testing. Common languages used by test tools include Java, Python, C#, C++, VBScript, etc., with some tools supporting multiple languages. Languages offer a range of features and flexibility and a range of effort to learn them. Identifying tools with the right balance of features and flexibility as they pertain to the knowledge and skills in the organization are key to using a specified tool effectively.","title":"Language"},{"location":"testing/5-3-evaluation/#reporting","text":"When we look at the reporting features of tools we want evaluate both test reporting and logging functionality. The logging function which is often undervalued or not evaluated and is important in determining if errors occurred specific to the automation of tests. The logging function is an audit trail that can be examined to know exactly what occurred doing execution, irrespective of any application criteria being examined. Often the logging function can be customizable to provide specific information that may be required for analysis. For reporting, features should include meaningful displays of data and analysis from which decisions can be made. These may require additional test runs in order to show varying parameters or cumulative data. Most tools have a basic level of on-demand reporting but the better tools will allow for the customization of reporting. Dashboards also provide reporting, most often in a graphical or table based approach where application health is readily displayed. Where other reporting systems exist, exporting data from the tool may be necessary in order to integrate the results with project-level metrics required by project management for planning and reporting purposes.","title":"Reporting"},{"location":"testing/5-3-evaluation/#ease-of-use","text":"Test tools should be intuitive and easy to understand and use. They should be well documented so that common answers to questions and techniques can be quickly identified. For example, one may need to know what function is used to verify the content on a calendar widget or how to export a test report in csv format. Although some test tools may claim that there is no need to use scripting for test development, most medium to complex test requirements will likely require a level of scripting that makes the test perform to meet standards and requirements. Therefore, \"ease of use\" is a relative term. For those automators with strong programming skills it will be easy to develop scripts with a test tool. However, for the traditional manual tester, the requirement to write program code may be difficult and counterproductive to their domain-specific skills.","title":"Ease of Use"},{"location":"testing/5-3-evaluation/#sourcing","text":"As defined in section 6.3.1 tools are available form a variety of sources. These can include COTS, GOTS, and OSS. Each category may have very good solutions. The solution needs to include the sourcing of the tool, the training required for the tool, the ongoing maintenance requirements to the tool, and the support available for the tool (in the form of technical support, product updates, etc.)","title":"Sourcing"},{"location":"testing/5-3-evaluation/#support","text":"Support for test tools can be available from many sources. Vendors often have dedicated support sites that allow logging of issues. These are normally restricted to customers paying for support, either directly or indirectly via maintenance contracts. Additionally forums exist on the internet that focus specifically on particular testing tools. These forums may not be a reliable place for answers as contributions are made by volunteers who may or may not have the knowledge to answer correctly.","title":"Support"},{"location":"testing/5-3-evaluation/#investment","text":"Test tools from commercial entities have a variety of licensing fees structures. These can include individual, per seat, and floating, among others. Understanding the intended usage by your team will help define which license structure that is best for you. Additionally, commercial entities have support and maintenance fees. Support allows for technical questions or issues to be submitted and responded to, while maintenance usually provides for minor and major updates to the testing tool. Working with the most recent version of a tool will often help resolve technical issues (e.g., compatibility, defects, etc.). Training should also be included as a cost, both for vendor and open source solutions.","title":"Investment"},{"location":"testing/5-3-evaluation/#evaluation-tables","text":"Evaluation of the above criteria can be reduced to a table indicating the relative importance for each category, with a total weight at 100%. As tools are evaluated, completing the table helps to compare one tool against another tool objectively. (sample values for illustration) Categories should be rated for how closely they meet the intended requirements. A score allows the category to show a strength or weakness in meeting the category requirement. Use of a scoring system ranging from 0 to 5 where each value indicates alignment to the requirement score. Finally, no tool evaluation is complete without trying the tool out in the intended environment where there is a need to automate. This will ensure that the tool really does work as intended.","title":"EVALUATION TABLES"},{"location":"testing/5-3-evaluation/#533-proof-of-concept","text":"A proof of concept (PoC) is the first step in understanding if a given test tool meets the anticipated needs of the project. With a PoC we want to ensure that the technology that we've provisionally selected actually works in the intended environment. This is key as any prior demonstration of the tool, however capable, needs to now show the same capability in the intended environment.","title":"5.3.3 Proof-of-concept"},{"location":"testing/5-3-evaluation/#534-test-tool-prototypes","text":"A prototype takes the PoC further along by automating a narrowly defined set of functionality from a system where automation is to take hold. The prototype helps the project team understand the complexities of implementation in a timeframe that will not drain excessive resources or funding. The prototype shows the way ahead and serves to realign expectations of how long it actually takes to get test built for automation. The lessons learned from the prototype will bring greater efficiency to the next phase of automation.","title":"5.3.4 Test tool prototypes"},{"location":"testing/5-3-evaluation/#535-tool-training-and-support","text":"Success in automation requires an overall understanding of testing, technology, and the features and functions of specific testing tools in meeting the stated requirements. Appendix B: Test Tools provides a listing of tools that have been shown to be successful across projects and programs. Appendix A: Resources provides additional resources that cover education and certification around testing best practices and test tools. Combining education and certification with hands-on test tool knowledge empowers the test team to develop purpose-built solutions that align with project and program needs.","title":"5.3.5 Tool training and support"},{"location":"testing/6-1-what/","text":"6.1 What Makes Sense to Automate The process of test case selection and evaluation Complex tests Tests that are complex create the possibility of introducing errors into their execution. Testers, careful as they are, are susceptible to making execution errors while they are testing. Complexity is a quality best delegated to computers. However, the complexity of the test need to be designed and tested before or during the codification to automation. Complex tests may require testing results from calculations and those calculation results are best defined outside of the automated test. Otherwise, the automated test adds additional risk of coding and logic error if it not only has to validate results but also needs to calculate them as well. Long tests Often, business scenarios can take 100 - 300 steps in order to be fully exercised. This creates very long tests which are very time-consuming to execute. The longer the manual execution time, the more time there is to introduce an operator error. Additionally, manually executing a long test introduces risk as it is difficult to document the intervening steps making it difficult to state unequivocally if the test was 100% successful. Automation allows us to codify any number of steps necessary to execute a test, all with the possibility of providing an audit trail of that activity. Repeatable tests Tests that are run on a regular basis in order to validate application functionality are excellent candidates for automation as reuse provides high return on investment. Often, projects will use a risk-based approach to testing that balances the risks with the high-value system functions. In this way the most critical functionality is tested first, while less critical functionality is tested time permitting. Often the first tests that will be automated are the smoke tests, or high-level tests which are run for every release, major and minor, and whose function is to establish the most basic operational requirement. This often will include the ability to access a system with valid credentials, navigate across major application functions, and verify that there is database connectivity. Dependency tests Although we develop tests as stand-alone entities, often tests and test data are dependent on one another. For example, when entering an airplane part into an order, we would expect to find that same airplane part in a shipping manifest for that newly created order. If we have one test that creates the order, we need to somehow pass the new order number to the next test so that it can verify the shipping manifest. When testing this manually, we look at the system generated order number, write it down, and then use that order number on the following test. This can get cumbersome and inefficient. With automation, we merely provide an instruction to capture and store the value that we can access at a later time. Scenario based tests Business scenarios often involve multiple dependencies, as described above. However, for the scenario we have a larger scale process that we need to confirm is working. Automation provides an opportunity to link the various functions that are tested across a business scenario. Automation can help synchronize the starting of tests, passing of data from one test to another, aggregating test results, and monitoring systems while the automated test is running. For example, when testing month-end or quarter-end close activities there are a number of processes that need to be done, in a specific order, and dependent upon each other, in order that the final month-end reporting is correct and accurate.","title":"6.1 What Makes Sense to Automate"},{"location":"testing/6-1-what/#61-what-makes-sense-to-automate","text":"The process of test case selection and evaluation","title":"6.1 What Makes Sense to Automate"},{"location":"testing/6-1-what/#complex-tests","text":"Tests that are complex create the possibility of introducing errors into their execution. Testers, careful as they are, are susceptible to making execution errors while they are testing. Complexity is a quality best delegated to computers. However, the complexity of the test need to be designed and tested before or during the codification to automation. Complex tests may require testing results from calculations and those calculation results are best defined outside of the automated test. Otherwise, the automated test adds additional risk of coding and logic error if it not only has to validate results but also needs to calculate them as well.","title":"Complex tests"},{"location":"testing/6-1-what/#long-tests","text":"Often, business scenarios can take 100 - 300 steps in order to be fully exercised. This creates very long tests which are very time-consuming to execute. The longer the manual execution time, the more time there is to introduce an operator error. Additionally, manually executing a long test introduces risk as it is difficult to document the intervening steps making it difficult to state unequivocally if the test was 100% successful. Automation allows us to codify any number of steps necessary to execute a test, all with the possibility of providing an audit trail of that activity.","title":"Long tests"},{"location":"testing/6-1-what/#repeatable-tests","text":"Tests that are run on a regular basis in order to validate application functionality are excellent candidates for automation as reuse provides high return on investment. Often, projects will use a risk-based approach to testing that balances the risks with the high-value system functions. In this way the most critical functionality is tested first, while less critical functionality is tested time permitting. Often the first tests that will be automated are the smoke tests, or high-level tests which are run for every release, major and minor, and whose function is to establish the most basic operational requirement. This often will include the ability to access a system with valid credentials, navigate across major application functions, and verify that there is database connectivity.","title":"Repeatable tests"},{"location":"testing/6-1-what/#dependency-tests","text":"Although we develop tests as stand-alone entities, often tests and test data are dependent on one another. For example, when entering an airplane part into an order, we would expect to find that same airplane part in a shipping manifest for that newly created order. If we have one test that creates the order, we need to somehow pass the new order number to the next test so that it can verify the shipping manifest. When testing this manually, we look at the system generated order number, write it down, and then use that order number on the following test. This can get cumbersome and inefficient. With automation, we merely provide an instruction to capture and store the value that we can access at a later time.","title":"Dependency tests"},{"location":"testing/6-1-what/#scenario-based-tests","text":"Business scenarios often involve multiple dependencies, as described above. However, for the scenario we have a larger scale process that we need to confirm is working. Automation provides an opportunity to link the various functions that are tested across a business scenario. Automation can help synchronize the starting of tests, passing of data from one test to another, aggregating test results, and monitoring systems while the automated test is running. For example, when testing month-end or quarter-end close activities there are a number of processes that need to be done, in a specific order, and dependent upon each other, in order that the final month-end reporting is correct and accurate.","title":"Scenario based tests"},{"location":"testing/6-2-when/","text":"6.2 When Should Automation Occur Ideally, automation of tests should occur once we have a strong understanding of what needs to be tested, when have defined test cases, and when we've developed test data for those test cases. When we've achieved the above, we've likely already tested once or more times manually in order to ensure that our test definitions are correct. This initial manual test activity can save much time for the test automation engineer as that individual will now have valid test conditions and data to work with in developing automated tests. For traditional development methodologies, this would occur after the initial software release and automation would be most helpful in building out a regression test bed. For Agile projects, the automation will likely be scheduled as a 1- or 2-sprint offset as individual sprints themselves do not often allow adequate time to build out the test automation architecture and framework. Automation in Agile becomes a work-in-progress where each successive sprint sees additional functionality and maturation added to the test automation solution.","title":"6.2 When Should Automation Occur"},{"location":"testing/6-2-when/#62-when-should-automation-occur","text":"Ideally, automation of tests should occur once we have a strong understanding of what needs to be tested, when have defined test cases, and when we've developed test data for those test cases. When we've achieved the above, we've likely already tested once or more times manually in order to ensure that our test definitions are correct. This initial manual test activity can save much time for the test automation engineer as that individual will now have valid test conditions and data to work with in developing automated tests. For traditional development methodologies, this would occur after the initial software release and automation would be most helpful in building out a regression test bed. For Agile projects, the automation will likely be scheduled as a 1- or 2-sprint offset as individual sprints themselves do not often allow adequate time to build out the test automation architecture and framework. Automation in Agile becomes a work-in-progress where each successive sprint sees additional functionality and maturation added to the test automation solution.","title":"6.2 When Should Automation Occur"},{"location":"testing/6-3-newtests/","text":"6.3 Criteria for Creating New Automated Tests There may be an opportunity to immediately automate tests, rather than prepare for automation with manual tests. In order for this to happen, the test automation framework has to be sufficiently developed to allow its use for new tests. The timing of this is dependent on the complexity of the application and components that need to be tested. For example, if an application has 200 different controls spread across 5 functional areas, the framework must be capable of identifying and interacting with each of those controls, so that no test is off limits for development. If the 200 controls can be mapped out against the 5 functional areas, then as long as the functional areas under test have been verified and are compatible automation can proceed. Often automation teams do not do their due diligence to find all controls and ensure that the test automation solution indeed is compatible with every one of them. It only takes 1 error in trying to interact with a control for testing to fail, thus undermining the automated approach.","title":"6.3 Criteria for Creating New Automated Tests"},{"location":"testing/6-3-newtests/#63-criteria-for-creating-new-automated-tests","text":"There may be an opportunity to immediately automate tests, rather than prepare for automation with manual tests. In order for this to happen, the test automation framework has to be sufficiently developed to allow its use for new tests. The timing of this is dependent on the complexity of the application and components that need to be tested. For example, if an application has 200 different controls spread across 5 functional areas, the framework must be capable of identifying and interacting with each of those controls, so that no test is off limits for development. If the 200 controls can be mapped out against the 5 functional areas, then as long as the functional areas under test have been verified and are compatible automation can proceed. Often automation teams do not do their due diligence to find all controls and ensure that the test automation solution indeed is compatible with every one of them. It only takes 1 error in trying to interact with a control for testing to fail, thus undermining the automated approach.","title":"6.3 Criteria for Creating New Automated Tests"},{"location":"testing/6-4-manualtests/","text":"6.4 Criteria for Converting Manual Tests to Automation Most projects have documented test cases and scripts defining the test steps. When evaluating the migration of tests to automation, the following should be considered: Is the test necessary? Often, tests that were developed a long time ago no longer provide the value they once did as applications evolve and other newer tests may already cover parts of the functionality from older tests. When examining existing tests, evaluate if any or all of a test's functions may already be present in other tests. Is the test complete? Does the test exercise the complete business process so that it provides relevant, meaningful results? If not, the business analyst, manual tester, and test automation engineer will likely need to work together to enhance the capability of the automated test. Is the test effective? Effectiveness for any test can be measured by coverage to the requirement and coverage to the code. Specification based testing techniques help us determine how to construct data sets that will provide us with the least amount of test cases that can generate the highest level of coverage, thus mitigating deployment risk. Code coverage tools can be run by developers in parallel to test execution to verify the code coverage. Automation provides us the vehicle by which additional quality test cases can now be executed which previously were not possible, due to time and resource constraints, under a manual scenario. Is the test efficient? Test efficiency can take on several aspects, from speed of execution to overall construction. Automation by itself will always execute a test faster than can be done manually. However, not all manual tests have been designed in a way that is efficient for automation to process them. For example, for many applications, testing follows a prescribed path through an application. The path of navigation is what allows us to test getting from, say, the login screen to the reports screen. Some applications can have complex or lengthy paths before even getting to test for data. With automation we have the opportunity to create navigational tests that can be combined with functional tests in a manner that allows for reuse. Regarding test construction, the approach used to develop a manual test will often differ from the approach to develop an automated test. This is due to the different ways in which each test is executed. Testers think and act linearly, while computers can be made to jump from one area to another. Decomposition of manual tests and reconstruction is a worthwhile effort in order to maximize the quality of automated tests produced. Depending on how manual tests have been created, they may be: Broken apart and reconstituted across various automated tests Combined into one larger automated test Converted one-for-one as an automated test","title":"6.4 Criteria for Converting Manual Tests to Automation"},{"location":"testing/6-4-manualtests/#64-criteria-for-converting-manual-tests-to-automation","text":"Most projects have documented test cases and scripts defining the test steps. When evaluating the migration of tests to automation, the following should be considered:","title":"6.4 Criteria for Converting Manual Tests to Automation"},{"location":"testing/6-4-manualtests/#is-the-test-necessary","text":"Often, tests that were developed a long time ago no longer provide the value they once did as applications evolve and other newer tests may already cover parts of the functionality from older tests. When examining existing tests, evaluate if any or all of a test's functions may already be present in other tests.","title":"Is the test necessary?"},{"location":"testing/6-4-manualtests/#is-the-test-complete","text":"Does the test exercise the complete business process so that it provides relevant, meaningful results? If not, the business analyst, manual tester, and test automation engineer will likely need to work together to enhance the capability of the automated test.","title":"Is the test complete?"},{"location":"testing/6-4-manualtests/#is-the-test-effective","text":"Effectiveness for any test can be measured by coverage to the requirement and coverage to the code. Specification based testing techniques help us determine how to construct data sets that will provide us with the least amount of test cases that can generate the highest level of coverage, thus mitigating deployment risk. Code coverage tools can be run by developers in parallel to test execution to verify the code coverage. Automation provides us the vehicle by which additional quality test cases can now be executed which previously were not possible, due to time and resource constraints, under a manual scenario.","title":"Is the test effective?"},{"location":"testing/6-4-manualtests/#is-the-test-efficient","text":"Test efficiency can take on several aspects, from speed of execution to overall construction. Automation by itself will always execute a test faster than can be done manually. However, not all manual tests have been designed in a way that is efficient for automation to process them. For example, for many applications, testing follows a prescribed path through an application. The path of navigation is what allows us to test getting from, say, the login screen to the reports screen. Some applications can have complex or lengthy paths before even getting to test for data. With automation we have the opportunity to create navigational tests that can be combined with functional tests in a manner that allows for reuse. Regarding test construction, the approach used to develop a manual test will often differ from the approach to develop an automated test. This is due to the different ways in which each test is executed. Testers think and act linearly, while computers can be made to jump from one area to another. Decomposition of manual tests and reconstruction is a worthwhile effort in order to maximize the quality of automated tests produced. Depending on how manual tests have been created, they may be: Broken apart and reconstituted across various automated tests Combined into one larger automated test Converted one-for-one as an automated test","title":"Is the test efficient?"},{"location":"testing/6-5-transition/","text":"6.5 Transitioning Staff to Automation Since the advent of testing tools there has been talk that automation kills testing jobs. For large programs heavily dependent on manual testers we would expect to see a reduction of an inefficient process. However, automation mostly helps testers increase their focus on developing quality tests rather than on time consuming \"key pounding\" test execution activity. It is very important to make sure staff understand that they are valued for their knowledge of systems and their testing acumen. It is also important to acknowledge that in order for automation to be successful, there are different roles, and not all roles require programing skills. Section 3.5 describes the various roles necessary for the tasks required to make automation successful. Outsourced solutions Test automation solutions can be contracted out to firms knowledgeable in creating and maintaining test automation frameworks. In this scenario, a firm would be contracted to assist in automating all or part of a system. Once the capability is developed the government would request documentation, training, and transitioning as part of the final deliverable. Government developed solutions Government developed automation would require the selection of staff with the appropriate skills and training so that the process of building out automation does not become a learn-as-you-go exercise, which ultimately will not show a high return on investment. Appendix A covers many resources that can provide the necessary knowledge for team members. Acquiring automation assets In addition to the wide range of test automation tools described in Section 5.3.1 and listed in Appendix B there exist pre-made frameworks that can be used with existing tools. These frameworks can offer a shortcut to a build-from-scratch strategy, and often one can continue to build additional functionality to the base framework libraries. Regardless of the solution used in migrating to automation, a tool-agnostic approach that abstracts test data from test tools provides the greatest flexibility and overall longevity.","title":"6.5 Transitioning Staff to Automation"},{"location":"testing/6-5-transition/#65-transitioning-staff-to-automation","text":"Since the advent of testing tools there has been talk that automation kills testing jobs. For large programs heavily dependent on manual testers we would expect to see a reduction of an inefficient process. However, automation mostly helps testers increase their focus on developing quality tests rather than on time consuming \"key pounding\" test execution activity. It is very important to make sure staff understand that they are valued for their knowledge of systems and their testing acumen. It is also important to acknowledge that in order for automation to be successful, there are different roles, and not all roles require programing skills. Section 3.5 describes the various roles necessary for the tasks required to make automation successful.","title":"6.5 Transitioning Staff to Automation"},{"location":"testing/6-5-transition/#outsourced-solutions","text":"Test automation solutions can be contracted out to firms knowledgeable in creating and maintaining test automation frameworks. In this scenario, a firm would be contracted to assist in automating all or part of a system. Once the capability is developed the government would request documentation, training, and transitioning as part of the final deliverable.","title":"Outsourced solutions"},{"location":"testing/6-5-transition/#government-developed-solutions","text":"Government developed automation would require the selection of staff with the appropriate skills and training so that the process of building out automation does not become a learn-as-you-go exercise, which ultimately will not show a high return on investment. Appendix A covers many resources that can provide the necessary knowledge for team members.","title":"Government developed solutions"},{"location":"testing/6-5-transition/#acquiring-automation-assets","text":"In addition to the wide range of test automation tools described in Section 5.3.1 and listed in Appendix B there exist pre-made frameworks that can be used with existing tools. These frameworks can offer a shortcut to a build-from-scratch strategy, and often one can continue to build additional functionality to the base framework libraries. Regardless of the solution used in migrating to automation, a tool-agnostic approach that abstracts test data from test tools provides the greatest flexibility and overall longevity.","title":"Acquiring automation assets"},{"location":"testing/7-1-phases/","text":"7.1 Phases in Automation Development The lifecycle phases for development of a test automation solution are not unlike software development for software applications. Although there are differences the process mostly follows the same steps, which include: Requirements Phase The requirements phase allows us to capture features and functionality necessary for our automation solution. Requirements for automation often fall within the following areas: Input/output (I/O) requirements External interface requirements User interface (UI) control requirements Navigation requirements Timing and synchronization requirements Development of logging and reporting functions Requirements for utilities Requirements for automation are all about enabling interaction with the SUT and providing clear reporting of those interactions. Design Phase The design phase for automation includes the evaluation of tools that as described in section 5.3, Evaluation and selection of test tools. Here, we differ from traditional software development in that we are finding test tools that offer compatibility and features needed to interact with our SUT. This is the primary consideration of our design as failing to ensure compatibility with the SUT prevents us from effectively automating. Technical Design Phase The technical design for automation is described in section 5.2, Overall architectural considerations. Here we define an approach that covers the various interfaces and reporting requirements of our SUT. We map out our framework components in this phase so that we know what development activity will be required. Development Phase The development phase in automation will include the possibility of programming functions and developing libraries that address our stated requirements. Additionally it may include some pre-built modules that provide out-of-the-box functionality from our selected test tool or it may include some third-party modules that integrate with the test tool add functionality. Test Phase Each feature and function that has been engineered into our automated solution must be tested in order that we can be certain it will reliably and accurately help us in testing the SUT. A test baseline must be used in order to validate functionality as testing the automation against the SUT may be unpredictable. Implementation Phase Once we have a high degree of confidence that our automation solution is working properly, we can start using it to test against the SUT. While we expect that automated testing will help us uncover defects, we always first need to verify that the defect is not attributable to the automation components. With automation, the features and functions we build are there to support our need for testing against software application programs.","title":"7.1 Phases in Automation Development"},{"location":"testing/7-1-phases/#71-phases-in-automation-development","text":"The lifecycle phases for development of a test automation solution are not unlike software development for software applications. Although there are differences the process mostly follows the same steps, which include:","title":"7.1 Phases in Automation Development"},{"location":"testing/7-1-phases/#requirements-phase","text":"The requirements phase allows us to capture features and functionality necessary for our automation solution. Requirements for automation often fall within the following areas: Input/output (I/O) requirements External interface requirements User interface (UI) control requirements Navigation requirements Timing and synchronization requirements Development of logging and reporting functions Requirements for utilities Requirements for automation are all about enabling interaction with the SUT and providing clear reporting of those interactions.","title":"Requirements Phase"},{"location":"testing/7-1-phases/#design-phase","text":"The design phase for automation includes the evaluation of tools that as described in section 5.3, Evaluation and selection of test tools. Here, we differ from traditional software development in that we are finding test tools that offer compatibility and features needed to interact with our SUT. This is the primary consideration of our design as failing to ensure compatibility with the SUT prevents us from effectively automating.","title":"Design Phase"},{"location":"testing/7-1-phases/#technical-design-phase","text":"The technical design for automation is described in section 5.2, Overall architectural considerations. Here we define an approach that covers the various interfaces and reporting requirements of our SUT. We map out our framework components in this phase so that we know what development activity will be required.","title":"Technical Design Phase"},{"location":"testing/7-1-phases/#development-phase","text":"The development phase in automation will include the possibility of programming functions and developing libraries that address our stated requirements. Additionally it may include some pre-built modules that provide out-of-the-box functionality from our selected test tool or it may include some third-party modules that integrate with the test tool add functionality.","title":"Development Phase"},{"location":"testing/7-1-phases/#test-phase","text":"Each feature and function that has been engineered into our automated solution must be tested in order that we can be certain it will reliably and accurately help us in testing the SUT. A test baseline must be used in order to validate functionality as testing the automation against the SUT may be unpredictable.","title":"Test Phase"},{"location":"testing/7-1-phases/#implementation-phase","text":"Once we have a high degree of confidence that our automation solution is working properly, we can start using it to test against the SUT. While we expect that automated testing will help us uncover defects, we always first need to verify that the defect is not attributable to the automation components. With automation, the features and functions we build are there to support our need for testing against software application programs.","title":"Implementation Phase"},{"location":"testing/7-2-appdev/","text":"7.2 Similarities to Application Development Development of a test automation solution should include best practices. These include, but are not limited to: Reviews Reviews are an important aspect of making sure that what is being developed stays true to what is expected. Implied in the review process is that someone other than the individual producing the work has an opportunity to evaluate and provide feedback. Reviews are often done incrementally thus allowing for changes or course-correction to take place if warranted. Reviews can start at a very high level, progress to a very detailed level, and also include quality characteristics. Reviews can cover: Architecture Code Peer Usability Documentation Documentation helps us understand the automated solution at various levels. From how it works, and what features it contains, to how to make changes or upgrades. Documentation helps make sure that the automated solution is used properly. In summary we can use documentation for: In-line code descriptions Function descriptions Library cataloging User instructions Maintenance instructions Standard variable naming The way in which variables are named in a software often helps us understand the context and use of that variable. Using capitalization and lower case letters in a mixed case format along with compound word choices can facilitate the automation engineer's understanding of what variables are used for. This also provides discipline for new variables to use the same naming standards and conventions. Abstraction Abstraction indicates a separation of all but the most relevant data in order to reduce complexity, duplication, and increase efficiency of the automation code base. With automation, an example of abstraction may revolve around the way we choose to interact with a given UI control. With abstraction, we would create a single function that is used to interact with that control regardless of where it appears within the SUT. The function itself will have the details pertaining to what methods and data the control needs. Cyclomatic complexity The cyclomatic complexity metric is a quantitative measure of code complexity. It allows us to measure the number of linearly independent paths through code. A high cyclomatic complexity value indicates that many (if not too many) paths exist which in turn indicates a high number of test cases necessary to fully validate code. Although most test automation code is not subject to cyclomatic complexity analysis, in the way that a software program might, it is good practice to keep the number of independent paths (often referred to as conditions) low so that we can ensure proper testing can be done while minimizing potential errors due to code complexity.","title":"7.2 Similarities to Application Development"},{"location":"testing/7-2-appdev/#72-similarities-to-application-development","text":"Development of a test automation solution should include best practices. These include, but are not limited to:","title":"7.2 Similarities to Application Development"},{"location":"testing/7-2-appdev/#reviews","text":"Reviews are an important aspect of making sure that what is being developed stays true to what is expected. Implied in the review process is that someone other than the individual producing the work has an opportunity to evaluate and provide feedback. Reviews are often done incrementally thus allowing for changes or course-correction to take place if warranted. Reviews can start at a very high level, progress to a very detailed level, and also include quality characteristics. Reviews can cover: Architecture Code Peer Usability","title":"Reviews"},{"location":"testing/7-2-appdev/#documentation","text":"Documentation helps us understand the automated solution at various levels. From how it works, and what features it contains, to how to make changes or upgrades. Documentation helps make sure that the automated solution is used properly. In summary we can use documentation for: In-line code descriptions Function descriptions Library cataloging User instructions Maintenance instructions","title":"Documentation"},{"location":"testing/7-2-appdev/#standard-variable-naming","text":"The way in which variables are named in a software often helps us understand the context and use of that variable. Using capitalization and lower case letters in a mixed case format along with compound word choices can facilitate the automation engineer's understanding of what variables are used for. This also provides discipline for new variables to use the same naming standards and conventions.","title":"Standard variable naming"},{"location":"testing/7-2-appdev/#abstraction","text":"Abstraction indicates a separation of all but the most relevant data in order to reduce complexity, duplication, and increase efficiency of the automation code base. With automation, an example of abstraction may revolve around the way we choose to interact with a given UI control. With abstraction, we would create a single function that is used to interact with that control regardless of where it appears within the SUT. The function itself will have the details pertaining to what methods and data the control needs.","title":"Abstraction"},{"location":"testing/7-2-appdev/#cyclomatic-complexity","text":"The cyclomatic complexity metric is a quantitative measure of code complexity. It allows us to measure the number of linearly independent paths through code. A high cyclomatic complexity value indicates that many (if not too many) paths exist which in turn indicates a high number of test cases necessary to fully validate code. Although most test automation code is not subject to cyclomatic complexity analysis, in the way that a software program might, it is good practice to keep the number of independent paths (often referred to as conditions) low so that we can ensure proper testing can be done while minimizing potential errors due to code complexity.","title":"Cyclomatic complexity"},{"location":"testing/7-3-manualtests/","text":"7.3 Similarities to Manual Testing Once we have our test automation solution up and running and we have data to drive some testing we can confirm that our automated solution properly tests the SUT and faithfully reproduces the testing that was otherwise done manually. We still need to analyze what is to be tested. From this we need to define the test types and develop test data. This is all still very similar to the work we do in manual testing. However, the definition of data for automated testing is more structured as we're now reliant on the test automation solution and specifically the testing framework to work with our defined data and provide us with results. As with manual testing we will have results to analyze, but with automation we would expect a good portion of this analysis, at least as it pertains to verifications and comparisons, to occur automatically via automation. From here we need to ensure the confidence in our acceptance in that automation has met or exceeded our previous manual testing efforts. This is an important milestone and one which can help bring the team together in supporting their contributions in the development of test automation.","title":"7.3 Similarities to Manual Testing"},{"location":"testing/7-3-manualtests/#73-similarities-to-manual-testing","text":"Once we have our test automation solution up and running and we have data to drive some testing we can confirm that our automated solution properly tests the SUT and faithfully reproduces the testing that was otherwise done manually. We still need to analyze what is to be tested. From this we need to define the test types and develop test data. This is all still very similar to the work we do in manual testing. However, the definition of data for automated testing is more structured as we're now reliant on the test automation solution and specifically the testing framework to work with our defined data and provide us with results. As with manual testing we will have results to analyze, but with automation we would expect a good portion of this analysis, at least as it pertains to verifications and comparisons, to occur automatically via automation. From here we need to ensure the confidence in our acceptance in that automation has met or exceeded our previous manual testing efforts. This is an important milestone and one which can help bring the team together in supporting their contributions in the development of test automation.","title":"7.3 Similarities to Manual Testing"},{"location":"testing/8-1-measurements/","text":"8.1 Effectiveness Measurements Automation impacts can be measured beyond speed of test execution. The following areas provide metrics on use and effectiveness of automation. Schedule Test Execution time improvement Test Setup time improvement Time to determine failures/defects Time to analyze data Effectiveness Failures found Number of test required/number of system errors Defects found/number of test procedures executed Test procedures executed without defects/ total test procedures Coverage Test Coverage - test procedures/test requirements Automation test coverage - automated test cases/total test cases New test capabilities Reusability improvement within project/program Cost Man-hour reduction Total project or program savings Additional training requirement Additional resources Additional Maintainability Each project or program should select those metrics that provide the most relevant feedback to assess quality and effectiveness of automation. Although test execution times are dramatically shortened through the use of automation, test preparation steps and maintenance for automation need to be measured as part of the overall effort and cost, as compared to manual testing.","title":"8.1 Effectiveness Measurements"},{"location":"testing/8-1-measurements/#81-effectiveness-measurements","text":"Automation impacts can be measured beyond speed of test execution. The following areas provide metrics on use and effectiveness of automation.","title":"8.1 Effectiveness Measurements"},{"location":"testing/8-1-measurements/#schedule","text":"Test Execution time improvement Test Setup time improvement Time to determine failures/defects Time to analyze data","title":"Schedule"},{"location":"testing/8-1-measurements/#effectiveness","text":"Failures found Number of test required/number of system errors Defects found/number of test procedures executed Test procedures executed without defects/ total test procedures","title":"Effectiveness"},{"location":"testing/8-1-measurements/#coverage","text":"Test Coverage - test procedures/test requirements Automation test coverage - automated test cases/total test cases New test capabilities Reusability improvement within project/program","title":"Coverage"},{"location":"testing/8-1-measurements/#cost","text":"Man-hour reduction Total project or program savings Additional training requirement Additional resources Additional Maintainability Each project or program should select those metrics that provide the most relevant feedback to assess quality and effectiveness of automation. Although test execution times are dramatically shortened through the use of automation, test preparation steps and maintenance for automation need to be measured as part of the overall effort and cost, as compared to manual testing.","title":"Cost"},{"location":"testing/9-1-reporting/","text":"9.1 Reporting Test reporting is an important part of the process of automated testing. There are a number of different ways by which we can produce reports from automation. Test execution tools Test execution tools represent the most critical component in reporting. It is at the execution of tests that data can be captured which is then used for reporting. Test execution tools will often have one reporting mechanism that shows that occurred during the test execution, including any verification steps and any failure points. The reporting provided by these tools is very focused to the sequence of events that occurred and often do not capture larger trends. Execution tools often have the ability to customize the reporting, often by inserting messages and custom output text to complement default reporting. Additionally, execution tools may have separate logs that show if any errors occurred as functions were called. Custom logs can be created in order to meet specific output requirements, like when data needs to be imported into other tools in a standardized format. Test management tools Test management tools often help to store and aggregate data and can report on an individual or group of tests. This is helpful in order to see trends in application quality. Management tools often have several mechanisms for reporting including standard table reports, summary table reports, and graphical data representations. These can include charts, graphs, and other visual elements that facilitate analyzing high level data without having to look at the more granular data. Test reporting tools Reporting tools exist that are not specific to testing but that can take a variety of input files (e.g. xls, cvs, etc.) and aggregate results for meaningful display. There is overlap with the management tools on some reports. However, reporting tools can also include project management tools that help with scheduling activities and task interdependencies. As tools have a diverse set of reporting functionality, it may take more than one tool to get all reporting requirements in place. Therefore, understanding each tool's import/export capabilities and requirements will ensure that data can freely flow from one reporting tool to another.","title":"9.1 Reporting"},{"location":"testing/9-1-reporting/#91-reporting","text":"Test reporting is an important part of the process of automated testing. There are a number of different ways by which we can produce reports from automation.","title":"9.1 Reporting"},{"location":"testing/9-1-reporting/#test-execution-tools","text":"Test execution tools represent the most critical component in reporting. It is at the execution of tests that data can be captured which is then used for reporting. Test execution tools will often have one reporting mechanism that shows that occurred during the test execution, including any verification steps and any failure points. The reporting provided by these tools is very focused to the sequence of events that occurred and often do not capture larger trends. Execution tools often have the ability to customize the reporting, often by inserting messages and custom output text to complement default reporting. Additionally, execution tools may have separate logs that show if any errors occurred as functions were called. Custom logs can be created in order to meet specific output requirements, like when data needs to be imported into other tools in a standardized format.","title":"Test execution tools"},{"location":"testing/9-1-reporting/#test-management-tools","text":"Test management tools often help to store and aggregate data and can report on an individual or group of tests. This is helpful in order to see trends in application quality. Management tools often have several mechanisms for reporting including standard table reports, summary table reports, and graphical data representations. These can include charts, graphs, and other visual elements that facilitate analyzing high level data without having to look at the more granular data.","title":"Test management tools"},{"location":"testing/9-1-reporting/#test-reporting-tools","text":"Reporting tools exist that are not specific to testing but that can take a variety of input files (e.g. xls, cvs, etc.) and aggregate results for meaningful display. There is overlap with the management tools on some reports. However, reporting tools can also include project management tools that help with scheduling activities and task interdependencies. As tools have a diverse set of reporting functionality, it may take more than one tool to get all reporting requirements in place. Therefore, understanding each tool's import/export capabilities and requirements will ensure that data can freely flow from one reporting tool to another.","title":"Test reporting tools"},{"location":"ux/1-1-purpose/","text":"1.1 Purpose This User Experience Playbook is a continuation of effort by the BES PEO to establish modern practices and methods to accelerate software development and deployment of value for Logistics Information Systems and its end users. Preceded by playbooks for Agile and Automated Testing, the User Experience playbook aims to define a framework for how to plan and structure projects to include User Experience (UX) in both Agile and Waterfall environments, describing each stage of the process including key activities and deliverables as well as their benefits. Furthermore, this playbook aims to establish core User Experience design principles unique to the mission of Logistics Information Systems, as well as Web and Component Design Standards to create a more unified and consistent digital presence while enabling more rapid planning and deployment of future digital initiatives. These Web and Component Design Standards will include guidelines for typography, color and other style parameters in addition to reusable design patterns for common components such as navigation, buttons, alerts and form controls. The User Experience Playbook will serve as a \u201cliving document,\u201d delivering value in the present while providing a foundation for future updates and enhancements as the state of technology and the needs of stakeholders and users served by Logistics Information Systems continually evolve. For those seeking further resources and materials to help you advance along the path the understanding User Experience practices and methods, please see the Resources page within the Appendix.","title":"1.1 Purpose"},{"location":"ux/1-1-purpose/#11-purpose","text":"This User Experience Playbook is a continuation of effort by the BES PEO to establish modern practices and methods to accelerate software development and deployment of value for Logistics Information Systems and its end users. Preceded by playbooks for Agile and Automated Testing, the User Experience playbook aims to define a framework for how to plan and structure projects to include User Experience (UX) in both Agile and Waterfall environments, describing each stage of the process including key activities and deliverables as well as their benefits. Furthermore, this playbook aims to establish core User Experience design principles unique to the mission of Logistics Information Systems, as well as Web and Component Design Standards to create a more unified and consistent digital presence while enabling more rapid planning and deployment of future digital initiatives. These Web and Component Design Standards will include guidelines for typography, color and other style parameters in addition to reusable design patterns for common components such as navigation, buttons, alerts and form controls. The User Experience Playbook will serve as a \u201cliving document,\u201d delivering value in the present while providing a foundation for future updates and enhancements as the state of technology and the needs of stakeholders and users served by Logistics Information Systems continually evolve. For those seeking further resources and materials to help you advance along the path the understanding User Experience practices and methods, please see the Resources page within the Appendix.","title":"1.1 Purpose"},{"location":"ux/1-2-audience/","text":"1.2 Audience While this playbook can provide value to all personnel involved in a software development project, the primary audience for this playbook are those individuals who are responsible for the planning, management and development of projects that employ or might benefit from User Experience methodologies. For program managers and those in similar roles, this playbook will provide a foundation of knowledge to enable more effective planning and support for programs where User Experience methodologies might be employed. It will also establish a framework by which the quality and effectiveness of Logistics Information Systems\u2019 digital experiences can be evaluated. For software engineers and those in similar roles, this playbook will provide a valuable resource for design patterns and guidelines from which new digital experiences can be created, enabling faster design decisions and more rapid deployment while ensuring consistency and quality across all digital experiences delivered by Logistics Information Systems. For software development project teams as a whole, this playbook will help establish key concepts and methods that will enable more consistent delivery of solutions that meet the needs of end users and the broader organization. These operational benefits will translate to a more efficient and effective workforce, equipped with digital tools that reliably enhance their ability to achieve mission-critical goals.","title":"1.2 Audience"},{"location":"ux/1-2-audience/#12-audience","text":"While this playbook can provide value to all personnel involved in a software development project, the primary audience for this playbook are those individuals who are responsible for the planning, management and development of projects that employ or might benefit from User Experience methodologies. For program managers and those in similar roles, this playbook will provide a foundation of knowledge to enable more effective planning and support for programs where User Experience methodologies might be employed. It will also establish a framework by which the quality and effectiveness of Logistics Information Systems\u2019 digital experiences can be evaluated. For software engineers and those in similar roles, this playbook will provide a valuable resource for design patterns and guidelines from which new digital experiences can be created, enabling faster design decisions and more rapid deployment while ensuring consistency and quality across all digital experiences delivered by Logistics Information Systems. For software development project teams as a whole, this playbook will help establish key concepts and methods that will enable more consistent delivery of solutions that meet the needs of end users and the broader organization. These operational benefits will translate to a more efficient and effective workforce, equipped with digital tools that reliably enhance their ability to achieve mission-critical goals.","title":"1.2 Audience"},{"location":"ux/1-3-benefits/","text":"1.3 Benefits of UX While a number of disciplines have long paved the way for User Experience \u2013 including cognitive psychology, library science and human-computer interaction (HCI) \u2013 the need for organizations to create and adopt this unique discipline arose at the outset of the internet era as society became increasingly dependent on user interfaces to facilitate daily tasks. The aim of this new discipline was to establish more reliable practices and methods to deliver user-centered software solutions, putting aside biases in the way project teams imagine user needs to create a more firm foundation of evidence upon which to base design decisions. The practices and methods offered by the User Experience discipline ultimately help create greater efficiency on the project team while promoting greater effectiveness and satisfaction among end users. Studies consistently reinforce these benefits. A frequently cited report by IEEE states that: 70% of projects fail due to lack of user acceptance Investment in User Experience results in 33\u201350% reduced development time by having better upfront definition of requirements and avoiding rework Every dollar invested in UX brings 100 dollars in return Among the most common factors for project failure are: Unrealistic or unarticulated project goals Inaccurate estimates of needed resources Badly defined system requirements\u00b4 Poor communication among customers, developers and users Inability to handle the project\u2019s complexity User Experience is the key to addressing many of these factors. A well-defined User Experience process can help to establish and clarify project goals, balancing the needs of the people and organizations that stand to benefit most from digital products. The process also helps validate and refine system requirements by facilitating their analysis through the lens of user value, organizational value and complexity, identifying and resolving areas of ambiguity prior to the initiation of development cycles. These benefits leads to stronger project plans, better estimation and increased chances for project success. The USAF is unique in its challenges and opportunities as they relate to incorporating User Experience practices and methods within its daily operations. The USAF became reliant on technology systems far in advance of the general public, and many of those early systems were deployed at a larger scale than comparable commercial systems. In addition, these software systems support highly mission-critical operations where effectiveness cannot be compromised. This makes the effort associated with updating legacy systems and modernizing practices much more challenging and sensitive than are typically found. However these factors also reinforce the need to make these changes, taking advantage of better technological capabilities and User Experience practices that yield greater effectiveness across the organization and its workforce, ensuring greater success and reliability for these mission-critical operations. Reference Why Software Fails https://spectrum.ieee.org/computing/software/why-software-fails","title":"1.3 Benefits of UX"},{"location":"ux/1-3-benefits/#13-benefits-of-ux","text":"While a number of disciplines have long paved the way for User Experience \u2013 including cognitive psychology, library science and human-computer interaction (HCI) \u2013 the need for organizations to create and adopt this unique discipline arose at the outset of the internet era as society became increasingly dependent on user interfaces to facilitate daily tasks. The aim of this new discipline was to establish more reliable practices and methods to deliver user-centered software solutions, putting aside biases in the way project teams imagine user needs to create a more firm foundation of evidence upon which to base design decisions. The practices and methods offered by the User Experience discipline ultimately help create greater efficiency on the project team while promoting greater effectiveness and satisfaction among end users.","title":"1.3 Benefits of UX"},{"location":"ux/1-3-benefits/#studies-consistently-reinforce-these-benefits-a-frequently-cited-report-by-ieee-states-that","text":"70% of projects fail due to lack of user acceptance Investment in User Experience results in 33\u201350% reduced development time by having better upfront definition of requirements and avoiding rework Every dollar invested in UX brings 100 dollars in return","title":"Studies consistently reinforce these benefits. A frequently cited report by IEEE states that:"},{"location":"ux/1-3-benefits/#among-the-most-common-factors-for-project-failure-are","text":"Unrealistic or unarticulated project goals Inaccurate estimates of needed resources Badly defined system requirements\u00b4 Poor communication among customers, developers and users Inability to handle the project\u2019s complexity User Experience is the key to addressing many of these factors. A well-defined User Experience process can help to establish and clarify project goals, balancing the needs of the people and organizations that stand to benefit most from digital products. The process also helps validate and refine system requirements by facilitating their analysis through the lens of user value, organizational value and complexity, identifying and resolving areas of ambiguity prior to the initiation of development cycles. These benefits leads to stronger project plans, better estimation and increased chances for project success. The USAF is unique in its challenges and opportunities as they relate to incorporating User Experience practices and methods within its daily operations. The USAF became reliant on technology systems far in advance of the general public, and many of those early systems were deployed at a larger scale than comparable commercial systems. In addition, these software systems support highly mission-critical operations where effectiveness cannot be compromised. This makes the effort associated with updating legacy systems and modernizing practices much more challenging and sensitive than are typically found. However these factors also reinforce the need to make these changes, taking advantage of better technological capabilities and User Experience practices that yield greater effectiveness across the organization and its workforce, ensuring greater success and reliability for these mission-critical operations.","title":"Among the most common factors for project failure are:"},{"location":"ux/1-3-benefits/#reference","text":"Why Software Fails https://spectrum.ieee.org/computing/software/why-software-fails","title":"Reference"},{"location":"ux/1-4-maturity/","text":"1.4 Levels of Design Maturity Integration of user experience as a core strategic pillar within your organization is not a binary proposition. Every organization will have differences in the extent to which they have adopted design into their business process. For this reason, InVision defined a maturity model for experience design adoption. In this model, organizations are rated at one of five levels. It\u2019s important to be cognizant of your current maturity level within this model, and to appreciate that moving up this model only increases the overall return on investment to your mission, your stakeholders, and your end users. For example, per InVision\u2019s research, organizations are five times more likely to report having an impact on cost savings, when functioning at a Level 5 versus a Level 1. This number only increases when examining time to release. 1.4.1 Leveling Up Increasing your organization\u2019s strategic alignment around design and adoption of design practices can be done by adhering to a few guiding principles. Within each principle below are statements that, per InVision\u2019s findings, hold true at least twice as often in Level 5 organizations as in Level 1. Top-down belief in the value of design Executives talk about the value of design internally. Design shares priorities and goals with key partners. Executives prioritize decisions that lead to the best design/customer experience. Involve design throughout the software development process Design is well-integrated in the product development process. Design leaders are peers with product management and engineering leaders. Value user research Employees participate in user/customer research. Employees understand why human-centered design is valuable. Share design research and decision-making across disciplines Design work is shared in all hands meetings, important executive meetings, and other influential gatherings. Design has joint working sessions with key partners (e.g., workshops, stand-ups, etc.). Product/feature ideas are jointly developed and owned between design and key partners. Reference The New Design Frontier https://www.invisionapp.com/design-better/design-maturity-model/","title":"1.4 Levels of Design Maturity"},{"location":"ux/1-4-maturity/#14-levels-of-design-maturity","text":"Integration of user experience as a core strategic pillar within your organization is not a binary proposition. Every organization will have differences in the extent to which they have adopted design into their business process. For this reason, InVision defined a maturity model for experience design adoption. In this model, organizations are rated at one of five levels. It\u2019s important to be cognizant of your current maturity level within this model, and to appreciate that moving up this model only increases the overall return on investment to your mission, your stakeholders, and your end users. For example, per InVision\u2019s research, organizations are five times more likely to report having an impact on cost savings, when functioning at a Level 5 versus a Level 1. This number only increases when examining time to release.","title":"1.4 Levels of Design Maturity"},{"location":"ux/1-4-maturity/#141-leveling-up","text":"Increasing your organization\u2019s strategic alignment around design and adoption of design practices can be done by adhering to a few guiding principles. Within each principle below are statements that, per InVision\u2019s findings, hold true at least twice as often in Level 5 organizations as in Level 1.","title":"1.4.1 Leveling Up"},{"location":"ux/1-4-maturity/#top-down-belief-in-the-value-of-design","text":"Executives talk about the value of design internally. Design shares priorities and goals with key partners. Executives prioritize decisions that lead to the best design/customer experience.","title":"Top-down belief in the value of design"},{"location":"ux/1-4-maturity/#involve-design-throughout-the-software-development-process","text":"Design is well-integrated in the product development process. Design leaders are peers with product management and engineering leaders.","title":"Involve design throughout the software development process"},{"location":"ux/1-4-maturity/#value-user-research","text":"Employees participate in user/customer research. Employees understand why human-centered design is valuable.","title":"Value user research"},{"location":"ux/1-4-maturity/#share-design-research-and-decision-making-across-disciplines","text":"Design work is shared in all hands meetings, important executive meetings, and other influential gatherings. Design has joint working sessions with key partners (e.g., workshops, stand-ups, etc.). Product/feature ideas are jointly developed and owned between design and key partners.","title":"Share design research and decision-making across disciplines"},{"location":"ux/1-4-maturity/#reference","text":"The New Design Frontier https://www.invisionapp.com/design-better/design-maturity-model/","title":"Reference"},{"location":"ux/2-1-what-is-ux/","text":"2.1 What is User Experience? Defined broadly, \u201cUser Experience\u201d is about how people experience and interact with an organization\u2019s varied products, systems and services. The focus of the User Experience craft is typically on interactive, digital experiences, but UX practitioners tend to take a broader, more holistic view, looking not only at a given product or service itself but at its users\u2019 expectations and the context in which it is used \u2013 which can include other products, non-digital communications and even people with whom the user communicates while using a product or service. This holistic view yields insights that help us to design digital experiences that fit more seamlessly into users\u2019 lives while helping them achieve more successful and satisfactory outcomes. In many cases, the insights and recommendations uncovered by the UX process can extend to those very same people and non-digital communications that surround an experience as well. 2.1.1 The \u201cThree Circles\u201d of User Experience This holistic focus is conveyed well via the classic \u201cThree Circles\u201d diagram first proposed by Peter Morville, considered one of the \u201cfounding fathers\u201d of the modern UX field: The meaning of each circle in this diagram is as follows: Content : This refers not just to images and copy, but to all the content, features and functions that comprise the experience. It\u2019s important to ensure that all aspects of the experience are included thoughtfully and purposefully to serve the needs of the system\u2019s users. Context : This refers to all of the external factors that a user may consider or encounter while using a given product, system or service. These factors vary greatly depending on the system and can include anything from distractions in the environment, to the device on which the experience is viewed, to other tools and systems that a system\u2019s user might be using simultaneously. Users : This refers to the people who use a given product, system or service. In most cases, the goal is to move beyond a singular, demographic-driven view of the user to establish a more nuanced understanding of distinct user profiles along with the unique needs, mindset, motivations, behaviors and limitations of each one. A deep understanding of the needs and context for each user profile results in more insightful design solutions that align more closely with the way that the system\u2019s users think and work. 2.1.2 Important Qualities of User Experience Usability is often the first aspect that comes to mind when considering the focus of user experience, but there are in actuality a number of other factors that UX practitioners take into account when shaping a product, system or service. This is captured well by another classic model created by Peter Morville: Each hexagon within this Honeycomb diagram is defined as follows: Useful : This refers to the relevance of content and features within a given system to its users. Content and features on a given interface are typically positioned and emphasized based on their level of usefulness or relevance in relation to other content on the screen. Usable : This refers to the ease of use of a given product or service, which includes the clarity of how features are presented as well as how reliably they behave. Desirable : This refers to emotional aspects of a system\u2019s design, which can include not only the sense of satisfaction experienced when a system aligns seamlessly with the users\u2019 needs, but also whether the organizational values reflected in the design resonate with those of the system\u2019s users. Findable : This means ensuring that navigation and content are designed and positioned in ways that are intuitive to end-users, allowing them to quickly find what they need in the places where they might expect to find them. Accessible : This means ensuring that products and services are usable for people with disabilities, which can include anything from hearing or vision impairment to color-blindness. Credible : This means designing so that users can feel that they can trust and rely on the information being presented within an experience, having confidence in the data integrity and system status presented therein. Valuable : This means ensuring that a product or service effectively advances the goals of the organization that sponsors it, whether the nature of those goals is educational, operational or otherwise. UX practitioners can design more effective digital experiences through careful and balanced consideration of these factors. References The Definition of User Experience (UX) https://www.nngroup.com/articles/definition-user-experience User Experience Design http://semanticstudios.com/user_experience_design","title":"2.1 What is UX?"},{"location":"ux/2-1-what-is-ux/#21-what-is-user-experience","text":"Defined broadly, \u201cUser Experience\u201d is about how people experience and interact with an organization\u2019s varied products, systems and services. The focus of the User Experience craft is typically on interactive, digital experiences, but UX practitioners tend to take a broader, more holistic view, looking not only at a given product or service itself but at its users\u2019 expectations and the context in which it is used \u2013 which can include other products, non-digital communications and even people with whom the user communicates while using a product or service. This holistic view yields insights that help us to design digital experiences that fit more seamlessly into users\u2019 lives while helping them achieve more successful and satisfactory outcomes. In many cases, the insights and recommendations uncovered by the UX process can extend to those very same people and non-digital communications that surround an experience as well.","title":"2.1  What is User Experience?"},{"location":"ux/2-1-what-is-ux/#211-the-three-circles-of-user-experience","text":"This holistic focus is conveyed well via the classic \u201cThree Circles\u201d diagram first proposed by Peter Morville, considered one of the \u201cfounding fathers\u201d of the modern UX field: The meaning of each circle in this diagram is as follows: Content : This refers not just to images and copy, but to all the content, features and functions that comprise the experience. It\u2019s important to ensure that all aspects of the experience are included thoughtfully and purposefully to serve the needs of the system\u2019s users. Context : This refers to all of the external factors that a user may consider or encounter while using a given product, system or service. These factors vary greatly depending on the system and can include anything from distractions in the environment, to the device on which the experience is viewed, to other tools and systems that a system\u2019s user might be using simultaneously. Users : This refers to the people who use a given product, system or service. In most cases, the goal is to move beyond a singular, demographic-driven view of the user to establish a more nuanced understanding of distinct user profiles along with the unique needs, mindset, motivations, behaviors and limitations of each one. A deep understanding of the needs and context for each user profile results in more insightful design solutions that align more closely with the way that the system\u2019s users think and work.","title":"2.1.1 The \u201cThree Circles\u201d of User Experience"},{"location":"ux/2-1-what-is-ux/#212-important-qualities-of-user-experience","text":"Usability is often the first aspect that comes to mind when considering the focus of user experience, but there are in actuality a number of other factors that UX practitioners take into account when shaping a product, system or service. This is captured well by another classic model created by Peter Morville: Each hexagon within this Honeycomb diagram is defined as follows: Useful : This refers to the relevance of content and features within a given system to its users. Content and features on a given interface are typically positioned and emphasized based on their level of usefulness or relevance in relation to other content on the screen. Usable : This refers to the ease of use of a given product or service, which includes the clarity of how features are presented as well as how reliably they behave. Desirable : This refers to emotional aspects of a system\u2019s design, which can include not only the sense of satisfaction experienced when a system aligns seamlessly with the users\u2019 needs, but also whether the organizational values reflected in the design resonate with those of the system\u2019s users. Findable : This means ensuring that navigation and content are designed and positioned in ways that are intuitive to end-users, allowing them to quickly find what they need in the places where they might expect to find them. Accessible : This means ensuring that products and services are usable for people with disabilities, which can include anything from hearing or vision impairment to color-blindness. Credible : This means designing so that users can feel that they can trust and rely on the information being presented within an experience, having confidence in the data integrity and system status presented therein. Valuable : This means ensuring that a product or service effectively advances the goals of the organization that sponsors it, whether the nature of those goals is educational, operational or otherwise. UX practitioners can design more effective digital experiences through careful and balanced consideration of these factors.","title":"2.1.2 Important Qualities of User Experience"},{"location":"ux/2-1-what-is-ux/#references","text":"The Definition of User Experience (UX) https://www.nngroup.com/articles/definition-user-experience User Experience Design http://semanticstudios.com/user_experience_design","title":"References"},{"location":"ux/2-2-disciplines/","text":"2.2 UX Disciplines & Project Roles In one sense, all participants in the software development lifecycle play a critical role in ensuring the quality of a digital product\u2019s user experience. Everyone from developers to program managers to visual designers and content creators must take into account how their decisions might affect the experience of the system\u2019s users. But for those who specialize in user experience, the core disciplines that comprise their skillset might be summarized as follows: User Research : A truly user-centered design cannot be delivered without first assembling a sufficient body of research on the system\u2019s target users. This research can consist of quantitative data such as analytics, or qualitative insights gained from observing or interviewing current or potential users. Experience Strategy : Once the users\u2019 needs, expectations and challenges are well understood, those insights must then be synthesized and reconciled with the goals of the organization sponsoring the experience. This means ensuring that the value the organization is looking to provide aligns with the value the system\u2019s users seek. Once the core values driving the experience are established, those can then be used as the foundation for determining what kinds of content and features should be incorporated and how they should be prioritized, then translated into strategically-driven product roadmaps and other plans that lay a clear path to realizing value for both the users of a system and the organization that sponsored its creation. Information Architecture : This discipline entails organizing information within an experience in a way that is meaningful and intuitive to users. Prior to beginning screen designs, UX practitioners spend time considering the structure of the experience and the relationships between different types of content within it. They consider where features and content should fall within that structure in order to meet users\u2019 needs. This typically results in maps of the system\u2019s architecture and key processes within it, and often extends to content strategy documentation that outlines what content can be reused or refined versus what needs to be newly created. Interaction Design : Once user research, experience strategy and information architecture (IA) have been established, UX practitioners can then begin designing screens within the experience to align with established needs and goals. Content and features are incorporated into user interfaces (UI) that align with the target devices through which an experience will be accessed. At this point, the presentation and behavior of all interactive elements such as buttons, controls, transitions and animations are defined and documented in detail to prepare for technical implementation of the system. 2.2.1 Planning User Experience Teams While personnel from all disciplines share some level of responsibility for delivering products that meet user needs, at least one User Experience specialist should be incorporated within each software development team. This ensures that end users have clear and consistent advocacy within the software development lifecycle, uninhibited by conflicting objectives that may be held by developers, visual designers, program managers and others that may be involved in project delivery. The balance of these roles helps to ensure that each one\u2019s objectives become transparent in the planning and execution of the design, yielding better communication and decision-making overall. Specializations do exist for each of the separate core disciplines outlined above, however many User Experience professionals carry a sufficient balance of these skills to effectively manage all of them at once. A strong User Experience practitioner will be skilled in user research methods, navigation structure and process analysis in addition to interaction design. The more senior-level practitioners will be proficient in product strategy and planning, and should be involved by Program Management teams at the earliest stages of a project\u2019s conception to ensure the right research, design and testing approach through all stages of the project. Enlisting strong UX generalists rather than specialized research and design functions is generally more cost-effective, and will help to maintain a cohesive product vision while ensuring a high degree of consistency, adaptability and agility within a dynamic project environment. While User Experience practitioners do establish the foundations for interface design, the craft of creating pixel-perfect page layouts are often managed by a separate Visual Design function who holds a much deeper understanding of factors such as color, typography and creative asset production. Some practitioners may have both skillsets, but considering these as separate functions will increase the likelihood of identifying talent that holds sufficient depth of experience, skill and perspective for each role. Similarly, while User Experience practitioners should be competent in prototyping and understanding the implications of technical factors identified by development teams, true front-end development skills should be considered a separate role within the project team. References What Is User Experience (UX) Design? Everything You Need To Know To Get Started https://careerfoundry.com/en/blog/ux-design/what-is-user-experience-ux-design-everything-you-need-to-know-to-get-started","title":"2.2 UX Disciplines & Project Roles"},{"location":"ux/2-2-disciplines/#22-ux-disciplines-project-roles","text":"In one sense, all participants in the software development lifecycle play a critical role in ensuring the quality of a digital product\u2019s user experience. Everyone from developers to program managers to visual designers and content creators must take into account how their decisions might affect the experience of the system\u2019s users. But for those who specialize in user experience, the core disciplines that comprise their skillset might be summarized as follows: User Research : A truly user-centered design cannot be delivered without first assembling a sufficient body of research on the system\u2019s target users. This research can consist of quantitative data such as analytics, or qualitative insights gained from observing or interviewing current or potential users. Experience Strategy : Once the users\u2019 needs, expectations and challenges are well understood, those insights must then be synthesized and reconciled with the goals of the organization sponsoring the experience. This means ensuring that the value the organization is looking to provide aligns with the value the system\u2019s users seek. Once the core values driving the experience are established, those can then be used as the foundation for determining what kinds of content and features should be incorporated and how they should be prioritized, then translated into strategically-driven product roadmaps and other plans that lay a clear path to realizing value for both the users of a system and the organization that sponsored its creation. Information Architecture : This discipline entails organizing information within an experience in a way that is meaningful and intuitive to users. Prior to beginning screen designs, UX practitioners spend time considering the structure of the experience and the relationships between different types of content within it. They consider where features and content should fall within that structure in order to meet users\u2019 needs. This typically results in maps of the system\u2019s architecture and key processes within it, and often extends to content strategy documentation that outlines what content can be reused or refined versus what needs to be newly created. Interaction Design : Once user research, experience strategy and information architecture (IA) have been established, UX practitioners can then begin designing screens within the experience to align with established needs and goals. Content and features are incorporated into user interfaces (UI) that align with the target devices through which an experience will be accessed. At this point, the presentation and behavior of all interactive elements such as buttons, controls, transitions and animations are defined and documented in detail to prepare for technical implementation of the system.","title":"2.2 UX Disciplines &amp; Project Roles"},{"location":"ux/2-2-disciplines/#221-planning-user-experience-teams","text":"While personnel from all disciplines share some level of responsibility for delivering products that meet user needs, at least one User Experience specialist should be incorporated within each software development team. This ensures that end users have clear and consistent advocacy within the software development lifecycle, uninhibited by conflicting objectives that may be held by developers, visual designers, program managers and others that may be involved in project delivery. The balance of these roles helps to ensure that each one\u2019s objectives become transparent in the planning and execution of the design, yielding better communication and decision-making overall. Specializations do exist for each of the separate core disciplines outlined above, however many User Experience professionals carry a sufficient balance of these skills to effectively manage all of them at once. A strong User Experience practitioner will be skilled in user research methods, navigation structure and process analysis in addition to interaction design. The more senior-level practitioners will be proficient in product strategy and planning, and should be involved by Program Management teams at the earliest stages of a project\u2019s conception to ensure the right research, design and testing approach through all stages of the project. Enlisting strong UX generalists rather than specialized research and design functions is generally more cost-effective, and will help to maintain a cohesive product vision while ensuring a high degree of consistency, adaptability and agility within a dynamic project environment. While User Experience practitioners do establish the foundations for interface design, the craft of creating pixel-perfect page layouts are often managed by a separate Visual Design function who holds a much deeper understanding of factors such as color, typography and creative asset production. Some practitioners may have both skillsets, but considering these as separate functions will increase the likelihood of identifying talent that holds sufficient depth of experience, skill and perspective for each role. Similarly, while User Experience practitioners should be competent in prototyping and understanding the implications of technical factors identified by development teams, true front-end development skills should be considered a separate role within the project team.","title":"2.2.1 Planning User Experience Teams"},{"location":"ux/2-2-disciplines/#references","text":"What Is User Experience (UX) Design? Everything You Need To Know To Get Started https://careerfoundry.com/en/blog/ux-design/what-is-user-experience-ux-design-everything-you-need-to-know-to-get-started","title":"References"},{"location":"ux/2-3-lifecycle/","text":"2.3 UX in Software Lifecycle Methodologies When planning a software development project, the process typically breaks down into four discrete stages, each of which will be described in greater detail within section 3.0. Research & Discovery : This is the stage where initial research activities will be performed and insights will be synthesized based on the research findings. A high-level strategy should be established at this stage that includes experience goals, tactics, plans and content/feature recommendations which can then be used as a foundation for Conceptual Design. Conceptual Design : During this stage, key aspects of the experience will be modeled and discussed in order to establish alignment around the overall approach and design framework for the experience. The conceptual models produced during this stage can describe things like site architecture, processes, navigation patterns and key page layouts to help lay the foundations for an efficient Detailed Design process. A key goal of this stage is to establish clear expectations about how a digital experience will be presented at a high level in order to minimize the need for significant rework in the future. Detailed Design : Once foundations for the experience have been established, the Detailed Design stage then builds on those foundations, designing and specifying detailed elements and interactions for each section and component of the experience. This provides the basis for visual design comps to be created in addition to a clear and detailed plan that developers can follow in order to implement the experience. Support : During this stage, UX practitioners play a supporting role to the visual design and technical development teams who are producing the experience. This can involve addressing questions to clarify intended interactive behaviors, revising designs to resolve technical implementation challenges, and assisting with the testing and delivery of the implemented experience. These stages can sometimes be named or broken down differently, but in essence outline the stages of a typical user experience process. However it is important to note that some of these stages may not be required at times depending on the nature and goals of the project. For example, if a project entails targeted refinements and enhancements to an existing experience, full Research/Discovery and Conceptual Design stages may not be needed; however in this scenario, some level of user input should be collected and reviewed in order to determine what refinements should be made. Similarly, a Conceptual Design stage can in some case proceed without a Research/Discovery stage, assuming that existing research sufficiently addresses key questions relevant to the design problem at hand. The approach to planning and managing each of these stages can vary considerably depending on the software development process leveraged by the project team as a whole, described in further detail below. 2.3.1 Waterfall Process Considerations In a \u201cwaterfall\u201d process, each of these stages happens in sequential order, with the output of each stage being typically reviewed, finalized and approved in its entirety before proceeding to the next stage. In this type of process methodology, the typical expectation is that all documentation is comprehensive and exhaustive, addressing all possible questions and scenarios prior to any development being performed. Representative members of each project team can be incorporated into each stage to ensure that proper communication occurs and relevant questions are identified early in the process, but often this is not the case in a classic waterfall process. Instead, each project team often works independently from each other, with the resulting documentation being tossed \u201cover the wall\u201d so to speak to other project teams in order to guide their efforts for the next process stage. The main advantage of this approach is the upfront clarity and stability of plans and specifications prior to the beginning of technical implementation. However there are several disadvantages to the waterfall approach: Reduced communication and collaboration between project teams Heavy and often unwieldy design documentation Longer overall project timelines Working software not available for evaluation until late in the project lifecycle Inflexibility to changing requirements and circumstances surrounding the project Cross-team communication challenges can sometimes be circumvented in a waterfall process through adopting daily \u201cstand-up\u201d or \u201cscrum\u201d meeting that are typical in an Agile process; however daily scrum meetings alone do not make a project truly \u201cAgile, and leave many of the other disadvantages of the Waterfall methodology unaddressed. 2.3.2 Agile Process Considerations The Agile methodology was devised in order to address many of these disadvantages of waterfall processes. However the classic Agile methodology focuses more so on technical development aspects and less so on user experience or design aspects of the software development lifecycle. In order for user experience and design teams to work efficiently and effectively within the process, some additional process considerations must be made. The core Agile values are what remain consistent regardless of project role or the type of Agile process being employed. These core values are: Individuals and interactions over processes and tools Working software over comprehensive documentation Customer collaboration over contract negotiation Responding to change over following a plan Putting these values into context, things like plans, processes, tools and documentation are still relied upon heavily in an Agile environment, however all of these are secondary to effective communication, collaboration and adaptability among members of the project team. As such, there are many crucial \u201cceremonies\u201d that also remain consistent within an Agile process, playing a key role in ensuring that the values and benefits of the Agile methodology are realized. A daily \u201cscrum\u201d or \u201cstandup\u201d meeting is one type of Agile ceremony that ensures that team members across disciplines have a daily view of what features are in focus today and what key challenges might impact their completion. Teams typically work from a \u201cproduct backlog\u201d \u2013 a prioritized list of all features and capabilities that will ultimately be part of the final experience \u2013 and break that product backlog down into \u201csprints\u201d, typically 2 weeks in duration, where a portion of the items from the backlog are expected to be complete. As changes occur or new requirements are realized, this product backlog is continually \u201cgroomed\u201d to ensure that the project plan is optimized for the best outcome, and planning sessions at the start of each new sprint offer an opportunity to put the adjusted plan into effect. See the Agile Playbook for further details on typical Agile ceremonies, tools and methods. In addition to values and ceremonies, the Agile management framework is another aspect of the methodology that remains relatively unchanged when design teams are incorporated, however slight amendments must be made to define a clear role for User Experience. The Agile management framework identifies two key roles \u2013 the Scrum Master and the Product Owner \u2013 where the Scrum Master\u2019s primary role is to keep the project team focused on its goals for the sprint, and the Product Owner\u2019s primary role is to keep the team\u2019s work aligned with the overall product vision. While the Agile methodology does not directly prescribe a role for User Experience teams, their role is best considered as an extension to the Product Owner role. This means helping to establish the product context during the Research/Discovery stage, summarizing core user needs and business requirements. This also entails modeling the product vision during the Conceptual Design stage, creating preliminary wireframes and user stories that describe the expected user needs and behaviors that each feature of the experience will be designed to support. Lastly, this means leading the creation, prioritization and ongoing \u201cgrooming\u201d of the product backlog, ensuring that the most valuable features are delivered first and meet the expectations of the users for whom they are designed. As a project moves into detailed design, the task of backlog grooming is often shared with members of the Project Management team, with members of the UX team offering significant guidance while focusing mainly on the creation of design specifications for each item in the backlog. The aspect in which the classic Agile methodology is least prescriptive for User Experience teams is its guidance around planning each of the process stages and determining what user experience practices to incorporate within them. Many of the Agile ceremonies outlined above are more relevant to the Detailed Design and Support stages than they are to the initial Research/Discovery and Conceptual Design stages. In Agile terms, these first two stages are often combined and named \u201cSprint Zero\u201d, continuing to resemble a waterfall process in many ways. This allows for solid research foundations and a clear product vision to be established in advance of working iteratively on detailed design specifications. Cross-team input is valuable at any stage, and daily scrums may be incorporated to facilitate this, but beginning front-end development before a clear product vision is set can result in lost development cycles and a significant amount of rework. Design teams should focus first on establishing a clear product architecture and basic alignment around how features might be translated into layouts before the team begins iterations of detailed design and prototyping. Once a product backlog is created at the end of Conceptual Design, the project team is prepared to adopt all other typical Agile ceremonies for the remainder of the project. Detailed Design and Support are the stages where the Agile methodology is utilized in its truest form. In an ideal scenario, all project teams are focused on the same set of features at once, working in unison to arrive at a functioning prototype of a specific feature. User Experience teams leads their counterparts through the iterative process for each feature: Understanding and clarifying requirements Defining key criteria for the design solution based user needs, business goals and technology capabilities Exploring different design solutions that meet the requirements and criteria Deciding which solution to pursue based on input from across team functions Prototyping the solution Testing, validating and potentially refining the solution This constant communication and direct translation of designs into working code can significantly reduce the amount documentation created or needed within a project, a documentation approach often referred to as \u201cLean\u201d wherein design specifications are only as exhaustive as necessitated by the project team. In an ideal Agile scenario where all teams can focus on the same set of features at once, the cycle described above can take anywhere from 2-5 days to complete, assuming that cross-disciplinary teams are well-integrated and that features in the product backlog are broken into small, manageable chunks that are achievable within that time frame. By the end of the sprint, the expectation is that all backlog items that have been initiated are completed, reviewed and approved, however selective items can move into later sprints if necessary. 2.3.3 UX Process at Different Stages of the \u201cAgility Spectrum\u201d However some organizations may have difficulty achieving this level of integration, and even then, readiness for these methods may vary between different teams or projects within an organization, falling at different points of the \u201cagility spectrum\u201d. The approach to planning the Detailed Design stage may vary depending on the degree of \u201cagility\u201d at which any given team or project is ready to operate. Limiting factors to project agility often go beyond the team or organization\u2019s level of training and experience, and can extend to project-specific factors such as resource availability, vendor involvement, project budget and ability to co-locate. In these scenarios, there are a number of ways that a project approach can be adjusted to ensure successful collaboration and delivery. One approach is to rely on a User Experience team\u2019s competency in creating clickable prototypes using software such as InVision, Sketch or Axure. This reduces reliance on the development team to arrive at a working model and significantly simplifies the level of effort required to produce it. Development teams still need to stay closely involved in its creation and will certainly have additional tasks to perform such as data sourcing and more complex interactivity, but creating clickable prototypes in software allows project teams to effectively validate the usability and flow of a given feature while enabling development teams to work independently and in parallel on those additional tasks. This also allows the user experience team to work at a faster velocity on a range of features while development teams work at their own pace determining the optimal implementation approach. The key here is ensuring that both teams have a portion of their velocity (typically 10-20% of available bandwidth) dedicated to addressing questions and collaborating across teams on different pieces of work. The length of each sprint is another variable to consider. While a 2-week sprint cycle is considered standard, lengthening that cycle to 3 or even 4 weeks can help ensure sprint objectives are successfully achieved. In the scenario described above where project teams spend some portion of their time working independently and in parallel, a longer sprint cycle can ensure that all teams have sufficient time to reconvene, discuss their findings and make adjustments so that all sprint output is delivered on time, with exhaustive validation and alignment across stakeholders, further reducing the potential need for rework throughout the project timeline. Another approach is to anticipate \u201cstaggered sprints\u201d from the outset. This means that the user experience team always working one full sprint ahead of the development team. To do this, the notion must be applied here of having each team\u2019s velocity account for a portion of time dedicate to collaborating across teams on different pieces of work. While it would be expected that the same staggered sprint duration would be maintained throughout the project lifecycle, this approach does allow one team to stay on track with delivery in the event that another team faces challenges with maintaining that pace. The need for additional time to work through complex issues is a common challenge for development teams, but can be a challenge for user experience teams as well. If this type of challenge is foreseen during the project\u2019s planning activities, something called a \u201cdesign spike\u201d can be instituted to alleviate this issue. A design spike is an activity that can take place of a regular sprint to resolve big unknowns and work through complexities that would otherwise impact the efficiency of the project team. During this time, development teams are typically assigned non-dependent work while the user experience team gathers additional requirements and potential explore concepts for specific feature areas within the product. While these practices may not be considered Agile in its truest form, they may become essential in managing a team successfully through limiting factors to agility such as resource availability, vendor involvement, project budget and ability to co-locate. These practices might also be considered stepping stones to more advanced and integrated Agile practices, enabling project teams to abide by the value and reap the benefits of the Agile methodology while ensuring project plans and output are optimized for success. 2.3.4 Practical Considerations When planning a project or estimating work that involves a User Experience component within an Agile setting, there are a few key guidelines or common practices to consider. One common practice is aligning team size and levels across disciplines. A general rule of thumb is to match every user experience designer with a visual designer and a front-end developer, also taking the levels of seniority and team hierarchy into account. This helps to ensure that the output of one team aligns with the production capacity of other teams on the project. This may require adjustment based on project-specific factors, but is often a good place to start. This rule of thumb does not typically apply to project management or back-end technology functions, who each have unique considerations to take into account when estimating team size. Another common practice is ensuring that separate user stories are written for user experience versus technology teams. There may be significant overlap or even replication of stories between teams but this is not always the case. For one thing, development teams have different considerations to make when estimating the level of effort associated with a user story, which can result in the development effort associated with a story being much larger than the design effort. In these cases, user stories may be decomposed into smaller, more manageable stories from a development perspective. Likewise, development teams often approach work differently from an efficiency standpoint, resulting in a different view of how user stories should be structured. For example, user experience stories are typically focused on the front-end experience, but many features may have a significant back-end component in common, resulting in greater development efficiency if those stories are in some way grouped together. The vast majority of user stories will be shared across both teams, but there are frequently cases where differentiating a handful of these stories will result in a more efficient development process. One final consideration is around estimating the \u201csize\u201d or level of effort associated with a user story. While any design problem may have a number of viable solutions, the Conceptual Design stage helps narrow down the range of possible solutions which in turn makes estimation easier. On this basis, the User Experience team should first discuss what successful completion of each user story might entail, then determine how complex and time-consuming the delivery of that solution might be. To approximate and track this, each item in the product backlog is often assigned a number from the Fibonacci sequence (e.g. 1, 2, 3, 5, 8, 13, 21, etc.) which represents the complexity of the design problem in increasing orders of magnitude. These \u201cstory points\u201d are often used to track a team\u2019s velocity, with a baseline established in the first sprint as to how many story points the User Experience team can successfully deliver. Particularly large values are usually an indication that a story needs to be decomposed into smaller, more manageable stories, particularly when those values are higher than the baseline velocity that an individual team member can deliver in one sprint. These story point values can be taken into account when planning what items to take into a sprint, and can be adjusted at the start of each sprint as new requirements or complexities are learned. Further details about each stage of the User Experience process, including the key methods and activities conducted at each stage, will be outlined in the UX Principles & Methodologies section of this playbook. References Agile Manifesto https://agilemanifesto.org Scrum https://www.atlassian.com/agile/scrum Design Sprint Kit https://designsprintkit.withgoogle.com/introduction/overview Benefits of Partnering Closely with Your Product Owner https://www.uxmatters.com/mt/archives/2018/08/benefits-of-partnering-closely-with-your-product-owner.php A Spectrum of Approaches to Project Agility https://www.pmi.org/-/media/pmi/documents/public/pdf/learning/thought-leadership/achieving-greater-agility-series/spectrum-approaches.pdf Spikes https://www.scaledagileframework.com/spikes Fitting Big-Picture UX Into Agile Development https://www.smashingmagazine.com/2012/11/design-spikes-fit-big-picture-ux-agile-development","title":"2.3 UX in Software Lifecycle Methodologies"},{"location":"ux/2-3-lifecycle/#23-ux-in-software-lifecycle-methodologies","text":"When planning a software development project, the process typically breaks down into four discrete stages, each of which will be described in greater detail within section 3.0. Research & Discovery : This is the stage where initial research activities will be performed and insights will be synthesized based on the research findings. A high-level strategy should be established at this stage that includes experience goals, tactics, plans and content/feature recommendations which can then be used as a foundation for Conceptual Design. Conceptual Design : During this stage, key aspects of the experience will be modeled and discussed in order to establish alignment around the overall approach and design framework for the experience. The conceptual models produced during this stage can describe things like site architecture, processes, navigation patterns and key page layouts to help lay the foundations for an efficient Detailed Design process. A key goal of this stage is to establish clear expectations about how a digital experience will be presented at a high level in order to minimize the need for significant rework in the future. Detailed Design : Once foundations for the experience have been established, the Detailed Design stage then builds on those foundations, designing and specifying detailed elements and interactions for each section and component of the experience. This provides the basis for visual design comps to be created in addition to a clear and detailed plan that developers can follow in order to implement the experience. Support : During this stage, UX practitioners play a supporting role to the visual design and technical development teams who are producing the experience. This can involve addressing questions to clarify intended interactive behaviors, revising designs to resolve technical implementation challenges, and assisting with the testing and delivery of the implemented experience. These stages can sometimes be named or broken down differently, but in essence outline the stages of a typical user experience process. However it is important to note that some of these stages may not be required at times depending on the nature and goals of the project. For example, if a project entails targeted refinements and enhancements to an existing experience, full Research/Discovery and Conceptual Design stages may not be needed; however in this scenario, some level of user input should be collected and reviewed in order to determine what refinements should be made. Similarly, a Conceptual Design stage can in some case proceed without a Research/Discovery stage, assuming that existing research sufficiently addresses key questions relevant to the design problem at hand. The approach to planning and managing each of these stages can vary considerably depending on the software development process leveraged by the project team as a whole, described in further detail below.","title":"2.3 UX in Software Lifecycle Methodologies"},{"location":"ux/2-3-lifecycle/#231-waterfall-process-considerations","text":"In a \u201cwaterfall\u201d process, each of these stages happens in sequential order, with the output of each stage being typically reviewed, finalized and approved in its entirety before proceeding to the next stage. In this type of process methodology, the typical expectation is that all documentation is comprehensive and exhaustive, addressing all possible questions and scenarios prior to any development being performed. Representative members of each project team can be incorporated into each stage to ensure that proper communication occurs and relevant questions are identified early in the process, but often this is not the case in a classic waterfall process. Instead, each project team often works independently from each other, with the resulting documentation being tossed \u201cover the wall\u201d so to speak to other project teams in order to guide their efforts for the next process stage. The main advantage of this approach is the upfront clarity and stability of plans and specifications prior to the beginning of technical implementation. However there are several disadvantages to the waterfall approach: Reduced communication and collaboration between project teams Heavy and often unwieldy design documentation Longer overall project timelines Working software not available for evaluation until late in the project lifecycle Inflexibility to changing requirements and circumstances surrounding the project Cross-team communication challenges can sometimes be circumvented in a waterfall process through adopting daily \u201cstand-up\u201d or \u201cscrum\u201d meeting that are typical in an Agile process; however daily scrum meetings alone do not make a project truly \u201cAgile, and leave many of the other disadvantages of the Waterfall methodology unaddressed.","title":"2.3.1 Waterfall Process Considerations"},{"location":"ux/2-3-lifecycle/#232-agile-process-considerations","text":"The Agile methodology was devised in order to address many of these disadvantages of waterfall processes. However the classic Agile methodology focuses more so on technical development aspects and less so on user experience or design aspects of the software development lifecycle. In order for user experience and design teams to work efficiently and effectively within the process, some additional process considerations must be made. The core Agile values are what remain consistent regardless of project role or the type of Agile process being employed. These core values are: Individuals and interactions over processes and tools Working software over comprehensive documentation Customer collaboration over contract negotiation Responding to change over following a plan Putting these values into context, things like plans, processes, tools and documentation are still relied upon heavily in an Agile environment, however all of these are secondary to effective communication, collaboration and adaptability among members of the project team. As such, there are many crucial \u201cceremonies\u201d that also remain consistent within an Agile process, playing a key role in ensuring that the values and benefits of the Agile methodology are realized. A daily \u201cscrum\u201d or \u201cstandup\u201d meeting is one type of Agile ceremony that ensures that team members across disciplines have a daily view of what features are in focus today and what key challenges might impact their completion. Teams typically work from a \u201cproduct backlog\u201d \u2013 a prioritized list of all features and capabilities that will ultimately be part of the final experience \u2013 and break that product backlog down into \u201csprints\u201d, typically 2 weeks in duration, where a portion of the items from the backlog are expected to be complete. As changes occur or new requirements are realized, this product backlog is continually \u201cgroomed\u201d to ensure that the project plan is optimized for the best outcome, and planning sessions at the start of each new sprint offer an opportunity to put the adjusted plan into effect. See the Agile Playbook for further details on typical Agile ceremonies, tools and methods. In addition to values and ceremonies, the Agile management framework is another aspect of the methodology that remains relatively unchanged when design teams are incorporated, however slight amendments must be made to define a clear role for User Experience. The Agile management framework identifies two key roles \u2013 the Scrum Master and the Product Owner \u2013 where the Scrum Master\u2019s primary role is to keep the project team focused on its goals for the sprint, and the Product Owner\u2019s primary role is to keep the team\u2019s work aligned with the overall product vision. While the Agile methodology does not directly prescribe a role for User Experience teams, their role is best considered as an extension to the Product Owner role. This means helping to establish the product context during the Research/Discovery stage, summarizing core user needs and business requirements. This also entails modeling the product vision during the Conceptual Design stage, creating preliminary wireframes and user stories that describe the expected user needs and behaviors that each feature of the experience will be designed to support. Lastly, this means leading the creation, prioritization and ongoing \u201cgrooming\u201d of the product backlog, ensuring that the most valuable features are delivered first and meet the expectations of the users for whom they are designed. As a project moves into detailed design, the task of backlog grooming is often shared with members of the Project Management team, with members of the UX team offering significant guidance while focusing mainly on the creation of design specifications for each item in the backlog. The aspect in which the classic Agile methodology is least prescriptive for User Experience teams is its guidance around planning each of the process stages and determining what user experience practices to incorporate within them. Many of the Agile ceremonies outlined above are more relevant to the Detailed Design and Support stages than they are to the initial Research/Discovery and Conceptual Design stages. In Agile terms, these first two stages are often combined and named \u201cSprint Zero\u201d, continuing to resemble a waterfall process in many ways. This allows for solid research foundations and a clear product vision to be established in advance of working iteratively on detailed design specifications. Cross-team input is valuable at any stage, and daily scrums may be incorporated to facilitate this, but beginning front-end development before a clear product vision is set can result in lost development cycles and a significant amount of rework. Design teams should focus first on establishing a clear product architecture and basic alignment around how features might be translated into layouts before the team begins iterations of detailed design and prototyping. Once a product backlog is created at the end of Conceptual Design, the project team is prepared to adopt all other typical Agile ceremonies for the remainder of the project. Detailed Design and Support are the stages where the Agile methodology is utilized in its truest form. In an ideal scenario, all project teams are focused on the same set of features at once, working in unison to arrive at a functioning prototype of a specific feature. User Experience teams leads their counterparts through the iterative process for each feature: Understanding and clarifying requirements Defining key criteria for the design solution based user needs, business goals and technology capabilities Exploring different design solutions that meet the requirements and criteria Deciding which solution to pursue based on input from across team functions Prototyping the solution Testing, validating and potentially refining the solution This constant communication and direct translation of designs into working code can significantly reduce the amount documentation created or needed within a project, a documentation approach often referred to as \u201cLean\u201d wherein design specifications are only as exhaustive as necessitated by the project team. In an ideal Agile scenario where all teams can focus on the same set of features at once, the cycle described above can take anywhere from 2-5 days to complete, assuming that cross-disciplinary teams are well-integrated and that features in the product backlog are broken into small, manageable chunks that are achievable within that time frame. By the end of the sprint, the expectation is that all backlog items that have been initiated are completed, reviewed and approved, however selective items can move into later sprints if necessary.","title":"2.3.2 Agile Process Considerations"},{"location":"ux/2-3-lifecycle/#233-ux-process-at-different-stages-of-the-agility-spectrum","text":"However some organizations may have difficulty achieving this level of integration, and even then, readiness for these methods may vary between different teams or projects within an organization, falling at different points of the \u201cagility spectrum\u201d. The approach to planning the Detailed Design stage may vary depending on the degree of \u201cagility\u201d at which any given team or project is ready to operate. Limiting factors to project agility often go beyond the team or organization\u2019s level of training and experience, and can extend to project-specific factors such as resource availability, vendor involvement, project budget and ability to co-locate. In these scenarios, there are a number of ways that a project approach can be adjusted to ensure successful collaboration and delivery. One approach is to rely on a User Experience team\u2019s competency in creating clickable prototypes using software such as InVision, Sketch or Axure. This reduces reliance on the development team to arrive at a working model and significantly simplifies the level of effort required to produce it. Development teams still need to stay closely involved in its creation and will certainly have additional tasks to perform such as data sourcing and more complex interactivity, but creating clickable prototypes in software allows project teams to effectively validate the usability and flow of a given feature while enabling development teams to work independently and in parallel on those additional tasks. This also allows the user experience team to work at a faster velocity on a range of features while development teams work at their own pace determining the optimal implementation approach. The key here is ensuring that both teams have a portion of their velocity (typically 10-20% of available bandwidth) dedicated to addressing questions and collaborating across teams on different pieces of work. The length of each sprint is another variable to consider. While a 2-week sprint cycle is considered standard, lengthening that cycle to 3 or even 4 weeks can help ensure sprint objectives are successfully achieved. In the scenario described above where project teams spend some portion of their time working independently and in parallel, a longer sprint cycle can ensure that all teams have sufficient time to reconvene, discuss their findings and make adjustments so that all sprint output is delivered on time, with exhaustive validation and alignment across stakeholders, further reducing the potential need for rework throughout the project timeline. Another approach is to anticipate \u201cstaggered sprints\u201d from the outset. This means that the user experience team always working one full sprint ahead of the development team. To do this, the notion must be applied here of having each team\u2019s velocity account for a portion of time dedicate to collaborating across teams on different pieces of work. While it would be expected that the same staggered sprint duration would be maintained throughout the project lifecycle, this approach does allow one team to stay on track with delivery in the event that another team faces challenges with maintaining that pace. The need for additional time to work through complex issues is a common challenge for development teams, but can be a challenge for user experience teams as well. If this type of challenge is foreseen during the project\u2019s planning activities, something called a \u201cdesign spike\u201d can be instituted to alleviate this issue. A design spike is an activity that can take place of a regular sprint to resolve big unknowns and work through complexities that would otherwise impact the efficiency of the project team. During this time, development teams are typically assigned non-dependent work while the user experience team gathers additional requirements and potential explore concepts for specific feature areas within the product. While these practices may not be considered Agile in its truest form, they may become essential in managing a team successfully through limiting factors to agility such as resource availability, vendor involvement, project budget and ability to co-locate. These practices might also be considered stepping stones to more advanced and integrated Agile practices, enabling project teams to abide by the value and reap the benefits of the Agile methodology while ensuring project plans and output are optimized for success.","title":"2.3.3 UX Process at Different Stages of the \u201cAgility Spectrum\u201d"},{"location":"ux/2-3-lifecycle/#234-practical-considerations","text":"When planning a project or estimating work that involves a User Experience component within an Agile setting, there are a few key guidelines or common practices to consider. One common practice is aligning team size and levels across disciplines. A general rule of thumb is to match every user experience designer with a visual designer and a front-end developer, also taking the levels of seniority and team hierarchy into account. This helps to ensure that the output of one team aligns with the production capacity of other teams on the project. This may require adjustment based on project-specific factors, but is often a good place to start. This rule of thumb does not typically apply to project management or back-end technology functions, who each have unique considerations to take into account when estimating team size. Another common practice is ensuring that separate user stories are written for user experience versus technology teams. There may be significant overlap or even replication of stories between teams but this is not always the case. For one thing, development teams have different considerations to make when estimating the level of effort associated with a user story, which can result in the development effort associated with a story being much larger than the design effort. In these cases, user stories may be decomposed into smaller, more manageable stories from a development perspective. Likewise, development teams often approach work differently from an efficiency standpoint, resulting in a different view of how user stories should be structured. For example, user experience stories are typically focused on the front-end experience, but many features may have a significant back-end component in common, resulting in greater development efficiency if those stories are in some way grouped together. The vast majority of user stories will be shared across both teams, but there are frequently cases where differentiating a handful of these stories will result in a more efficient development process. One final consideration is around estimating the \u201csize\u201d or level of effort associated with a user story. While any design problem may have a number of viable solutions, the Conceptual Design stage helps narrow down the range of possible solutions which in turn makes estimation easier. On this basis, the User Experience team should first discuss what successful completion of each user story might entail, then determine how complex and time-consuming the delivery of that solution might be. To approximate and track this, each item in the product backlog is often assigned a number from the Fibonacci sequence (e.g. 1, 2, 3, 5, 8, 13, 21, etc.) which represents the complexity of the design problem in increasing orders of magnitude. These \u201cstory points\u201d are often used to track a team\u2019s velocity, with a baseline established in the first sprint as to how many story points the User Experience team can successfully deliver. Particularly large values are usually an indication that a story needs to be decomposed into smaller, more manageable stories, particularly when those values are higher than the baseline velocity that an individual team member can deliver in one sprint. These story point values can be taken into account when planning what items to take into a sprint, and can be adjusted at the start of each sprint as new requirements or complexities are learned. Further details about each stage of the User Experience process, including the key methods and activities conducted at each stage, will be outlined in the UX Principles & Methodologies section of this playbook.","title":"2.3.4 Practical Considerations"},{"location":"ux/2-3-lifecycle/#references","text":"Agile Manifesto https://agilemanifesto.org Scrum https://www.atlassian.com/agile/scrum Design Sprint Kit https://designsprintkit.withgoogle.com/introduction/overview Benefits of Partnering Closely with Your Product Owner https://www.uxmatters.com/mt/archives/2018/08/benefits-of-partnering-closely-with-your-product-owner.php A Spectrum of Approaches to Project Agility https://www.pmi.org/-/media/pmi/documents/public/pdf/learning/thought-leadership/achieving-greater-agility-series/spectrum-approaches.pdf Spikes https://www.scaledagileframework.com/spikes Fitting Big-Picture UX Into Agile Development https://www.smashingmagazine.com/2012/11/design-spikes-fit-big-picture-ux-agile-development","title":"References"},{"location":"ux/3-1-principles/","text":"3.1 UX Principles Establishing anchoring user experience principles allows us a mechanism to instill consistency across the breadth of USAF Logistics Information Systems\u2019 portfolio. These principles represent goals at a high, abstract level of the user\u2019s experience, but should be reflected in the design and execution of specific capabilities wherever applicable. In this way, we can know that even where specific interactions and interface components will differ per the respective requirements of a given system, as long as they are successfully fulfilling the same larger UX principle, an overarching consistency of purpose, experience, and mission support is being met. Referring to these principles consistently over time offers decision-making guidance, from strategic efforts (e.g. prioritizing features) to tactical execution (e.g. determining specific interactions and system flows). To best serve the logistics community and its missions, systems should adhere to the following eight interrelated UX principles: 3.1.1 Enable Clear and Immediate Decision Support Paramount to a system\u2019s ability to support its mission is highly effective user enablement, especially for logistics information systems in the area of decision-making. To that end, a system\u2019s design should first and foremost support this critical function. Proper enablement includes: Intuitive and easily repeatable task flows for arriving at decision-supporting information. Formatting and presenting decision-supporting information in a way that facilitates subsequent steps (either within or outside of the system). Providing appropriate descriptions, context, and caveats with data to better inform decision-making. Favoring recognition over recall by the user. The user can select from clearly presented options instead of recalling codes or meanings. Options are reduced to only those that are applicable in context. Plain-text descriptions are offered wherever data is coded. All of this requires that users and their key tasks and decisions are understood deeply by the system owners and designers. 3.1.2 Promote Data Integrity and Accuracy Data lies at the heart of logistics information systems and processes. Faithful representation and management of this data, then, is crucial to mission success for their users. For users to have confidence in a system\u2019s data, they must understand how the system works. Further, a policy of data transparency will improve the data\u2019s accuracy over time and build trust in its systems. Enterprise-wide data integrity and accuracy can be ensured by: Never obscuring or correcting problematic source data. Instead, at a minimum, intend to notify the user of possible issues and, optimally, offer means to resolving issues. Indicating from where data is sourced and, where relevant, the business logic applied by the system to create the displayed data. Minimizing the possibility of human error. Use structured inputs wherever possible, reduce options to only those that are allowable by business rules, and offer rich type-ahead suggestions where a user needs more open-ended data entry or query. This principle requires system owners and designers to have thorough expertise in relevant technical orders and their system\u2019s contributing source systems. 3.1.3 Streamline Common Tasks and Analyses Making common tasks and analyses more efficient for the end user allows the system to maximize its value to the user and to the mission overall. The system\u2019s design should favor its users\u2019 most frequent needs by streamlining its flows and interfaces toward those ends. Some means toward that goal include: Emphasizing most commonly used functions. Allowing users to individually save settings, custom searches, and tool preferences. Providing smart defaults wherever possible. This ranges from pre-selecting the most common form field options to displaying the most commonly used features or sections upon initial login. Successfully following this principle requires comprehensively researching your users\u2019 intents and monitoring system usage. 3.1.4 Tailor Tasks and Interfaces to Roles Too often, DoD systems err by attempting to do everything for everyone, and by doing so, ultimately impede the mission. Offering users the right content and functionality for their needs and assignments is a meaningful way to support the above UX principles, but also to aid mission attainment. Ways to tailor the experience include: Emphasizing or exposing interfaces or portions of interfaces, especially for data entry and transactional functions, to only those user roles with a need and authority for said functionality. Designing task flows and interfaces so that they at a minimum support, but optimally increase the efficiency of, the larger assignment beyond the system for key end-user groups. Reducing data inputs, and options within those inputs, to only those that are meaningful and relevant to the user\u2019s role and their current context. 3.1.5 Provide Clear System Status Clear, consistent status indication and feedback is a certain measure for instilling trust in users and providing a sense of confidence and control within the system. With this sense of control, users do not have to split their attention between managing the system and contextualizing its responses and outputs, and can instead focus entirely on quickly and accurately accomplishing their end goal. A system should clearly report its status by: Indicating the recency and providing a detailed status of its source systems. Providing up-to-date context for the content and data presented by the system. Utilizing consistent enterprise metaphors for indicating status, such as stoplight coloring, at both the system and individual data record levels. Telling the user when it is busy processing their request, and, if the response is expected to take longer than a few seconds, offering an indication of how much longer the response will take or what percent of the process is complete. 3.1.6 Prioritize Alerts and Exceptions As the nature of many tasks within the logistics community includes attending to conspicuous, outlying data and \u201cgreening up\u201d problem areas, many users can greatly benefit by having these situations brought to their attention systematically, instead of by someone up or down the chain of command, or by hunting through data themselves. Where appropriate then, systems should prioritize alerts and exceptions to support this type of task by: Alerting users where problems may exist in the source data or in calculations made by the system with uncertain source data. Highlighting metrics that are below target goals, limits, or enterprise standards. Offering deeper assessments with explanations, breakdowns, or drivers of metrics and calculations. 3.1.7 Ensure Fast Findability Due to the inherent urgency of some mission support tasks, systems should be designed to allow users to quickly find information. Some means to assist this include: Providing smart defaults on interface configurations and search parameters. Tailoring data reports to include unrequested but meaningful supporting data alongside the user\u2019s requested information, sparing the user a second query or deeper analysis. Allowing users to individually save settings, custom searches, and tool preferences. Adhering to visual design best practices for clear presentation of content and data. 3.1.8 Reduce Reliance on Externalities Fragmented experiences are too often the norm, whether it be requiring users to jump between systems, or referencing paper documents or print materials. Pulling as much information and as many sub-tasks as makes sense into a user\u2019s primary system of need can consolidate work and reduce fragmentation. The end result is an allowance for the user to give more attention to their actual end goals and less on managing tools, thereby supporting the above principles of faster, more streamlined decision-making. Providing plain-text descriptions of acronyms and codes. Optimizing system task flows to seamlessly fit into larger external processes. Digitizing paper processes, especially where immediate transcription back into a digital system is expected.","title":"3.1 UX Principles"},{"location":"ux/3-1-principles/#31-ux-principles","text":"Establishing anchoring user experience principles allows us a mechanism to instill consistency across the breadth of USAF Logistics Information Systems\u2019 portfolio. These principles represent goals at a high, abstract level of the user\u2019s experience, but should be reflected in the design and execution of specific capabilities wherever applicable. In this way, we can know that even where specific interactions and interface components will differ per the respective requirements of a given system, as long as they are successfully fulfilling the same larger UX principle, an overarching consistency of purpose, experience, and mission support is being met. Referring to these principles consistently over time offers decision-making guidance, from strategic efforts (e.g. prioritizing features) to tactical execution (e.g. determining specific interactions and system flows). To best serve the logistics community and its missions, systems should adhere to the following eight interrelated UX principles:","title":"3.1 UX Principles"},{"location":"ux/3-1-principles/#311-enable-clear-and-immediate-decision-support","text":"Paramount to a system\u2019s ability to support its mission is highly effective user enablement, especially for logistics information systems in the area of decision-making. To that end, a system\u2019s design should first and foremost support this critical function. Proper enablement includes: Intuitive and easily repeatable task flows for arriving at decision-supporting information. Formatting and presenting decision-supporting information in a way that facilitates subsequent steps (either within or outside of the system). Providing appropriate descriptions, context, and caveats with data to better inform decision-making. Favoring recognition over recall by the user. The user can select from clearly presented options instead of recalling codes or meanings. Options are reduced to only those that are applicable in context. Plain-text descriptions are offered wherever data is coded. All of this requires that users and their key tasks and decisions are understood deeply by the system owners and designers.","title":"3.1.1 Enable Clear and Immediate Decision Support"},{"location":"ux/3-1-principles/#312-promote-data-integrity-and-accuracy","text":"Data lies at the heart of logistics information systems and processes. Faithful representation and management of this data, then, is crucial to mission success for their users. For users to have confidence in a system\u2019s data, they must understand how the system works. Further, a policy of data transparency will improve the data\u2019s accuracy over time and build trust in its systems. Enterprise-wide data integrity and accuracy can be ensured by: Never obscuring or correcting problematic source data. Instead, at a minimum, intend to notify the user of possible issues and, optimally, offer means to resolving issues. Indicating from where data is sourced and, where relevant, the business logic applied by the system to create the displayed data. Minimizing the possibility of human error. Use structured inputs wherever possible, reduce options to only those that are allowable by business rules, and offer rich type-ahead suggestions where a user needs more open-ended data entry or query. This principle requires system owners and designers to have thorough expertise in relevant technical orders and their system\u2019s contributing source systems.","title":"3.1.2 Promote Data Integrity and Accuracy"},{"location":"ux/3-1-principles/#313-streamline-common-tasks-and-analyses","text":"Making common tasks and analyses more efficient for the end user allows the system to maximize its value to the user and to the mission overall. The system\u2019s design should favor its users\u2019 most frequent needs by streamlining its flows and interfaces toward those ends. Some means toward that goal include: Emphasizing most commonly used functions. Allowing users to individually save settings, custom searches, and tool preferences. Providing smart defaults wherever possible. This ranges from pre-selecting the most common form field options to displaying the most commonly used features or sections upon initial login. Successfully following this principle requires comprehensively researching your users\u2019 intents and monitoring system usage.","title":"3.1.3 Streamline Common Tasks and Analyses"},{"location":"ux/3-1-principles/#314-tailor-tasks-and-interfaces-to-roles","text":"Too often, DoD systems err by attempting to do everything for everyone, and by doing so, ultimately impede the mission. Offering users the right content and functionality for their needs and assignments is a meaningful way to support the above UX principles, but also to aid mission attainment. Ways to tailor the experience include: Emphasizing or exposing interfaces or portions of interfaces, especially for data entry and transactional functions, to only those user roles with a need and authority for said functionality. Designing task flows and interfaces so that they at a minimum support, but optimally increase the efficiency of, the larger assignment beyond the system for key end-user groups. Reducing data inputs, and options within those inputs, to only those that are meaningful and relevant to the user\u2019s role and their current context.","title":"3.1.4 Tailor Tasks and Interfaces to Roles"},{"location":"ux/3-1-principles/#315-provide-clear-system-status","text":"Clear, consistent status indication and feedback is a certain measure for instilling trust in users and providing a sense of confidence and control within the system. With this sense of control, users do not have to split their attention between managing the system and contextualizing its responses and outputs, and can instead focus entirely on quickly and accurately accomplishing their end goal. A system should clearly report its status by: Indicating the recency and providing a detailed status of its source systems. Providing up-to-date context for the content and data presented by the system. Utilizing consistent enterprise metaphors for indicating status, such as stoplight coloring, at both the system and individual data record levels. Telling the user when it is busy processing their request, and, if the response is expected to take longer than a few seconds, offering an indication of how much longer the response will take or what percent of the process is complete.","title":"3.1.5 Provide Clear System Status"},{"location":"ux/3-1-principles/#316-prioritize-alerts-and-exceptions","text":"As the nature of many tasks within the logistics community includes attending to conspicuous, outlying data and \u201cgreening up\u201d problem areas, many users can greatly benefit by having these situations brought to their attention systematically, instead of by someone up or down the chain of command, or by hunting through data themselves. Where appropriate then, systems should prioritize alerts and exceptions to support this type of task by: Alerting users where problems may exist in the source data or in calculations made by the system with uncertain source data. Highlighting metrics that are below target goals, limits, or enterprise standards. Offering deeper assessments with explanations, breakdowns, or drivers of metrics and calculations.","title":"3.1.6 Prioritize Alerts and Exceptions"},{"location":"ux/3-1-principles/#317-ensure-fast-findability","text":"Due to the inherent urgency of some mission support tasks, systems should be designed to allow users to quickly find information. Some means to assist this include: Providing smart defaults on interface configurations and search parameters. Tailoring data reports to include unrequested but meaningful supporting data alongside the user\u2019s requested information, sparing the user a second query or deeper analysis. Allowing users to individually save settings, custom searches, and tool preferences. Adhering to visual design best practices for clear presentation of content and data.","title":"3.1.7 Ensure Fast Findability"},{"location":"ux/3-1-principles/#318-reduce-reliance-on-externalities","text":"Fragmented experiences are too often the norm, whether it be requiring users to jump between systems, or referencing paper documents or print materials. Pulling as much information and as many sub-tasks as makes sense into a user\u2019s primary system of need can consolidate work and reduce fragmentation. The end result is an allowance for the user to give more attention to their actual end goals and less on managing tools, thereby supporting the above principles of faster, more streamlined decision-making. Providing plain-text descriptions of acronyms and codes. Optimizing system task flows to seamlessly fit into larger external processes. Digitizing paper processes, especially where immediate transcription back into a digital system is expected.","title":"3.1.8 Reduce Reliance on Externalities"},{"location":"ux/3-2-methodology/","text":"3.2 UX Methodology Successful user experience design requires accomplishing a number of successive, iterative steps, each helping drive towards a higher level of specificity and fidelity than the prior.","title":"3.2 UX Methodology"},{"location":"ux/3-2-methodology/#32-ux-methodology","text":"Successful user experience design requires accomplishing a number of successive, iterative steps, each helping drive towards a higher level of specificity and fidelity than the prior.","title":"3.2 UX Methodology"},{"location":"ux/3-3-1-1-interviews/","text":"Back to Phase 1: Research & Discovery 3.3.1.1 Interviews Direct interviews are typically the single most effective method for uncovering insight. There are different types of interviews, each serving a different purpose. When to use Use interviews to examine users, subject matter experts or stakeholders closely, especially to: Investigate more deeply into users\u2019 needs or behaviors, e.g. motivations, expectations, concerns, and frustrations. Gain subject-matter expertise on mission current state, best practices, and problem articulation. Understand mission objectives, current opportunities and obstacles, and project success criteria. Requirements Access to actual end users. (User proxies, or representatives, can be helpful, but frequently do not have a full picture of real end users\u2019 process, context or usage scenarios.) Ability to record and transcribe later, or have a second team member listening for note taking. (It is generally inefficient to lead the interview while also taking notes.) Variations Contextual/field study versus direct discussion Contextual interviews are conducted in the environment in which the user would typically interact with your system (e.g. at their workplace), and generally involves the participant allowing the interviewer to watch them use the system for actual purposes (i.e. while \u201cdoing their day job\u201d). This method allows the interviewer to learn, from direct observation, about details that frequently go unaccounted for, or unremembered by the user when out of setting, such as necessary supplemental materials (e.g. a field manual kept next to the computer). It also allows for pain points that have been normalized by the user over time to be noticed and discussed. Inviting a participant to a direct session (either away from the user\u2019s work station or even just via a dedicated phone call or online meeting) can remove the burden and distraction of routine job obligations and keep the focus on your topics. Group versus individual Interviewing a large group of users together is best used to get a wide range of input quickly and a shallow exploration of the problem space. This method is best done as an initial session, prior to breaking out individual or small-group interviews. In individual interviews, topics can be explored in depth, without concern for a \u201cloudest voice\u201d or highest ranking presence inhibiting equitable input. Structured versus unstructured Structured interviews should be used when you have a specific set of questions to be addressed with your participant, especially when the ability to compare responses between multiple participants is desired. In unstructured interviews the topics are only broadly laid out. The interviewer does much more listening than interacting, sometimes speaking only to prompt the participant to continue or explain something further. These interviews are effective when the desire is to cover touchy subjects without directly asking about them, or to probe deeper emotional reactions by offering a neutral, safe conversational space. Product/output Findings and even direct quotes from user interviews become the backbone of personas , user scenarios and user journeys , and drive the definition of use cases . Input from subject matter experts and stakeholders form the primary depiction of staff/support actions and processes in service blueprints and user journeys . References & Resources Reference Complete Beginner\u2019s Guide to UX Research https://www.uxbooth.com/articles/complete-beginners-guide-to-design-research Resources How to Conduct User Interviews https://www.interaction-design.org/literature/article/how-to-conduct-user-interviews Listening Tips https://indiyoung.com/listening-tips/#more-7443","title":"Interviews"},{"location":"ux/3-3-1-1-interviews/#3311-interviews","text":"Direct interviews are typically the single most effective method for uncovering insight. There are different types of interviews, each serving a different purpose.","title":"3.3.1.1 Interviews"},{"location":"ux/3-3-1-1-interviews/#when-to-use","text":"Use interviews to examine users, subject matter experts or stakeholders closely, especially to: Investigate more deeply into users\u2019 needs or behaviors, e.g. motivations, expectations, concerns, and frustrations. Gain subject-matter expertise on mission current state, best practices, and problem articulation. Understand mission objectives, current opportunities and obstacles, and project success criteria.","title":"When to use"},{"location":"ux/3-3-1-1-interviews/#requirements","text":"Access to actual end users. (User proxies, or representatives, can be helpful, but frequently do not have a full picture of real end users\u2019 process, context or usage scenarios.) Ability to record and transcribe later, or have a second team member listening for note taking. (It is generally inefficient to lead the interview while also taking notes.)","title":"Requirements"},{"location":"ux/3-3-1-1-interviews/#variations","text":"","title":"Variations"},{"location":"ux/3-3-1-1-interviews/#contextualfield-study-versus-direct-discussion","text":"Contextual interviews are conducted in the environment in which the user would typically interact with your system (e.g. at their workplace), and generally involves the participant allowing the interviewer to watch them use the system for actual purposes (i.e. while \u201cdoing their day job\u201d). This method allows the interviewer to learn, from direct observation, about details that frequently go unaccounted for, or unremembered by the user when out of setting, such as necessary supplemental materials (e.g. a field manual kept next to the computer). It also allows for pain points that have been normalized by the user over time to be noticed and discussed. Inviting a participant to a direct session (either away from the user\u2019s work station or even just via a dedicated phone call or online meeting) can remove the burden and distraction of routine job obligations and keep the focus on your topics.","title":"Contextual/field study versus direct discussion"},{"location":"ux/3-3-1-1-interviews/#group-versus-individual","text":"Interviewing a large group of users together is best used to get a wide range of input quickly and a shallow exploration of the problem space. This method is best done as an initial session, prior to breaking out individual or small-group interviews. In individual interviews, topics can be explored in depth, without concern for a \u201cloudest voice\u201d or highest ranking presence inhibiting equitable input.","title":"Group versus individual"},{"location":"ux/3-3-1-1-interviews/#structured-versus-unstructured","text":"Structured interviews should be used when you have a specific set of questions to be addressed with your participant, especially when the ability to compare responses between multiple participants is desired. In unstructured interviews the topics are only broadly laid out. The interviewer does much more listening than interacting, sometimes speaking only to prompt the participant to continue or explain something further. These interviews are effective when the desire is to cover touchy subjects without directly asking about them, or to probe deeper emotional reactions by offering a neutral, safe conversational space.","title":"Structured versus unstructured"},{"location":"ux/3-3-1-1-interviews/#productoutput","text":"Findings and even direct quotes from user interviews become the backbone of personas , user scenarios and user journeys , and drive the definition of use cases . Input from subject matter experts and stakeholders form the primary depiction of staff/support actions and processes in service blueprints and user journeys .","title":"Product/output"},{"location":"ux/3-3-1-1-interviews/#references-resources","text":"","title":"References &amp; Resources"},{"location":"ux/3-3-1-1-interviews/#reference","text":"Complete Beginner\u2019s Guide to UX Research https://www.uxbooth.com/articles/complete-beginners-guide-to-design-research","title":"Reference"},{"location":"ux/3-3-1-1-interviews/#resources","text":"How to Conduct User Interviews https://www.interaction-design.org/literature/article/how-to-conduct-user-interviews Listening Tips https://indiyoung.com/listening-tips/#more-7443","title":"Resources"},{"location":"ux/3-3-1-2-surveys/","text":"Back to Phase 1: Research & Discovery 3.3.1.2 Surveys Conducting surveys is a simple, quick tool for gathering a large amount of input. And since this method is generally simpler and easier than others, it can frequently be a default recommendation. However, it is important to consider the advantages and limitations of surveying before selecting this method. When to use Use to quickly gather shallow feedback from a large number of respondents, or from a set of respondents who have anonymity concerns. Requirements Ability to distribute the survey to your desired participants. Ability to collect its results (if anonymous, a third party must be used). Variations Identified-response versus anonymous With identified-response surveys, the responses are tied to the identify of the responder, either through requiring the responder to provide that information, or by issuing uniquely identified surveys to each responder. This level of control can have a suppressing effect on the survey, both in terms of total responses, and in amount of honest criticism offered in answers. On the other hand, slanderous or other malevolent responses will be largely avoided. Be mindful of your subject matter and its prevailing sentiment among your audience. Identified-response surveys also have the advantage of optionally asking respondents to avail themselves for follow-up surveys or interviews. Anonymous surveys offer the ability to collect more honest responses when you expect the topic to skew negative, and will generally receive higher participation because of the lower responsibility or risk to the respondent. Product/output Categorizing responses to open-ended questions can provide rough quantitative measures around frequency of similar responses. (For example, answers like \u201cSite is slow\u201d and \u201cPages take too long to load\u201d could both be categorized as \u201cSite performance does not meet expectations.\u201d) Close-ended questions frequently already lend themselves to this sort aggregate quantifying. This data can then provide support and evidence to personas and user scenarios , as well as help prioritize remediation efforts for major existing deficiencies. The individual open-ended responses themselves can uncover topics for follow-up user interview sessions around intents, motivations, and frustrations, especially if your survey\u2019s respondents allow their identities to be known and agree to participate further. Practical considerations Consider distributing the survey to a couple test participants prior to wider distribution, to uncover questions that can be misinterpreted and should be rewritten, and to ensure you receive the types of responses you are expecting. Ask questions that you have reason to believe your respondents are willing and able to answer sincerely. Be aware that requiring respondent identification will reduce your response rate. Avoid using Likert scales (i.e. 1-10 ratings) or similar structures for quantifying opinions. These tend to rely on subjective or arbitrary value assignments by your respondents, which devalues their responses. References & Resources References Online Surveys https://www.usability.gov/how-to-and-tools/methods/online-surveys.html Complete Beginner\u2019s Guide to UX Research https://www.uxbooth.com/articles/complete-beginners-guide-to-design-research Resources On Surveys https://medium.com/mule-design/on-surveys-5a73dda5e9a0","title":"Surveys"},{"location":"ux/3-3-1-2-surveys/#3312-surveys","text":"Conducting surveys is a simple, quick tool for gathering a large amount of input. And since this method is generally simpler and easier than others, it can frequently be a default recommendation. However, it is important to consider the advantages and limitations of surveying before selecting this method.","title":"3.3.1.2 Surveys"},{"location":"ux/3-3-1-2-surveys/#when-to-use","text":"Use to quickly gather shallow feedback from a large number of respondents, or from a set of respondents who have anonymity concerns.","title":"When to use"},{"location":"ux/3-3-1-2-surveys/#requirements","text":"Ability to distribute the survey to your desired participants. Ability to collect its results (if anonymous, a third party must be used).","title":"Requirements"},{"location":"ux/3-3-1-2-surveys/#variations","text":"","title":"Variations"},{"location":"ux/3-3-1-2-surveys/#identified-response-versus-anonymous","text":"With identified-response surveys, the responses are tied to the identify of the responder, either through requiring the responder to provide that information, or by issuing uniquely identified surveys to each responder. This level of control can have a suppressing effect on the survey, both in terms of total responses, and in amount of honest criticism offered in answers. On the other hand, slanderous or other malevolent responses will be largely avoided. Be mindful of your subject matter and its prevailing sentiment among your audience. Identified-response surveys also have the advantage of optionally asking respondents to avail themselves for follow-up surveys or interviews. Anonymous surveys offer the ability to collect more honest responses when you expect the topic to skew negative, and will generally receive higher participation because of the lower responsibility or risk to the respondent.","title":"Identified-response versus anonymous"},{"location":"ux/3-3-1-2-surveys/#productoutput","text":"Categorizing responses to open-ended questions can provide rough quantitative measures around frequency of similar responses. (For example, answers like \u201cSite is slow\u201d and \u201cPages take too long to load\u201d could both be categorized as \u201cSite performance does not meet expectations.\u201d) Close-ended questions frequently already lend themselves to this sort aggregate quantifying. This data can then provide support and evidence to personas and user scenarios , as well as help prioritize remediation efforts for major existing deficiencies. The individual open-ended responses themselves can uncover topics for follow-up user interview sessions around intents, motivations, and frustrations, especially if your survey\u2019s respondents allow their identities to be known and agree to participate further.","title":"Product/output"},{"location":"ux/3-3-1-2-surveys/#practical-considerations","text":"Consider distributing the survey to a couple test participants prior to wider distribution, to uncover questions that can be misinterpreted and should be rewritten, and to ensure you receive the types of responses you are expecting. Ask questions that you have reason to believe your respondents are willing and able to answer sincerely. Be aware that requiring respondent identification will reduce your response rate. Avoid using Likert scales (i.e. 1-10 ratings) or similar structures for quantifying opinions. These tend to rely on subjective or arbitrary value assignments by your respondents, which devalues their responses.","title":"Practical considerations"},{"location":"ux/3-3-1-2-surveys/#references-resources","text":"","title":"References &amp; Resources"},{"location":"ux/3-3-1-2-surveys/#references","text":"Online Surveys https://www.usability.gov/how-to-and-tools/methods/online-surveys.html Complete Beginner\u2019s Guide to UX Research https://www.uxbooth.com/articles/complete-beginners-guide-to-design-research","title":"References"},{"location":"ux/3-3-1-2-surveys/#resources","text":"On Surveys https://medium.com/mule-design/on-surveys-5a73dda5e9a0","title":"Resources"},{"location":"ux/3-3-1-3-metrics/","text":"Back to Phase 1: Research & Discovery 3.3.1.3 Site Metrics Analysis When a pre-existing capability is available in a live environment, and has an integrated data analytics tool, time should be spent assessing the data that has been captured to learn more about your users\u2019 actual usage and behavior patterns. When to use When a pre-existing capability is available in a live environment, and has an integrated data analytics tool, time should be spent assessing the data that has been captured to learn more about your users\u2019 actual usage and behavior patterns. Requirements Data captured through an analytics tool or similar. Product/output Behavioral patterns discerned through metrics analysis can be used to: Inform customer journeys and service design blueprints . Provide quantitative support and evidence to personas or user scenarios . Practical considerations Look for click paths (page-to-page navigational flows) that have drop-offs or exits you would not expect, to identify pain points or unknown user intents. Carefully consider sample sizes and occurrence percentages to avoid fixating on edge cases. Avoid attempting to characterize user intent/goals solely by assessing their behavior. Reference 8 Usability Metrics Tech Teams Can Use To Analyze User Behaviour https://www.shopify.com/partners/blog/9-usability-metrics-tech-teams-can-use-to-analyze-user-behaviour","title":"Site metrics analysis"},{"location":"ux/3-3-1-3-metrics/#3313-site-metrics-analysis","text":"When a pre-existing capability is available in a live environment, and has an integrated data analytics tool, time should be spent assessing the data that has been captured to learn more about your users\u2019 actual usage and behavior patterns.","title":"3.3.1.3 Site Metrics Analysis"},{"location":"ux/3-3-1-3-metrics/#when-to-use","text":"When a pre-existing capability is available in a live environment, and has an integrated data analytics tool, time should be spent assessing the data that has been captured to learn more about your users\u2019 actual usage and behavior patterns.","title":"When to use"},{"location":"ux/3-3-1-3-metrics/#requirements","text":"Data captured through an analytics tool or similar.","title":"Requirements"},{"location":"ux/3-3-1-3-metrics/#productoutput","text":"Behavioral patterns discerned through metrics analysis can be used to: Inform customer journeys and service design blueprints . Provide quantitative support and evidence to personas or user scenarios .","title":"Product/output"},{"location":"ux/3-3-1-3-metrics/#practical-considerations","text":"Look for click paths (page-to-page navigational flows) that have drop-offs or exits you would not expect, to identify pain points or unknown user intents. Carefully consider sample sizes and occurrence percentages to avoid fixating on edge cases. Avoid attempting to characterize user intent/goals solely by assessing their behavior.","title":"Practical considerations"},{"location":"ux/3-3-1-3-metrics/#reference","text":"8 Usability Metrics Tech Teams Can Use To Analyze User Behaviour https://www.shopify.com/partners/blog/9-usability-metrics-tech-teams-can-use-to-analyze-user-behaviour","title":"Reference"},{"location":"ux/3-3-1-4-diary/","text":"Back to Phase 1: Research & Discovery 3.3.1.4 Diary Studies In this method, study participants are asked to keep a diary and log specific information over time about activities being studied. The diary itself can range from a simple paper journal to a digital recording device, and the input to be collected in the log entries can range from highly structured responses (like duration of the activity in seconds) to open-ended responses like detailed depictions of thoughts or emotions. When to use Use to collect qualitative data about user behaviors, activities and experiences over time, especially when field study or \u201cshadowing\u201d is not possible, such as when the duration of the activities to be studied is longer than a day or two, or involves the user traveling to multiple geographic locations, or requires round-the-clock monitoring. Requirements Access to actual end users who are willing to earnestly and accurately report their own thoughts and actions. A means of collecting diaries at the end of the reporting period. Product/output Depending on the types of input your study requested of its participants, the diary entries can be decomposed and categorized or aggregated into quantitative measures to inform and support personas, or can be used for qualitative inputs to populate personas , user scenarios , journey maps and service design blueprints . Reference Diary Studies: Understanding Long-Term User Behavior and Experiences https://www.nngroup.com/articles/diary-studies","title":"Diary studies"},{"location":"ux/3-3-1-4-diary/#3314-diary-studies","text":"In this method, study participants are asked to keep a diary and log specific information over time about activities being studied. The diary itself can range from a simple paper journal to a digital recording device, and the input to be collected in the log entries can range from highly structured responses (like duration of the activity in seconds) to open-ended responses like detailed depictions of thoughts or emotions.","title":"3.3.1.4 Diary Studies"},{"location":"ux/3-3-1-4-diary/#when-to-use","text":"Use to collect qualitative data about user behaviors, activities and experiences over time, especially when field study or \u201cshadowing\u201d is not possible, such as when the duration of the activities to be studied is longer than a day or two, or involves the user traveling to multiple geographic locations, or requires round-the-clock monitoring.","title":"When to use"},{"location":"ux/3-3-1-4-diary/#requirements","text":"Access to actual end users who are willing to earnestly and accurately report their own thoughts and actions. A means of collecting diaries at the end of the reporting period.","title":"Requirements"},{"location":"ux/3-3-1-4-diary/#productoutput","text":"Depending on the types of input your study requested of its participants, the diary entries can be decomposed and categorized or aggregated into quantitative measures to inform and support personas, or can be used for qualitative inputs to populate personas , user scenarios , journey maps and service design blueprints .","title":"Product/output"},{"location":"ux/3-3-1-4-diary/#reference","text":"Diary Studies: Understanding Long-Term User Behavior and Experiences https://www.nngroup.com/articles/diary-studies","title":"Reference"},{"location":"ux/3-3-2-1-personas/","text":"Back to Phase 1: Research & Discovery 3.3.2.1 Personas Personas are realistic amalgamated representations of your key audience segments. Their humanistic details offer your team the ability to better empathize with your user types. They attempt to help your team understand, relate to, and remember the end user throughout the development process. When to use Use to humanize your users, especially in order to create rich scenarios and journey maps . Referring back to a well-crafted persona that contains specific human concerns and feelings, can help identify opportunities for your system to better match their needs. Requirements Deep understanding of your users, including an understanding of how to break them up into meaningfully different segments, from direct user input collected in your research. Product/output The output should be a single page or card, that fully characterizes its represented user segment, including goals and motivations, challenges and frustrations, behaviors and habits, attitudes and concerns. Personas are used as the insight to generate scenarios and journey maps that include a comprehensive user perspective. Practical considerations Avoid adding details to a persona when they are not relevant to helping achieve that user segment\u2019s goals. Examples could be demographic information like gender and age or lifestyle information like occupation or hobbies. In some instances, those details may be meaningful, but generally are not. Instead, those details allow for bias, unconscious or otherwise, to affect our consideration of the user segment. Write personas such that they are always sympathetic, meaning they are always able to elicit fondness and sympathy from your team. Creating opportunity for antagonism in a persona will only serve to alienate your team from a valid user segment. References Describing Personas https://medium.com/inclusive-software/describing-personas-af992e3fc527 Personas Make Users Memorable for Product Team Members https://www.nngroup.com/articles/persona","title":"Personas"},{"location":"ux/3-3-2-1-personas/#3321-personas","text":"Personas are realistic amalgamated representations of your key audience segments. Their humanistic details offer your team the ability to better empathize with your user types. They attempt to help your team understand, relate to, and remember the end user throughout the development process.","title":"3.3.2.1 Personas"},{"location":"ux/3-3-2-1-personas/#when-to-use","text":"Use to humanize your users, especially in order to create rich scenarios and journey maps . Referring back to a well-crafted persona that contains specific human concerns and feelings, can help identify opportunities for your system to better match their needs.","title":"When to use"},{"location":"ux/3-3-2-1-personas/#requirements","text":"Deep understanding of your users, including an understanding of how to break them up into meaningfully different segments, from direct user input collected in your research.","title":"Requirements"},{"location":"ux/3-3-2-1-personas/#productoutput","text":"The output should be a single page or card, that fully characterizes its represented user segment, including goals and motivations, challenges and frustrations, behaviors and habits, attitudes and concerns. Personas are used as the insight to generate scenarios and journey maps that include a comprehensive user perspective.","title":"Product/output"},{"location":"ux/3-3-2-1-personas/#practical-considerations","text":"Avoid adding details to a persona when they are not relevant to helping achieve that user segment\u2019s goals. Examples could be demographic information like gender and age or lifestyle information like occupation or hobbies. In some instances, those details may be meaningful, but generally are not. Instead, those details allow for bias, unconscious or otherwise, to affect our consideration of the user segment. Write personas such that they are always sympathetic, meaning they are always able to elicit fondness and sympathy from your team. Creating opportunity for antagonism in a persona will only serve to alienate your team from a valid user segment.","title":"Practical considerations"},{"location":"ux/3-3-2-1-personas/#references","text":"Describing Personas https://medium.com/inclusive-software/describing-personas-af992e3fc527 Personas Make Users Memorable for Product Team Members https://www.nngroup.com/articles/persona","title":"References"},{"location":"ux/3-3-2-2-scenarios/","text":"Back to Phase 1: Research & Discovery 3.3.2.2 User Scenarios User scenarios are essentially short expositions, used to explore why a specific user or user group would use your system within a narrow context and purpose. They detail the user\u2019s motivations, goals and concerns, and are perfect setups for journey maps . When comparing different scenarios that have the same user goals, opportunities for the system to be more helpful in accomplishing those goals can be discovered. When to use Use scenarios to explore how users might approach your system in specific contexts or environments. This exploration should foster insight into ways to optimize the system for these scenarios, thus increasing the value your system offers its users. Requirements Scenarios should be crafted around actual, real-world circumstances, and require realistic user perspectives. As such, having direct input from end users is crucial for accurate scenarios. Working from their actual stories, provided in interviews or even possibly surveys , grounds your scenarios in reality. While not a hard and fast requirement, starting from personas is a good way to ensure your scenarios are focused on your key user types and their needs. Product/output Scenarios are typically written as simple prose, like the start of a short story. They form the input for user journey maps , where the scenario can be played out and interactions with your system can be explored. Scenarios should also become the foundation of your concept testing and usability testing \u2013 having your test participants attempt to accomplish the goals laid out in your scenarios is an effective method of design validation. Tim is preparing to report at the quarterly WSR on his weapon system\u2019s availability in the previous quarter. When doing this analysis previously, he\u2019s relied on downloading ESR data then importing it into a spreadsheet created years ago by a colleague. This quarter, however, his CO has told him his analysis needs to go further and identify the 10 maintenance issues most limiting overall availability and at what locations they are most frequently occurring. This has Tim worried, as he doesn\u2019t believe he can break down the data and prepare it for presentation in the time he has before the conference.\u201d Practical considerations It\u2019s impossible to craft every scenario your users would have for using your system. Instead, start by drawing some of the most common scenarios out of your user research. Be willing to explore highly specific scenarios. Unexpected insights come from examining how your users\u2019 behaviors and needs change as their context does. Resource When It Comes To Personas, The Real Value Is In The Scenarios https://articles.uie.com/when-it-comes-to-personas-the-real-value-is-in-the-scenarios","title":"User Scenarios"},{"location":"ux/3-3-2-2-scenarios/#3322-user-scenarios","text":"User scenarios are essentially short expositions, used to explore why a specific user or user group would use your system within a narrow context and purpose. They detail the user\u2019s motivations, goals and concerns, and are perfect setups for journey maps . When comparing different scenarios that have the same user goals, opportunities for the system to be more helpful in accomplishing those goals can be discovered.","title":"3.3.2.2 User Scenarios"},{"location":"ux/3-3-2-2-scenarios/#when-to-use","text":"Use scenarios to explore how users might approach your system in specific contexts or environments. This exploration should foster insight into ways to optimize the system for these scenarios, thus increasing the value your system offers its users.","title":"When to use"},{"location":"ux/3-3-2-2-scenarios/#requirements","text":"Scenarios should be crafted around actual, real-world circumstances, and require realistic user perspectives. As such, having direct input from end users is crucial for accurate scenarios. Working from their actual stories, provided in interviews or even possibly surveys , grounds your scenarios in reality. While not a hard and fast requirement, starting from personas is a good way to ensure your scenarios are focused on your key user types and their needs.","title":"Requirements"},{"location":"ux/3-3-2-2-scenarios/#productoutput","text":"Scenarios are typically written as simple prose, like the start of a short story. They form the input for user journey maps , where the scenario can be played out and interactions with your system can be explored. Scenarios should also become the foundation of your concept testing and usability testing \u2013 having your test participants attempt to accomplish the goals laid out in your scenarios is an effective method of design validation. Tim is preparing to report at the quarterly WSR on his weapon system\u2019s availability in the previous quarter. When doing this analysis previously, he\u2019s relied on downloading ESR data then importing it into a spreadsheet created years ago by a colleague. This quarter, however, his CO has told him his analysis needs to go further and identify the 10 maintenance issues most limiting overall availability and at what locations they are most frequently occurring. This has Tim worried, as he doesn\u2019t believe he can break down the data and prepare it for presentation in the time he has before the conference.\u201d","title":"Product/output"},{"location":"ux/3-3-2-2-scenarios/#practical-considerations","text":"It\u2019s impossible to craft every scenario your users would have for using your system. Instead, start by drawing some of the most common scenarios out of your user research. Be willing to explore highly specific scenarios. Unexpected insights come from examining how your users\u2019 behaviors and needs change as their context does.","title":"Practical considerations"},{"location":"ux/3-3-2-2-scenarios/#resource","text":"When It Comes To Personas, The Real Value Is In The Scenarios https://articles.uie.com/when-it-comes-to-personas-the-real-value-is-in-the-scenarios","title":"Resource"},{"location":"ux/3-3-2-3-journey/","text":"Back to Phase 1: Research & Discovery 3.3.2.3 Journey Maps A journey map is a narrative-driven graph that describes the typical journey of an end user by representing the different touchpoints and interactions that encompass their experience with the system and surrounding environment. When to use Use journey maps to explore how users might use your system as part of accomplishing the goals laid out in specific scenarios . This exploration should foster insight into ways to optimize the system\u2019s design to best support these journeys, thus increasing the value your system offers its users. Requirements An understanding of meaningful scenarios to map, and the user insights to map them, from user research ( interviews in particular). Product/output The map product is a timeline-based chart, typically split into two primary sections. The first section, the lens, depicts the user\u2019s perspective as they become oriented to the activities and requirements of each new stage of the journey. The journey section then captures the specific activities and interactions in which the user is involved at each stage, along with typical thoughts and feelings they might have along the way. This layer of thoughts and feelings provides context for ideas about better ways to support their experience. The process of depicting a user journey will uncover insights and opportunities to better align the current experience with user needs, or introduce new capabilities to fill gaps in the experience. These ideas should next be explored in conceptual designs , evaluated for feasibility, and finally be roadmapped for implementation. If the journey occurs as part of a larger service offering from your system, a next step could be exploring the full details of the service execution in a service design blueprint . Resource Journey Mapping in Real Life: A Survey of UX Practitioners https://www.nngroup.com/articles/journey-mapping-ux-practitioners","title":"Journey maps"},{"location":"ux/3-3-2-3-journey/#3323-journey-maps","text":"A journey map is a narrative-driven graph that describes the typical journey of an end user by representing the different touchpoints and interactions that encompass their experience with the system and surrounding environment.","title":"3.3.2.3 Journey Maps"},{"location":"ux/3-3-2-3-journey/#when-to-use","text":"Use journey maps to explore how users might use your system as part of accomplishing the goals laid out in specific scenarios . This exploration should foster insight into ways to optimize the system\u2019s design to best support these journeys, thus increasing the value your system offers its users.","title":"When to use"},{"location":"ux/3-3-2-3-journey/#requirements","text":"An understanding of meaningful scenarios to map, and the user insights to map them, from user research ( interviews in particular).","title":"Requirements"},{"location":"ux/3-3-2-3-journey/#productoutput","text":"The map product is a timeline-based chart, typically split into two primary sections. The first section, the lens, depicts the user\u2019s perspective as they become oriented to the activities and requirements of each new stage of the journey. The journey section then captures the specific activities and interactions in which the user is involved at each stage, along with typical thoughts and feelings they might have along the way. This layer of thoughts and feelings provides context for ideas about better ways to support their experience. The process of depicting a user journey will uncover insights and opportunities to better align the current experience with user needs, or introduce new capabilities to fill gaps in the experience. These ideas should next be explored in conceptual designs , evaluated for feasibility, and finally be roadmapped for implementation. If the journey occurs as part of a larger service offering from your system, a next step could be exploring the full details of the service execution in a service design blueprint .","title":"Product/output"},{"location":"ux/3-3-2-3-journey/#resource","text":"Journey Mapping in Real Life: A Survey of UX Practitioners https://www.nngroup.com/articles/journey-mapping-ux-practitioners","title":"Resource"},{"location":"ux/3-3-2-4-blueprints/","text":"Back to Phase 1: Research & Discovery 3.3.2.4 Service Design Blueprints A service design blueprint is detailed diagram that captures key processes in the delivery of a service, starting from the end user\u2019s actions and system touchpoints and layering in the front- and backstage support personnel\u2019s tasks and roles and the additional systems that all ultimately enable the service. When to use Use blueprinting to model solutions that address specific process inefficiencies and pain points. This is especially useful in cases where a provided service is complex, such as when multiple support roles or systems are required to facilitate accomplishing the end user\u2019s goal. Requirements Service design blueprints work best when layered onto an existing journey map , but can be executed independently. A thorough understanding of the service delivery process is necessary to accurately capture it. Because complex services can require the efforts of a host of different support personnel and systems, elicit direct input from all participants through interviews or a collaborative workshop session . Product/output A service design blueprint should be a time-based diagram, with swim lanes for the end user\u2019s actions, system touchpoints, frontstage support personnel actions, backstage actions, and additional support processes/additional required systems. The detailed analysis inherit in creating a service blueprint will uncover gaps, inefficiencies, and pain points in your current service delivery model that your conceptual designs can address. Resources Service Blueprints: Laying the Foundation https://www.cooper.com/journal/2014/08/service-blueprints-laying-the-foundation The difference between a journey map and a service blueprint https://blog.practicalservicedesign.com/the-difference-between-a-journey-map-and-a-service-blueprint-31a6e24c4a6c","title":"Service design blueprints"},{"location":"ux/3-3-2-4-blueprints/#3324-service-design-blueprints","text":"A service design blueprint is detailed diagram that captures key processes in the delivery of a service, starting from the end user\u2019s actions and system touchpoints and layering in the front- and backstage support personnel\u2019s tasks and roles and the additional systems that all ultimately enable the service.","title":"3.3.2.4 Service Design Blueprints"},{"location":"ux/3-3-2-4-blueprints/#when-to-use","text":"Use blueprinting to model solutions that address specific process inefficiencies and pain points. This is especially useful in cases where a provided service is complex, such as when multiple support roles or systems are required to facilitate accomplishing the end user\u2019s goal.","title":"When to use"},{"location":"ux/3-3-2-4-blueprints/#requirements","text":"Service design blueprints work best when layered onto an existing journey map , but can be executed independently. A thorough understanding of the service delivery process is necessary to accurately capture it. Because complex services can require the efforts of a host of different support personnel and systems, elicit direct input from all participants through interviews or a collaborative workshop session .","title":"Requirements"},{"location":"ux/3-3-2-4-blueprints/#productoutput","text":"A service design blueprint should be a time-based diagram, with swim lanes for the end user\u2019s actions, system touchpoints, frontstage support personnel actions, backstage actions, and additional support processes/additional required systems. The detailed analysis inherit in creating a service blueprint will uncover gaps, inefficiencies, and pain points in your current service delivery model that your conceptual designs can address.","title":"Product/output"},{"location":"ux/3-3-2-4-blueprints/#resources","text":"Service Blueprints: Laying the Foundation https://www.cooper.com/journal/2014/08/service-blueprints-laying-the-foundation The difference between a journey map and a service blueprint https://blog.practicalservicedesign.com/the-difference-between-a-journey-map-and-a-service-blueprint-31a6e24c4a6c","title":"Resources"},{"location":"ux/3-3-2-5-usecase/","text":"Back to Phase 1: Research & Discovery 3.3.2.5 Use Cases A use case is a simple depiction of a sequence of actions in a system that result in a meaningful outcome for the actor (who is typically an end user of the system, but could also be support personnel in the case of a service). When to use Create use cases to identify and catalog all of the tasks and sub-tasks that the system needs to support in order to fulfill your users\u2019 needs within it. They can be derived by decomposing stakeholder requirements around system purpose and intent, or by decomposing journey maps into discrete tasks and system interactions. Product/output Use cases are typically written in a two-column format. The left column lists the intention of the actor and the right column lists the system's responsibilities and responses. In this way, the use case can resemble a dialogue between actor and system. Any prerequisites should be identified and noted. Use cases are good building blocks for user stories and helpful references while identifying a scope of work for a given sprint or release. Practical considerations Use cases function most effectively when they are written simply, technology-free and implementation-agnostic. That is, they are written unaware of their eventual technical solutions. This keeps the focus on task accomplishment from the user\u2019s perspective, and keeps the cases relevant even as the system\u2019s technology and architecture change. Reference Essential (Abstract) Use Cases: An Agile Introduction http://agilemodeling.com/artifacts/essentialUseCase.htm","title":"Use cases"},{"location":"ux/3-3-2-5-usecase/#3325-use-cases","text":"A use case is a simple depiction of a sequence of actions in a system that result in a meaningful outcome for the actor (who is typically an end user of the system, but could also be support personnel in the case of a service).","title":"3.3.2.5 Use Cases"},{"location":"ux/3-3-2-5-usecase/#when-to-use","text":"Create use cases to identify and catalog all of the tasks and sub-tasks that the system needs to support in order to fulfill your users\u2019 needs within it. They can be derived by decomposing stakeholder requirements around system purpose and intent, or by decomposing journey maps into discrete tasks and system interactions.","title":"When to use"},{"location":"ux/3-3-2-5-usecase/#productoutput","text":"Use cases are typically written in a two-column format. The left column lists the intention of the actor and the right column lists the system's responsibilities and responses. In this way, the use case can resemble a dialogue between actor and system. Any prerequisites should be identified and noted. Use cases are good building blocks for user stories and helpful references while identifying a scope of work for a given sprint or release.","title":"Product/output"},{"location":"ux/3-3-2-5-usecase/#practical-considerations","text":"Use cases function most effectively when they are written simply, technology-free and implementation-agnostic. That is, they are written unaware of their eventual technical solutions. This keeps the focus on task accomplishment from the user\u2019s perspective, and keeps the cases relevant even as the system\u2019s technology and architecture change.","title":"Practical considerations"},{"location":"ux/3-3-2-5-usecase/#reference","text":"Essential (Abstract) Use Cases: An Agile Introduction http://agilemodeling.com/artifacts/essentialUseCase.htm","title":"Reference"},{"location":"ux/3-3-research/","text":"3.3 Phase 1: Research & Discovery \u201cUX without user research is not UX.\u201d \u2013 Nielsen Norman Group Designing a product or system that meets the needs of its users is simply not possible without first understanding those users. This principle is core to the purpose of user experience design. The research phase, then, is critical to success and becomes the foundation upon which design decisions should be made for a user-centered product. And while examining and understanding your users is the primary goal, comprehensive research should also include gaining a clear understanding of mission and stakeholder objectives and requirements, and in commercial settings, would also include market or landscape assessments. Successful designs bridge both user and stakeholder needs. The crux of conducting relevant, impactful research is having clear objectives at the outset. You should be setting these research objectives by having a clear purpose for how and where you intend to turn your research findings into inputs for later activities and methods. Only then can you know which research methods to employ and how best to employ them. In other words, start with the questions you wish to have answered and select methods best suited to answering them. Continue reading below to learn about some of the research methods most appropriate for logistics information systems and how they can be leveraged to inform subsequent work. 3.3.1 Methods for Gathering Information Interviews Direct communication in the form of interviews is a reliable way to gather user and business needs. Surveys Surveys are an easy way to gather a large amount of information in minimal time. Site metrics analysis Data-driven analysis of site usage and user behavior can provide important context and theory validation. Diary studies Logs of activities by users as they occur offer insights like context and environment details, real-time needs and behaviors. 3.3.2 Methods for Synthesizing Insights Personas Personas are realistic amalgamated representations of your key audience segments. Their humanistic details offer your team the ability to better empathize with your user types. User Scenarios These narratives explore why a specific user or user group would use your system within a narrow context and purpose, focusing on their motivations, goals, and concerns. Journey maps Visualizations that depict the typical journey for users accomplishing a task or going through a scenario, including their thoughts, system interactions, and reactions along the way. Service design blueprints Detailed diagrams that capture key processes in service delivery across all touchpoints, including the actions of the end user and the roles and tasks of any support personnel. Use cases As simple descriptions of a user\u2019s intent and the system\u2019s desired responses to satisfy, use cases help quickly catalog all of a system\u2019s necessary features and interactions. Reference UX Without User Research Is Not UX https://www.nngroup.com/articles/ux-without-user-research","title":"3.3 Phase 1: Research & Discovery"},{"location":"ux/3-3-research/#33-phase-1-research-discovery","text":"\u201cUX without user research is not UX.\u201d \u2013 Nielsen Norman Group Designing a product or system that meets the needs of its users is simply not possible without first understanding those users. This principle is core to the purpose of user experience design. The research phase, then, is critical to success and becomes the foundation upon which design decisions should be made for a user-centered product. And while examining and understanding your users is the primary goal, comprehensive research should also include gaining a clear understanding of mission and stakeholder objectives and requirements, and in commercial settings, would also include market or landscape assessments. Successful designs bridge both user and stakeholder needs. The crux of conducting relevant, impactful research is having clear objectives at the outset. You should be setting these research objectives by having a clear purpose for how and where you intend to turn your research findings into inputs for later activities and methods. Only then can you know which research methods to employ and how best to employ them. In other words, start with the questions you wish to have answered and select methods best suited to answering them. Continue reading below to learn about some of the research methods most appropriate for logistics information systems and how they can be leveraged to inform subsequent work.","title":"3.3 Phase 1: Research &amp; Discovery"},{"location":"ux/3-3-research/#331-methods-for-gathering-information","text":"","title":"3.3.1 Methods for Gathering Information"},{"location":"ux/3-3-research/#interviews","text":"Direct communication in the form of interviews is a reliable way to gather user and business needs.","title":"Interviews"},{"location":"ux/3-3-research/#surveys","text":"Surveys are an easy way to gather a large amount of information in minimal time.","title":"Surveys"},{"location":"ux/3-3-research/#site-metrics-analysis","text":"Data-driven analysis of site usage and user behavior can provide important context and theory validation.","title":"Site metrics analysis"},{"location":"ux/3-3-research/#diary-studies","text":"Logs of activities by users as they occur offer insights like context and environment details, real-time needs and behaviors.","title":"Diary studies"},{"location":"ux/3-3-research/#332-methods-for-synthesizing-insights","text":"","title":"3.3.2 Methods for Synthesizing Insights"},{"location":"ux/3-3-research/#personas","text":"Personas are realistic amalgamated representations of your key audience segments. Their humanistic details offer your team the ability to better empathize with your user types.","title":"Personas"},{"location":"ux/3-3-research/#user-scenarios","text":"These narratives explore why a specific user or user group would use your system within a narrow context and purpose, focusing on their motivations, goals, and concerns.","title":"User Scenarios"},{"location":"ux/3-3-research/#journey-maps","text":"Visualizations that depict the typical journey for users accomplishing a task or going through a scenario, including their thoughts, system interactions, and reactions along the way.","title":"Journey maps"},{"location":"ux/3-3-research/#service-design-blueprints","text":"Detailed diagrams that capture key processes in service delivery across all touchpoints, including the actions of the end user and the roles and tasks of any support personnel.","title":"Service design blueprints"},{"location":"ux/3-3-research/#use-cases","text":"As simple descriptions of a user\u2019s intent and the system\u2019s desired responses to satisfy, use cases help quickly catalog all of a system\u2019s necessary features and interactions.","title":"Use cases"},{"location":"ux/3-3-research/#reference","text":"UX Without User Research Is Not UX https://www.nngroup.com/articles/ux-without-user-research","title":"Reference"},{"location":"ux/3-4-1-1-wireframe/","text":"Back to Phase 2: Conceptual Design 3.4.1.1 Wireframing/Sketching Low-fidelity wireframing or sketching is a method for quickly translating requirements into interface designs by using simple line drawings to depict the interface. The low fidelity is a feature, as it helps signify the design is in its early stages, and that adjusting to feedback at this stage is still very low-effort and anticipated. Product/output At the initial stage, the wireframes or sketches need only be detailed enough to communicate their intent. The larger goal is to explore a range of possibilities, not to explore the nuances of any single possibility. Resource How to design a low-fi wireframe https://www.creativebloq.com/wireframes/how-design-low-fi-wireframe-91516934","title":"Wireframing/sketching"},{"location":"ux/3-4-1-1-wireframe/#3411-wireframingsketching","text":"Low-fidelity wireframing or sketching is a method for quickly translating requirements into interface designs by using simple line drawings to depict the interface. The low fidelity is a feature, as it helps signify the design is in its early stages, and that adjusting to feedback at this stage is still very low-effort and anticipated.","title":"3.4.1.1 Wireframing/Sketching"},{"location":"ux/3-4-1-1-wireframe/#productoutput","text":"At the initial stage, the wireframes or sketches need only be detailed enough to communicate their intent. The larger goal is to explore a range of possibilities, not to explore the nuances of any single possibility.","title":"Product/output"},{"location":"ux/3-4-1-1-wireframe/#resource","text":"How to design a low-fi wireframe https://www.creativebloq.com/wireframes/how-design-low-fi-wireframe-91516934","title":"Resource"},{"location":"ux/3-4-1-2-ia/","text":"Back to Phase 2: Conceptual Design 3.4.1.2 Information Architecture Information architecture (IA) is the scheme and structure defining the organization of your system\u2019s content and features. An effective IA allows users to find information and complete tasks efficiently. Scheme refers to how content is categorized or segmented. Schemes can either be objective (e.g. alphabetical, or chronological), or subjective (e.g. by topic, or by audience type). Structure refers to the relationship between content. Two common structures are hierarchical (top-down), where initial categories are broad, and lead to more specific later categories; and sequential, where content is presented along a linear progression. Methods Cardsorting In this method, participants organize topics into categories that make sense to them. In an open card sort, the participants can assign their own labels to their groupings. In a closed sort, participants are only allowed to categorize within set categories. This method is an effective means of identifying or validating an appropriate topical architecture scheme. Tree testing To validate a hierarchical structure for your content, use tree testing. In this test, a participant is asked to choose a path along the hierarchy, or \u201ctree,\u201d they would follow in order to find a given piece of information. Practical considerations Consider long-term implications of your architecture. Future content additions should be easily placeable within the architecture. Avoid structures that make for very shallow schemes (i.e. many top-level categories) or very deep schemes (i.e. many levels of categorization). References Complete Beginner\u2019s Guide to UX Research https://www.uxbooth.com/articles/complete-beginners-guide-to-design-research Organization Schemes https://www.usability.gov/how-to-and-tools/methods/organization-schemes.html Organization Structures https://www.usability.gov/how-to-and-tools/methods/organization-structures.html The Encyclopedia of Human-Computer Interaction, 2nd Ed. \u2013 Card Sorting https://www.interaction-design.org/literature/book/the-encyclopedia-of-human-computer-interaction-2nd-ed/card-sorting Tree Testing: Fast, Iterative Evaluation of Menu Labels and Categories https://www.interaction-design.org/literature/book/the-encyclopedia-of-human-computer-interaction-2nd-ed/card-sorting","title":"Information architecture"},{"location":"ux/3-4-1-2-ia/#3412-information-architecture","text":"Information architecture (IA) is the scheme and structure defining the organization of your system\u2019s content and features. An effective IA allows users to find information and complete tasks efficiently. Scheme refers to how content is categorized or segmented. Schemes can either be objective (e.g. alphabetical, or chronological), or subjective (e.g. by topic, or by audience type). Structure refers to the relationship between content. Two common structures are hierarchical (top-down), where initial categories are broad, and lead to more specific later categories; and sequential, where content is presented along a linear progression.","title":"3.4.1.2 Information Architecture"},{"location":"ux/3-4-1-2-ia/#methods","text":"","title":"Methods"},{"location":"ux/3-4-1-2-ia/#cardsorting","text":"In this method, participants organize topics into categories that make sense to them. In an open card sort, the participants can assign their own labels to their groupings. In a closed sort, participants are only allowed to categorize within set categories. This method is an effective means of identifying or validating an appropriate topical architecture scheme.","title":"Cardsorting"},{"location":"ux/3-4-1-2-ia/#tree-testing","text":"To validate a hierarchical structure for your content, use tree testing. In this test, a participant is asked to choose a path along the hierarchy, or \u201ctree,\u201d they would follow in order to find a given piece of information.","title":"Tree testing"},{"location":"ux/3-4-1-2-ia/#practical-considerations","text":"Consider long-term implications of your architecture. Future content additions should be easily placeable within the architecture. Avoid structures that make for very shallow schemes (i.e. many top-level categories) or very deep schemes (i.e. many levels of categorization).","title":"Practical considerations"},{"location":"ux/3-4-1-2-ia/#references","text":"Complete Beginner\u2019s Guide to UX Research https://www.uxbooth.com/articles/complete-beginners-guide-to-design-research Organization Schemes https://www.usability.gov/how-to-and-tools/methods/organization-schemes.html Organization Structures https://www.usability.gov/how-to-and-tools/methods/organization-structures.html The Encyclopedia of Human-Computer Interaction, 2nd Ed. \u2013 Card Sorting https://www.interaction-design.org/literature/book/the-encyclopedia-of-human-computer-interaction-2nd-ed/card-sorting Tree Testing: Fast, Iterative Evaluation of Menu Labels and Categories https://www.interaction-design.org/literature/book/the-encyclopedia-of-human-computer-interaction-2nd-ed/card-sorting","title":"References"},{"location":"ux/3-4-1-3-participatory/","text":"Back to Phase 2: Conceptual Design 3.4.1.3 Participatory Design Participatory design is typically done in a group workshop setting but can ultimately take many forms and span a broad range of activities. The real constant is the involvement of \u201cnon-designers\u201d in idea generation. This direct collaboration with stakeholders, subject matter experts, and end users allows for ideas to be validated as they are created, speeding up the design process and increasing the chances of user adoption. When to use Use when you have access to subject matter experts or end users who are willing to engage in the design process, and preferably have some amount of stake in your design outcomes. Participating in the design can help develop a sense of ownership, so this method is particularly effective with end user of systems with smaller user communities. Offering your end users early investment and ownership in the process can also help reduce their resistance to the changes the designs will require of them, once implemented. Activities There is a large range of activities that can be conducted as part of a participatory design workshop. In fact, many of the methods covered in this playbook work well in a workshop session, such as journey mapping , service blueprinting and card sorting . As your participants are largely not going to immediately be comfortable taking on the role of \u201cdesigner,\u201d it\u2019s important that chosen activities grant them opportunities to participate in multiple ways. Further, the order of activities should prime your participants, such that they are introduced and immersed into the problem space, then subsequently given a chance to provide solutions. Practical considerations Limit workshops to about 4\u20135 activities over a few hours or less to keep participants focused. If the scope of design requires more time collaborating, consider splitting into multiple workshops by topic or theme. To ensure the session is productive, the facilitator should keep the group in agreement on meaningful insights and outcomes as they are generated. References Bringing Users into Your Process Through Participatory Design https://www.slideshare.net/frogdesign/bringing-users-into-your-process-through-participatory-design","title":"Participatory design"},{"location":"ux/3-4-1-3-participatory/#3413-participatory-design","text":"Participatory design is typically done in a group workshop setting but can ultimately take many forms and span a broad range of activities. The real constant is the involvement of \u201cnon-designers\u201d in idea generation. This direct collaboration with stakeholders, subject matter experts, and end users allows for ideas to be validated as they are created, speeding up the design process and increasing the chances of user adoption.","title":"3.4.1.3 Participatory Design"},{"location":"ux/3-4-1-3-participatory/#when-to-use","text":"Use when you have access to subject matter experts or end users who are willing to engage in the design process, and preferably have some amount of stake in your design outcomes. Participating in the design can help develop a sense of ownership, so this method is particularly effective with end user of systems with smaller user communities. Offering your end users early investment and ownership in the process can also help reduce their resistance to the changes the designs will require of them, once implemented.","title":"When to use"},{"location":"ux/3-4-1-3-participatory/#activities","text":"There is a large range of activities that can be conducted as part of a participatory design workshop. In fact, many of the methods covered in this playbook work well in a workshop session, such as journey mapping , service blueprinting and card sorting . As your participants are largely not going to immediately be comfortable taking on the role of \u201cdesigner,\u201d it\u2019s important that chosen activities grant them opportunities to participate in multiple ways. Further, the order of activities should prime your participants, such that they are introduced and immersed into the problem space, then subsequently given a chance to provide solutions.","title":"Activities"},{"location":"ux/3-4-1-3-participatory/#practical-considerations","text":"Limit workshops to about 4\u20135 activities over a few hours or less to keep participants focused. If the scope of design requires more time collaborating, consider splitting into multiple workshops by topic or theme. To ensure the session is productive, the facilitator should keep the group in agreement on meaningful insights and outcomes as they are generated.","title":"Practical considerations"},{"location":"ux/3-4-1-3-participatory/#references","text":"Bringing Users into Your Process Through Participatory Design https://www.slideshare.net/frogdesign/bringing-users-into-your-process-through-participatory-design","title":"References"},{"location":"ux/3-4-1-4-concept/","text":"Back to Phase 2: Conceptual Design 3.4.1.4 Concept Testing Testing early and often is the most certain way to ensure the ultimately implemented solution completely meets your users\u2019 needs. To that end, testing should commence as soon as concepts are ready. When to use Start validating with end users as soon as conceptual designs are mature enough to demonstrate their intent. With this type of testing, early beats late in terms of benefit. Since the conceptual phase typically revolves around exploring a range of solutions, this phase of testing functions well as a means of identifying \u201cbest of breed\u201d ideas that warrant further pursuit. Requirements Designs that are meant to fulfill at least one complete user task. Access to end users willing to validate the designs. A test script or plan, for the participant to follow, that covers the user tasks the designs fulfill. An ability to collect feedback. Practical considerations See usability testing Resources Paper Prototyping: Getting User Data Before You Code https://www.nngroup.com/articles/paper-prototyping","title":"Concept testing"},{"location":"ux/3-4-1-4-concept/#3414-concept-testing","text":"Testing early and often is the most certain way to ensure the ultimately implemented solution completely meets your users\u2019 needs. To that end, testing should commence as soon as concepts are ready.","title":"3.4.1.4 Concept Testing"},{"location":"ux/3-4-1-4-concept/#when-to-use","text":"Start validating with end users as soon as conceptual designs are mature enough to demonstrate their intent. With this type of testing, early beats late in terms of benefit. Since the conceptual phase typically revolves around exploring a range of solutions, this phase of testing functions well as a means of identifying \u201cbest of breed\u201d ideas that warrant further pursuit.","title":"When to use"},{"location":"ux/3-4-1-4-concept/#requirements","text":"Designs that are meant to fulfill at least one complete user task. Access to end users willing to validate the designs. A test script or plan, for the participant to follow, that covers the user tasks the designs fulfill. An ability to collect feedback.","title":"Requirements"},{"location":"ux/3-4-1-4-concept/#practical-considerations","text":"See usability testing","title":"Practical considerations"},{"location":"ux/3-4-1-4-concept/#resources","text":"Paper Prototyping: Getting User Data Before You Code https://www.nngroup.com/articles/paper-prototyping","title":"Resources"},{"location":"ux/3-4-2-1-roadmapping/","text":"Back to Phase 2: Conceptual Design 3.4.2.1 Roadmapping The process of roadmapping is done to translate the totality of the collected requirements and conceptual design direction into an actionable plan for phased implementation. First, the requirements and designs are decomposed into an itemization of features and development efforts. Each item is then prioritized by assessing a combination of its user value, organizational value and implementation readiness. Finally, the prioritized items are strategically grouped and sequenced into releases that deliver the greatest incremental value to all parties. When to use Use roadmapping when the scope of the designed solution looks likely to exceed the capacity of a single development increment (release or similar), or valuable features require additional planning and preparation to be ready to implement. Requirements An itemization of designed features to be roadmapped. Stakeholder input on user and business value, and implementation readiness, of itemized features. Participation from all disciplines, from product ownership through the development team, to ensure the targets are realistic. Product/output The roadmap itself can take many forms, but a common one is a timeline-based chart that reflects the team\u2019s plan for implementation. It shows a target execution period or completion date for each thread of currently identified and prioritized features. Resources Roadmap Basics https://www.productplan.com/roadmap-basics","title":"Roadmapping"},{"location":"ux/3-4-2-1-roadmapping/#3421-roadmapping","text":"The process of roadmapping is done to translate the totality of the collected requirements and conceptual design direction into an actionable plan for phased implementation. First, the requirements and designs are decomposed into an itemization of features and development efforts. Each item is then prioritized by assessing a combination of its user value, organizational value and implementation readiness. Finally, the prioritized items are strategically grouped and sequenced into releases that deliver the greatest incremental value to all parties.","title":"3.4.2.1 Roadmapping"},{"location":"ux/3-4-2-1-roadmapping/#when-to-use","text":"Use roadmapping when the scope of the designed solution looks likely to exceed the capacity of a single development increment (release or similar), or valuable features require additional planning and preparation to be ready to implement.","title":"When to use"},{"location":"ux/3-4-2-1-roadmapping/#requirements","text":"An itemization of designed features to be roadmapped. Stakeholder input on user and business value, and implementation readiness, of itemized features. Participation from all disciplines, from product ownership through the development team, to ensure the targets are realistic.","title":"Requirements"},{"location":"ux/3-4-2-1-roadmapping/#productoutput","text":"The roadmap itself can take many forms, but a common one is a timeline-based chart that reflects the team\u2019s plan for implementation. It shows a target execution period or completion date for each thread of currently identified and prioritized features.","title":"Product/output"},{"location":"ux/3-4-2-1-roadmapping/#resources","text":"Roadmap Basics https://www.productplan.com/roadmap-basics","title":"Resources"},{"location":"ux/3-4-2-2-story/","text":"Back to Phase 2: Conceptual Design 3.4.2.2 Story Writing Story writing is the process of breaking down a feature or group of features that are to be built into discrete, achieveable implementation tasks. In Agile terminology, a story may be also called a Product Backlog Item. The term \u201cstory\u201d is frequently used, however, because of the important notion that these implementation tasks be oriented around the user and achieving value for the user. Thus, the task is very loosely written in the format of a \u201cstory\u201d of which the target user is the main character. Use cases are ideal building blocks for stories. The user\u2019s need becomes the focus of the story. The sequence of actions, and the system functionality necessary to support those actions, form the basis for the story\u2019s acceptance criteria. Product/output A typical user story starts with a statement in the format of \u201cAs a [user type], I need [functionality] so that [goal/task to be accomplished].\u201d From there, additional description can be included, as well as any already defined requirements, conceptual designs for fulfilling the identified user need, and known technological leverage or constraint. As the story matures as is prepped for execution, complete requirements, in the form of acceptance criteria, should be captured and included. These acceptance criteria should form the basis for later quality assurance, including acceptance testing . Practical considerations Stories are best written and reviewed by the entire team, across disciplines. Stories can be split into experience-led and technology-led versions if implementation efficiencies will be gained by doing so. Initially, the story should have little clarity around how the need it raises will be fulfilled. In other words, the story identifies the problem, but not its solution. Resources User Stories: An Agile Introduction http://agilemodeling.com/artifacts/userStory.htm","title":"Story writing"},{"location":"ux/3-4-2-2-story/#3422-story-writing","text":"Story writing is the process of breaking down a feature or group of features that are to be built into discrete, achieveable implementation tasks. In Agile terminology, a story may be also called a Product Backlog Item. The term \u201cstory\u201d is frequently used, however, because of the important notion that these implementation tasks be oriented around the user and achieving value for the user. Thus, the task is very loosely written in the format of a \u201cstory\u201d of which the target user is the main character. Use cases are ideal building blocks for stories. The user\u2019s need becomes the focus of the story. The sequence of actions, and the system functionality necessary to support those actions, form the basis for the story\u2019s acceptance criteria.","title":"3.4.2.2 Story Writing"},{"location":"ux/3-4-2-2-story/#productoutput","text":"A typical user story starts with a statement in the format of \u201cAs a [user type], I need [functionality] so that [goal/task to be accomplished].\u201d From there, additional description can be included, as well as any already defined requirements, conceptual designs for fulfilling the identified user need, and known technological leverage or constraint. As the story matures as is prepped for execution, complete requirements, in the form of acceptance criteria, should be captured and included. These acceptance criteria should form the basis for later quality assurance, including acceptance testing .","title":"Product/output"},{"location":"ux/3-4-2-2-story/#practical-considerations","text":"Stories are best written and reviewed by the entire team, across disciplines. Stories can be split into experience-led and technology-led versions if implementation efficiencies will be gained by doing so. Initially, the story should have little clarity around how the need it raises will be fulfilled. In other words, the story identifies the problem, but not its solution.","title":"Practical considerations"},{"location":"ux/3-4-2-2-story/#resources","text":"User Stories: An Agile Introduction http://agilemodeling.com/artifacts/userStory.htm","title":"Resources"},{"location":"ux/3-4-conceptual/","text":"3.4 Phase 2: Conceptual Design Once the research and discovery work has provided a clear understanding of the problem space and your target users, the next step is translating those insights into a range of testable concepts for a system architecture and initial, low-fidelity interface designs; validating and honing in on the most successful concepts (eventually narrowing to the single best concept); and finally devising a workable strategy for implementation of the selected direction. 3.4.1 Activities for Conceptual Design Wireframing/sketching Using quick, low-fidelity drawings helps explore a broader range of potential solutions in less time. Information architecture Create an organizational structure for your system\u2019s features and content in ways that are most meaningful to your users. Participatory design Collaborating on initial design with subject matter experts and end users reduces risk and rework. Concept testing Test early concepts with actual users to gauge effectiveness. 3.4.2 Methods for Strategic Planning Roadmapping A strategic roadmap provides the team alignment on a plan for implementation. Story writing Break up requirements and conceptual designs into discrete, independently executable pieces.","title":"3.4 Phase 2: Conceptual Design"},{"location":"ux/3-4-conceptual/#34-phase-2-conceptual-design","text":"Once the research and discovery work has provided a clear understanding of the problem space and your target users, the next step is translating those insights into a range of testable concepts for a system architecture and initial, low-fidelity interface designs; validating and honing in on the most successful concepts (eventually narrowing to the single best concept); and finally devising a workable strategy for implementation of the selected direction.","title":"3.4 Phase 2: Conceptual Design"},{"location":"ux/3-4-conceptual/#341-activities-for-conceptual-design","text":"","title":"3.4.1 Activities for Conceptual Design"},{"location":"ux/3-4-conceptual/#wireframingsketching","text":"Using quick, low-fidelity drawings helps explore a broader range of potential solutions in less time.","title":"Wireframing/sketching"},{"location":"ux/3-4-conceptual/#information-architecture","text":"Create an organizational structure for your system\u2019s features and content in ways that are most meaningful to your users.","title":"Information architecture"},{"location":"ux/3-4-conceptual/#participatory-design","text":"Collaborating on initial design with subject matter experts and end users reduces risk and rework.","title":"Participatory design"},{"location":"ux/3-4-conceptual/#concept-testing","text":"Test early concepts with actual users to gauge effectiveness.","title":"Concept testing"},{"location":"ux/3-4-conceptual/#342-methods-for-strategic-planning","text":"","title":"3.4.2 Methods for Strategic Planning"},{"location":"ux/3-4-conceptual/#roadmapping","text":"A strategic roadmap provides the team alignment on a plan for implementation.","title":"Roadmapping"},{"location":"ux/3-4-conceptual/#story-writing","text":"Break up requirements and conceptual designs into discrete, independently executable pieces.","title":"Story writing"},{"location":"ux/3-5-1-1-visualdesign/","text":"Back to Phase 3: Detailed Design 3.5.1.1 High-Fidelity Wireframing & Visual Design High-fidelity wireframing and the creation of visual design comps are activities done to create a fully detailed articulation of the interface (plus all its attendant states necessary to support a functionality). Like low-fidelity wireframes, high-fidelity wireframes are still mostly line renderings representing the interface. But the additional detail at this stage should offer language, labels and fully depicted interactions including success and error cases, and provide guidance for how to handle not just primary use cases but also all edge cases. Visual design comps should offer presentation details such as how individual components should be visually styled, and how the components relate to one another in the interface. Requirements A determination of which conceptual design direction to pursue in detail. A scope of design work to be detailed, in user stories or similar. Product/output High-fidelity wireframes and comps serve as the foundation for communicating the final design. For lean documentation practices and usability testing , these artifacts will serve as the design source for a prototype . They also serve as the source material for writing full developer specifications . Practical considerations Visual design comps can organize the interface differently than the wireframes, so long as there is no contradiction between the two. In cases where the comps do not match the wireframes exactly, the comps should be followed for form and the wireframes should be followed for function. Frequently high-fidelity wireframes and visual design comps are created in parallel, and help inform one another. In this process, the best ideas from each are combined in the final solution. Resources What is Interaction Design? https://www.interaction-design.org/literature/article/what-is-interaction-design Adaptive vs. Responsive Design https://www.interaction-design.org/literature/article/adaptive-vs-responsive-design","title":"High-fidelity wireframing and visual design"},{"location":"ux/3-5-1-1-visualdesign/#3511-high-fidelity-wireframing-visual-design","text":"High-fidelity wireframing and the creation of visual design comps are activities done to create a fully detailed articulation of the interface (plus all its attendant states necessary to support a functionality). Like low-fidelity wireframes, high-fidelity wireframes are still mostly line renderings representing the interface. But the additional detail at this stage should offer language, labels and fully depicted interactions including success and error cases, and provide guidance for how to handle not just primary use cases but also all edge cases. Visual design comps should offer presentation details such as how individual components should be visually styled, and how the components relate to one another in the interface.","title":"3.5.1.1 High-Fidelity Wireframing &amp; Visual Design"},{"location":"ux/3-5-1-1-visualdesign/#requirements","text":"A determination of which conceptual design direction to pursue in detail. A scope of design work to be detailed, in user stories or similar.","title":"Requirements"},{"location":"ux/3-5-1-1-visualdesign/#productoutput","text":"High-fidelity wireframes and comps serve as the foundation for communicating the final design. For lean documentation practices and usability testing , these artifacts will serve as the design source for a prototype . They also serve as the source material for writing full developer specifications .","title":"Product/output"},{"location":"ux/3-5-1-1-visualdesign/#practical-considerations","text":"Visual design comps can organize the interface differently than the wireframes, so long as there is no contradiction between the two. In cases where the comps do not match the wireframes exactly, the comps should be followed for form and the wireframes should be followed for function. Frequently high-fidelity wireframes and visual design comps are created in parallel, and help inform one another. In this process, the best ideas from each are combined in the final solution.","title":"Practical considerations"},{"location":"ux/3-5-1-1-visualdesign/#resources","text":"What is Interaction Design? https://www.interaction-design.org/literature/article/what-is-interaction-design Adaptive vs. Responsive Design https://www.interaction-design.org/literature/article/adaptive-vs-responsive-design","title":"Resources"},{"location":"ux/3-5-1-2-prototyping/","text":"Back to Phase 3: Detailed Design 3.5.1.2 Prototyping A prototype is a simulation of the intended presentation and functionality of the system. It allows user validation prior to committing to build, and demonstrates its intended functionality to the development team. In the detailed design phase, a prototype would typically be based on high-fidelity wireframes or comps. Requirements High-fidelity wireframes or comps to act as source material. Use cases the prototype is meant to simulate. User stories or similar for detailed requirements or acceptance criteria the prototype should follow. Product/output A high-fidelity prototype should be digital and interactive, even if only for highly specific click-paths. The fidelity at this point should be close enough to an exact representation of the intended final product, that testing of the prototype should result in reasonably accurate user performance data (e.g. time to perform a given task). Practical considerations If usability testing goals do not require the prototype to dynamically respond to user inputs, a prototype comprised simply of clickable static interface images (i.e. visual design comps) can suffice. It is generally better to prototype small units of an experience such as key pages, sections or features than to manage one comprehensive prototype. This keeps prototypes manageable and focused, and minimizes need for additional time in refactoring patterns and interactions across a larger whole, especially when the delivery focus is narrower. Reference Prototyping https://www.usability.gov/how-to-and-tools/methods/prototyping.html","title":"Prototyping"},{"location":"ux/3-5-1-2-prototyping/#3512-prototyping","text":"A prototype is a simulation of the intended presentation and functionality of the system. It allows user validation prior to committing to build, and demonstrates its intended functionality to the development team. In the detailed design phase, a prototype would typically be based on high-fidelity wireframes or comps.","title":"3.5.1.2 Prototyping"},{"location":"ux/3-5-1-2-prototyping/#requirements","text":"High-fidelity wireframes or comps to act as source material. Use cases the prototype is meant to simulate. User stories or similar for detailed requirements or acceptance criteria the prototype should follow.","title":"Requirements"},{"location":"ux/3-5-1-2-prototyping/#productoutput","text":"A high-fidelity prototype should be digital and interactive, even if only for highly specific click-paths. The fidelity at this point should be close enough to an exact representation of the intended final product, that testing of the prototype should result in reasonably accurate user performance data (e.g. time to perform a given task).","title":"Product/output"},{"location":"ux/3-5-1-2-prototyping/#practical-considerations","text":"If usability testing goals do not require the prototype to dynamically respond to user inputs, a prototype comprised simply of clickable static interface images (i.e. visual design comps) can suffice. It is generally better to prototype small units of an experience such as key pages, sections or features than to manage one comprehensive prototype. This keeps prototypes manageable and focused, and minimizes need for additional time in refactoring patterns and interactions across a larger whole, especially when the delivery focus is narrower.","title":"Practical considerations"},{"location":"ux/3-5-1-2-prototyping/#reference","text":"Prototyping https://www.usability.gov/how-to-and-tools/methods/prototyping.html","title":"Reference"},{"location":"ux/3-5-1-3-usability/","text":"Back to Phase 3: Detailed Design 3.5.1.3 Usability Testing Compared to earlier concept testing , the testing done at this phase should not be centered on exploring solutions so much as refining and optimizing specifics. In much the same fashion as earlier testing, however, participants should be given scenarios or tasks, and asked to complete them through use of the prototyped interfaces, while also thinking aloud to express their thoughts and feelings of the experience as they proceed. Requirements A test script based on real scenarios or use cases . A prototype that allows for the completion of the tasks in the test script. The ability to recruit target end users to participate. An ability to record the tests, or to take careful notes during the sessions. Variations Moderated versus unmoderated With moderated testing, a moderator sits with the participant to guide the session. This involves giving the participant an introduction to the test and its goals, then giving tasks to the tester as the session progresses, prompting the user to explain their thoughts and actions, and helping prevent the tester from getting completely off track. In this method, the moderator must be careful to avoid offering any guidance on how to complete the test tasks, even if the tester begs off a difficult task, until the entire test is done. If the tester has veered so far off as to make their continuation unproductive, the moderator may elect to gently direct the tester to start over or move to the next task. The moderator must also be extremely careful not to ask leading or biased questions about the design in an attempt to elicit specific feedback. The moderator should exhibit neutral attitudes regarding the design and the test tasks. In unmoderated testing, the efficacy of the test relies on the participants to clearly understand the goals of the test and their instructions for properly participating, including a desire to have them continuously thinking aloud for the duration of the session. Because that behavior is fairly unnatural, it is easily forgotten about when attempting a particularly challenging task, which is exactly when that vocalization is most beneficial to the design team. Unmoderated testing is typically done via an online testing tool, where the test can be done at the participant\u2019s convenience on their own computer, which makes participation easier. Formal versus informal/guerilla In formal testing, the test is conducted in a lab setting with a moderator on hand to lead the sessions. In highly formal lab settings, there is frequently an observation area separated from the test area by a one-way mirror. This keeps the participant and moderator able to focus on the test, while allowing stakeholders and other team members to observe the sessions firsthand. Formal settings often have advanced technologies for recording the test, including video of the participant, screen capture of the participant\u2019s on-screen actions, and even eye tracking. In this way, formal tests can yield highly nuanced findings. Informal or guerilla-style testing is conducted in any environment where testers can find participants. This can be simply at the participant\u2019s desk, or a conference room. The test need not be conducted in a highly controlled setting in order to elicit meaningful feedback. Product/output Ideally, your setup allows for a recording of the test sessions (most importantly audio recording and screen capture) for later analysis and detailed reporting. If that is not possible, having someone available to take notes during the sessions, such as key quotes from the testers and details around specific difficulties, will suffice. The findings should inform iterations of the detailed designs and prototype, and a repeat of testing until the designs satisfy user needs. Practical considerations Make sure the test participants are made aware that they are not being tested \u2013 the effectiveness of the design is. Any difficulty the participant has completing the test script is a reflection of a deficient design, not of their abilities. If recording is not available, make sure there is a second person available to take notes. The moderator should be able to focus on the participant and their test tasks, not on documenting findings. References & Resources References Running a Usability Test https://www.usability.gov/how-to-and-tools/methods/running-usability-tests.html Complete Beginner\u2019s Guide to UX Research https://www.uxbooth.com/articles/complete-beginners-guide-to-design-research Resources Selecting an Online Tool for Unmoderated Remote User Testing https://www.nngroup.com/articles/unmoderated-user-testing-tools","title":"Usability testing"},{"location":"ux/3-5-1-3-usability/#3513-usability-testing","text":"Compared to earlier concept testing , the testing done at this phase should not be centered on exploring solutions so much as refining and optimizing specifics. In much the same fashion as earlier testing, however, participants should be given scenarios or tasks, and asked to complete them through use of the prototyped interfaces, while also thinking aloud to express their thoughts and feelings of the experience as they proceed.","title":"3.5.1.3 Usability Testing"},{"location":"ux/3-5-1-3-usability/#requirements","text":"A test script based on real scenarios or use cases . A prototype that allows for the completion of the tasks in the test script. The ability to recruit target end users to participate. An ability to record the tests, or to take careful notes during the sessions.","title":"Requirements"},{"location":"ux/3-5-1-3-usability/#variations","text":"","title":"Variations"},{"location":"ux/3-5-1-3-usability/#moderated-versus-unmoderated","text":"With moderated testing, a moderator sits with the participant to guide the session. This involves giving the participant an introduction to the test and its goals, then giving tasks to the tester as the session progresses, prompting the user to explain their thoughts and actions, and helping prevent the tester from getting completely off track. In this method, the moderator must be careful to avoid offering any guidance on how to complete the test tasks, even if the tester begs off a difficult task, until the entire test is done. If the tester has veered so far off as to make their continuation unproductive, the moderator may elect to gently direct the tester to start over or move to the next task. The moderator must also be extremely careful not to ask leading or biased questions about the design in an attempt to elicit specific feedback. The moderator should exhibit neutral attitudes regarding the design and the test tasks. In unmoderated testing, the efficacy of the test relies on the participants to clearly understand the goals of the test and their instructions for properly participating, including a desire to have them continuously thinking aloud for the duration of the session. Because that behavior is fairly unnatural, it is easily forgotten about when attempting a particularly challenging task, which is exactly when that vocalization is most beneficial to the design team. Unmoderated testing is typically done via an online testing tool, where the test can be done at the participant\u2019s convenience on their own computer, which makes participation easier.","title":"Moderated versus unmoderated"},{"location":"ux/3-5-1-3-usability/#formal-versus-informalguerilla","text":"In formal testing, the test is conducted in a lab setting with a moderator on hand to lead the sessions. In highly formal lab settings, there is frequently an observation area separated from the test area by a one-way mirror. This keeps the participant and moderator able to focus on the test, while allowing stakeholders and other team members to observe the sessions firsthand. Formal settings often have advanced technologies for recording the test, including video of the participant, screen capture of the participant\u2019s on-screen actions, and even eye tracking. In this way, formal tests can yield highly nuanced findings. Informal or guerilla-style testing is conducted in any environment where testers can find participants. This can be simply at the participant\u2019s desk, or a conference room. The test need not be conducted in a highly controlled setting in order to elicit meaningful feedback.","title":"Formal versus informal/guerilla"},{"location":"ux/3-5-1-3-usability/#productoutput","text":"Ideally, your setup allows for a recording of the test sessions (most importantly audio recording and screen capture) for later analysis and detailed reporting. If that is not possible, having someone available to take notes during the sessions, such as key quotes from the testers and details around specific difficulties, will suffice. The findings should inform iterations of the detailed designs and prototype, and a repeat of testing until the designs satisfy user needs.","title":"Product/output"},{"location":"ux/3-5-1-3-usability/#practical-considerations","text":"Make sure the test participants are made aware that they are not being tested \u2013 the effectiveness of the design is. Any difficulty the participant has completing the test script is a reflection of a deficient design, not of their abilities. If recording is not available, make sure there is a second person available to take notes. The moderator should be able to focus on the participant and their test tasks, not on documenting findings.","title":"Practical considerations"},{"location":"ux/3-5-1-3-usability/#references-resources","text":"","title":"References &amp; Resources"},{"location":"ux/3-5-1-3-usability/#references","text":"Running a Usability Test https://www.usability.gov/how-to-and-tools/methods/running-usability-tests.html Complete Beginner\u2019s Guide to UX Research https://www.uxbooth.com/articles/complete-beginners-guide-to-design-research","title":"References"},{"location":"ux/3-5-1-3-usability/#resources","text":"Selecting an Online Tool for Unmoderated Remote User Testing https://www.nngroup.com/articles/unmoderated-user-testing-tools","title":"Resources"},{"location":"ux/3-5-1-4-annotating/","text":"Back to Phase 3: Detailed Design 3.5.1.4 Specifying/Annotating In order to properly support development, all possible states of the interface should be depicted in wireframe or comp, or described in detailed specifications. These specifications and annotations are an opportunity to describe the design\u2019s intent beyond what can be conveyed in a static wireframe of visual design comp alone. This typically includes details like dynamic language, how business rules drive presentation, or exact details on how an interaction should function. Requirements High-fidelity wireframes or visual design comps to start from. Product/output Design specifications are most useful when presented side-by-side with the detailed design artifacts (wireframes or comps). Typically, a numbered marker is placed on top of the artifact, that references its respective annotation. Practical considerations In Agile and Lean environments, verbal and collaborative communication is favored to extensive documentation like fully annotated wireframes. Even so, some level of specification is still generally necessary to fully convey the designs for implementation. Resource Wireframing \u2013 The Perfectionist's Guide https://www.smashingmagazine.com/2016/11/wireframe-perfectionist-guide/#annotating-the-wireframes","title":"Specifying/annotating"},{"location":"ux/3-5-1-4-annotating/#3514-specifyingannotating","text":"In order to properly support development, all possible states of the interface should be depicted in wireframe or comp, or described in detailed specifications. These specifications and annotations are an opportunity to describe the design\u2019s intent beyond what can be conveyed in a static wireframe of visual design comp alone. This typically includes details like dynamic language, how business rules drive presentation, or exact details on how an interaction should function.","title":"3.5.1.4 Specifying/Annotating"},{"location":"ux/3-5-1-4-annotating/#requirements","text":"High-fidelity wireframes or visual design comps to start from.","title":"Requirements"},{"location":"ux/3-5-1-4-annotating/#productoutput","text":"Design specifications are most useful when presented side-by-side with the detailed design artifacts (wireframes or comps). Typically, a numbered marker is placed on top of the artifact, that references its respective annotation.","title":"Product/output"},{"location":"ux/3-5-1-4-annotating/#practical-considerations","text":"In Agile and Lean environments, verbal and collaborative communication is favored to extensive documentation like fully annotated wireframes. Even so, some level of specification is still generally necessary to fully convey the designs for implementation.","title":"Practical considerations"},{"location":"ux/3-5-1-4-annotating/#resource","text":"Wireframing \u2013 The Perfectionist's Guide https://www.smashingmagazine.com/2016/11/wireframe-perfectionist-guide/#annotating-the-wireframes","title":"Resource"},{"location":"ux/3-5-detailed/","text":"3.5 Phase 3: Detailed Design This phase involves building out the conceptual design into fully detailed designs that encompass the entirety of the interfaces and interactions within a given scope of requirements. The final product should be development-ready, including enough specification to explain the how the user may interact with dynamic portions of the designs, and how the designs satisfy their intended requirements or user stories. 3.5.1 Activities for Detailing Designs High-fidelity wireframing and visual design Fully detailed renderings of the system\u2019s relevant interfaces help clearly articulate the system and its capabilities. Prototyping A simulation of the intended presentation and functionality of the system allows user validation prior to committing to build, and demonstrates this intended functionality to the development team. Usability testing Assessing the detailed design at this stage allows the team to more nimbly correct course and enhance the experience prior to development. Specifying/annotating Provide additional details to the development team to explain all of the ways a user can interact with the designs.","title":"3.5 Phase 3: Detailed Design"},{"location":"ux/3-5-detailed/#35-phase-3-detailed-design","text":"This phase involves building out the conceptual design into fully detailed designs that encompass the entirety of the interfaces and interactions within a given scope of requirements. The final product should be development-ready, including enough specification to explain the how the user may interact with dynamic portions of the designs, and how the designs satisfy their intended requirements or user stories.","title":"3.5 Phase 3: Detailed Design"},{"location":"ux/3-5-detailed/#351-activities-for-detailing-designs","text":"","title":"3.5.1 Activities for Detailing Designs"},{"location":"ux/3-5-detailed/#high-fidelity-wireframing-and-visual-design","text":"Fully detailed renderings of the system\u2019s relevant interfaces help clearly articulate the system and its capabilities.","title":"High-fidelity wireframing and visual design"},{"location":"ux/3-5-detailed/#prototyping","text":"A simulation of the intended presentation and functionality of the system allows user validation prior to committing to build, and demonstrates this intended functionality to the development team.","title":"Prototyping"},{"location":"ux/3-5-detailed/#usability-testing","text":"Assessing the detailed design at this stage allows the team to more nimbly correct course and enhance the experience prior to development.","title":"Usability testing"},{"location":"ux/3-5-detailed/#specifyingannotating","text":"Provide additional details to the development team to explain all of the ways a user can interact with the designs.","title":"Specifying/annotating"},{"location":"ux/3-6-support/","text":"3.6 Phase 4: Support User experience involvement should not end at a hand-off to the development team. Continuing to participate in the development, deployment and post-delivery support periods is crucial to ensuring the delivered experience matches the delivered designs and meets stakeholder and end-user expectations. 3.6.1 Activities in Post-Delivery Support Developer communication and design adjustment Collaboration with the development team during build helps cover missed edge cases or ambiguous requirements, and ensures that detailed designs are built as specified. Acceptance testing The product ownership team, including the user experience team, should thoroughly test the built capabilities prior to live deployment. The acceptance criteria collected in user stories serve well as an ad hoc test script. Post-launch, conducting acceptance testing with actual end users serves as another validation of the release\u2019s designs as well as research for future iterations or new additional features.","title":"3.6 Phase 4: Support"},{"location":"ux/3-6-support/#36-phase-4-support","text":"User experience involvement should not end at a hand-off to the development team. Continuing to participate in the development, deployment and post-delivery support periods is crucial to ensuring the delivered experience matches the delivered designs and meets stakeholder and end-user expectations.","title":"3.6 Phase 4: Support"},{"location":"ux/3-6-support/#361-activities-in-post-delivery-support","text":"","title":"3.6.1 Activities in Post-Delivery Support"},{"location":"ux/3-6-support/#developer-communication-and-design-adjustment","text":"Collaboration with the development team during build helps cover missed edge cases or ambiguous requirements, and ensures that detailed designs are built as specified.","title":"Developer communication and design adjustment"},{"location":"ux/3-6-support/#acceptance-testing","text":"The product ownership team, including the user experience team, should thoroughly test the built capabilities prior to live deployment. The acceptance criteria collected in user stories serve well as an ad hoc test script. Post-launch, conducting acceptance testing with actual end users serves as another validation of the release\u2019s designs as well as research for future iterations or new additional features.","title":"Acceptance testing"},{"location":"ux/4-1-introduction/","text":"4.1 Introduction Welcome The visual design section of the BES User Experience Playbook catalogues and describes the best practices of digital visual design, and how they inform logistics information application user experiences. These best practices are illustrated with examples from existing USAF applications, as well as \"hybrid\u201d components where necessary to provide a unique visualization. Purpose This is not a style guide . This content is intended as a teaching tool, to complement technical documentation from other design and development playbooks. The visualizations are not intended as redesigns of existing or new applications, but rather guidelines for making decisions within the context of your own design systems. When designing specific user interface components, first consult your application\u2019s style guide, then refer to this playbook should any questions remain. This content also exists as a living document. As USAF applications, best practices, and use cases continue to evolve, so too will this document and the examples herein.","title":"4.1 Introduction"},{"location":"ux/4-1-introduction/#41-introduction","text":"","title":"4.1 Introduction"},{"location":"ux/4-1-introduction/#welcome","text":"The visual design section of the BES User Experience Playbook catalogues and describes the best practices of digital visual design, and how they inform logistics information application user experiences. These best practices are illustrated with examples from existing USAF applications, as well as \"hybrid\u201d components where necessary to provide a unique visualization.","title":"Welcome"},{"location":"ux/4-1-introduction/#purpose","text":"This is not a style guide . This content is intended as a teaching tool, to complement technical documentation from other design and development playbooks. The visualizations are not intended as redesigns of existing or new applications, but rather guidelines for making decisions within the context of your own design systems. When designing specific user interface components, first consult your application\u2019s style guide, then refer to this playbook should any questions remain. This content also exists as a living document. As USAF applications, best practices, and use cases continue to evolve, so too will this document and the examples herein.","title":"Purpose"},{"location":"ux/4-10-imagery/","text":"4.10 Imagery Worth 1000 Words Images are a highly effective way to communicate information and evoke emotions. In more editorial layouts, images are useful for breaking up copy and reinforcing narrative points. In data visualizations (a matrix of aircraft types, for instance), they can improve scannability and actually increase the efficiency of a platform. Imagery Images aren\u2019t just decoration, but tools for encouraging certain user behavior and response. Whether for orientation or texture, they should follow best practices: Images should have purpose . Though it may be tempting to \u201cdecorate\u201d a text- or data-heavy page, introducing purely decorative images may inadvertently distract from key user tasks and unnecessarily increase the page\u2019s file weight. Images should do what could not be done otherwise, or done more efficiently than if done in text. Reinforce the user experience . The aesthetic of a layout should serve the intent of the UX design, particularly when images can be used as a shorthand in the display of information. Direct the eye toward key layout elements . The subject and composition of an image can help move the eye toward important components, such as mandatory fields and calls-to-action. Human subjects in images should \u201clook at\u201d those components, rather than looking away. Likewise, jets should \u201cfly toward,\u201d lines should \u201cpoint,\u201d etc. Illustrate concepts . The most useful images illustrate concepts too cumbersome to put into words. If text describes at length something in terms of its appearance, that\u2019s often a cue to use an image instead. Avoid placing key copy in an image . From a technical perspective, text in an image introduces an accessibility risk. It is unrecognizable by automated screen readers, and may be made illegible during the image optimization process. It also eliminates searchability and copy-paste functionality. There are exceptions, of course, such as in cases of inline labels and platform limitations. Naturally, images should also follow best practices of contrast, composition, and standards set by USAF design guidelines. Formatting and Optimizing With a few exceptions (such as .SVGs for icons) virtually all digital image assets will be in the RGB raster formats of .JPG, .PNG, and .GIF, which each have slightly different properties and merits. In short: .JPG formats compress image information to a very small file size, but at the cost of a permanent loss in image quality (a \u201clossy\u201d image that results in more noticeable .JPG \u201cartifacts\u201d the smaller the file size). .PNG formats compress image information without a loss in image quality, and also support a transparency layer \u2013 useful for placing the image atop textured or colored backgrounds. .PNGs are most useful for web / digital formats but tend to have a larger file size. .GIF formats compress image information by reducing the total number of colors. .GIFs support transparency, and also multi-frame animations. As an older technology, they are usually only used in limited circumstances. When evaluating your optimization method, consider the nature of the image and most important characteristics. Is the priority the crispness / quality of the image? The smallest possible file size? Is there a production requirement that requires transparency? In what context and on what device will the user be viewing the image? When in doubt, attempt to optimize for the smallest possible file size without an obvious loss in visual quality. References Web Fundamentals from Google https://developers.google.com/web/fundamentals/performance/optimizing-content-efficiency/image-optimization Image Optimizers https://tinypng.com https://kraken.io/web-interface","title":"4.10 Imagery"},{"location":"ux/4-10-imagery/#410-imagery","text":"","title":"4.10 Imagery"},{"location":"ux/4-10-imagery/#worth-1000-words","text":"Images are a highly effective way to communicate information and evoke emotions. In more editorial layouts, images are useful for breaking up copy and reinforcing narrative points. In data visualizations (a matrix of aircraft types, for instance), they can improve scannability and actually increase the efficiency of a platform.","title":"Worth 1000 Words"},{"location":"ux/4-10-imagery/#imagery","text":"Images aren\u2019t just decoration, but tools for encouraging certain user behavior and response. Whether for orientation or texture, they should follow best practices: Images should have purpose . Though it may be tempting to \u201cdecorate\u201d a text- or data-heavy page, introducing purely decorative images may inadvertently distract from key user tasks and unnecessarily increase the page\u2019s file weight. Images should do what could not be done otherwise, or done more efficiently than if done in text. Reinforce the user experience . The aesthetic of a layout should serve the intent of the UX design, particularly when images can be used as a shorthand in the display of information. Direct the eye toward key layout elements . The subject and composition of an image can help move the eye toward important components, such as mandatory fields and calls-to-action. Human subjects in images should \u201clook at\u201d those components, rather than looking away. Likewise, jets should \u201cfly toward,\u201d lines should \u201cpoint,\u201d etc. Illustrate concepts . The most useful images illustrate concepts too cumbersome to put into words. If text describes at length something in terms of its appearance, that\u2019s often a cue to use an image instead. Avoid placing key copy in an image . From a technical perspective, text in an image introduces an accessibility risk. It is unrecognizable by automated screen readers, and may be made illegible during the image optimization process. It also eliminates searchability and copy-paste functionality. There are exceptions, of course, such as in cases of inline labels and platform limitations. Naturally, images should also follow best practices of contrast, composition, and standards set by USAF design guidelines.","title":"Imagery"},{"location":"ux/4-10-imagery/#formatting-and-optimizing","text":"With a few exceptions (such as .SVGs for icons) virtually all digital image assets will be in the RGB raster formats of .JPG, .PNG, and .GIF, which each have slightly different properties and merits. In short: .JPG formats compress image information to a very small file size, but at the cost of a permanent loss in image quality (a \u201clossy\u201d image that results in more noticeable .JPG \u201cartifacts\u201d the smaller the file size). .PNG formats compress image information without a loss in image quality, and also support a transparency layer \u2013 useful for placing the image atop textured or colored backgrounds. .PNGs are most useful for web / digital formats but tend to have a larger file size. .GIF formats compress image information by reducing the total number of colors. .GIFs support transparency, and also multi-frame animations. As an older technology, they are usually only used in limited circumstances. When evaluating your optimization method, consider the nature of the image and most important characteristics. Is the priority the crispness / quality of the image? The smallest possible file size? Is there a production requirement that requires transparency? In what context and on what device will the user be viewing the image? When in doubt, attempt to optimize for the smallest possible file size without an obvious loss in visual quality.","title":"Formatting and Optimizing"},{"location":"ux/4-10-imagery/#references","text":"Web Fundamentals from Google https://developers.google.com/web/fundamentals/performance/optimizing-content-efficiency/image-optimization Image Optimizers https://tinypng.com https://kraken.io/web-interface","title":"References"},{"location":"ux/4-11-buttons/","text":"4.11 Buttons & Controls Creating Custom-Styled Controls Buttons and controls, in the context of this design playbook, are key interactive elements that are custom-styled to match the look & feel of a USAF application. There are many other types of controls (radio buttons, inline scrolls, dropdown menus, etc.), but these most frequently adopt the style of the browser itself, and are thus excluded. Additional styled elements (like navigation and breadcrumbs) can be found within the Component Library of this playbook. Buttons Buttons are a key component of interaction design, and are often the primary call-to-action at the page and component level. They usually \u201ccommit\u201d the action of a user \u2013 submitting a form or piece of data, opening / closing a page element, or navigating to a new content section. Buttons should adhere to the following best practices: Buttons should look like buttons. Unlike links \u2013 which are often just highlighted text \u2013 buttons employ a containing element (usually a square or rounded rectangle) to look like the buttons of the physical world. This helps increase their visual emphasis in a layout, and communicate their clickability. Buttons should be findable. The button location should be logical in relation to the actions of the layout. A \u201csubmit\u201d button, for instance, should be readily visible as the user is completing the last required field of a form. A \u201cnext\u201d button should live near the end of a content section (or universally accessible, if the content is intended to be scanned and not read to completion). Buttons placement should never be a hunting game. Buttons should communicate their action. Button labels should be clear and obvious, indicating the behavior of the button. \u201cSubmit form,\u201d \u201cLearn More,\u201d and \u201cNext\u201d articulate the intention of the button, and relate directly to the content around it. Furthermore, combining buttons labels and buttons styles \u2013 such as in the case with a \u201cCancel\u201d button and an adjacent \u201cOK\u201d button -- enhances the clarity of each button\u2019s action. Button Emphasis & States Buttons often come in primary and secondary styles, both of which follow call-to-action color rules but are treated differently to communicate priority and emphasis. In this case, a primary button style might be used to submit a form, while a secondary button style might be used to cancel the form submission. As interactive elements, buttons often have multiple states to communicate to the user the status of the button. Commonly these states are active, hover (on desktop) / clicked, and disabled. The disabled button state is particularly useful for compelling the user to provide all mandatory data before they can proceed; once all form fields have been completed, the button changes to an active \u2013 thus clickable \u2013 state. Styling custom buttons should follow your application\u2019s design guidelines, and the rules of contrast, legibility, and color mentioned elsewhere in this playbook. The basic button states follow a complementary logic: The active button state reflects the call-to-action color, improving the obviousness of its function. The hover state is a slightly lighter or darker than the active state, further communicating that it is an interactive element. The disabled state is desaturated and reduced in opacity; ideally, it is just visible enough to discern as a button, but not distract from the other active page elements. Button Feedback As a key site interaction, users often want validation that their button-click has performed the intended operation. In some cases, loading the subsequent page will be an adequate response to clicking \u201cLearn More.\u201d In others \u2013 such as when submitting a form \u2013 additional validation may be required. In these cases, consider confirmation and error message styles that are unique and explicit. These feedback elements are a perfect example of the interrelatedness of UX and visual design. Tabs Tabs are a common interactive element \u2013 especially within data tables \u2013 and communicate lateral movement between content of like categories. They are useful in navigation, and also in comparing similar content types on separate layouts. Combine in like categories . Tabbed items should live at the same hierarchical level with one another. They should also have mutually exclusive content. For example, if the tab category is \u201cmedia,\u201d individual tabs could be \u201cMusic,\u201d \u201cMovies,\u201d and \u201cBooks.\u201d Arrange tabs in a logical order . The first (leftmost) tab in the set is usually the default tab, and thus sets the standard for content and behavior of other tabs. This tab should also feature your prioritized content, with less prioritized content as the user moves right. There are some exceptions, of course, such as in the case of tabs that are organized alphabetically or numerically. Mind horizontal space . Since tabs are usually bound by screen width (other than an infinite vertical scroll), your tab solution should be meaningful at the given device\u2019s viewport. That might mean a scalable tab set that goes \u201coffscreen,\u201d using truncated text, or switching from text to icons when users reach the mobile breakpoint. Tabs must maintain their meaning and scannability, at any scale. Similar to buttons and navigation elements, tabs often have states to communicate their status. References Button Design Best Practices https://uxplanet.org/7-basic-rules-for-button-design-63dcdf5676b4 https://www.smashingmagazine.com/2016/11/a-quick-guide-for-designing-better-buttons https://material.io/design/components/buttons.html Table Design Best Practices https://uxplanet.org/tabs-for-mobile-ux-design-d4cc4d9410d1 https://www.justinmind.com/blog/8-tips-to-get-tabs-right-in-web-design https://material.io/design/components/tabs.html","title":"4.11 Buttons & Controls"},{"location":"ux/4-11-buttons/#411-buttons-controls","text":"","title":"4.11 Buttons &amp; Controls"},{"location":"ux/4-11-buttons/#creating-custom-styled-controls","text":"Buttons and controls, in the context of this design playbook, are key interactive elements that are custom-styled to match the look & feel of a USAF application. There are many other types of controls (radio buttons, inline scrolls, dropdown menus, etc.), but these most frequently adopt the style of the browser itself, and are thus excluded. Additional styled elements (like navigation and breadcrumbs) can be found within the Component Library of this playbook.","title":"Creating Custom-Styled Controls"},{"location":"ux/4-11-buttons/#buttons","text":"Buttons are a key component of interaction design, and are often the primary call-to-action at the page and component level. They usually \u201ccommit\u201d the action of a user \u2013 submitting a form or piece of data, opening / closing a page element, or navigating to a new content section. Buttons should adhere to the following best practices: Buttons should look like buttons. Unlike links \u2013 which are often just highlighted text \u2013 buttons employ a containing element (usually a square or rounded rectangle) to look like the buttons of the physical world. This helps increase their visual emphasis in a layout, and communicate their clickability. Buttons should be findable. The button location should be logical in relation to the actions of the layout. A \u201csubmit\u201d button, for instance, should be readily visible as the user is completing the last required field of a form. A \u201cnext\u201d button should live near the end of a content section (or universally accessible, if the content is intended to be scanned and not read to completion). Buttons placement should never be a hunting game. Buttons should communicate their action. Button labels should be clear and obvious, indicating the behavior of the button. \u201cSubmit form,\u201d \u201cLearn More,\u201d and \u201cNext\u201d articulate the intention of the button, and relate directly to the content around it. Furthermore, combining buttons labels and buttons styles \u2013 such as in the case with a \u201cCancel\u201d button and an adjacent \u201cOK\u201d button -- enhances the clarity of each button\u2019s action.","title":"Buttons"},{"location":"ux/4-11-buttons/#button-emphasis-states","text":"Buttons often come in primary and secondary styles, both of which follow call-to-action color rules but are treated differently to communicate priority and emphasis. In this case, a primary button style might be used to submit a form, while a secondary button style might be used to cancel the form submission. As interactive elements, buttons often have multiple states to communicate to the user the status of the button. Commonly these states are active, hover (on desktop) / clicked, and disabled. The disabled button state is particularly useful for compelling the user to provide all mandatory data before they can proceed; once all form fields have been completed, the button changes to an active \u2013 thus clickable \u2013 state. Styling custom buttons should follow your application\u2019s design guidelines, and the rules of contrast, legibility, and color mentioned elsewhere in this playbook. The basic button states follow a complementary logic: The active button state reflects the call-to-action color, improving the obviousness of its function. The hover state is a slightly lighter or darker than the active state, further communicating that it is an interactive element. The disabled state is desaturated and reduced in opacity; ideally, it is just visible enough to discern as a button, but not distract from the other active page elements.","title":"Button Emphasis &amp; States"},{"location":"ux/4-11-buttons/#button-feedback","text":"As a key site interaction, users often want validation that their button-click has performed the intended operation. In some cases, loading the subsequent page will be an adequate response to clicking \u201cLearn More.\u201d In others \u2013 such as when submitting a form \u2013 additional validation may be required. In these cases, consider confirmation and error message styles that are unique and explicit. These feedback elements are a perfect example of the interrelatedness of UX and visual design.","title":"Button Feedback"},{"location":"ux/4-11-buttons/#tabs","text":"Tabs are a common interactive element \u2013 especially within data tables \u2013 and communicate lateral movement between content of like categories. They are useful in navigation, and also in comparing similar content types on separate layouts. Combine in like categories . Tabbed items should live at the same hierarchical level with one another. They should also have mutually exclusive content. For example, if the tab category is \u201cmedia,\u201d individual tabs could be \u201cMusic,\u201d \u201cMovies,\u201d and \u201cBooks.\u201d Arrange tabs in a logical order . The first (leftmost) tab in the set is usually the default tab, and thus sets the standard for content and behavior of other tabs. This tab should also feature your prioritized content, with less prioritized content as the user moves right. There are some exceptions, of course, such as in the case of tabs that are organized alphabetically or numerically. Mind horizontal space . Since tabs are usually bound by screen width (other than an infinite vertical scroll), your tab solution should be meaningful at the given device\u2019s viewport. That might mean a scalable tab set that goes \u201coffscreen,\u201d using truncated text, or switching from text to icons when users reach the mobile breakpoint. Tabs must maintain their meaning and scannability, at any scale. Similar to buttons and navigation elements, tabs often have states to communicate their status.","title":"Tabs"},{"location":"ux/4-11-buttons/#references","text":"Button Design Best Practices https://uxplanet.org/7-basic-rules-for-button-design-63dcdf5676b4 https://www.smashingmagazine.com/2016/11/a-quick-guide-for-designing-better-buttons https://material.io/design/components/buttons.html Table Design Best Practices https://uxplanet.org/tabs-for-mobile-ux-design-d4cc4d9410d1 https://www.justinmind.com/blog/8-tips-to-get-tabs-right-in-web-design https://material.io/design/components/tabs.html","title":"References"},{"location":"ux/4-12-mobile/","text":"4.12 Key Mobile Standards Designing for In-Hand and On-the-Go \u201cMobile first\u201d is a design mantra that helps remind us that an ever-increasing percentage of platform access is via mobile device (both phone and tablet). In some cases, mobile devices make up the majority of access. So while we can\u2019t yet dismiss the importance of desktop devices, it\u2019s a best practice to remember that our users first reach for the computers in their pockets. Mobile is Different Most visual design principles are universal, and applicable across devices. The elements of type and color and imagery employ the same best practices. But two key factors (and many smaller ones) require slightly different design thinking, and a real consideration of user experience. The device is in-hand . Mobile devices have small viewports, obviously. That smaller screen size means that longer copy and larger interactive elements need to be treated with a sort of shorthand. An icon, perhaps, where before there was icon and text. That viewport means a smaller keyboard with smaller keys. They\u2019re often thumb-typed, making long form entry uncomfortable. And to just shrink interactive elements fails the user \u2013 often resulted in the dreaded \u201cfat finger\u201d mis-tap. The user is on-the-go . Mobile access often indicates that the user isn\u2019t at their workstation, is in a remote working environment, or is even working \u201cmulti-screen.\u201d They may be using cellular data and thus reluctant to download large files, if they\u2019re able to at all. They may be in an \u201cin-between time,\u201d waiting in line or walking to their next meeting, hoping for the most efficient task completion, without frills. When translating desktop designs to mobile, don\u2019t just miniaturize it \u2013 consider how the device and context should influence changes. Other mobile best practices include: Hide and reveal content . Text truncation, \u201cshow more\u201d buttons, and accordion controls increase the scannability of a mobile page, and allow the user to reveal content only on demand. Additionally, menus, headers, and footers can hide when scrolling away, and reveal when scrolling toward \u2013 reclaiming that visual real estate for higher priority elements. Remove unnecessary ornamentation . A beautiful brand image might work on a desktop design (and over reliable wifi), but on mobile is a waste of bandwidth. Keep only those images that orient and communicate critical information \u2013 and optimize those to the viewport of your target devices. Embrace scrolling . The most predictable, responsive, mobile designs translate desktop layouts into long, scrollable pages. Components should be prioritized from top to bottom in a logical linear order, and when possible provide an affordance for the component that follows. Test vigorously ! Minor differences between devices tend to disrupt pixel-precise mobile designs. The most reliable way to assure a predictable user experience is to test on your user\u2019s most common devices, within the browser of that device. If the actual phones / tables are unavailable, device emulators and browser plugins can still remove some of the guesswork. Phone vs. Tablet Differences Remember that a mobile device isn\u2019t just a phone. Scalability across devices, more specifically between a phone and tablet, is a common challenge among designers. While the phone and tablet share many similarities, users use tablets, phones, phablets (not small enough to be a phone, not big enough to be a tablet) very differently. Phone Interfaces Mobile interfaces less than 7 inches width should be treated as a phone. Layout should be aligned across these devices as much as possible, and should also leverage native platform guidelines and capabilities when possible. Mobile phone designs should include only necessary information . The phone is a convenient way to consume information on the go. Airmen use a phone to complete quick actions while they are not at their workspace, capture data in the field, view content, and perhaps return to look later on a larger device. Tablet Interfaces Mobile interfaces greater 7 inches width should be treated as a tablet. Layout should be aligned across these devices as much as possible; they do not need to align to phone interfaces. Tablet designs should look and feel like desktop web, but function like a phone (tap / swipe / hold gestures, etc.). Tablets are more likely to be held in landscape view \u2013 approximating the desktop viewport \u2013 and in this way, many users consider the tablet a hybrid device. \u201cHit Area\u201d and Button Design Unlike the pixel-precise cursor on desktop, mobile interactions rely on human fingers of vastly different sizes. The rule of thumb (!) is that any clickable element should be 48px x 48px (accounting for 2x or greater design if necessary) to accommodate the average fingertip. This hit area should also have adequate padding around it; immediately adjacent clickable elements are not recommended. Native Device Capabilities While most USAF platforms are web-based application viewed within the mobile device browser, native OS design (mobile apps) unlocks the potential of an integrated device. Smart phones and tablets have a lot to offer: touch, voice, pressure, location tracking, accelerometer, notifications, etc. You are designing around the device, the platform, the user experience. How can these device features be utilized in products? How can the mobile device benefit users beyond the screen interface in front of them? When designing for native platforms, however, consistently refer to the native OS design guidelines. These constantly evolve with new version releases and system redesigns, so it\u2019s always good practice to stay on top of these guidelines and refresh your memory and knowledge often. References Apple\u2019s Human Interface Guidelines https://developer.apple.com/ios/human-interface-guidelines Google\u2019s Material Design Guidelines https://material.io/guidelines Mobile Design Principles https://medium.com/blueprint-by-intuit/native-mobile-app-design-overall-principles-and-common-patterns-26edee8ced10 https://uxplanet.org/7-rules-for-mobile-ui-button-design-e9cf2ea54556","title":"4.12 Key Mobile Standards"},{"location":"ux/4-12-mobile/#412-key-mobile-standards","text":"","title":"4.12 Key Mobile Standards"},{"location":"ux/4-12-mobile/#designing-for-in-hand-and-on-the-go","text":"\u201cMobile first\u201d is a design mantra that helps remind us that an ever-increasing percentage of platform access is via mobile device (both phone and tablet). In some cases, mobile devices make up the majority of access. So while we can\u2019t yet dismiss the importance of desktop devices, it\u2019s a best practice to remember that our users first reach for the computers in their pockets.","title":"Designing for In-Hand and On-the-Go"},{"location":"ux/4-12-mobile/#mobile-is-different","text":"Most visual design principles are universal, and applicable across devices. The elements of type and color and imagery employ the same best practices. But two key factors (and many smaller ones) require slightly different design thinking, and a real consideration of user experience. The device is in-hand . Mobile devices have small viewports, obviously. That smaller screen size means that longer copy and larger interactive elements need to be treated with a sort of shorthand. An icon, perhaps, where before there was icon and text. That viewport means a smaller keyboard with smaller keys. They\u2019re often thumb-typed, making long form entry uncomfortable. And to just shrink interactive elements fails the user \u2013 often resulted in the dreaded \u201cfat finger\u201d mis-tap. The user is on-the-go . Mobile access often indicates that the user isn\u2019t at their workstation, is in a remote working environment, or is even working \u201cmulti-screen.\u201d They may be using cellular data and thus reluctant to download large files, if they\u2019re able to at all. They may be in an \u201cin-between time,\u201d waiting in line or walking to their next meeting, hoping for the most efficient task completion, without frills. When translating desktop designs to mobile, don\u2019t just miniaturize it \u2013 consider how the device and context should influence changes. Other mobile best practices include: Hide and reveal content . Text truncation, \u201cshow more\u201d buttons, and accordion controls increase the scannability of a mobile page, and allow the user to reveal content only on demand. Additionally, menus, headers, and footers can hide when scrolling away, and reveal when scrolling toward \u2013 reclaiming that visual real estate for higher priority elements. Remove unnecessary ornamentation . A beautiful brand image might work on a desktop design (and over reliable wifi), but on mobile is a waste of bandwidth. Keep only those images that orient and communicate critical information \u2013 and optimize those to the viewport of your target devices. Embrace scrolling . The most predictable, responsive, mobile designs translate desktop layouts into long, scrollable pages. Components should be prioritized from top to bottom in a logical linear order, and when possible provide an affordance for the component that follows. Test vigorously ! Minor differences between devices tend to disrupt pixel-precise mobile designs. The most reliable way to assure a predictable user experience is to test on your user\u2019s most common devices, within the browser of that device. If the actual phones / tables are unavailable, device emulators and browser plugins can still remove some of the guesswork.","title":"Mobile is Different"},{"location":"ux/4-12-mobile/#phone-vs-tablet-differences","text":"Remember that a mobile device isn\u2019t just a phone. Scalability across devices, more specifically between a phone and tablet, is a common challenge among designers. While the phone and tablet share many similarities, users use tablets, phones, phablets (not small enough to be a phone, not big enough to be a tablet) very differently.","title":"Phone vs. Tablet Differences"},{"location":"ux/4-12-mobile/#phone-interfaces","text":"Mobile interfaces less than 7 inches width should be treated as a phone. Layout should be aligned across these devices as much as possible, and should also leverage native platform guidelines and capabilities when possible. Mobile phone designs should include only necessary information . The phone is a convenient way to consume information on the go. Airmen use a phone to complete quick actions while they are not at their workspace, capture data in the field, view content, and perhaps return to look later on a larger device.","title":"Phone Interfaces"},{"location":"ux/4-12-mobile/#tablet-interfaces","text":"Mobile interfaces greater 7 inches width should be treated as a tablet. Layout should be aligned across these devices as much as possible; they do not need to align to phone interfaces. Tablet designs should look and feel like desktop web, but function like a phone (tap / swipe / hold gestures, etc.). Tablets are more likely to be held in landscape view \u2013 approximating the desktop viewport \u2013 and in this way, many users consider the tablet a hybrid device.","title":"Tablet Interfaces"},{"location":"ux/4-12-mobile/#hit-area-and-button-design","text":"Unlike the pixel-precise cursor on desktop, mobile interactions rely on human fingers of vastly different sizes. The rule of thumb (!) is that any clickable element should be 48px x 48px (accounting for 2x or greater design if necessary) to accommodate the average fingertip. This hit area should also have adequate padding around it; immediately adjacent clickable elements are not recommended.","title":"\u201cHit Area\u201d and Button Design"},{"location":"ux/4-12-mobile/#native-device-capabilities","text":"While most USAF platforms are web-based application viewed within the mobile device browser, native OS design (mobile apps) unlocks the potential of an integrated device. Smart phones and tablets have a lot to offer: touch, voice, pressure, location tracking, accelerometer, notifications, etc. You are designing around the device, the platform, the user experience. How can these device features be utilized in products? How can the mobile device benefit users beyond the screen interface in front of them? When designing for native platforms, however, consistently refer to the native OS design guidelines. These constantly evolve with new version releases and system redesigns, so it\u2019s always good practice to stay on top of these guidelines and refresh your memory and knowledge often.","title":"Native Device Capabilities"},{"location":"ux/4-12-mobile/#references","text":"Apple\u2019s Human Interface Guidelines https://developer.apple.com/ios/human-interface-guidelines Google\u2019s Material Design Guidelines https://material.io/guidelines Mobile Design Principles https://medium.com/blueprint-by-intuit/native-mobile-app-design-overall-principles-and-common-patterns-26edee8ced10 https://uxplanet.org/7-rules-for-mobile-ui-button-design-e9cf2ea54556","title":"References"},{"location":"ux/4-13-accessibility/","text":"4.13 Accessibility Accessibility Considers the User Experience for All Users As excerpted from the WCAG Guidelines, \u201cAccessibility defines how to make Web content more accessible to people with disabilities. Accessibility involves a wide range of disabilities, including visual, auditory, physical, speech, cognitive, language, learning, and neurological disabilities.\u201d While this might not be a requirement of your particular application\u2019s users, accessibility standards often reflect the most stringent interpretation of contrast, legibility, and usability best practices \u2013 and thus are of use to all designers. Accessibility Tips for Designers Accessible application design is a collaboration between designers and developers, affecting UI and code alike. In the interest of a useful shorthand for this playbook\u2019s primary users, this section focuses on best practices of visual design & accessibility (quoted heavily from the Web Accessibility Initiative): Provide sufficient contrast between foreground and background . Foreground text needs to have sufficient contrast with background colors. This includes text on images, background gradients, buttons, and other elements. Don\u2019t use color alone to convey information . While color can be useful to convey information, color should not be the only way information is conveyed. When using color to differentiate elements, also provide additional identification that does not rely on color perception. For example, use an asterisk in addition to color to indicate required form fields, and use labels to distinguish areas on graphs. Ensure that interactive elements are easy to identify . Provide distinct styles for interactive elements, such as links and buttons, to make them easy to identify. For example, change the appearance of links on mouse hover, keyboard focus, and touch-screen activation. Ensure that styles and naming for interactive elements are used consistently throughout the website. Provide clear and consistent navigation options . Ensure that navigation across pages within a website has consistent naming, styling, and positioning. Provide more than one method of website navigation, such as a site search or a site map. Help users understand where they are in a website or page by providing orientation cues, such as breadcrumbs and clear headings. Ensure that form elements include clearly associated labels . Ensure that all fields have a descriptive label adjacent to the field. For left-to-right languages, labels are usually positioned to the left or above the field, except for checkboxes and radio buttons where they are usually to the right. Avoid having too much space between labels and fields. Provide easily identifiable feedback . Provide feedback for interactions, such as confirming form submission, alerting the user when something goes wrong, or notifying the user of changes on the page. Instructions should be easy to identify. Important feedback that requires user action should be presented in a prominent style. Use headings and spacing to group related content . Use whitespace and proximity to make relationships between content more apparent. Style headings to group content, reduce clutter, and make it easier to scan and understand. Create designs for different viewport sizes . Consider how page information is presented in different sized viewports, such as mobile phones or zoomed browser windows. Position and presentation of main elements, such as header and navigation can be changed to make best use of the space. Ensure that text size and line width are set to maximize readability and legibility. Include image and media alternatives in your design . Provide a place in your design for alternatives for images and media. For example, you might need: visible links to transcripts of audio, visible links to audio described versions of videos, text along with icons and graphical buttons, and / or captions and descriptions for tables or complex graphs. Work with content authors and developers to provide alternatives for non-text content. Provide controls for content that starts automatically . Provide visible controls to allow users to stop any animations or auto-playing sound. This applies to carousels, image sliders, background sound, and videos. Most government platforms are subject to the Revised Section 508 Standards and thus WCAG 2.0 Level AA Success Criteria. In addition to other requirements, this will most commonly affect a designer\u2019s text & background color (contrast) choices: Text (including images of text) have a contrast ratio of at least 4.5:1. For text and images of that is at least 24px and normal weight or 19px and bold, use a contrast ratio that is at least 3:1. Color contrast for graphics and interactive UI components must be at least 3:1 so that different parts can be distinguished. When providing custom states for elements (e.g. hover, active, focus), color contrast for those states should be at least 3:1. References W3.org Tips & Resources for Designers https://www.w3.org/WAI/tips/designing Web Content Accessibility Guidelines (WCAG) 2.0 https://www.w3.org/TR/WCAG20 US Web Design System https://www.usability.gov/what-and-why/accessibility.html https://designsystem.digital.gov/documentation/accessibility HHS Design Standards https://webstandards.hhs.gov/guidelines","title":"4.13 Accessibility"},{"location":"ux/4-13-accessibility/#413-accessibility","text":"","title":"4.13 Accessibility"},{"location":"ux/4-13-accessibility/#accessibility-considers-the-user-experience-for-all-users","text":"As excerpted from the WCAG Guidelines, \u201cAccessibility defines how to make Web content more accessible to people with disabilities. Accessibility involves a wide range of disabilities, including visual, auditory, physical, speech, cognitive, language, learning, and neurological disabilities.\u201d While this might not be a requirement of your particular application\u2019s users, accessibility standards often reflect the most stringent interpretation of contrast, legibility, and usability best practices \u2013 and thus are of use to all designers.","title":"Accessibility Considers the User Experience for All Users"},{"location":"ux/4-13-accessibility/#accessibility-tips-for-designers","text":"Accessible application design is a collaboration between designers and developers, affecting UI and code alike. In the interest of a useful shorthand for this playbook\u2019s primary users, this section focuses on best practices of visual design & accessibility (quoted heavily from the Web Accessibility Initiative): Provide sufficient contrast between foreground and background . Foreground text needs to have sufficient contrast with background colors. This includes text on images, background gradients, buttons, and other elements. Don\u2019t use color alone to convey information . While color can be useful to convey information, color should not be the only way information is conveyed. When using color to differentiate elements, also provide additional identification that does not rely on color perception. For example, use an asterisk in addition to color to indicate required form fields, and use labels to distinguish areas on graphs. Ensure that interactive elements are easy to identify . Provide distinct styles for interactive elements, such as links and buttons, to make them easy to identify. For example, change the appearance of links on mouse hover, keyboard focus, and touch-screen activation. Ensure that styles and naming for interactive elements are used consistently throughout the website. Provide clear and consistent navigation options . Ensure that navigation across pages within a website has consistent naming, styling, and positioning. Provide more than one method of website navigation, such as a site search or a site map. Help users understand where they are in a website or page by providing orientation cues, such as breadcrumbs and clear headings. Ensure that form elements include clearly associated labels . Ensure that all fields have a descriptive label adjacent to the field. For left-to-right languages, labels are usually positioned to the left or above the field, except for checkboxes and radio buttons where they are usually to the right. Avoid having too much space between labels and fields. Provide easily identifiable feedback . Provide feedback for interactions, such as confirming form submission, alerting the user when something goes wrong, or notifying the user of changes on the page. Instructions should be easy to identify. Important feedback that requires user action should be presented in a prominent style. Use headings and spacing to group related content . Use whitespace and proximity to make relationships between content more apparent. Style headings to group content, reduce clutter, and make it easier to scan and understand. Create designs for different viewport sizes . Consider how page information is presented in different sized viewports, such as mobile phones or zoomed browser windows. Position and presentation of main elements, such as header and navigation can be changed to make best use of the space. Ensure that text size and line width are set to maximize readability and legibility. Include image and media alternatives in your design . Provide a place in your design for alternatives for images and media. For example, you might need: visible links to transcripts of audio, visible links to audio described versions of videos, text along with icons and graphical buttons, and / or captions and descriptions for tables or complex graphs. Work with content authors and developers to provide alternatives for non-text content. Provide controls for content that starts automatically . Provide visible controls to allow users to stop any animations or auto-playing sound. This applies to carousels, image sliders, background sound, and videos. Most government platforms are subject to the Revised Section 508 Standards and thus WCAG 2.0 Level AA Success Criteria. In addition to other requirements, this will most commonly affect a designer\u2019s text & background color (contrast) choices: Text (including images of text) have a contrast ratio of at least 4.5:1. For text and images of that is at least 24px and normal weight or 19px and bold, use a contrast ratio that is at least 3:1. Color contrast for graphics and interactive UI components must be at least 3:1 so that different parts can be distinguished. When providing custom states for elements (e.g. hover, active, focus), color contrast for those states should be at least 3:1.","title":"Accessibility Tips for Designers"},{"location":"ux/4-13-accessibility/#references","text":"W3.org Tips & Resources for Designers https://www.w3.org/WAI/tips/designing Web Content Accessibility Guidelines (WCAG) 2.0 https://www.w3.org/TR/WCAG20 US Web Design System https://www.usability.gov/what-and-why/accessibility.html https://designsystem.digital.gov/documentation/accessibility HHS Design Standards https://webstandards.hhs.gov/guidelines","title":"References"},{"location":"ux/4-2-guidelines/","text":"4.2 General Interface Guidelines Designing the User Interface As the visualized part of the user experience, a thoughtfully designed user interface (UI) is critical to helping end users quickly and efficiently complete tasks. It\u2019s said that \u201cgood design is 99% invisible,\u201d and so should be your choices. When users notice clashing colors, illegible text, or misplaced buttons, they grow frustrated and worse. Design for the User Design is not a purely aesthetic task. Before placing a pixel, orient yourself with any UX and audience findings. You should be able to answer the following questions: What\u2019s your application\u2019s ultimate goal? What tasks do you want users to accomplish? Who is going to use your application? What do they want or need? What are the benchmarks for their success? On what devices will your application be used? In what context (remote, at a workstation, etc.) will they use it? Design for Interaction Digital platforms are not passive environments. While some principles of print design hold true, these pages, platforms, and applications have a fundamentally different relationship with the user. The user is expected to affect the application, to interact and communicate their intent. In return, the platform should be a conversation with the user. Guide the Eye . Users are drawn toward heavier elements of a page, and can wander if there are no distinctions in visual weight between elements. Critical components or calls-to-action should be larger and bolder. Less critical components \u2013 such as supplementary text \u2013 can be smaller and lower contrast. Also, eye tracking studies indicate that people generally scan pages in an F pattern (described in section 4.6), which is a useful starting point. Focus on Task Completion . A design should perform it\u2019s intended task and be beautiful, and is a failure if it\u2019s just beautiful. Each design decision should serve the function of the page, and evaluate decorative elements (like brand images) on their contribution to task completion. Design Light . Bandwidth and download speeds plague users in a need-it-now world. As a designer, you can increase their working speed by minimizing the file size of elements in your design. Text, solid colors, and default browser elements are \u201clight\u201d and can be used liberally. Images (and animations in particular) should only be used when necessary to serve the function of the page. Provide Proactive and Immediate Feedback . Obvious labels, content categorization, and color cues create a proactive shorthand for users. Button hover states and dynamic rollovers allow them to \u201cpeek behind the curtain\u201d and know better what comes after their click (see Buttons & Controls). Progressively Reveal . Only display \u2013 through truncated content and other components \u2013 what the user absolutely needs to know in order to make their next, informed choice. There is a good reason the web is so rife with \u201cLearn More\u201d buttons \u2013 this saves on both page weight and cognitive load. Differentiate Clicks/Taps, Hover, and Scroll . Every time the user interacts with the application, they tell us something about their intent. While a hover is exploratory, a click is committal. Scrolling down a page says \u201cI haven\u2019t found what I\u2019m looking for.\u201d Consider how your design choices respond to the nuanced behaviors of the user. Reference General Assembly\u2019s Guide to UI https://generalassemb.ly/design/visual-design/user-interfaces","title":"4.2 General Interface Guidelines"},{"location":"ux/4-2-guidelines/#42-general-interface-guidelines","text":"","title":"4.2 General Interface Guidelines"},{"location":"ux/4-2-guidelines/#designing-the-user-interface","text":"As the visualized part of the user experience, a thoughtfully designed user interface (UI) is critical to helping end users quickly and efficiently complete tasks. It\u2019s said that \u201cgood design is 99% invisible,\u201d and so should be your choices. When users notice clashing colors, illegible text, or misplaced buttons, they grow frustrated and worse.","title":"Designing the User Interface"},{"location":"ux/4-2-guidelines/#design-for-the-user","text":"Design is not a purely aesthetic task. Before placing a pixel, orient yourself with any UX and audience findings. You should be able to answer the following questions: What\u2019s your application\u2019s ultimate goal? What tasks do you want users to accomplish? Who is going to use your application? What do they want or need? What are the benchmarks for their success? On what devices will your application be used? In what context (remote, at a workstation, etc.) will they use it?","title":"Design for the User"},{"location":"ux/4-2-guidelines/#design-for-interaction","text":"Digital platforms are not passive environments. While some principles of print design hold true, these pages, platforms, and applications have a fundamentally different relationship with the user. The user is expected to affect the application, to interact and communicate their intent. In return, the platform should be a conversation with the user. Guide the Eye . Users are drawn toward heavier elements of a page, and can wander if there are no distinctions in visual weight between elements. Critical components or calls-to-action should be larger and bolder. Less critical components \u2013 such as supplementary text \u2013 can be smaller and lower contrast. Also, eye tracking studies indicate that people generally scan pages in an F pattern (described in section 4.6), which is a useful starting point. Focus on Task Completion . A design should perform it\u2019s intended task and be beautiful, and is a failure if it\u2019s just beautiful. Each design decision should serve the function of the page, and evaluate decorative elements (like brand images) on their contribution to task completion. Design Light . Bandwidth and download speeds plague users in a need-it-now world. As a designer, you can increase their working speed by minimizing the file size of elements in your design. Text, solid colors, and default browser elements are \u201clight\u201d and can be used liberally. Images (and animations in particular) should only be used when necessary to serve the function of the page. Provide Proactive and Immediate Feedback . Obvious labels, content categorization, and color cues create a proactive shorthand for users. Button hover states and dynamic rollovers allow them to \u201cpeek behind the curtain\u201d and know better what comes after their click (see Buttons & Controls). Progressively Reveal . Only display \u2013 through truncated content and other components \u2013 what the user absolutely needs to know in order to make their next, informed choice. There is a good reason the web is so rife with \u201cLearn More\u201d buttons \u2013 this saves on both page weight and cognitive load. Differentiate Clicks/Taps, Hover, and Scroll . Every time the user interacts with the application, they tell us something about their intent. While a hover is exploratory, a click is committal. Scrolling down a page says \u201cI haven\u2019t found what I\u2019m looking for.\u201d Consider how your design choices respond to the nuanced behaviors of the user.","title":"Design for Interaction"},{"location":"ux/4-2-guidelines/#reference","text":"General Assembly\u2019s Guide to UI https://generalassemb.ly/design/visual-design/user-interfaces","title":"Reference"},{"location":"ux/4-3-grids/","text":"4.3 Grids & Breakpoints About the Grid A grid is an organizing system of a layout, consisting of invisible rulers that align layout elements like copy, images, and navigation. Most often, a grid defines a series of equally sized columns with smaller, equally sized columns for padding (\u201cgutters\u201d) in between. The grid behaves differently depending upon the viewport, as defined by the device upon which the layout is viewed. The viewport is essentially the screen size of the device, measured in pixels, and is the amount of visual real estate available for your layout. A thoughtful grid is particularly helpful in responsive design. This type of design is a collaboration with front-end development, and programmatically scales down the layout to be most appropriate for the device / viewport in use. As the browser window shrinks horizontally, the point at which a grid \u201cbreaks\u201d to a fewer-column grid is called the breakpoint. Defining Pixels As device display technology improves, the density of pixels has grown to differ across devices. Names like HD and 4k indicate different numbers of pixels per inch \u2013 all in pursuit of a crisper image. To retain predictability and consistency, designers and developers rely on CSS pixels , which provide a standard definition of pixel size for the web that does not vary based on the device\u2019s pixel density. It is highly recommended that designers work with their front-end developers to define target devices and pixel densities, and use resources that track changing display technology (like https://vizdevices.yesviz.com/ ). Small Viewport The Small Viewport grid is intended to accommodate portrait-view smartphones (approx. 320 px) and many landscape view smartphones. On these devices, the 8-column grid switches to a 4-column structure to create a more comfortable layout on a handheld, as well as to allow for larger tap-targets. This format equates to a maximum width of 767 px , with a minimum width of 320 px . Medium Viewport The Medium Viewport grid is intended to accommodate most portrait-view tablets (768 px), most landscape view phablets (768 px), and larger landscape view smart phones. On these devices, the 12-column grid switches to an 8-column structure to create a more comfortable layout on tablets, as well as to allow for larger tap-targets. This format equates to a maximum width of 1023 px , with a minimum width of 768 px . Large Viewport The Large Viewport grid is intended to accommodate high-resolution monitors, most landscape-view tablets (1042 px), and everything in between. This equates to a maximum width that is infinite , and a minimum width of 1024 px . Responsive Component Reordering As responsive layouts break to smaller viewports, page elements \u2013 components \u2013 should logically reorder and stack vertically to maintain the intent of the layout. This diagram illustrates one solution for component reorganization with respect to responsive layouts. Each component is designed to occupy a minimum of 2 columns and maximum of 6. The Medium Viewport layout includes a potential for additional white space to appear, in the event that a design contains a 3-component row. Being that the use-case is relatively obscure (with respect to hardware, UI, content, and user needs), the choice was made to include the layout as described, thus avoiding either bespoke solutions or arbitrary hierarchical relationships. As a takeaway, design with a minimum of 4 columns / 1 component width for the smallest viewport, and otherwise subdivide the total number of grid columns evenly to create a consistent layout on table and desktop. Reference Interaction Design Foundation https://www.interaction-design.org/literature/article/responsive-design-let-the-device-do-the-work","title":"4.3 Grids & Breakpoints"},{"location":"ux/4-3-grids/#43-grids-breakpoints","text":"","title":"4.3 Grids &amp; Breakpoints"},{"location":"ux/4-3-grids/#about-the-grid","text":"A grid is an organizing system of a layout, consisting of invisible rulers that align layout elements like copy, images, and navigation. Most often, a grid defines a series of equally sized columns with smaller, equally sized columns for padding (\u201cgutters\u201d) in between. The grid behaves differently depending upon the viewport, as defined by the device upon which the layout is viewed. The viewport is essentially the screen size of the device, measured in pixels, and is the amount of visual real estate available for your layout. A thoughtful grid is particularly helpful in responsive design. This type of design is a collaboration with front-end development, and programmatically scales down the layout to be most appropriate for the device / viewport in use. As the browser window shrinks horizontally, the point at which a grid \u201cbreaks\u201d to a fewer-column grid is called the breakpoint.","title":"About the Grid"},{"location":"ux/4-3-grids/#defining-pixels","text":"As device display technology improves, the density of pixels has grown to differ across devices. Names like HD and 4k indicate different numbers of pixels per inch \u2013 all in pursuit of a crisper image. To retain predictability and consistency, designers and developers rely on CSS pixels , which provide a standard definition of pixel size for the web that does not vary based on the device\u2019s pixel density. It is highly recommended that designers work with their front-end developers to define target devices and pixel densities, and use resources that track changing display technology (like https://vizdevices.yesviz.com/ ).","title":"Defining Pixels"},{"location":"ux/4-3-grids/#small-viewport","text":"The Small Viewport grid is intended to accommodate portrait-view smartphones (approx. 320 px) and many landscape view smartphones. On these devices, the 8-column grid switches to a 4-column structure to create a more comfortable layout on a handheld, as well as to allow for larger tap-targets. This format equates to a maximum width of 767 px , with a minimum width of 320 px .","title":"Small Viewport"},{"location":"ux/4-3-grids/#medium-viewport","text":"The Medium Viewport grid is intended to accommodate most portrait-view tablets (768 px), most landscape view phablets (768 px), and larger landscape view smart phones. On these devices, the 12-column grid switches to an 8-column structure to create a more comfortable layout on tablets, as well as to allow for larger tap-targets. This format equates to a maximum width of 1023 px , with a minimum width of 768 px .","title":"Medium Viewport"},{"location":"ux/4-3-grids/#large-viewport","text":"The Large Viewport grid is intended to accommodate high-resolution monitors, most landscape-view tablets (1042 px), and everything in between. This equates to a maximum width that is infinite , and a minimum width of 1024 px .","title":"Large Viewport"},{"location":"ux/4-3-grids/#responsive-component-reordering","text":"As responsive layouts break to smaller viewports, page elements \u2013 components \u2013 should logically reorder and stack vertically to maintain the intent of the layout. This diagram illustrates one solution for component reorganization with respect to responsive layouts. Each component is designed to occupy a minimum of 2 columns and maximum of 6. The Medium Viewport layout includes a potential for additional white space to appear, in the event that a design contains a 3-component row. Being that the use-case is relatively obscure (with respect to hardware, UI, content, and user needs), the choice was made to include the layout as described, thus avoiding either bespoke solutions or arbitrary hierarchical relationships. As a takeaway, design with a minimum of 4 columns / 1 component width for the smallest viewport, and otherwise subdivide the total number of grid columns evenly to create a consistent layout on table and desktop.","title":"Responsive Component Reordering"},{"location":"ux/4-3-grids/#reference","text":"Interaction Design Foundation https://www.interaction-design.org/literature/article/responsive-design-let-the-device-do-the-work","title":"Reference"},{"location":"ux/4-4-branding/","text":"4.4 Branding/Logo Our Identification The Air Force Symbol is the official symbol of the United States Air Force. It honors the heritage of our past and represents the promise of our future. Furthermore, it retains the core elements of our Air Corps heritage, the \"Arnold\" wings and star with circle, and modernizes them to reflect our air and space force of today and tomorrow. The USAF symbol was thoughtfully crafted to represent the Air Force\u2019s history as well as the promise of the future of the armed forces branch. The symbol can take on two different forms depending on how you choose to see it: a medal of valor in service or our nation\u2019s emblem of freedom, an eagle. Some Rules Around the USAF Signature A 15% stand-off space around the Symbol and/or signature is required. The stand-off space takes the shape of a square, not the outline of the Symbol. The U.S. Air Force signature consists of the Air Force Symbol and the logotype (U.S. Air Force) The Symbol can be used with or without the logotype If used with the logotype, the two elements are in a fixed relationship and cannot be altered. The only alternate words permitted \u201cdirectly\u201d under the Symbol are those approved by the Chief of Staff of the Air Force (see Formats) Logo Application The spacing and positioning for the logomark has been carefully considered and optimized to create an ideal optical balance. Because the shape is comprised of sharp, angular points, in tandem with the illusion of a 3-dimensional shape, a sense of symmetry is achieved through subtle repositioning of the mathematical center. Tips on usage White logo on photographic/textural background White or color logo on solid color background Avoid using USAF color logo on full-color photographic image background Spacing The spacing and positioning for the logomark has been carefully considered and optimized to create an ideal optical balance. Because the shape is comprised of sharp, angular points, in tandem with the illusion of a 3-dimensional shape, a sense of symmetry is achieved through subtle repositioning of the mathematical center. Sizing The shape of the mark should maintain its integrity at relatively small sizes. Designers should use discretion and consider the output-media when utilizing the mark at a smaller size. References The Official Website of the Air Force Trademark and Licensing Program https://www.trademark.af.mil/About-Us/The-Air-Force-Symbol/Display-guidelines Meaning behind the mark https://www.airman.af.mil/Portals/17/002%20All%20Products/003%20PACEsetters/Meaning_Air_Force_Symbol.pdf?ver=2016-03-30-001043-347","title":"4.4 Branding/Logo"},{"location":"ux/4-4-branding/#44-brandinglogo","text":"","title":"4.4 Branding/Logo"},{"location":"ux/4-4-branding/#our-identification","text":"The Air Force Symbol is the official symbol of the United States Air Force. It honors the heritage of our past and represents the promise of our future. Furthermore, it retains the core elements of our Air Corps heritage, the \"Arnold\" wings and star with circle, and modernizes them to reflect our air and space force of today and tomorrow. The USAF symbol was thoughtfully crafted to represent the Air Force\u2019s history as well as the promise of the future of the armed forces branch. The symbol can take on two different forms depending on how you choose to see it: a medal of valor in service or our nation\u2019s emblem of freedom, an eagle.","title":"Our Identification"},{"location":"ux/4-4-branding/#some-rules-around-the-usaf-signature","text":"A 15% stand-off space around the Symbol and/or signature is required. The stand-off space takes the shape of a square, not the outline of the Symbol. The U.S. Air Force signature consists of the Air Force Symbol and the logotype (U.S. Air Force) The Symbol can be used with or without the logotype If used with the logotype, the two elements are in a fixed relationship and cannot be altered. The only alternate words permitted \u201cdirectly\u201d under the Symbol are those approved by the Chief of Staff of the Air Force (see Formats)","title":"Some Rules Around the USAF Signature"},{"location":"ux/4-4-branding/#logo-application","text":"The spacing and positioning for the logomark has been carefully considered and optimized to create an ideal optical balance. Because the shape is comprised of sharp, angular points, in tandem with the illusion of a 3-dimensional shape, a sense of symmetry is achieved through subtle repositioning of the mathematical center.","title":"Logo Application"},{"location":"ux/4-4-branding/#tips-on-usage","text":"White logo on photographic/textural background White or color logo on solid color background Avoid using USAF color logo on full-color photographic image background","title":"Tips on usage"},{"location":"ux/4-4-branding/#spacing","text":"The spacing and positioning for the logomark has been carefully considered and optimized to create an ideal optical balance. Because the shape is comprised of sharp, angular points, in tandem with the illusion of a 3-dimensional shape, a sense of symmetry is achieved through subtle repositioning of the mathematical center.","title":"Spacing"},{"location":"ux/4-4-branding/#sizing","text":"The shape of the mark should maintain its integrity at relatively small sizes. Designers should use discretion and consider the output-media when utilizing the mark at a smaller size.","title":"Sizing"},{"location":"ux/4-4-branding/#references","text":"The Official Website of the Air Force Trademark and Licensing Program https://www.trademark.af.mil/About-Us/The-Air-Force-Symbol/Display-guidelines Meaning behind the mark https://www.airman.af.mil/Portals/17/002%20All%20Products/003%20PACEsetters/Meaning_Air_Force_Symbol.pdf?ver=2016-03-30-001043-347","title":"References"},{"location":"ux/4-5-headers/","text":"4.5 Global Headers & Footers Headers & Footers In a web page layout, the header is the upper (topmost) part of the page, immediately beneath the browser chrome (where the URL, search field, and bookmarks are located). The footer is the lower (bottommost) part of the page, where scrolling terminates. Most mobile devices remove the chrome from the browser in order to allow more space for the header and footer elements. Headers Headers can include a variety of meaningful elements: Basic elements of brand identity: logo, brand / application name, tagline or brand statement, application colors, corporate colors, etc. Navigation to primary site or application sections Language-switching functionality (if applicable) Search field Not all of the mentioned elements should be included in one web page header: in this case, the risk is high that the header section would be overloaded with information. The more objects that attract a user\u2019s attention, the harder it is to concentrate on the vital ones. As with all design decisions, apply UX best practices to focus on user orientation (\u201cwhere am I and what does this do?\u201d) and task completion (\u201chow do I do it?\u201d). Desktop Navigation Search is Intertwined with Navigation Search is a form of navigation. In many situations, the reader will use a combination of the \u201ccontent gatherers\u201d. They will use search to bring them to the subject area or product type they are interested in. Then the navigation should kick in, giving them the context for their search. Footers The footer is the lower (bottommost) part of the page, where scrolling terminates. Footers can support wide varieties and large volumes of content, and often contain universal content (contact details and forms), expanded navigation options, and links outside of the given site or application. Contemporary users have demonstrated comfort scrolling long pages and engaging with large page footers, provided both follow layout best practices. It is reasonable to use the page footer as a repository for all content that is both deprioritized but should also be universally accessible. Visual Hierarchy Given that the footer is often more visually dense than other page components, a visual hierarchy is critical. Adequate spacing helps improve both focus and legibility. Thoughtful typography helps improve scanning and the overall layout. Consider \u201creversing\u201d the colors of the main page in the page\u2019s footer in order to communicate that they\u2019ve reached the end of the page. That is, if the body of the page is on a light background, put the footer on a dark background. Given that this is a common technique, note that \u201creversing\u201d the colors of a component in the page body can sometimes create a \u201cfalse bottom,\u201d causing users to believe they\u2019ve hit the footer, and possibly miss the rest of the page. Anchoring Both headers and footers can \u201canchor\u201d to the top or bottom of the page (though rarely should both page elements should behave this way simultaneously). An anchored \u2013 or \u201csticky\u201d \u2013 element stays on screen as the user scrolls, no matter the scroll depth. This is particularly useful for bringing persistent information or interaction along with the user, such as a form submission, call to action, or mode toggle (edit / review). References U.S. Web Design System https://designsystem.digital.gov/page-templates/#documentation-page UX Planet uxplanet.org","title":"4.5 Global Headers & Footers"},{"location":"ux/4-5-headers/#45-global-headers-footers","text":"","title":"4.5 Global Headers &amp; Footers"},{"location":"ux/4-5-headers/#headers-footers","text":"In a web page layout, the header is the upper (topmost) part of the page, immediately beneath the browser chrome (where the URL, search field, and bookmarks are located). The footer is the lower (bottommost) part of the page, where scrolling terminates. Most mobile devices remove the chrome from the browser in order to allow more space for the header and footer elements.","title":"Headers &amp; Footers"},{"location":"ux/4-5-headers/#headers","text":"Headers can include a variety of meaningful elements: Basic elements of brand identity: logo, brand / application name, tagline or brand statement, application colors, corporate colors, etc. Navigation to primary site or application sections Language-switching functionality (if applicable) Search field Not all of the mentioned elements should be included in one web page header: in this case, the risk is high that the header section would be overloaded with information. The more objects that attract a user\u2019s attention, the harder it is to concentrate on the vital ones. As with all design decisions, apply UX best practices to focus on user orientation (\u201cwhere am I and what does this do?\u201d) and task completion (\u201chow do I do it?\u201d).","title":"Headers"},{"location":"ux/4-5-headers/#desktop-navigation","text":"","title":"Desktop Navigation"},{"location":"ux/4-5-headers/#search-is-intertwined-with-navigation","text":"Search is a form of navigation. In many situations, the reader will use a combination of the \u201ccontent gatherers\u201d. They will use search to bring them to the subject area or product type they are interested in. Then the navigation should kick in, giving them the context for their search.","title":"Search is Intertwined with Navigation"},{"location":"ux/4-5-headers/#footers","text":"The footer is the lower (bottommost) part of the page, where scrolling terminates. Footers can support wide varieties and large volumes of content, and often contain universal content (contact details and forms), expanded navigation options, and links outside of the given site or application. Contemporary users have demonstrated comfort scrolling long pages and engaging with large page footers, provided both follow layout best practices. It is reasonable to use the page footer as a repository for all content that is both deprioritized but should also be universally accessible.","title":"Footers"},{"location":"ux/4-5-headers/#visual-hierarchy","text":"Given that the footer is often more visually dense than other page components, a visual hierarchy is critical. Adequate spacing helps improve both focus and legibility. Thoughtful typography helps improve scanning and the overall layout. Consider \u201creversing\u201d the colors of the main page in the page\u2019s footer in order to communicate that they\u2019ve reached the end of the page. That is, if the body of the page is on a light background, put the footer on a dark background. Given that this is a common technique, note that \u201creversing\u201d the colors of a component in the page body can sometimes create a \u201cfalse bottom,\u201d causing users to believe they\u2019ve hit the footer, and possibly miss the rest of the page.","title":"Visual Hierarchy"},{"location":"ux/4-5-headers/#anchoring","text":"Both headers and footers can \u201canchor\u201d to the top or bottom of the page (though rarely should both page elements should behave this way simultaneously). An anchored \u2013 or \u201csticky\u201d \u2013 element stays on screen as the user scrolls, no matter the scroll depth. This is particularly useful for bringing persistent information or interaction along with the user, such as a form submission, call to action, or mode toggle (edit / review).","title":"Anchoring"},{"location":"ux/4-5-headers/#references","text":"U.S. Web Design System https://designsystem.digital.gov/page-templates/#documentation-page UX Planet uxplanet.org","title":"References"},{"location":"ux/4-6-layouts/","text":"4.6 Page Layouts Layouts Generally speaking, the layout of a page should prioritize content importance from top to bottom, providing orientation (wayfinding and labels) to components throughout. Layouts should also follow the natural flow of task completion; users completing a number of form fields on a long vertical page might encounter the \u201csubmit\u201d button \u2013 the primary call-to-action \u2013 beneath the original viewport and offscreen. This is permissible because the form fields are the prerequisite for completing the task of the page, and should thus be prioritized in the visual hierarchy. F Pattern Studies have found that, in cultures that read from left to right, most people scan screens in an \u201cF\u201d pattern, with preference given to elements that are positioned at the top and left of the screen. Consider placing the most important elements at the top and left of your layout. The upper right of the page is considered secondary in importance due to its positioning at the top of the page, but the importance of the right side rapidly diminishes as you move further down the page. Other layout patterns support different densities of content and types of tasks to complete. They all acknowledge the way the user scans the page, tending to favor the top and left. References NN/g Nielsen Norma Group : Pattern of Reading https://www.nngroup.com/articles/f-shaped-pattern-reading-web-content/ Vanseo Design : Design Layouts : Gutenberg Diagram, Z-OPattern and F-Pattern http://vanseodesign.com/web-design/3-design-layouts U.S. Web Design System https://designsystem.digital.gov","title":"4.6 Page Layouts"},{"location":"ux/4-6-layouts/#46-page-layouts","text":"","title":"4.6 Page Layouts"},{"location":"ux/4-6-layouts/#layouts","text":"Generally speaking, the layout of a page should prioritize content importance from top to bottom, providing orientation (wayfinding and labels) to components throughout. Layouts should also follow the natural flow of task completion; users completing a number of form fields on a long vertical page might encounter the \u201csubmit\u201d button \u2013 the primary call-to-action \u2013 beneath the original viewport and offscreen. This is permissible because the form fields are the prerequisite for completing the task of the page, and should thus be prioritized in the visual hierarchy.","title":"Layouts"},{"location":"ux/4-6-layouts/#f-pattern","text":"Studies have found that, in cultures that read from left to right, most people scan screens in an \u201cF\u201d pattern, with preference given to elements that are positioned at the top and left of the screen. Consider placing the most important elements at the top and left of your layout. The upper right of the page is considered secondary in importance due to its positioning at the top of the page, but the importance of the right side rapidly diminishes as you move further down the page. Other layout patterns support different densities of content and types of tasks to complete. They all acknowledge the way the user scans the page, tending to favor the top and left.","title":"F Pattern"},{"location":"ux/4-6-layouts/#references","text":"NN/g Nielsen Norma Group : Pattern of Reading https://www.nngroup.com/articles/f-shaped-pattern-reading-web-content/ Vanseo Design : Design Layouts : Gutenberg Diagram, Z-OPattern and F-Pattern http://vanseodesign.com/web-design/3-design-layouts U.S. Web Design System https://designsystem.digital.gov","title":"References"},{"location":"ux/4-7-typography/","text":"4.7 Typography Reinforcing the Goals of Typography More than 95% of information on the web is in the form of written language. If typography is done well, it goes unnoticed. If it\u2019s not, it sticks out like a sore thumb and moreover disrupts the user experience. Typography holds an important place in any form of design that features text, and this is especially true for web and application design. Three Fundamental Aspects of Typography Although in a non-technical sense \u201clegible\u201d and \u201creadable\u201d are often used synonymously, typographically they are separate but related concepts. Legibility is the ease with which a reader can recognize individual characters in text. Readability is the ease with which a reader can recognize words, sentences, and paragraphs comprised of characters. Aesthetics is the emotional property of the text, communicating everything from precision to speed to humor. Typography as an art is nuanced; our primary concern is functional \u2013 the fluid communication of information by the written word. As such, we focus on core concepts for achieving legibility, readability, and context-appropriate aesthetics. Font Type Of the many font categorizations, the two largest (and most common categories) are \u201cserif\u201d and \u201csans-serif\u201d fonts (literally translating to \u201cfeet\u201d and \u201cwithout feet\u201d). The \u201cfeet\u201d to which they refer are the small visual elements that branch out at the end of a stroke. Due to their clean-line, technical appearance, sans-serif fonts are often considered a more modern aesthetic. They are appropriate for both headline and body copy; when used as headlines they often pair well with serif body copy. Due to their origins in mechanical letterpress, serif fonts are often considered a more timeless aesthetic. Studies have shown larger blocks of copy to be more readable when printed in serif type, which is why most books and long-form copy employ serif fonts to this day. Font Size Font size is another major determinant of text readability. A font size of about 16px is optimal for easy online reading of long-form content. To support overall visual hierarchy, consider using three or fewer different font sizes in any given component, Rules on minimum font size can be found on the Accessibility section. Contrast Color contrast ultimately determines whether or not text is readable. Black text on a white background, for example, is very high contrast, but for optimum readability, place very dark grey text on a white background; it will maximize contrast while lowering eye strain. The rules of contrast are outlined specifically in the Web Content Accessibility Guidelines (WCAG) 2.0, addressed elsewhere in this playbook. Depending upon accessibility requirements for the visually impaired, contrast compliance may need to be more or less strictly followed. Hierarchy Text hierarchy becomes especially important in web and application design because it helps users navigate through a site quickly and scan text easily. If all type was the same size and weight, it would be difficult to know which was the most important information on the page. In order to orient the user to critical layout components, headings are usually the most dominant, sub-headings less so, and body type even less so. This hierarchy is accomplished through a combination of font size (px), contrast (color), and weight (thin, bold). Line Height Line height, or leading, refers to the space between lines in a body of text. A general rule for readable text is that your leading value should be 125\u2013150% of the font size. Frustratingly, the \u201csingle spacing\u201d default is typically too tight for text on a web page while \u201cdouble spacing\u201d can be so loose that the text no longer looks as though it is part of one unit. Consider adjusting your line height to satisfy this 125\u2013150% rule. Line Length Line length defines the number of characters in a single line of text, until the reader returns to the beginning of the following line. In large viewports, long lines of body text can be cumbersome to consume. A best practice for body text is a single line character length of 50-60 characters, beyond which diminishes the readability of text. White Space Your layout\u2019s \u201cwhite space\u201d \u2013 visual areas unoccupied by text or images \u2013 is essential for offsetting large amounts of text, and providing focus and orientation for users. It should offer separation between different elements of the text layout, such as text and images, and body text and headers. References Tubik Blog https://tubikstudio.com/20-wise-thoughts-by-typography-master-erik-spiekermann Smashing Design https://www.smashingmagazine.com/2011/01/guidelines-for-responsive-web-design","title":"4.7 Typography"},{"location":"ux/4-7-typography/#47-typography","text":"","title":"4.7 Typography"},{"location":"ux/4-7-typography/#reinforcing-the-goals-of-typography","text":"More than 95% of information on the web is in the form of written language. If typography is done well, it goes unnoticed. If it\u2019s not, it sticks out like a sore thumb and moreover disrupts the user experience. Typography holds an important place in any form of design that features text, and this is especially true for web and application design.","title":"Reinforcing the Goals of Typography"},{"location":"ux/4-7-typography/#three-fundamental-aspects-of-typography","text":"Although in a non-technical sense \u201clegible\u201d and \u201creadable\u201d are often used synonymously, typographically they are separate but related concepts. Legibility is the ease with which a reader can recognize individual characters in text. Readability is the ease with which a reader can recognize words, sentences, and paragraphs comprised of characters. Aesthetics is the emotional property of the text, communicating everything from precision to speed to humor. Typography as an art is nuanced; our primary concern is functional \u2013 the fluid communication of information by the written word. As such, we focus on core concepts for achieving legibility, readability, and context-appropriate aesthetics.","title":"Three Fundamental Aspects of Typography"},{"location":"ux/4-7-typography/#font-type","text":"Of the many font categorizations, the two largest (and most common categories) are \u201cserif\u201d and \u201csans-serif\u201d fonts (literally translating to \u201cfeet\u201d and \u201cwithout feet\u201d). The \u201cfeet\u201d to which they refer are the small visual elements that branch out at the end of a stroke. Due to their clean-line, technical appearance, sans-serif fonts are often considered a more modern aesthetic. They are appropriate for both headline and body copy; when used as headlines they often pair well with serif body copy. Due to their origins in mechanical letterpress, serif fonts are often considered a more timeless aesthetic. Studies have shown larger blocks of copy to be more readable when printed in serif type, which is why most books and long-form copy employ serif fonts to this day.","title":"Font Type"},{"location":"ux/4-7-typography/#font-size","text":"Font size is another major determinant of text readability. A font size of about 16px is optimal for easy online reading of long-form content. To support overall visual hierarchy, consider using three or fewer different font sizes in any given component, Rules on minimum font size can be found on the Accessibility section.","title":"Font Size"},{"location":"ux/4-7-typography/#contrast","text":"Color contrast ultimately determines whether or not text is readable. Black text on a white background, for example, is very high contrast, but for optimum readability, place very dark grey text on a white background; it will maximize contrast while lowering eye strain. The rules of contrast are outlined specifically in the Web Content Accessibility Guidelines (WCAG) 2.0, addressed elsewhere in this playbook. Depending upon accessibility requirements for the visually impaired, contrast compliance may need to be more or less strictly followed.","title":"Contrast"},{"location":"ux/4-7-typography/#hierarchy","text":"Text hierarchy becomes especially important in web and application design because it helps users navigate through a site quickly and scan text easily. If all type was the same size and weight, it would be difficult to know which was the most important information on the page. In order to orient the user to critical layout components, headings are usually the most dominant, sub-headings less so, and body type even less so. This hierarchy is accomplished through a combination of font size (px), contrast (color), and weight (thin, bold).","title":"Hierarchy"},{"location":"ux/4-7-typography/#line-height","text":"Line height, or leading, refers to the space between lines in a body of text. A general rule for readable text is that your leading value should be 125\u2013150% of the font size. Frustratingly, the \u201csingle spacing\u201d default is typically too tight for text on a web page while \u201cdouble spacing\u201d can be so loose that the text no longer looks as though it is part of one unit. Consider adjusting your line height to satisfy this 125\u2013150% rule.","title":"Line Height"},{"location":"ux/4-7-typography/#line-length","text":"Line length defines the number of characters in a single line of text, until the reader returns to the beginning of the following line. In large viewports, long lines of body text can be cumbersome to consume. A best practice for body text is a single line character length of 50-60 characters, beyond which diminishes the readability of text.","title":"Line Length"},{"location":"ux/4-7-typography/#white-space","text":"Your layout\u2019s \u201cwhite space\u201d \u2013 visual areas unoccupied by text or images \u2013 is essential for offsetting large amounts of text, and providing focus and orientation for users. It should offer separation between different elements of the text layout, such as text and images, and body text and headers.","title":"White Space"},{"location":"ux/4-7-typography/#references","text":"Tubik Blog https://tubikstudio.com/20-wise-thoughts-by-typography-master-erik-spiekermann Smashing Design https://www.smashingmagazine.com/2011/01/guidelines-for-responsive-web-design","title":"References"},{"location":"ux/4-8-color/","text":"4.8 Color About Colors Color theory hypothesizes that humans react to color in visceral ways. The heat we feel from reds, the chill from blues \u2013 these reactions to color are ingrained in us. It gives color the power to spark emotions and be a sort of shorthand for categorical types. When leveraging the tool of color, remember that not everyone sees the colors the way you do and usability trumps beauty. Colors Color is one of the visual designer\u2019s most powerful tools, reinforcing both the brand and user experience. In addition to supporting brand recognition, color is particularly useful for: Creating contrast Grouping elements Encoding additional meaning Communicating interactivity Primary Colors The primary palette should be applied in marketing communications and application design. The darker palette lends sophistication and polish has been designed to give a bold and exciting direction to the brand. Percentage tints can be used in any of these colors. Secondary Colors The secondary palette extends the original colors to support new contexts, such as color-coded categorization, complex data visualization, and interactive color cues. Colors for Accessibility WCAG (Web Content Accessibility Guidelines) ensure that content is accessible by everyone, regardless of disability or user device. To meet the highest standards, text and interactive elements should have a color contrast ratio of at least 4.5:1. The contrast ratio is the comparison of luminance between two adjacent colors, one darker and one lighter. An appropriate ensures that viewers who cannot see the full color spectrum are able to read the text. The options below offer color palette combinations that fall within the range of Section 508 compliant foreground/background color contrast ratios. To ensure that text remains readable and accessible, use only these permitted color combinations. If you choose to customize beyond this palette, https://webaim.org/resources/contrastchecker/ is a useful resource for testing the compliance of any color combination. Colors should be used to denote the type of component or content being displayed. Large blocks of passive, read-only text should be colored to achieve maximum readability, whereas interactive links within that text should be colored with a more eye-catching \u201ccall-to-action\" (CTA) standard. Reds and greens should be used sparingly, as they are often reserved for \u201calert colors,\u201d or stylized system notifications (for when a form field is filled incorrectly, for instance). A color that indicates a disabled state could be the same as one that indicates active, but applied at 50% opacity. While your particular USAF application may adhere to its own style guide, all color palettes should comply with the USAF brand and digital best practices. As a matter of example, the following color palettes have been designed and optimized specifically for USAF experiences. Careful consideration has been made with regards to content, data, accessibility, mobile form factors, and eye fatigue. In addition, hues have been strategically chosen to either compliment or reinforce the existing USAF parent brand palettes. In this way, the following schemes should be seen as an extension of the USAF brand, with additions and minor modifications included to create an optimal digital experience. First consult your application\u2019s style guide, should one exist. References From AF Branding & Trademark Licensing https://www.trademark.af.mil/About-Us/The-Air-Force-Symbol/Display-guidelines From CCE https://company-123432.frontify.com/d/YQiReCF6Sab5/usaf-cce-style-guide#/brand-design/colors","title":"4.8 Color"},{"location":"ux/4-8-color/#48-color","text":"","title":"4.8 Color"},{"location":"ux/4-8-color/#about-colors","text":"Color theory hypothesizes that humans react to color in visceral ways. The heat we feel from reds, the chill from blues \u2013 these reactions to color are ingrained in us. It gives color the power to spark emotions and be a sort of shorthand for categorical types. When leveraging the tool of color, remember that not everyone sees the colors the way you do and usability trumps beauty.","title":"About Colors"},{"location":"ux/4-8-color/#colors","text":"Color is one of the visual designer\u2019s most powerful tools, reinforcing both the brand and user experience. In addition to supporting brand recognition, color is particularly useful for: Creating contrast Grouping elements Encoding additional meaning Communicating interactivity","title":"Colors"},{"location":"ux/4-8-color/#primary-colors","text":"The primary palette should be applied in marketing communications and application design. The darker palette lends sophistication and polish has been designed to give a bold and exciting direction to the brand. Percentage tints can be used in any of these colors.","title":"Primary Colors"},{"location":"ux/4-8-color/#secondary-colors","text":"The secondary palette extends the original colors to support new contexts, such as color-coded categorization, complex data visualization, and interactive color cues.","title":"Secondary Colors"},{"location":"ux/4-8-color/#colors-for-accessibility","text":"WCAG (Web Content Accessibility Guidelines) ensure that content is accessible by everyone, regardless of disability or user device. To meet the highest standards, text and interactive elements should have a color contrast ratio of at least 4.5:1. The contrast ratio is the comparison of luminance between two adjacent colors, one darker and one lighter. An appropriate ensures that viewers who cannot see the full color spectrum are able to read the text. The options below offer color palette combinations that fall within the range of Section 508 compliant foreground/background color contrast ratios. To ensure that text remains readable and accessible, use only these permitted color combinations. If you choose to customize beyond this palette, https://webaim.org/resources/contrastchecker/ is a useful resource for testing the compliance of any color combination. Colors should be used to denote the type of component or content being displayed. Large blocks of passive, read-only text should be colored to achieve maximum readability, whereas interactive links within that text should be colored with a more eye-catching \u201ccall-to-action\" (CTA) standard. Reds and greens should be used sparingly, as they are often reserved for \u201calert colors,\u201d or stylized system notifications (for when a form field is filled incorrectly, for instance). A color that indicates a disabled state could be the same as one that indicates active, but applied at 50% opacity. While your particular USAF application may adhere to its own style guide, all color palettes should comply with the USAF brand and digital best practices. As a matter of example, the following color palettes have been designed and optimized specifically for USAF experiences. Careful consideration has been made with regards to content, data, accessibility, mobile form factors, and eye fatigue. In addition, hues have been strategically chosen to either compliment or reinforce the existing USAF parent brand palettes. In this way, the following schemes should be seen as an extension of the USAF brand, with additions and minor modifications included to create an optimal digital experience. First consult your application\u2019s style guide, should one exist.","title":"Colors for Accessibility"},{"location":"ux/4-8-color/#references","text":"From AF Branding & Trademark Licensing https://www.trademark.af.mil/About-Us/The-Air-Force-Symbol/Display-guidelines From CCE https://company-123432.frontify.com/d/YQiReCF6Sab5/usaf-cce-style-guide#/brand-design/colors","title":"References"},{"location":"ux/4-9-icons/","text":"4.9 Iconography Icons An icon\u2019s first job is orientation. Icons are an essential part of many user interfaces, visually expressing objects, actions and ideas. When done correctly, they communicate the core idea and intent of an element or action, save screen real estate, and enhance aesthetic appeal. Best Practices Icons are highly context-specific, but general best practices include: Use a platform or system standard icon should one exist; rarely should an application design require you to create a new icon Pull your icons from a single icon family / library to simplify the overall composition; these families will have similar line weights, levels of fidelity, repeating elements, etc. Employ icon fonts or open-source font families when possible , use .SVG (scalable vector graphics) when possible for optimal versatility and filesize If you must design custom icons and they can\u2019t be vector / SVG, design first in the largest viewport (desktop), giving your icon the appropriate level of detail. Subsequently, scale down for smaller viewports and remove details in order to keep icons scannable and understandable. Keep icons simple and schematic. Focusing on the basic characteristics of the object. Test them with neutral users for usability, recognizability, and memorability. Icons and Button Labels Icons accompanied by labels make information easier to find and scan, as long as they\u2019re placed in the right spot. Place icons according to the natural reading order. There are two important factors in an icon\u2019s location: In order for icons to serve as a visual scanning aid, users need to see them before they see the accompanying label. Place icons to the left of their labels so that users see them first. Align the icon with the label\u2019s heading, instead of centering it with the heading and body. Seeing the icon first will help users to scan the page more easily. Icons in Data Tables Icons to the left of a number usually indicate the intent of the data, whereas icons to the right usually indicate the quality of the data. As with icons with button labels, the placement of icons should follow the natural reading order. There are two possibilities for icon placement: Status icons would appear at the end of the line. As seen in the example below, the user will see the subject first, then the value associated with the subject and, finally, the status of the value. If the icons themselves are the subject, then they would appear at the start of the line, and everything else would follow thereafter. References Smashing Magazine; perspectives on icons https://www.smashingmagazine.com/2016/10/icons-as-part-of-a-great-user-experience The Noun Project; a comprehensive source of free and attributed icons https://thenounproject.com","title":"4.9 Iconography"},{"location":"ux/4-9-icons/#49-iconography","text":"","title":"4.9 Iconography"},{"location":"ux/4-9-icons/#icons","text":"An icon\u2019s first job is orientation. Icons are an essential part of many user interfaces, visually expressing objects, actions and ideas. When done correctly, they communicate the core idea and intent of an element or action, save screen real estate, and enhance aesthetic appeal.","title":"Icons"},{"location":"ux/4-9-icons/#best-practices","text":"Icons are highly context-specific, but general best practices include: Use a platform or system standard icon should one exist; rarely should an application design require you to create a new icon Pull your icons from a single icon family / library to simplify the overall composition; these families will have similar line weights, levels of fidelity, repeating elements, etc. Employ icon fonts or open-source font families when possible , use .SVG (scalable vector graphics) when possible for optimal versatility and filesize If you must design custom icons and they can\u2019t be vector / SVG, design first in the largest viewport (desktop), giving your icon the appropriate level of detail. Subsequently, scale down for smaller viewports and remove details in order to keep icons scannable and understandable. Keep icons simple and schematic. Focusing on the basic characteristics of the object. Test them with neutral users for usability, recognizability, and memorability.","title":"Best Practices"},{"location":"ux/4-9-icons/#icons-and-button-labels","text":"Icons accompanied by labels make information easier to find and scan, as long as they\u2019re placed in the right spot. Place icons according to the natural reading order. There are two important factors in an icon\u2019s location: In order for icons to serve as a visual scanning aid, users need to see them before they see the accompanying label. Place icons to the left of their labels so that users see them first. Align the icon with the label\u2019s heading, instead of centering it with the heading and body. Seeing the icon first will help users to scan the page more easily.","title":"Icons and Button Labels"},{"location":"ux/4-9-icons/#icons-in-data-tables","text":"Icons to the left of a number usually indicate the intent of the data, whereas icons to the right usually indicate the quality of the data. As with icons with button labels, the placement of icons should follow the natural reading order. There are two possibilities for icon placement: Status icons would appear at the end of the line. As seen in the example below, the user will see the subject first, then the value associated with the subject and, finally, the status of the value. If the icons themselves are the subject, then they would appear at the start of the line, and everything else would follow thereafter.","title":"Icons in Data Tables"},{"location":"ux/4-9-icons/#references","text":"Smashing Magazine; perspectives on icons https://www.smashingmagazine.com/2016/10/icons-as-part-of-a-great-user-experience The Noun Project; a comprehensive source of free and attributed icons https://thenounproject.com","title":"References"},{"location":"ux/5-1-intro/","text":"5.1 Introduction Design is the Little Things Elements. Components. Modules. We often use these words interchangeably, but all of them refer to the pieces of varying complexity that make up a design system. From the single pixel to the entire page, their consistency contributes to both usability and visual appeal. How to use this Component Library As previously noted, this playbook is not a style guide; it is intended to complement and fill gaps in style guides. As such, please: Refer to your application\u2019s style guide for your specific design standards, Work with your design and front-end teams to determine an appropriate pre-existing solution Confirm any relevant standards within the USAF brand or US government guidelines. In the absence of that standards documentation, this library provides general design guidance. Style Specificity Given the differences between specific application style guides, this component library frequently refers to page elements by the purpose they serve or their front-end (HTML) shorthand. So, instead of defining a block of copy by its specific typographic properties, for instance (font name, size, hex color, etc.), we label it as \u201cBody\u201d or \u201cH1 - Headline\u201d in reference to your specific application\u2019s styles. In the case of entirely new components, enterprise-wide updates, or emergent devices / contexts / interaction patterns not accounted for in foundational style guides, this library provides a more prescriptive design: \u201cAlpha Standard.\u201d Again, these styles should only be applied if you\u2019ve exhausted all other standards, and are primarily to demonstrate the best practices outlined in Web Design Standards. Desktop / Tablet / Mobile This component library places an increased focus on mobile (small viewport) use cases. When possible, desktop (and landscape tablet) components are shown with their behavior at the mobile breakpoint. USAF Application Style Guides USAF Branding & Trademark Licensing https://www.trademark.af.mil/About-Us/The-Air-Force-Symbol/Display-guidelines US Web Design System https://designsystem.digital.gov","title":"5.1 Introduction"},{"location":"ux/5-1-intro/#51-introduction","text":"","title":"5.1 Introduction"},{"location":"ux/5-1-intro/#design-is-the-little-things","text":"Elements. Components. Modules. We often use these words interchangeably, but all of them refer to the pieces of varying complexity that make up a design system. From the single pixel to the entire page, their consistency contributes to both usability and visual appeal.","title":"Design is the Little Things"},{"location":"ux/5-1-intro/#how-to-use-this-component-library","text":"As previously noted, this playbook is not a style guide; it is intended to complement and fill gaps in style guides. As such, please: Refer to your application\u2019s style guide for your specific design standards, Work with your design and front-end teams to determine an appropriate pre-existing solution Confirm any relevant standards within the USAF brand or US government guidelines. In the absence of that standards documentation, this library provides general design guidance.","title":"How to use this Component Library"},{"location":"ux/5-1-intro/#style-specificity","text":"Given the differences between specific application style guides, this component library frequently refers to page elements by the purpose they serve or their front-end (HTML) shorthand. So, instead of defining a block of copy by its specific typographic properties, for instance (font name, size, hex color, etc.), we label it as \u201cBody\u201d or \u201cH1 - Headline\u201d in reference to your specific application\u2019s styles. In the case of entirely new components, enterprise-wide updates, or emergent devices / contexts / interaction patterns not accounted for in foundational style guides, this library provides a more prescriptive design: \u201cAlpha Standard.\u201d Again, these styles should only be applied if you\u2019ve exhausted all other standards, and are primarily to demonstrate the best practices outlined in Web Design Standards.","title":"Style Specificity"},{"location":"ux/5-1-intro/#desktop-tablet-mobile","text":"This component library places an increased focus on mobile (small viewport) use cases. When possible, desktop (and landscape tablet) components are shown with their behavior at the mobile breakpoint.","title":"Desktop / Tablet / Mobile"},{"location":"ux/5-1-intro/#references","text":"USAF Branding & Trademark Licensing https://www.trademark.af.mil/About-Us/The-Air-Force-Symbol/Display-guidelines US Web Design System https://designsystem.digital.gov","title":"USAF Application Style Guides"},{"location":"ux/5-2-nav/","text":"5.2 Global Navigation About Global Navigation Any element that, upon interaction, moves a user through an application or site is technically a navigation element. Our focus is on those items that persist regardless of the user\u2019s location within the application: global navigation. The vast majority of global navigation exists at the top of the screen, either within or adjacent to the page header. Some global navigation exists at the left or right side of the screen, and may also behave like a \u201cdrawer\u201d of other user options. Alpha Standard The following example component illustrates the web standards outlined previously, with the practical choices that make it so. Note that the Alpha Standard below is a stylistic proposal only. The inclusion / exclusion of particular navigation items (including utility nav, search, and functional elements) is usually determined by UX designers in accordance with user needs. Task Completion . In content and layout, it first considers the user\u2019s intention. Hierarchy . The component features prioritized items that must be universally accessible, with interactivity and a search component to access everything else. Status . Design elements communicate interactivity, as well as the active state of nav items (I.e. the user\u2019s location). As reflected in the web standards, the following should be considered: a hover state to indicate interactivity, a highlighted state to indicate the currently selected option, a disabled state where applicable to indicate something is disabled. Contrast . The combination of color ratios and the spacing between elements assures scannability and distinction of critical items. Legibility . The combination of color contrast and font characteristics (font type, size, line weight) meet visual accessibility standards. Disclaimer : Please default to your application\u2019s and USAF styles; the following component standards are to be used only if those assets are not applicable or not available. Desktop Navigation Tablet Navigation Phablet Navigation Mobile Navigation References U.S. Web Design System https://designsystem.digital.gov/page-templates/#documentation-page UX Planet uxplanet.org","title":"5.2 Global Navigation"},{"location":"ux/5-2-nav/#52-global-navigation","text":"","title":"5.2 Global Navigation"},{"location":"ux/5-2-nav/#about-global-navigation","text":"Any element that, upon interaction, moves a user through an application or site is technically a navigation element. Our focus is on those items that persist regardless of the user\u2019s location within the application: global navigation. The vast majority of global navigation exists at the top of the screen, either within or adjacent to the page header. Some global navigation exists at the left or right side of the screen, and may also behave like a \u201cdrawer\u201d of other user options.","title":"About Global Navigation"},{"location":"ux/5-2-nav/#alpha-standard","text":"The following example component illustrates the web standards outlined previously, with the practical choices that make it so. Note that the Alpha Standard below is a stylistic proposal only. The inclusion / exclusion of particular navigation items (including utility nav, search, and functional elements) is usually determined by UX designers in accordance with user needs. Task Completion . In content and layout, it first considers the user\u2019s intention. Hierarchy . The component features prioritized items that must be universally accessible, with interactivity and a search component to access everything else. Status . Design elements communicate interactivity, as well as the active state of nav items (I.e. the user\u2019s location). As reflected in the web standards, the following should be considered: a hover state to indicate interactivity, a highlighted state to indicate the currently selected option, a disabled state where applicable to indicate something is disabled. Contrast . The combination of color ratios and the spacing between elements assures scannability and distinction of critical items. Legibility . The combination of color contrast and font characteristics (font type, size, line weight) meet visual accessibility standards. Disclaimer : Please default to your application\u2019s and USAF styles; the following component standards are to be used only if those assets are not applicable or not available.","title":"Alpha Standard"},{"location":"ux/5-2-nav/#desktop-navigation","text":"","title":"Desktop Navigation"},{"location":"ux/5-2-nav/#tablet-navigation","text":"","title":"Tablet Navigation"},{"location":"ux/5-2-nav/#phablet-navigation","text":"","title":"Phablet Navigation"},{"location":"ux/5-2-nav/#mobile-navigation","text":"","title":"Mobile Navigation"},{"location":"ux/5-2-nav/#references","text":"U.S. Web Design System https://designsystem.digital.gov/page-templates/#documentation-page UX Planet uxplanet.org","title":"References"},{"location":"ux/5-3-icons/","text":"5.3 Icons USAF Application Styles The following icons are an aggregate of USAF applications and labeled accordingly. When selecting new icons, choose only from a single \u201cfamily\u201d to retain consistency, or match the characteristics of your pre-existing icon set. An icon family is usually created by the same designer, and each icon will have similar complexity, line weight, repeating elements, and themes. When selecting new icons, choose only from a single family to retain consistency, or match the characteristics of your pre-existing icon set. A good practice is ensuring the icons fit within the same square, having matching line weight / complexity when compared at the same size. Alpha Standard The following example component illustrates the best practices outlined previously, with the practical choices that make it so. Clear meaning . Icon designs favor obvious over clever, communicating one- or two-word concepts in culturally established standards. Simple design . Limited visual complexity improves scannability, plus the ability to scale up and down as contexts require. Standardization . Stylistic similarities between icons (complexity, line weight, repeating elements) improve the coherence of the design system. These styles are made consistent within an icon family. Example Icon Classifications Disclaimer : Please default to USAF application styles; these component standards are to be used only if those assets are not applicable or not available.","title":"5.3 Icons"},{"location":"ux/5-3-icons/#53-icons","text":"","title":"5.3 Icons"},{"location":"ux/5-3-icons/#usaf-application-styles","text":"The following icons are an aggregate of USAF applications and labeled accordingly. When selecting new icons, choose only from a single \u201cfamily\u201d to retain consistency, or match the characteristics of your pre-existing icon set. An icon family is usually created by the same designer, and each icon will have similar complexity, line weight, repeating elements, and themes. When selecting new icons, choose only from a single family to retain consistency, or match the characteristics of your pre-existing icon set. A good practice is ensuring the icons fit within the same square, having matching line weight / complexity when compared at the same size.","title":"USAF Application Styles"},{"location":"ux/5-3-icons/#alpha-standard","text":"The following example component illustrates the best practices outlined previously, with the practical choices that make it so. Clear meaning . Icon designs favor obvious over clever, communicating one- or two-word concepts in culturally established standards. Simple design . Limited visual complexity improves scannability, plus the ability to scale up and down as contexts require. Standardization . Stylistic similarities between icons (complexity, line weight, repeating elements) improve the coherence of the design system. These styles are made consistent within an icon family.","title":"Alpha Standard"},{"location":"ux/5-3-icons/#example-icon-classifications","text":"Disclaimer : Please default to USAF application styles; these component standards are to be used only if those assets are not applicable or not available.","title":"Example Icon Classifications"},{"location":"ux/5-4-buttons/","text":"5.4 Buttons & Labels USAF Application Styles Buttons styles are specific to applications, though button behaviors should follow best practices laid out in Buttons & Controls (4.11). Machine Learning Engines Health Positive Inventory Control Alpha Standard The following example component illustrates the best practices outlined previously, with the practical choices that make it so. Obvious . By placing active text into a containing element (usually a rectangle or rounded rectangle), they follow the design standard of the web and real-world. Clear . Button labels like \u201cSubmit\u201d and \u201cLearn More\u201d communicate the action that the user is taking upon click. Feedback . Interacting with the button changes its style, and clicking it provides other feedback (like success / error messages) to clarity the user experience. Contrast . The spacing and color ratios of the element provide adequate legibility and scannability. Disclaimer : Please default to your application\u2019s and USAF styles; the following component standards are to be used only if those assets are not applicable or not available.","title":"5.4 Buttons & Labels"},{"location":"ux/5-4-buttons/#54-buttons-labels","text":"","title":"5.4 Buttons &amp; Labels"},{"location":"ux/5-4-buttons/#usaf-application-styles","text":"Buttons styles are specific to applications, though button behaviors should follow best practices laid out in Buttons & Controls (4.11).","title":"USAF Application Styles"},{"location":"ux/5-4-buttons/#machine-learning","text":"","title":"Machine Learning"},{"location":"ux/5-4-buttons/#engines-health","text":"","title":"Engines Health"},{"location":"ux/5-4-buttons/#positive-inventory-control","text":"","title":"Positive Inventory Control"},{"location":"ux/5-4-buttons/#alpha-standard","text":"The following example component illustrates the best practices outlined previously, with the practical choices that make it so. Obvious . By placing active text into a containing element (usually a rectangle or rounded rectangle), they follow the design standard of the web and real-world. Clear . Button labels like \u201cSubmit\u201d and \u201cLearn More\u201d communicate the action that the user is taking upon click. Feedback . Interacting with the button changes its style, and clicking it provides other feedback (like success / error messages) to clarity the user experience. Contrast . The spacing and color ratios of the element provide adequate legibility and scannability. Disclaimer : Please default to your application\u2019s and USAF styles; the following component standards are to be used only if those assets are not applicable or not available.","title":"Alpha Standard"},{"location":"ux/5-5-modules/","text":"5.5 Content Modules Designing for Editorial Content When layouts are particularly content-heavy (such as in the case of an article page), they may require components that support copy, images, and other editorial elements. These components are called \u201ccontent modules,\u201d and can be used individually or stacked to create long-form content. Your application will likely feature content modules specific to the style of your platform. For the sake of consistency and efficiency, first try re-purposing an existing design solution. Should one not exist within your style guide or front-end code, the following examples act as a guide for designing new components. Full-Width Content Modules Full-width content modules span the width of the viewport at any breakpoint, split and stack as the layout responds down. Particularly in the mobile viewport, these modules should follow best practices of content reordering (section 4.6) and degradation of individual elements like images, nav elements, and longer copy blocks (section 4.12) . Global Navigation (See section 5.2) Branded Header A header for major content categories (generally those items featured in top-level navigation); generally reserved for more editorial (and less functional) pages. Can support large calls-to-action that drive to elsewhere on the page, or other pages entirely. Inline Introduction / Search Combining both introductory text and a search element, this component is useful for guiding the user through long-form content (articles, FAQs, etc.) via search. Content Block: Short Form Copy A simple inline content block supporting short-form copy, branded images, and a call-to-action. Content Block: Video A simple inline content block supporting quoted text and a video player; the video can play either inline or within a modal. Content Block: Brand Call Out A simple inline content block supporting brand taglines, images, and a call-to-action. Content Block: Headline and Image This variant on Editorial Block A introduces a headline element; useful for linking to articles and major content sections, or employing near the top of the layout in lieu of a branded header. Content Block: Number/Bullet List Another variant on Editorial Block A refactors the copy to support a numbered or bulleted list. Inline links provide additional details without disrupting the sequence of content. Content Block: Image Carousel Appropriate for galleries of five or fewer images, this inline carousel can rotate automatically after a few seconds, or based on user click. Content Block: Data Visualization A chart, table, or graph \u2013 in part or whole \u2013 featuring either inline interactivity or a call-to-action linking to the interactive data. Dependent upon your application, this module may exist within a summary article or on an \u201cdashboard\u201d view. Content Block: Data Callout \u201cBig idea\u201d callouts focus on important, singular data points and support headlines, body copy, and branded images; useful for providing an executive view into data without overwhelming with data visualizations. Global Footer (see section 5.2) Half-Width (2-Up) Content Modules Half-width (or 2-up) content modules split the viewport down the middle, and are useful for shorter-form content, callouts, and links to other pages / sections. They are to be avoided in the mobile viewport, were instead they span full-width. Copy 2-Up This simple copy module supports short-form text and a call-to action; given its visual dominance it is appropriate for content of lower priority. Image 2-Up A simple static element supporting an image, caption / body copy, and call-to-action. Can also support inline animation or video. Data 2-Up So named because of its half-width nature in desktop view, this component supports a data visualization preview and caption, though most often links to a full scale data display.","title":"5.5 Content Modules"},{"location":"ux/5-5-modules/#55-content-modules","text":"","title":"5.5 Content Modules"},{"location":"ux/5-5-modules/#designing-for-editorial-content","text":"When layouts are particularly content-heavy (such as in the case of an article page), they may require components that support copy, images, and other editorial elements. These components are called \u201ccontent modules,\u201d and can be used individually or stacked to create long-form content. Your application will likely feature content modules specific to the style of your platform. For the sake of consistency and efficiency, first try re-purposing an existing design solution. Should one not exist within your style guide or front-end code, the following examples act as a guide for designing new components.","title":"Designing for Editorial Content"},{"location":"ux/5-5-modules/#full-width-content-modules","text":"Full-width content modules span the width of the viewport at any breakpoint, split and stack as the layout responds down. Particularly in the mobile viewport, these modules should follow best practices of content reordering (section 4.6) and degradation of individual elements like images, nav elements, and longer copy blocks (section 4.12) .","title":"Full-Width Content Modules"},{"location":"ux/5-5-modules/#global-navigation-see-section-52","text":"","title":"Global Navigation (See section 5.2)"},{"location":"ux/5-5-modules/#branded-header","text":"A header for major content categories (generally those items featured in top-level navigation); generally reserved for more editorial (and less functional) pages. Can support large calls-to-action that drive to elsewhere on the page, or other pages entirely.","title":"Branded Header"},{"location":"ux/5-5-modules/#inline-introduction-search","text":"Combining both introductory text and a search element, this component is useful for guiding the user through long-form content (articles, FAQs, etc.) via search.","title":"Inline Introduction / Search"},{"location":"ux/5-5-modules/#content-block-short-form-copy","text":"A simple inline content block supporting short-form copy, branded images, and a call-to-action.","title":"Content Block: Short Form Copy"},{"location":"ux/5-5-modules/#content-block-video","text":"A simple inline content block supporting quoted text and a video player; the video can play either inline or within a modal.","title":"Content Block: Video"},{"location":"ux/5-5-modules/#content-block-brand-call-out","text":"A simple inline content block supporting brand taglines, images, and a call-to-action.","title":"Content Block: Brand Call Out"},{"location":"ux/5-5-modules/#content-block-headline-and-image","text":"This variant on Editorial Block A introduces a headline element; useful for linking to articles and major content sections, or employing near the top of the layout in lieu of a branded header.","title":"Content Block: Headline and Image"},{"location":"ux/5-5-modules/#content-block-numberbullet-list","text":"Another variant on Editorial Block A refactors the copy to support a numbered or bulleted list. Inline links provide additional details without disrupting the sequence of content.","title":"Content Block: Number/Bullet List"},{"location":"ux/5-5-modules/#content-block-image-carousel","text":"Appropriate for galleries of five or fewer images, this inline carousel can rotate automatically after a few seconds, or based on user click.","title":"Content Block: Image Carousel"},{"location":"ux/5-5-modules/#content-block-data-visualization","text":"A chart, table, or graph \u2013 in part or whole \u2013 featuring either inline interactivity or a call-to-action linking to the interactive data. Dependent upon your application, this module may exist within a summary article or on an \u201cdashboard\u201d view.","title":"Content Block: Data Visualization"},{"location":"ux/5-5-modules/#content-block-data-callout","text":"\u201cBig idea\u201d callouts focus on important, singular data points and support headlines, body copy, and branded images; useful for providing an executive view into data without overwhelming with data visualizations.","title":"Content Block: Data Callout"},{"location":"ux/5-5-modules/#global-footer-see-section-52","text":"","title":"Global Footer (see section 5.2)"},{"location":"ux/5-5-modules/#half-width-2-up-content-modules","text":"Half-width (or 2-up) content modules split the viewport down the middle, and are useful for shorter-form content, callouts, and links to other pages / sections. They are to be avoided in the mobile viewport, were instead they span full-width.","title":"Half-Width (2-Up) Content Modules"},{"location":"ux/5-5-modules/#copy-2-up","text":"This simple copy module supports short-form text and a call-to action; given its visual dominance it is appropriate for content of lower priority.","title":"Copy 2-Up"},{"location":"ux/5-5-modules/#image-2-up","text":"A simple static element supporting an image, caption / body copy, and call-to-action. Can also support inline animation or video.","title":"Image 2-Up"},{"location":"ux/5-5-modules/#data-2-up","text":"So named because of its half-width nature in desktop view, this component supports a data visualization preview and caption, though most often links to a full scale data display.","title":"Data 2-Up"},{"location":"ux/5-6-alerts/","text":"5.6 Alerts & Messaging USAF Application Styles Alerts & messaging are specific to applications, though their triggers, appearance, and behaviors should follow best practices. Machine Learning Engines Health Management Log Common Operating Picture Positive Inventory Control Alpha Standard The following example component illustrates the best practices outlined previously, with the practical choices that make it so. Clear . Alerts state in clear language, and with obvious color cues that they are positive / negative / neutral, the reason for the alert, and the action required of the user in order to resolve it. Consistent . Alerts follow web or application-standard patterns that are repeating and predictable. If a user were to perform the same triggering action twice, they would receive the same alert twice. Actionable . Alerts & messages offer clear next steps to resolve or address them. When appropriate to the context, alter text offers inline links, or anchor links to the offending component. Disclaimer : Please default to your application\u2019s and USAF styles; the following component standards are to be used only if those assets are not applicable or not available Reference Alerts U.S. Web Design System https://designsystem.digital.gov/components/alerts","title":"5.6 Alerts & Messaging"},{"location":"ux/5-6-alerts/#56-alerts-messaging","text":"","title":"5.6 Alerts &amp; Messaging"},{"location":"ux/5-6-alerts/#usaf-application-styles","text":"Alerts & messaging are specific to applications, though their triggers, appearance, and behaviors should follow best practices.","title":"USAF Application Styles"},{"location":"ux/5-6-alerts/#machine-learning","text":"","title":"Machine Learning"},{"location":"ux/5-6-alerts/#engines-health-management","text":"","title":"Engines Health Management"},{"location":"ux/5-6-alerts/#log-common-operating-picture","text":"","title":"Log Common Operating Picture"},{"location":"ux/5-6-alerts/#positive-inventory-control","text":"","title":"Positive Inventory Control"},{"location":"ux/5-6-alerts/#alpha-standard","text":"The following example component illustrates the best practices outlined previously, with the practical choices that make it so. Clear . Alerts state in clear language, and with obvious color cues that they are positive / negative / neutral, the reason for the alert, and the action required of the user in order to resolve it. Consistent . Alerts follow web or application-standard patterns that are repeating and predictable. If a user were to perform the same triggering action twice, they would receive the same alert twice. Actionable . Alerts & messages offer clear next steps to resolve or address them. When appropriate to the context, alter text offers inline links, or anchor links to the offending component. Disclaimer : Please default to your application\u2019s and USAF styles; the following component standards are to be used only if those assets are not applicable or not available","title":"Alpha Standard"},{"location":"ux/5-6-alerts/#reference","text":"Alerts U.S. Web Design System https://designsystem.digital.gov/components/alerts","title":"Reference"},{"location":"ux/5-7-forms/","text":"5.7 Forms & Controls USAF Application Styles Form controls are specific to applications, though their triggers, appearance, and behaviors should follow best practices ( see Buttons & Controls in section 4.11 ). Note that many form controls are defined by the user\u2019s browser, and thus should be presumed to default to that design. Engines Health Management Positive Inventory Control Alpha Standard The following example component illustrates the best practices outlined previously, with the practical choices that make it so. Looks interactive . Controls are differentiated from \u201cpassive\u201d content by their label, form factor, and/or use of the design system\u2019s call-to-action color. Proximity . Controls are placed logically near the form or element they are intended to affect. For instance, a \u201cSUBMIT\u201d button lives at the bottom of the related text field. Predictable . Context, form label, and control label give the user a clear understanding of what will occur when they\u2019ve interacted with the component. Disclaimer : Please default to your application\u2019s and USAF styles; the following component standards are to be used only if those assets are not applicable or not available","title":"5.7 Forms & Controls"},{"location":"ux/5-7-forms/#57-forms-controls","text":"","title":"5.7 Forms &amp; Controls"},{"location":"ux/5-7-forms/#usaf-application-styles","text":"Form controls are specific to applications, though their triggers, appearance, and behaviors should follow best practices ( see Buttons & Controls in section 4.11 ). Note that many form controls are defined by the user\u2019s browser, and thus should be presumed to default to that design.","title":"USAF Application Styles"},{"location":"ux/5-7-forms/#engines-health-management","text":"","title":"Engines Health Management"},{"location":"ux/5-7-forms/#positive-inventory-control","text":"","title":"Positive Inventory Control"},{"location":"ux/5-7-forms/#alpha-standard","text":"The following example component illustrates the best practices outlined previously, with the practical choices that make it so. Looks interactive . Controls are differentiated from \u201cpassive\u201d content by their label, form factor, and/or use of the design system\u2019s call-to-action color. Proximity . Controls are placed logically near the form or element they are intended to affect. For instance, a \u201cSUBMIT\u201d button lives at the bottom of the related text field. Predictable . Context, form label, and control label give the user a clear understanding of what will occur when they\u2019ve interacted with the component. Disclaimer : Please default to your application\u2019s and USAF styles; the following component standards are to be used only if those assets are not applicable or not available","title":"Alpha Standard"},{"location":"ux/5-8-visualizations/","text":"5.8 Visualizations USAF Application Styles The styles of visualizations are specific to applications, though their appearance and behaviors should follow best practices. In the absence of a style guide, see the bottom of this section for common data visualization types, plus application-agnostic styles. Log Common Operating Picture Positive Inventory Control Machine Learning Alpha Standard Data visualizations should, in their very design, do most of the work of making sense of the data being displayed. Dominant sizes, color cues, and labels should provide the user the orientation and clarity they need to understand data at a glance. Fundamentals of Data Visualization Simplify the data . The intention of a data visualization is to reduce the overall complexity of what is being shared. The visualization should be selected and executed in such a way that does the majority of the mental legwork for the audience. Focus on a single story . The visualization should allow the viewer to clearly understanding the situation: \u201cthings are trending well,\u201d or \u201cthis inventory item is low,\u201d for instance. Sometimes, this story is user-selected, such as when they sort columns by different data characteristcs (status, low-to-high, etc.). Express data accurately . In telling the single story, it can be tempting to artificially increase the size of a data element \u2013 which actually distorts the real picture of it. Try to employ techniques that draw the user\u2019s eye without changing the visual area of the data on display. Data Visualizations As the most common data visualization type in USAF applications, tables warrant particular attention. Even as relatively dense displays, certain visual design choices can aid the user in making sense of the table, and focusing on particular elements. Bold and emphasize key data points and outliers, or highlight these particular cells. This improves the scannability of the table, and draws attention to information that may require action. Use standard color conventions to communicate additional meaning. In financial data, for instance, black numbers indicate a gain, and red numbers indicate a loss. Generally, green indicates a positive trend, and red indicates a negative one. Minimize \u201cchart junk.\u201d Chart junk refers to the design elements that are everything except the data \u2013 separating lines, containing elements, grids, etc. They should be applied as light-handedly as possible, to create an obvious contrast between the subject of the visualization and the container in which it lives. Caption: You can place copy here to add further context to your charts or graphs. References Catalog of Data Visualizations https://datavizcatalogue.com Data Visualization Best Practices https://www.promptcloud.com/blog/design-principles-for-effective-data-visualization","title":"5.8 Visualizations"},{"location":"ux/5-8-visualizations/#58-visualizations","text":"","title":"5.8 Visualizations"},{"location":"ux/5-8-visualizations/#usaf-application-styles","text":"The styles of visualizations are specific to applications, though their appearance and behaviors should follow best practices. In the absence of a style guide, see the bottom of this section for common data visualization types, plus application-agnostic styles.","title":"USAF Application Styles"},{"location":"ux/5-8-visualizations/#log-common-operating-picture","text":"","title":"Log Common Operating Picture"},{"location":"ux/5-8-visualizations/#positive-inventory-control","text":"","title":"Positive Inventory Control"},{"location":"ux/5-8-visualizations/#machine-learning","text":"","title":"Machine Learning"},{"location":"ux/5-8-visualizations/#alpha-standard","text":"Data visualizations should, in their very design, do most of the work of making sense of the data being displayed. Dominant sizes, color cues, and labels should provide the user the orientation and clarity they need to understand data at a glance.","title":"Alpha Standard"},{"location":"ux/5-8-visualizations/#fundamentals-of-data-visualization","text":"Simplify the data . The intention of a data visualization is to reduce the overall complexity of what is being shared. The visualization should be selected and executed in such a way that does the majority of the mental legwork for the audience. Focus on a single story . The visualization should allow the viewer to clearly understanding the situation: \u201cthings are trending well,\u201d or \u201cthis inventory item is low,\u201d for instance. Sometimes, this story is user-selected, such as when they sort columns by different data characteristcs (status, low-to-high, etc.). Express data accurately . In telling the single story, it can be tempting to artificially increase the size of a data element \u2013 which actually distorts the real picture of it. Try to employ techniques that draw the user\u2019s eye without changing the visual area of the data on display.","title":"Fundamentals of Data Visualization"},{"location":"ux/5-8-visualizations/#data-visualizations","text":"As the most common data visualization type in USAF applications, tables warrant particular attention. Even as relatively dense displays, certain visual design choices can aid the user in making sense of the table, and focusing on particular elements. Bold and emphasize key data points and outliers, or highlight these particular cells. This improves the scannability of the table, and draws attention to information that may require action. Use standard color conventions to communicate additional meaning. In financial data, for instance, black numbers indicate a gain, and red numbers indicate a loss. Generally, green indicates a positive trend, and red indicates a negative one. Minimize \u201cchart junk.\u201d Chart junk refers to the design elements that are everything except the data \u2013 separating lines, containing elements, grids, etc. They should be applied as light-handedly as possible, to create an obvious contrast between the subject of the visualization and the container in which it lives. Caption: You can place copy here to add further context to your charts or graphs.","title":"Data Visualizations"},{"location":"ux/5-8-visualizations/#references","text":"Catalog of Data Visualizations https://datavizcatalogue.com Data Visualization Best Practices https://www.promptcloud.com/blog/design-principles-for-effective-data-visualization","title":"References"},{"location":"ux/5-9-mobile/","text":"5.9 Key Mobile Components Mobile Requires Unique UI The small viewport and native operating systems of mobile devices require unique design considerations and, accordingly, unique UI elements. This section outlines the key components that differ from tablet / desktop, and their most common applications. For additional guidance on the theory and practice of designing for mobile, refer to elsewhere in this playbook: Key Mobile Standards and Content Modules . Considerations & Best Practices As a reminder, the core consideration of the mobile context is that the device is in-hand and the user is on-the-go . When translating desktop designs to mobile, don\u2019t just miniaturize it \u2013 consider how the device and context should influence changes. Additionally, mobile designs should Hide and reveal content. Remove unnecessary ornamentation. Embrace scrolling. Be tested vigorously! Navigation One of the most common differences in mobile UI is the navigation, which is most commonly collapsed into a three-line icon nicknamed the \u201chamburger menu.\u201d While the hamburger treatment may wane in popularity, its intent to minimize the navigation into an interactive icon remains an important mobile requirement. Other Mobile-Specific Components Certain mobile-specific elements satisfy the best practices of small viewport design, which other leverage the functionality of the phone itself. Below are common examples. Expand and Collapse More Button Call Button Share Full-screen Components Given the small viewport, it is more common in mobile designs to completely overtake the screen with modals, forms, alerts, and error messages that must be dismissed or completed by the user. These should be used sparingly, but are useful for focusing the user\u2019s attention. Accommodating OS Native Elements When designing components, consider any native OS elements that may be triggered by interacting with the component. For instance, an open text field will trigger the appearance of the native keyboard, potentially obscuring the component and resulting in a frustrating user experience. Alpha Standard The following mobile components illustrate the best practices outlined previously, with the practical choices that make it so. Disclaimer : Please default to USAF application styles; these component standards are to be used only if those assets are not applicable or not available. Closed and Open Hamburger Menu Headers Content Block and Images Media Charts and Graphs Alerts & Messaging Tables Translated from Desktop to Mobile References iOS Design Standards https://developer.apple.com/design/human-interface-guidelines/ios/overview/themes Android Design Standards https://developer.android.com/design/handhelds","title":"5.9 Key Mobile Components"},{"location":"ux/5-9-mobile/#59-key-mobile-components","text":"","title":"5.9 Key Mobile Components"},{"location":"ux/5-9-mobile/#mobile-requires-unique-ui","text":"The small viewport and native operating systems of mobile devices require unique design considerations and, accordingly, unique UI elements. This section outlines the key components that differ from tablet / desktop, and their most common applications. For additional guidance on the theory and practice of designing for mobile, refer to elsewhere in this playbook: Key Mobile Standards and Content Modules .","title":"Mobile Requires Unique UI"},{"location":"ux/5-9-mobile/#considerations-best-practices","text":"As a reminder, the core consideration of the mobile context is that the device is in-hand and the user is on-the-go . When translating desktop designs to mobile, don\u2019t just miniaturize it \u2013 consider how the device and context should influence changes. Additionally, mobile designs should Hide and reveal content. Remove unnecessary ornamentation. Embrace scrolling. Be tested vigorously!","title":"Considerations &amp; Best Practices"},{"location":"ux/5-9-mobile/#navigation","text":"One of the most common differences in mobile UI is the navigation, which is most commonly collapsed into a three-line icon nicknamed the \u201chamburger menu.\u201d While the hamburger treatment may wane in popularity, its intent to minimize the navigation into an interactive icon remains an important mobile requirement.","title":"Navigation"},{"location":"ux/5-9-mobile/#other-mobile-specific-components","text":"Certain mobile-specific elements satisfy the best practices of small viewport design, which other leverage the functionality of the phone itself. Below are common examples.","title":"Other Mobile-Specific Components"},{"location":"ux/5-9-mobile/#expand-and-collapse","text":"","title":"Expand and Collapse"},{"location":"ux/5-9-mobile/#more-button","text":"","title":"More Button"},{"location":"ux/5-9-mobile/#call-button","text":"","title":"Call Button"},{"location":"ux/5-9-mobile/#share","text":"","title":"Share"},{"location":"ux/5-9-mobile/#full-screen-components","text":"Given the small viewport, it is more common in mobile designs to completely overtake the screen with modals, forms, alerts, and error messages that must be dismissed or completed by the user. These should be used sparingly, but are useful for focusing the user\u2019s attention.","title":"Full-screen Components"},{"location":"ux/5-9-mobile/#accommodating-os-native-elements","text":"When designing components, consider any native OS elements that may be triggered by interacting with the component. For instance, an open text field will trigger the appearance of the native keyboard, potentially obscuring the component and resulting in a frustrating user experience.","title":"Accommodating OS Native Elements"},{"location":"ux/5-9-mobile/#alpha-standard","text":"The following mobile components illustrate the best practices outlined previously, with the practical choices that make it so. Disclaimer : Please default to USAF application styles; these component standards are to be used only if those assets are not applicable or not available.","title":"Alpha Standard"},{"location":"ux/5-9-mobile/#closed-and-open-hamburger-menu","text":"","title":"Closed and Open Hamburger Menu"},{"location":"ux/5-9-mobile/#headers","text":"","title":"Headers"},{"location":"ux/5-9-mobile/#content-block-and-images","text":"","title":"Content Block and Images"},{"location":"ux/5-9-mobile/#media","text":"","title":"Media"},{"location":"ux/5-9-mobile/#charts-and-graphs","text":"","title":"Charts and Graphs"},{"location":"ux/5-9-mobile/#alerts-messaging","text":"","title":"Alerts &amp; Messaging"},{"location":"ux/5-9-mobile/#tables-translated-from-desktop-to-mobile","text":"","title":"Tables Translated from Desktop to Mobile"},{"location":"ux/5-9-mobile/#references","text":"iOS Design Standards https://developer.apple.com/design/human-interface-guidelines/ios/overview/themes Android Design Standards https://developer.android.com/design/handhelds","title":"References"},{"location":"ux/6-1-appendix/","text":"6.1 Additional Resources The following is a list of additional excellent sources for learning more about user experience. Online resources usability.gov Nielsen Norman Group The Interaction Design Foundation UXRESOURCES.DESIGN Inside Design by InVision Courses Interaction Design Specialization \u2013 Coursera User Experience (UX): The Ultimate Guide to Usability and UX \u2013 Udemy Books The Elements of User Experience: User-Centered Design for the Web and Beyond About Face: The Essentials of Interaction Design Information Architecture: For the Web and Beyond Don\u2019t Make Me Think Rocket Surgery Made Easy UX for Beginners: A Crash Course in 100 Short Lessons Observing the User Experience: A Practitioner's Guide to User Research Communicating Design: Developing Web Site Documentation for Design and Planning The User Experience Team of One: A Research and Design Survival Guide","title":"6.1 Additional Resources"},{"location":"ux/6-1-appendix/#61-additional-resources","text":"The following is a list of additional excellent sources for learning more about user experience.","title":"6.1 Additional Resources"},{"location":"ux/6-1-appendix/#online-resources","text":"usability.gov Nielsen Norman Group The Interaction Design Foundation UXRESOURCES.DESIGN Inside Design by InVision","title":"Online resources"},{"location":"ux/6-1-appendix/#courses","text":"Interaction Design Specialization \u2013 Coursera User Experience (UX): The Ultimate Guide to Usability and UX \u2013 Udemy","title":"Courses"},{"location":"ux/6-1-appendix/#books","text":"The Elements of User Experience: User-Centered Design for the Web and Beyond About Face: The Essentials of Interaction Design Information Architecture: For the Web and Beyond Don\u2019t Make Me Think Rocket Surgery Made Easy UX for Beginners: A Crash Course in 100 Short Lessons Observing the User Experience: A Practitioner's Guide to User Research Communicating Design: Developing Web Site Documentation for Design and Planning The User Experience Team of One: A Research and Design Survival Guide","title":"Books"},{"location":"ux/6-2-layouts/","text":"6.2 Additional Standard Layouts Bringing Components Together The following examples show full-page desktop and mobile layouts of the Alpha Standard design system. This is intended to further demonstrate design best practices, as well as provide a tangible example of the stacking relationship of responsive components. As with all examples in this playbook, please first refer to your specific application\u2019s style guide","title":"6.2 Alpha Standard Layouts"},{"location":"ux/6-2-layouts/#62-additional-standard-layouts","text":"","title":"6.2 Additional Standard Layouts"},{"location":"ux/6-2-layouts/#bringing-components-together","text":"The following examples show full-page desktop and mobile layouts of the Alpha Standard design system. This is intended to further demonstrate design best practices, as well as provide a tangible example of the stacking relationship of responsive components. As with all examples in this playbook, please first refer to your specific application\u2019s style guide","title":"Bringing Components Together"}]}